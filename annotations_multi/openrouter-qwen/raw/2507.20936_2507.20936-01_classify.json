{
  "timestamp": "2026-02-19T11:47:41.488636+00:00",
  "paper_id": "2507.20936",
  "claim_id": "2507.20936-01",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2507.20936\nTitle: Dissecting Persona-Driven Reasoning via Activation Patching\nFull text:\n                 Dissecting Persona-Driven Reasoning in Language Models\n                                   via Activation Patching\n\n\n                                Ansh Poonia†, Maeghal Jain†\n                                                †Independent\n                             {pooniaansh11, maeghaljain}@gmail.com\n\n\n\n\n                          Abstract                       identifying \"correct letter heads\" in a 70B Chin-\n                                                                           chilla model-attention heads that track answer sym-\n                 Large language models (LLMs) exhibit remark-       bols and promote the correct choice based on po-\n                   able versatility in adopting diverse personas. In        sitional order. Wiegreffe et al. (2025) examined\n                     this study, we examine how assigning a per-2025                                            how successful models implement symbol binding\n                 sona influences a model’s reasoning on an ob-\n                                                                    in formatted MCQA using vocabulary projection                     jective task. Using activation patching, we take\n                                                       and activation patching, and Li and Gao (2025)                  a first step toward understanding how key com-Sep\n                 ponents of the model encode persona-specific       analyzed anchored positional bias in the GPT-2\n                   information. Our findings reveal that the early        family, showing that models consistently favor the21\n                 Multi-Layer Perceptron (MLP) layers attend          first option (’A’). Building on these interpretability\n                  not only to the syntactic structure of the input        techniques, we ask whether similar internal circuits\n                  but also process its semantic content. These                                                                     also govern how personas steer a model’s reasoning\n                    layers transform persona tokens into richer rep-\n                                                        and potentially introduce social bias.\n                    resentations, which are then used by the middle\n                                                               This study takes a step toward bridging the gap                Multi-Head Attention (MHA) layers to shape[cs.LG]\n                   the model’s output. Additionally, we identify      between surface-level observations of persona ef-\n                    specific attention heads that disproportionately        fects and the underlying mechanisms that produce\n                   attend to racial and color-based identities.1          them. We investigate the roles of key model com-\n                                                            ponents namely, Multi-Layer Perceptron (MLP)\n          1  Introduction                                    layers, Multi-Head Attention (MHA) layers, and\n                                                                    individual attention heads in shaping the reasoning\n            Recent advances in large language models (LLMs)\n                                                                           shifts induced by persona assignments. Using acti-\n            have demonstrated their striking ability to adopt a\n                                                                 vation patching, we probe the internal circuitry of\n           wide range of personas, enabling context-sensitive\n                                           LLMs to trace the origins of persona-driven varia-\n            and tailored responses (Serapio-García et al., 2023,\n                                                                     tion in objective tasks. Our findings challenge the\n           Zhang et al., 2024, Joshi et al., 2024, Sun et al.,\n                                                                  prevailing assumption that early MLP layers are\n             2025). However, studies such as those by Salewski\n                                                          concerned solely with syntactic processing. We\n               et al., 2023, Deshpande et al., 2023, Gupta et al.,\n                                                   show that these layers also encode semantic fea-arXiv:2507.20936v2       2024, Zheng et al., 2024 show that persona as-                                                                       tures related to persona. Furthermore, we identify a\n            signment can significantly influence reasoning and,\n                                                                small number of attention heads that disproportion-\n              in some cases, amplify underlying social biases.\n                                                                    ately focus on tokens associated with race-based\n           While these works focus on identifying and quanti-\n                                                            persona cues.  Although our work is limited to\n             fying such effects, they do not examine the causal\n                                                            uncovering the origin of persona-driven behavior,\n           mechanisms within a pre-trained language model\n                                                                                               it contributes to a deeper understanding of LLMs\n          (PLM) that give rise to them.\n                                                        and lays groundwork for future efforts to mitigate\n               Mechanistic interpretability provides framework                                                               deep-seated biases in these systems.\n              for uncovering the causal mechanisms by which\n            language models carry out specific tasks. Lieberum                                                 2  Experimental Setup\n                et al. (2023) introduced this approach in the context\n             of multiple-choice question answering (MCQA),   2.1  Dataset Details\n\n                                        We chose the MMLU dataset (Hendrycks et al.,                1Code and some  additional  results  are  available  at\n                https://github.com/anshpoonia/Persona-Driven-Reasoning     2021)  for  this  study, which contains 14,024\n\nmultiple-choice questions spanning 57 subjects.             good\n                                                                                                                       bright\nWe selected this dataset for two main reasons. First,              sharp\n                                                                                                                             intelligent\nthe objective, multiple-choice format allowed us to              Asian\nfocus on a fixed set of four answer tokens, giving               AfricanWhite\nus a well-defined target. Second, the wide range                      Identity   BrownIndian\nof subject areas helped reduce domain-specific or               stupid\n                                                                                                      Black\npersona-driven biases. The identities or personas2              Yellow\nwe examined in our study fall into four broad cate-                Britishdumb                                                                                             Race-based\n                                                                                                                                  dull                                                                                                     Color-basedPositive                                                                                                                                                                                                                                                                                                                                                      attributesgories: racial identities, color-based identities, and                                                                                                                                                                                                                                                                                      Negative                                                                                                                                                                                                                                                                                                                                                       attributes                                                                                           bad\nidentities defined by positive or negative attributes;                            0.015      0.010      0.005      0.000      0.005      0.010\n                                                                                                                                  Avg. Probability Difference\ndetails of each can be found in the Appendix A.\nTo maintain consistency and minimize variance,    Figure 1: Average difference in the probability of the\nwe used student as a gender-neutral subject across    correct token for each identity, relative to the base\nall defined identities. For instance: Asian student,    prompt.\nwhite student, good student, etc.\n\n                                                      calculated the probability of the next token, which,2.2  Model and Prompt\n                                          by design, corresponds to the selected answer for\nOur primary investigation was conducted using the                                                    the given question. This process was repeated for\nLlama 3.2 1B Instruct (Meta, 2024b) model to ac-                                                                 all 16 identities, and also the base identity.\ncommodate our computational constraints. We sup-                                           Our main focus is the change in the probability\nplement these main findings with additional results                                                     of the correct token for each persona relative to the\nfrom experiments on the Llama 3.2 3B Instruct                                                  base identity, as shown in Figure 1. This highlights\n(Meta, 2024b) and Qwen 2.5 1.5B Instruct (Yang                                                             shifts in reasoning attributable to persona alone. In\net al., 2025). Compact size of these models makes                                          some cases, the differences in probability followed\nit well-suited for efficient experimentation, while                                                        patterns that appeared to have a semantic basis. For\nstill delivering strong performance relative to other                                                       instance, the negatively attributed student persona\nopen-source models in their class. Our methods                                                performed significantly worse than those described\nare scalable and can be extended to larger models                                                with positive attributes, having an average proba-\nwith sufficient computational resources and minor                                                            bility difference of -0.0027 (T = 11.7, p < 0.001).\nadjustments. The Instruct variant of the models                                                   In contrast, the results for racially or color-coded\nalso permits the use of system prompts3, allowing                                                personas were less consistent, and no definitive\nus to specify the identity the model should adopt in                                                 conclusion could be drawn about whether the pat-\nits responses. A standard system prompt serves as                                                       terns reflect stereotypical associations. A similar\nthe base for each question, enabling identity shifts                                                    trend was observed when examining probability\nby modifying only two tokens in the entire prompt:                                                     differences across identities for other models, see\njust one token distinguishes each identity. We used                                             Appendix C for details. Overall, our results suggest\nthe prompt structure defined by Meta and Qwen                                                          that the model’s reasoning ability varies even with\nteam for MMLU dataset (Meta, 2024a), with the                                             minimal changes to the persona being imitated.\naddition of the system prompt, see Appendix B.\n                                       4  Interpretability Investigation\n3  Persona Evaluation\n                                                    4.1  Methods\nWe computed model outputs using zero-shot\n                                We focus on activation patching, also referred to\nprompts to isolate the variation introduced solely\n                                                     as Resample Ablation, or Causal Mediation Analy-\nby changes in the persona token, avoiding any influ-\n                                                            sis (Vig et al., 2020, Meng et al., 2022), to under-\nence from patterns introduced by few-shot prompt-\n                                                  stand the influence of individual components on\ning. This also reduced the length of each prompt, al-\n                                                      the model’s selection of the correct answer. Specifi-\nlowing for faster computation. For each prompt, we\n                                                              cally, we employ \"de-noising\" variant of activation\n   2The terms persona and identity have been used inter-    patching, where the activation of a component from\nchangeably in this work.                              a corrupted run is replaced with the correspond-\n   3System prompts are instructions given to the AI before\n                                                  ing activation from a clean run (Heimersheim andany user input. They define the AI’s behavior, role, and re-\nsponse style throughout an interaction.                  Nanda, 2024). The clean and corrupted inputs are\n\n 1                                       1\n\n 2                                       2                                                                                                                            0.2\n\n\n 3                                       3\n\n\n\n\n 4                                       4\n\n\n\n\n 5                                       5\n\n 6                                       6                                                                                                                            0.1\n\n\n\n\n 7                                       7\n\n\n\n\n 8                                       8   Layers                                                                                                                                                                                                                                            Layers\n  MLP9                                                                                                                    MHA9                                                                                                                            0.0\n\n   10                                                                               10\n\n\n   11                                                                               11\n\n\n   12                                                                               12\n\n                                                                                                                                                                                                                                                                                     0.1\n   13                                                                               13\n\n\n   14                                                                               14\n\n\n   15                                                                               15\n\n   16                                                                               16                                                                                                                             0.2\n                             -bad             0.1 Average0.0      0.1              -bad                                                                        -bad         0.0  Average0.1                                                           -bad                 -Brown -sharp -British -White  -Indian -Asian -Yellow -Black                                                             -Brown-sharp-British-White                                                -Indian -Asian-Yellow -Black\n Asian  helpful Asian  White  goodIndian  good African  helpful  dumb                                   Asian helpful Asian White  goodIndian goodAfrican helpful  dumb\n\n            MLP layer patching                       MHA layer patching\n\nFigure 2: Relative logit difference (∆r) when MLP layer (left) and MHA layer (right) is patched in Llama 1B model.\nAccompanying bar chart shows the average ∆r across identity pairs.\n\n\nconstructed using Symmetric Token Replacement,    lated contribution of the component to the output.\na technique in which only one or a few tokens   The indirect effect captures the influence the com-\nare altered (Meng et al., 2022, Wang et al., 2023).   ponent has via the behavior of later layers and is\nThis approach doesn’t throw the model’s internal   computed by subtracting the direct effect from the\nstate out-of-distribution and preserves the syntactic    total effect of patching the component. The direct\nstructure of the input (Zhang and Nanda, 2024).    effect of a given component can be measured by\nFor each experiment, we select a pair of personas    subtracting its output from the residual stream be-\nto generate the clean (ID1) and corrupted (ID2)    fore the final-layer norm in the corrupt run, and\nprompts. A total of ten persona pairs were chosen    adding the output of that component from the clean\nkeeping computational constraints in mind; details    run. This preserves the indirect effect of the com-\nare provided in the Appendix D. Care was taken to   ponent and only alters its direct effect. Together,\nbalance pairings identities both within and across    these effects help characterize the role the compo-\ncategories to ensure reliable results. Pairings with    nent plays in the processing of input information.\na base identity were also included for comparison.\n                                                    4.3  MetricsFor each pair, we divide the full set of questions\ninto four subsets, Appendix E. From these, we se-   To quantify the impact of patching, we use two met-\nlect the subset in which the first persona (ID1)    rics. First, we check whether patching causes the\nanswers correctly while the second persona (ID2)    logit (l) of the correct answer to become the highest\nanswers incorrectly. In each such pair of prompts,   among all four options. Second, we measure the\nthe only difference lies in the token representing    relative logit difference (∆r), i.e., change in the\nthe persona. As a result, any change in the logit    logit of the correct answer relative to the change in\nof the correct answer after patching reflects the    the mean logit across all options.\ninfluence of the component (and its downstream ef-\nfects) on how the model processes persona-related    ∆r = {lcorrect(P) −lcorrect(C)}\ninformation.\n                                               −{µ(lABCD(P)) −µ(lABCD(C))}\n\n4.2  Effects\n                                                   Here, l∗(P) is the logit from patched run and\nThe impact of patching on the model’s output can   l∗(C) from corrupt run, and µ is mean function.\nbe broken down into direct and indirect effects  We use this relative metric rather than an absolute\n(Pearl, 2001). The direct effect measures the iso-   one because some components may support the\n\n                                                                   0.2               1\n                                                                                                                 2\n                                                                   0.0               3\n                                                                                                                 4\n                                                                    0.2              5                                                                                               0.1\n  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16                            6\n                 MLP Layers                                                                                                                           Layers 78                                                                                               0.0\n                                                                                                                     MHA 109\nFigure 3: Average ∆r when only direct component of a            11                                                                                                0.1\nMLP layer is patched.                                                                       1213\n                                                                                                                14\n                                                                                                                15\n                                                                                                                16\n                                                                                                                     1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32\ncorrect answer not by increasing its logit directly,                                                    Attention Heads\nbut by decreasing the logits of incorrect options.                                                      Figure 4: Average ∆r for patching individual attention\nAn absolute measure, like simple logit difference,    heads.\nwould overlook such cases and only highlight com-\nponents with large magnitude effects on the correct\nanswer. These metrics are computed across all    to these, 18th MLP layer and 1st MHA in Qwen\nselected questions for each persona pair.              also gives higher ∆r, which requires further explo-\n                                                      ration in future studies. We hypothesize that the\n4.4  Findings                                     early MLP layers develop persona-specific infor-\nWe begin by patching the MLP and MHA layers    mation, particularly at the token position(s) repre-\nacross all token positions. The Figure 2 shows ∆r    senting the identity. This information is then picked\nacross all identity pairs, see Appendix F for results   up and used by the later MHA layers, giving rise\non other metric, and Appendix G for patching re-    to the observed persona-driven behavior. To test\nsults of other two models. Initial observations can     this, we patch only the activations at the identity\nbe made by comparing the semantic similarities of   token position in the MLP layers, rather than all\nidentity pairs with the results from activation patch-    positions. We observed that patching activations at\ning. The good-sharp identity pair, for instance,   the identity token position in the first MLP layer\nproduced a noticeably lower ∆r score across all   produced an effect nearly equivalent to patching all\nmodels. This is likely because the terms are seman-   token positions. Beyond the first layer, the effect\ntically similar; a good student and a sharp student    rapidly decays, with later layers showing little to\nboth represent a capable student, and the model   no impact, see Appendix H.\ngives nearly identical probabilities to the correct    We also find that only the MLP layers near the\nanswer for each. A similar, though less distinct,   end of the network have any direct effect on the\npattern can be seen with the bad-dumb identity    output, see Figure 3. This implies that the effect\npair. When identities like Asian and White are    seen in the initial layers is purely indirect. Since the\npatched with activations from the neutral base iden-    local syntax around the point of change remains\ntity, the effect on the model’s reasoning is much    constant, this suggests that the initial MLP lay-\nhigher. Since the base identity is a neutral persona,    ers are processing not just structure but also the\nthe fact that patching activations from it improves    semantics of the input tokens. This counter to ear-\nthe model’s performance suggests that these com-    lier findings (Belinkov et al., 2017, Peters et al.,\nponents are introducing bias in the presence of   2018, Jawahar et al., 2019) that claimed these lay-\nspecific identities. This bias hampers the model’s    ers were focused only on syntactic or local features,\nreasoning, and patching the output of these compo-   leaving semantic processing to later layers. The\nnents essentially prevents this bias from occurring.   subtlety of this semantic processing may explain\nThe lower ∆r values for pairs like White-Black in   why it was overlooked in previous studies. Our re-\nLlama 3B and Asian-Yellow in Qwen 1.5B may    sults align with observations that initial MLP layers\nbe a result of the specific ways the models were    transform tokens into richer representations (Stolfo\nfine-tuned, as this inconsistency was not observed    et al., 2023), supporting the hypothesis that these\nin other models.                                      layers induce persona-specific semantics that later\n  We observe that patching the early MLP layers    layers utilize.\n(layers 1–3) and the middle MHA layers (layers     To investigate MHA layer roles more closely,\n9–11) produces a consistently higher total effect   we performed activation patching on individual\nacross all ten identity pairs. Similar observations    attention heads (Hheadlayer number ), identifying eight\ncan be made for Llama 3B model, but in additions   heads with a high positive effect on the output\n\nand four with a high negative effect, see Figure 4.    terns and identified a subset that assigned dispropor-\nWe analyzed the value-weighted attention patterns    tionate weight to racial and color-related attributes\n(Lieberum et al., 2023) of these heads on the iden-   associated with a persona.\ntity token position across five questions per subject,     These findings also have significant practical im-\ncategorizing them based on the relative attention    plications for developing fairer and more reliable\ngiven when compared with other identities, see   AI systems. The research demonstrates how to pin-\nAppendix I. H259  , H2510, H2611, H313, and H1413 con-   point specific model components, like certain MLP\nsistently allocated higher attention to tokens repre-    layers and attention heads, that encode and act upon\nsenting racial identities. H2611, H313, and H1413 also    persona-driven biases related to race and other at-\nshowed elevated attention to color-based identities,    tributes. This allows for interventions that are far\nthough this pattern was less consistent across do-   more targeted than standard fine-tuning. Instead of\nmains. H1613 uniquely focused on color-based iden-   making broad adjustments, we can directly modify,\ntities, while H2515 prioritized both positive and neg-    steer, or even disable the specific neural circuits\native attributed identities at early token positions.   responsible for undesirable stereotypical behaviors,\nH259  also gives negative identities more attention    leading to more effective and efficient bias miti-\nat token positions near the end. We further exam-    gation. Furthermore, when coupled with methods\nined how these attention patterns of these heads    like probing, it serves as a powerful diagnostic tool,\nresponded to MLP layer patching. When activa-   enabling cheaper, more precise monitoring of how\ntions from runs with racial or color-based personas    a model processes sensitive information and offer-\nwere replaced with those from positive or negative    ing a clear window into its internal reasoning. This\nattributed personas, the attention of heads previ-   deeper interpretability is essential for debugging,\nously showing high focus on the identity token    ensuring AI safety, and building systems that are\nposition decreased significantly. This reduction oc-   not only less biased but also more transparent and\ncurred regardless of whether all token positions or    controllable in how they adopt these biases.\nonly the identity token position were patched. For      Overall, our observations offer preliminary in-\nmost heads, patching layers beyond the first had    sight into the subtle yet significant functions of\nminimal impact on attention patterns, for details    certain model components and how they can be\nsee Appendix J.                                    revealed through constrained but straightforward\n  Our findings validate the hypothesis of an in-   experiments. We took initial steps toward under-\nteraction between the initial MLP layers and the    standing the origins of persona-driven behavior in\nmiddle MHA layers in driving persona-driven be-  LLMs. In future studies, we will investigate why\nhavior. The initial MLP layers, especially at the    certain personas answer specific questions correctly\nidentity token position, form rich, persona-specific   while others do not, and how output vector circuits\nsemantic representations. These are then taken up    in attention heads use earlier-layer representations\nby the middle MHA layers, impacting the model’s    to shape final predictions. These directions will\nchoice of response.                                 lead to a deeper understanding of what \"persona\"\n                                                         truly means in the context of language models.\n5  Discussion\n                                            Limitations\nIn this work, we analyzed the impact of persona-\ndriven behavior on the reasoning ability of a lan-   Although the MMLU dataset contains a large num-\nguage model in objective tasks. Through the lens of    ber of mostly factual, objective questions, we ac-\nmechanistic interpretability, we examined the role   knowledge that it is not the only dataset that meets\nof different component models: MLP layers, MHA   our selection criteria. Our experiments were con-\nlayers, and individual attention heads in shaping   ducted on the Llama 3.2 1B, Llama 3.2 3B and\nthis behavior. We observed that early MLP layers   Qwen 2.5 1.5B Instruct models, while attention\nalso contributes towards semantic understanding   heads level patching experiments being limited to\nof inputs and encode persona-specific information   Llama 1B model, due to computational and time\ninto richer representation. This information is then    constraints. However, the methods described here\npassed to later MHA layers, which use it to influ-   can be readily extended to models of different sizes\nence the model’s response. We further categorized   and architectures, as well as to other datasets with\nattention heads based on their relative attention pat-    similar characteristics.\n\n  We selected a set of 16 personas to approximate    Ruizhe Li and Yanjun Gao. 2025. Anchored answers:\nthe space relevant to our probing efforts. The list       Unravelling positional bias in gpt-2’s multiple-choice\n                                                             questions. Preprint, arXiv:2405.03205.of personas is not exhaustive, but it serves as a\npractical starting point. Our analysis focused on   Tom Lieberum, Matthew Rahtz, János Kramár, Neel\nattention heads identified as important through ac-     Nanda, Geoffrey Irving, Rohin Shah, and Vladimir\n                                                         Mikulik. 2023. Does circuit analysis interpretabilitytivation patching. Examining additional heads may\n                                                             scale? evidence from multiple choice capabilities in\nimprove our understanding of how persona-driven                                                                 chinchilla. arXiv preprint arXiv:2307.09458.\nbehavior develops within the model. At present,\nhowever, attention pattern analysis requires man-   Kevin Meng, David Bau, Alex J Andonian, and Yonatan\n                                                          Belinkov. 2022. Locating and editing factual associ-\nual inspection, which remains a slow and labor-\n                                                             ations in GPT. In Advances in Neural Information\nintensive process.                                       Processing Systems.\n\n                                                   Meta. 2024a. Llama 3.2 Evals.\nReferences\n                                                   Meta. 2024b. Llama 3.2 family of models.\nYonatan Belinkov, Lluís Màrquez, Hassan Sajjad, Nadir\n   Durrani, Fahim Dalvi, and James Glass. 2017. Evalu-   Judea Pearl. 2001.  Direct and indirect effects.  In\n   ating layers of representation in neural machine trans-      Proceedings of the Seventeenth Conference on Un-\n   lation on part-of-speech and semantic tagging tasks.       certainty in Artificial Intelligence, UAI’01, page\n   In Proceedings of the Eighth International Joint Con-      411–420. Morgan Kaufmann Publishers Inc.\n   ference on Natural Language Processing (Volume\n                                               Matthew E. Peters, Mark Neumann, Luke Zettlemoyer,  1: Long Papers), pages 1–10, Taipei, Taiwan. Asian\n                                                   and Wen-tau Yih. 2018. Dissecting contextual word   Federation of Natural Language Processing.\n                                                      embeddings: Architecture and representation. In Pro-\nAmeet Deshpande, Vishvak Murahari, Tanmay Rajpuro-      ceedings of the 2018 Conference on Empirical Meth-\n   hit, Ashwin Kalyan, and Karthik Narasimhan. 2023.      ods in Natural Language Processing, pages 1499–\n   Toxicity in chatgpt: Analyzing persona-assigned lan-      1509, Brussels, Belgium. Association for Computa-\n  guage models.  In Findings of the Association for       tional Linguistics.\n  Computational Linguistics: EMNLP 2023, pages\n                                                 Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto,  1236–1270, Singapore. Association for Computa-\n                                                            Eric Schulz, and Zeynep Akata. 2023. In-context im-   tional Linguistics.\n                                                           personation reveals large language models’ strengths\nShashank Gupta, Vaishnavi Shrivastava, Ameet Desh-     and biases. In Thirty-seventh Conference on Neural\n  pande, Ashwin Kalyan, Peter Clark, Ashish Sabhar-      Information Processing Systems.\n   wal, and Tushar Khot. 2024. Bias runs deep: Implicit\n                                                 Gregory Serapio-García, Mustafa Safdari, Clément   reasoning biases in persona-assigned LLMs. In The\n   Twelfth International Conference on Learning Repre-      Crepy, Luning Sun, Stephen Fitz, Marwa Abdulhai,\n                                                     Aleksandra Faust, and Maja Matari´c. 2023. Person-   sentations.\n                                                                     ality traits in large language models. arXiv preprint\nStefan Heimersheim and Neel Nanda. 2024. How to      arXiv:2307.00184.\n  use and interpret activation patching. arXiv preprint\n  arXiv:2404.15255.                                 Alessandro Stolfo, Yonatan Belinkov, and Mrinmaya\n                                                       Sachan. 2023. A mechanistic interpretation of arith-\nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou,      metic reasoning in language models using causal\n  Mantas Mazeika, Dawn Song, and Jacob Steinhardt.      mediation analysis. In Proceedings of the 2023 Con-\n  2021. Measuring massive multitask language under-      ference on Empirical Methods in Natural Language\n   standing. In International Conference on Learning      Processing, pages 7035–7052, Singapore. Associa-\n   Representations.                                            tion for Computational Linguistics.\n\nGanesh Jawahar, Benoît Sagot, and Djamé Seddah.   Chenkai Sun, Ke Yang, Revanth Gangi Reddy, Yi Fung,\n  2019. What does BERT learn about the structure of     Hou Pong Chan, Kevin Small, ChengXiang Zhai,\n  language? In Proceedings of the 57th Annual Meet-     and Heng Ji. 2025. Persona-DB: Efficient large lan-\n   ing of the Association for Computational Linguistics,      guage model personalization for response prediction\n  pages 3651–3657, Florence, Italy. Association for      with collaborative data refinement. In Proceedings\n  Computational Linguistics.                                of the 31st International Conference on Computa-\n                                                                tional Linguistics, pages 281–296, Abu Dhabi, UAE.\nNitish Joshi, Javier Rando, Abulhair Saparov, Najoung      Association for Computational Linguistics.\n  Kim, and He He. 2024. Personas as a way to model\n   truthfulness in language models. In Proceedings of    Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov,\n   the 2024 Conference on Empirical Methods in Natu-     Sharon Qian, Daniel Nevo, Yaron Singer, and Stu-\n   ral Language Processing, pages 6346–6359, Miami,       art Shieber. 2020. Investigating gender bias in lan-\n   Florida, USA. Association for Computational Lin-     guage models using causal mediation analysis. In\n   guistics.                                           Advances in Neural Information Processing Systems,\n\n  volume 33, pages 12388–12401. Curran Associates,\n                                                   Category           Identity   Inc.\n                                                           Racial-based        Asian\nKevin Ro Wang, Alexandre Variengien, Arthur Conmy,                                Indian\n  Buck Shlegeris, and Jacob Steinhardt. 2023. Inter-                                                                              African\n   pretability in the wild: a circuit for indirect object\n                                                                                       British   identification in GPT-2 small. In The Eleventh Inter-\n   national Conference on Learning Representations.             Color-based        White\n                                                                         Black\nSarah Wiegreffe, Oyvind Tafjord, Yonatan Belinkov,                                                               Brown\n  Hannaneh Hajishirzi, and Ashish Sabharwal. 2025.\n                                                                        Yellow  Answer, assemble, ace:  Understanding how lms\n  answer  multiple  choice  questions.     Preprint,             Positive-attributes   good\n   arXiv:2407.15018.                                                                       intelligent\n                                                                                     bright\nAn Yang, Baosong Yang, Beichen Zhang, Binyuan Hui,\n                                                                              sharp  Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu,\n   Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jian-             Negative-attributes  bad\n  hong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang,                                   dull\n   Jingren Zhou, Junyang Lin, Kai Dang, and 23 oth-                                                                                   stupid\n   ers. 2025. Qwen2.5 technical report. arXiv preprint\n                                                            dumb   arXiv:2412.15115.\n\nFred Zhang and Neel Nanda. 2024. Towards best prac-      Table 1: Identities with their respective category.\n   tices of activation patching in language models: Met-\n   rics and methods. In The Twelfth International Con-\n   ference on Learning Representations.                       ID1           ID2\n                                                      Asian student    Indian student\nZhehao Zhang, Ryan A Rossi, Branislav Kveton, Yijia\n  Shao, Diyi Yang, Hamed Zamani, Franck Dernon-           helpful assistant   Asian student\n   court, Joe Barrow, Tong Yu, Sungchul Kim, and 1           Asian student   Yellow student\n   others. 2024. Personalization of large language mod-          White student    Black student\n   els: A survey. arXiv preprint arXiv:2411.00027.                                                   good student     bad student\nMingqian Zheng, Jiaxin Pei, Lajanugen Logeswaran,            Indian student   Brown student\n  Moontae Lee, and David Jurgens. 2024. When ”a           good student     sharp student\n   helpful assistant” is not really helpful: Personas in           African student   British student\n  system prompts do not improve performances of                                                             helpful assistant   White student\n   large language models. In Findings of the Associ-\n                                             dumb student     bad student   ation for Computational Linguistics: EMNLP 2024,\n  pages 15126–15154, Miami, Florida, USA. Associa-\n   tion for Computational Linguistics.                                  Table 2: Identity Pairs\n\nA  Identities\n                                                                                                                        Baseline   helpful\nIn this study, personas or identities refer to sin-                            brightgood\ngle words such as \"Asian\" or \"good.\" The selected              Positive   sharp\nidentities fall into four broad categories, with four                           intelligentAsian                                                                                 0.008\nidentities chosen from each to ensure balanced com-                         African                                                                                 0.004\n                                                                                                          Race\nparisons. A further criterion in selection was that                          Indian\n                                                                                                                                                                         British                                                                                 0.000\neach identity should be of a single token, so that                       White\nthe only variation between prompts would be one               Color  Brown                                                                                  0.004\n                                                                                                                                          Black\ntoken. Table 1 lists the identities alongside their                        Yellow                                                                                  0.008\nrespective categories.                                                                                                  stupid\n                                                                                                            dumb\n                                                                                                                      Negative\n                                                                                                                                                                                dull\nB  Prompt Structure                                                                        bad\n                                                                                                                                                             helpfulgoodbrightsharpintelligentAsianAfricanIndianBritishWhiteBrownBlackYellowstupiddumb dullbadThe prompt format used throughout the study is\nshown in Figure 6. The placeholder {helper} is                                                     Figure 5: Average difference in probability of correct\nreplaced with \"a\" or \"an\" depending on whether    token of identities w.r.t. each-other.\nthe first letter of {identity_1} is a vowel. The\n\nvariable {identity_1} is substituted with the iden-       Identity pair   C1   C2   C3  C4\n tities listed in Table 1, or with \"helpful\" in the       Asian, Indian   6909  6820  164  149\nbase prompt. The placeholder {identity_2} is        helpful, Asian   6846  6707  262  227\nreplaced with \"student\" in the persona prompts       Asian, Yellow   6888  6771  185  198\nand with \"assistant\" in the base prompt.  The       White, Black   6866  6831  188  157\n{question} field is filled with the target question,        good, bad     6834  6691  272  245\nand each {option_*} is replaced by the corre-       Indian, Brown   6855  6781  203  203\nsponding answer choice.                              good, sharp    7035  6864   71   72\n                                                        African, British  6863  6787  197  195\nC  Additional Performance Results                helpful, White   6808  6688  300  246\n                                               dumb, bad    6824  6726  237  255\nThe average of relative difference in the proba-\n bility assigned to correct token for each identity    Table 3: Number of questions in each subset for Llama\n w.r.t. base identity, for Llama 3B and Qwen 1.5B is   1B model\nshown in Figure 7. For Llama 1B model, average\nof difference in the probability assigned to correct\n                                                  Questions from subset S3 were chosen for acti-\ntoken for a given identity relative to other identities\n                                                    vation patching because they offer a well-defined\n is shown in Figure 5.\n                                                         target token to observe during the patched run. In\n                                                    the ID2(corrupt) run, the logit of the correct to-D  Identity Pairs\n                                              ken is lower than in the ID1(clean) run. Therefore,\nTable 2 shows the selected identity pairs. The pair-   components that raise the logit of the correct token\ning of identity terms was partly based on common    during the patched run help restore the model’s be-\nstereotypes, such as Asian-Yellow, Indian-Brown,   havior to that of ID1. Questions were divided in\nAsian-Indian, and contrasted with pairs like White-    similar sets for other models based on their respec-\nBlack and African-British. Other identities were    tive results.\nchosen from sets of positive and negative attributes,\n to include both semantically similar pairs (good-  F  Additional Patching Results\nsharp, dumb-bad) and dissimilar ones (good-bad).\nA few were added for comparison with baseline  We also measured, for each identity pair (ID1,\n identities such as helpful-Asian and helpful-White.   ID2), the proportion of questions where ID1 an-\nDuring activation patching, the prompt for ID1   swered correctly and ID2 did not, such that patch-\nserves as the clean prompt, while the prompt for    ing the activation of an MLP or MHA layer from\nID2 serves as the corrupt prompt.  Activations    ID1’s run into ID2’s run caused the correct token\nfrom the ID2 run are replaced with those from the    to receive the highest logit. Figure 9 presents the\nID1 run to identify which components restore the    results for both MLP and MHA layers, as well as\nmodel’s output to that of ID1. The only difference    their average across all identity pairs.\nbetween the ID1 and ID2 prompts is the identity\ntoken, except when ID1 corresponds to the base  G  Patching Results of other models\nprompt, in which case assistant is replaced with\n                                 We replicated the activation patching experiments student.\n                                           on the MLP and MHA layers for the Llama 3B\n                                            and Qwen 1.5B models. The results are shown inE  Question Subsets\n                                                  Figure 8. We did not perform head-level patching\nFor each identity pair (ID1, ID2), the questions   on these models due to computational and time\n in the dataset are divided into four subsets: S1 –    constraints. The results for the Llama 3B model\nquestions answered correctly by both identities;    are largely consistent with those of the Llama 1B\nS2 – questions answered incorrectly by both; S3 –   model; however, the results for the Qwen 1.5B\nquestions answered correctly by ID1 but incorrectly   model show some anomalies, such as higher ∆r\nby ID2; S4 – questions answered correctly by ID2    values for the 18th MLP layer and the 1st MHA\nbut incorrectly by ID1. The number of questions    layer, which might be interesting to investigate fur-\n in each category for the selected identity pairs is    ther in future studies. Nevertheless, the main obser-\nshown in Table 3.                                    vations made in this work hold for all three models.\n\n            Prompt for Llama Model\n\n              <|start_header_id|>system<|end_header_id|>\n              You are {helper}  {identity_1}  {identity_2}.\n              <|eot_id|><|start_header_id|>user<|end_header_id|>\n\n              Given the following question and four candidate answers (A, B, C and D), choose the\n              best answer.\n              Question:  {question}\n\n              A. {option_1}\n              B. {option_2}\n              C. {option_3}\n              D. {option_4}\n\n              Your response should end with \"The best answer is [the_answer_letter]\" where the\n              [the_answer_letter] is one of A, B, C or D.\n              <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n              The best answer is\n            Prompt for Qwen Model\n\n              <|im_start|>system\n              You are {helper}  {identity_1}  {identity_2}.<|im_end|>\n              <|im_start|>user\n\n              Given the following question and four candidate answers (A, B, C and D), choose the\n              best answer.\n              Question:  {question}\n\n              A. {option_1}\n              B. {option_2}\n              C. {option_3}\n              D. {option_4}\n\n              Your response should end with \"The best answer is [the_answer_letter]\" where the\n              [the_answer_letter] is one of A, B, C or D.\n              <|im_end|><|im_start|>assistant\n              The best answer is\n\n\n                                    Figure 6: MMLU prompt structure.\n\n\nH  Identity-token-position Patching           tionately more attention to a specific identity or\n    Results                                   group of identities.\n\nThe relative change in the logit of the correct token,   J  Attention after patching\nwhen only the identity token position’s activation is\n                                                 Figure 12 shows the change in value-weighted at-patched for the MLP layer, is shown in Figure 10a.\n                                                     tention at the identity position when MLP layerFigure 10b shows the percentage of questions for\n                                                      activations are patched from the \"good\" run intowhich the correct token receives the highest logit.\n                                                    the \"Asian\" run for a given question. The results\nI  Attention Visualization                       indicate that racial heads (attention heads that al-\n                                                    located higher attention to racial-based identity to-\nAttention heads were selected based on high posi-   kens) assigns significantly less attention when the\ntive effect (H259  , H2510, H2511, H2611, H2711, H912, H1413,    activations of early MLP layers are patched.\nH2515), and high negative effect (H1112, H313, H1613,\nH2615). Figure 11 shows the relative value-weighted\nattention given at the identity token position by\nselected attention heads, for a sample question\nfrom the dataset. Relative value-weighted atten-\ntion is computed by subtracting the mean value-\nweighted attention across all identities from the\nvalue-weighted attention assigned to a given iden-\ntity. This highlights the heads that pay dispropor-\n\n     intelligent                                                                                   sharp\n        Asian                                                                         Brown\n       White                                                                                   Asian\n       African                                                                                  White\n        stupid                                                                                                        British\n       good                                                                                                        intelligent\n        Indian                                                                                       Yellow\n  Identity    sharpbright                                                                                                                                                                                                                                 Identity    Indianbright\n        Black                                                                            good\n      dumb                                                                                                              dull\n         British                                                                                             African\n      Brown                                                                   dumb\n       Yellow                                                                                             Race-based                   stupid                                                                                             Race-based\n        bad                                                                                                     Color-basedPositive attributes              bad                                                                                                     Color-basedPositive attributes\n            dull                                                                                                     Negative attributes              Black                                                                                                     Negative attributes\n                  0.010     0.005    0.000     0.005     0.010     0.015     0.020                     0.015     0.010     0.005    0.000     0.005     0.010     0.015\n                                     Avg. Probability Difference                                                                  Avg. Probability Difference\n\n                    Llama 3B                                    Qwen 1.5B\n\nFigure 7: Results for Llama 3B (left) and Qwen 1.5B (right) for average difference in the probability of correct\ntokens w.r.t baseline.\n\n 1                                       1\n\n\n 2                                       2\n\n\n 3                                          3\n\n\n 4                                          4                                                                                                                            0.2\n\n\n 5                                       5\n\n\n 6                                       6\n\n\n 7                                       7\n\n\n 8                                       8\n\n\n 9                                       9\n   10                                                                               10                                                                                                                            0.1\n   11                                                                               11\n   12                                                                               12\n   Layers1314                                                                                                                                                                                                                                       Layers1314\n  MLP1516                                                                                                                    MHA1516                                                                                                                            0.0\n   17                                                                               17\n   18                                                                               18\n   19                                                                               19\n   20                                                                               20\n   21                                                                               21\n   22                                                                               22                                                                                                                             0.1\n   23                                                                               23\n   24                                                                               24\n   25                                                                               25\n   26                                                                               26\n   27                                                                               27\n   28                                                                               28                                                                                                                             0.2\n                             -bad              0.0 Average0.2              -bad                                                                        -bad              0.0Average  0.2                                                           -bad                 -Brown -sharp -British -White  -Indian -Asian -Yellow -Black                                                             -Brown-sharp-British-White                                                -Indian -Asian-Yellow -Black\n Asian  helpful Asian  White  goodIndian  good African  helpful  dumb                                   Asian helpful Asian White  goodIndian goodAfrican helpful  dumb\n\n         MLP layer patching (Llama-3B)                MHA layer patching (Llama-3B)\n\n\n\n\n\n 1                                       1\n\n\n 2                                       2\n\n\n 3                                          3\n\n\n 4                                          4                                                                                                                            0.2\n\n\n 5                                       5\n\n\n 6                                       6\n\n\n 7                                       7\n\n\n 8                                       8\n\n\n 9                                       9\n   10                                                                               10                                                                                                                            0.1\n   11                                                                               11\n   12                                                                               12\n   Layers1314                                                                                                                                                                                                                                       Layers1314\n  MLP1516                                                                                                                    MHA1516                                                                                                                            0.0\n   17                                                                               17\n   18                                                                               18\n   19                                                                               19\n   20                                                                               20\n   21                                                                               21\n   22                                                                               22                                                                                                                             0.1\n   23                                                                               23\n   24                                                                               24\n   25                                                                               25\n   26                                                                               26\n   27                                                                               27\n   28                                                                               28                                                                                                                             0.2\n                             -bad            0.1  Average0.0      0.1              -bad                                                                        -bad       0.0    0.1Average0.2    0.3                                                           -bad                 -Brown -sharp -British -White  -Indian -Asian -Yellow -Black                                                             -Brown-sharp-British-White                                                -Indian -Asian-Yellow -Black\n Asian  helpful Asian  White  goodIndian  good African  helpful  dumb                                   Asian helpful Asian White  goodIndian goodAfrican helpful  dumb\n\n        MLP layer patching (Qwen-1.5B)                MHA layer patching (Qwen-1.5B)\n\nFigure 8: Relative logit difference (∆r) when MLP layers (left) and MHA layers (right) are patched in Llama 3B\n(top row) and Qwen 1.5B (bottom row). Accompanying bar charts show the average ∆r across identity pairs.\n\n                                                                                                                                                                                                                                       100\n 1                                       1\n\n\n 2                                       2\n\n\n 3                                       3\n\n 4                                       4                                                                                                        80\n\n\n 5                                       5\n\n\n 6                                       6\n\n\n 7                                       7                                                                                                        60\n\n\n\n 8                                       8   Layers                                                                                                                                                                                                                                            Layers\n\n\n                                          9 MLP9                                                                                                                    MHA\n\n   10                                                                               10                                                                                                        40\n\n   11                                                                               11\n\n   12                                                                               12\n\n   13                                                                               13\n                                                                                                                                                                                                                                       20\n\n   14                                                                               14\n\n   15                                                                               15\n\n\n   16                                                                               16\n                                                                                                                                                                                                                                       0\n                             -bad      0      20Average40 %   60              -bad                                                                        -bad     0      25Average50%    75                                                           -bad                 -Brown -sharp -British -White  -Indian -Asian -Yellow -Black                                                             -Brown-sharp-British-White                                                -Indian -Asian-Yellow -Black\nAsian  helpful Asian  White  goodIndian  good African  helpful  dumb                                   Asian helpful Asian White  goodIndian goodAfrican helpful  dumb\n\n            MLP layer patching                       MHA layer patching\n\nFigure 9: Percentage of questions whose logit of correct token became maximum after patching MLP layer (left)\nand MHA layer (right).\n\n\n\n\n\n               (a) Relative logit difference (∆r).                 (b) Percentage of questions whose logit of correct token became\n                                                maximum.\n\n              Figure 10: Comparison of MLP layer patching effects at the identity token position.\n\n                Layer: 9; Head: 25                               Layer: 10; Head: 25                               Layer: 11; Head: 25\n     0                                               0                                               0\n     6                                               6                                               6\n    12                                              12                                              12\n    18                                              18                                              18\n    24                                              24                                              24\n    30                                              30                                              30\n    36                                              36                                              36\n    42                                              42                                              42\n    48                                              48                                              48\n    54                                              54                                              54 Positions 60                                                                                                                                                Positions 60                                                                                                                                                Positions 60    66                                              66                                              66\n Token 7278                                                                                Token 7278                                                                                Token 7278    84                                              84                                              84\n    90                                              90                                              90\n    96                                              96                                              96\n   102                                             102                                             102\n   108                                             108                                             108\n   114                                             114                                             114\n   120                                             120                                             120\n                  helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid\n                Layer: 11; Head: 26                               Layer: 11; Head: 27                               Layer: 12; Head: 9\n     0                                               0                                               0\n     6                                               6                                               6\n    12                                              12                                              12\n    18                                              18                                              18\n    24                                              24                                              24\n    30                                              30                                              30\n    36                                              36                                              36\n    42                                              42                                              42\n    48                                              48                                              48\n    54                                              54                                              54 Positions 60                                                                                                                                                Positions 60                                                                                                                                                Positions 60    66                                              66                                              66\n Token 7278                                                                                Token 7278                                                                                Token 7278    84                                              84                                              84\n    90                                              90                                              90\n    96                                              96                                              96\n   102                                             102                                             102\n   108                                             108                                             108\n   114                                             114                                             114\n   120                                             120                                             120\n                  helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid\n                Layer: 12; Head: 11                               Layer: 13; Head: 3                               Layer: 13; Head: 14\n     0                                               0                                               0\n     6                                               6                                               6\n    12                                              12                                              12\n    18                                              18                                              18\n    24                                              24                                              24\n    30                                              30                                              30\n    36                                              36                                              36\n    42                                              42                                              42\n    48                                              48                                              48\n    54                                              54                                              54 Positions 60                                                                                                                                                Positions 60                                                                                                                                                Positions 60    66                                              66                                              66\n Token 7278                                                                                Token 7278                                                                                Token 7278    84                                              84                                              84\n    90                                              90                                              90\n    96                                              96                                              96\n   102                                             102                                             102\n   108                                             108                                             108\n   114                                             114                                             114\n   120                                             120                                             120\n                  helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid\n                Layer: 13; Head: 16                               Layer: 15; Head: 25                               Layer: 15; Head: 26\n     0                                               0                                               0\n     6                                               6                                               6\n    12                                              12                                              12\n    18                                              18                                              18\n    24                                              24                                              24\n    30                                              30                                              30\n    36                                              36                                              36\n    42                                              42                                              42\n    48                                              48                                              48\n    54                                              54                                              54 Positions 60                                                                                                                                                Positions 60                                                                                                                                                Positions 60    66                                              66                                              66\n Token 7278                                                                                Token 7278                                                                                Token 7278    84                                              84                                              84\n    90                                              90                                              90\n    96                                              96                                              96\n   102                                             102                                             102\n   108                                             108                                             108\n   114                                             114                                             114\n   120                                             120                                             120\n                  helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid                                   helpfulAsianIndianAfricanBritishWhiteBlackBrownYellowgoodintelligentbrightsharpdullbaddumbstupid\n\nFigure 11: Relative value-weighted attention given by selected attention heads at identity token position. The\nprompt used is the first question from \"Abstract Algebra\" subject.\n\n                Layer: 9; Head: 25                               Layer: 10; Head: 25                               Layer: 11; Head: 25\n     0                                               0                                               0\n     7                                               7                                               7\n    14                                              14                                              14\n    21                                              21                                              21\n    28                                              28                                              28\n    35                                              35                                              35\n    42                                              42                                              42\n    49                                              49                                              49\n    56                                              56                                              56 Positions 63                                                                                                                                                Positions 63                                                                                                                                                Positions 63\n    70                                              70                                              70\n Token 7784                                                                                Token 7784                                                                                Token 7784\n    91                                              91                                              91\n    98                                              98                                              98\n   105                                             105                                             105\n   112                                             112                                             112\n   119                                             119                                             119\n        runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch\n               'good''Asian'                                                                                                   'good''Asian'                                                                                                   'good''Asian'                    MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16\n\n                Layer: 11; Head: 26                               Layer: 11; Head: 27                               Layer: 12; Head: 9\n     0                                               0                                               0\n     7                                               7                                               7\n    14                                              14                                              14\n    21                                              21                                              21\n    28                                              28                                              28\n    35                                              35                                              35\n    42                                              42                                              42\n    49                                              49                                              49\n    56                                              56                                              56 Positions 63                                                                                                                                                Positions 63                                                                                                                                                Positions 63\n    70                                              70                                              70\n Token 7784                                                                                Token 7784                                                                                Token 7784\n    91                                              91                                              91\n    98                                              98                                              98\n   105                                             105                                             105\n   112                                             112                                             112\n   119                                             119                                             119\n        runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch\n               'good''Asian'                                                                                                   'good''Asian'                                                                                                   'good''Asian'                    MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16\n\n                Layer: 12; Head: 11                               Layer: 13; Head: 3                               Layer: 13; Head: 14\n     0                                               0                                               0\n     7                                               7                                               7\n    14                                              14                                              14\n    21                                              21                                              21\n    28                                              28                                              28\n    35                                              35                                              35\n    42                                              42                                              42\n    49                                              49                                              49\n    56                                              56                                              56 Positions 63                                                                                                                                                Positions 63                                                                                                                                                Positions 63\n    70                                              70                                              70\n Token 7784                                                                                Token 7784                                                                                Token 7784\n    91                                              91                                              91\n    98                                              98                                              98\n   105                                             105                                             105\n   112                                             112                                             112\n   119                                             119                                             119\n        runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch\n               'good''Asian'                                                                                                   'good''Asian'                                                                                                   'good''Asian'                    MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16\n\n                Layer: 13; Head: 16                               Layer: 15; Head: 25                               Layer: 15; Head: 26\n     0                                               0                                               0\n     7                                               7                                               7\n    14                                              14                                              14\n    21                                              21                                              21\n    28                                              28                                              28\n    35                                              35                                              35\n    42                                              42                                              42\n    49                                              49                                              49\n    56                                              56                                              56 Positions 63                                                                                                                                                Positions 63                                                                                                                                                Positions 63\n    70                                              70                                              70\n Token 7784                                                                                Token 7784                                                                                Token 7784\n    91                                              91                                              91\n    98                                              98                                              98\n   105                                             105                                             105\n   112                                             112                                             112\n   119                                             119                                             119\n        runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch               runrunpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatchpatch\n               'good''Asian'                                                                                                   'good''Asian'                                                                                                   'good''Asian'                    MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16                                MLP-1MLP-2MLP-3MLP-4MLP-5MLP-6MLP-7MLP-8MLP-9MLP-10MLP-11MLP-12MLP-13MLP-14MLP-15MLP-16\n\nFigure 12: Relative value-weighted attention given by selected heads at identity token position after patching\nactivation at identity token position for MLP layer. The prompt used is the first question from \"Abstract Algebra\"\nsubject.\n\n## Claim to Classify\n\"early MLP layers attend not only to the syntactic structure but also process its semantic content\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Activation patching",
    "method_rung": 2,
    "claim_rung": 3,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The method used is activation patching, which is an interventional method (Rung 2) as it involves replacing activations and measuring effects. The claim states that early MLP layers 'attend not only to the syntactic structure but also process its semantic content'—this uses the verb 'process' and implies a mechanistic role in handling semantics, which constitutes a Rung 3 claim. There is no hedge (e.g., 'may' or 'suggests'), and the claim is stated as a definitive finding. This matches the common overclaim pattern of using Rung 2 methods to support Rung 3 mechanistic claims."
  },
  "metadata": {
    "model": "qwen/qwen3-235b-a22b-2507",
    "usage": {
      "prompt_tokens": 20326,
      "completion_tokens": 182,
      "total_tokens": 20508
    },
    "finish_reason": "stop"
  }
}