{
  "timestamp": "2026-02-19T11:40:02.407515+00:00",
  "paper_id": "2403.07809",
  "claim_id": "2403.07809-01",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2403.07809\nTitle: pyvene: A Library for Understanding and Improving PyTorch Models via Interventions\nFull text:\n          pyvene: A Library for Understanding and Improving PyTorch Models\n                                      via Interventions\n\n\n            Zhengxuan Wu†, Atticus Geiger‡, Aryaman Arora†, Jing Huang†, Zheng Wang†,\n                 Noah D. Goodman†, Christopher D. Manning†, Christopher Potts†\n                                     †Stanford University   ‡Pr(Ai)2R Group\n           {wuzhengx,atticusg,aryamana,hij,peterwz,ngd,manning,cgpotts}@stanford.edu\n\n\n\n                          Abstract\n\n                   Interventions on model-internal states are fun-\n                 damental operations in many areas of AI, in-\n                  cluding model editing, steering, robustness,\n                and interpretability. To facilitate such research,2024        we introduce pyvene, an open-source Python\n                    library that supports customizable interven-\n                    tions on a range of different PyTorch modules.Mar          pyvene supports complex intervention schemes\n                 with an intuitive configuration format, and its\n12             interventions can be static or include trainable\n                  parameters. We show how pyvene provides a\n                   unified and extensible framework for perform-\n                  ing interventions on neural models and shar-\n                  ing the intervened upon models with others.\n           We illustrate the power of the library via in-[cs.LG]              terpretability analyses using causal abstraction\n                and knowledge localization. We publish our\n                    library through Python Package Index (PyPI)\n                and provide code, documentation, and tutorials\n                     at https://github.com/stanfordnlp/pyvene.\n\n\n          1  Introduction\n\n         When we intervene on a neural network, we make\n                                                                   Figure 1: An inference-time intervention (Li et al.,\n           an in-place change to its activations, putting the                                                               2023a) on TinyStories-33M. The model is prompted\n           model in a counterfactual state. This fundamen-   with “Once upon a time there was a”, and is asked to\n                tal operation has emerged as a powerful tool for    complete the story. We add a static word embedding (for\n            both understanding and improving models; inter-   “happy” or “sad”) into the MLP output at each decoding\n             ventions of various kinds are key to recent efforts    step for all layers with a coefficient of 0.3. pyvene’sarXiv:2403.07809v1                                                           complete implementation is provided. The original and              in model robustness (He et al., 2019), model edit-\n                                                                      intervened generations use greedy decoding.\n             ing (Meng et al., 2022) and steering (Li et al.,\n            2023a), causal abstraction (Geiger et al., 2020,\n            2021, 2023; Wu et al., 2023) or activation patch-\n             ing (Chan et al., 2022; Wang et al., 2023), circuit    et al. 2023; Geiger et al. 2023 as examples) that lack\n              finding (Conmy et al., 2023; Goldowsky-Dill et al.,    extensibility and are hard to maintain and share,\n             2023), and knowledge tracing (Geva et al., 2023).    and current toolkits focus on single or non-nested\n            As intervention-based techniques have matured,    interventions (e.g., ablation neurons in a single for-\n              the need has arisen to run ever more complex inter-   ward pass) and are often limited to interventions\n             ventions on ever larger models. Currently, there is   on Transformers (Vaswani et al., 2017) without na-\n           no unified and generic intervention-oriented library    tively supporting other neural architectures. Some\n              to support such research. Existing libraries are of-   of these existing libraries (Bau, 2022; Lloyd, 2023;\n             ten project-based (see implementations for Wang   Fiotto-Kaufman, 2023; Mossing et al., 2024) can\n\n\n                                                    1\n\nsupport complex interventions such as exchanging   Python Package Index (PyPI),1 and the project site2\nactivations across multiple forward passes yet they    hosts more than 20 tutorials that cover interventions\nrequire sophisticated knowledge and heavy imple-    at different levels of complexity with various model\nmentations.                                          architectures from simple feed-foward models to\n  To address these  limitations, we introduce   multi-modal models.\npyvene, an open-source Python library that sup-\nports customizable interventions on different neu-   2  System Design and Architecture\nral architectures implemented in PyTorch.  Dif-\n                                    Two primary components of pyvene are the in-ferent from previous libraries (Bau, 2022; Nanda\n                                               tervenable configuration, which outlines whichand Bloom, 2022; Lloyd, 2023; Fiotto-Kaufman,\n                                          model components will be intervened upon, and2023; Mossing et al., 2024), pyvene is intervention-\n                                                      the intervenable model, which decorates the origi-oriented. It supports complex interventions by ma-\n                                                     nal torch model with hooks that allow activationsnipulating or exchanging activations across multi-\n                                                      to be collected and overwritten.3 Here is a setupple model forward runs while allowing these inter-\n                                                         for performing a zero-out intervention (often calledventions to be shared with a serialization configu-\n                                                a zero ablation; Li et al. 2023b) on the 10th, 11th,ration file. Specifically, pyvene has a number of\n                                            and 12th dimensions of the MLP output for 3rdadvantages:\n                                                 token embedding of layer 0 in GPT-2:\n  1. Intervention as the primitive. The interven-\n     tion is the basic primitive of pyvene. Inter-     importimport torchpyvene as pv\n     ventions are specified with a dict-based for-      # built -in helper to get a HuggingFace model\n                                                              _, tokenizer , gpt2 = pv.create_gpt2 ()\n     mat, in contrast to previous approaches where       # create with dict -based config\n     interventions are expressed as code and exe-     pv_config\"layer\": = 0,pv.IntervenableConfig ({\n     cuted during runtime (Bau, 2022; Lloyd, 2023;       \"component\": \"mlp_output\",\n                                                            \"intervention_type\": pv.VanillaIntervention })\n     Fiotto-Kaufman, 2023; Mossing et al., 2024).      # initialize model\n     All pyvene intervention schemes and mod-     pv_gpt2pv_config= pv.IntervenableModel(, model=gpt2)\n     els are serializable objects that can be shared       # run an intervened forward pass                                                           intervened_outputs = pv_gpt2(\n     through a public model hub such as Hugging-        # the base input\n                                                             base=tokenizer(\n     Face.                                                      \"The capital of Spain is\",\n                                                              return_tensors=\"pt\"),\n                                                                        # the location to intervene at (3rd token)\n  2. Complex intervention schemes. pyvene sup-       unit_locations ={\"base\": 3},\n     ports interventions at multiple locations, in-        #subspacesthe individual=[10 ,11 ,12]dimensions,        targetted\n     volving arbitrary subsets of neurons, and in-        # the intervention values\n                                                            source_representations=torch.zeros(\n     terventions can be performed in parallel or in          gpt2.config.n_embd)\n     sequence. For generative use of LMs, pyvene       )# sharing\n     supports interventions at decoding steps. Fur-     pv_gpt2.save(\"./tmp/\", save_to_hf_hub=True)\n     thermore, activations can easily be collected\n                                         The model takes a tensor input base and runs\n     for probe training.\n                                                 through the model’s computation graph modifying\n  3. Support for recurrent and non-recurrent    activations in place to be other values source. In\n    models. Existing libraries offer only limited    this code, we specified source in the forward call.\n     support for recurrent models. pyvene sup-  When source is a constant, it can alternatively be\n     ports simple feed-forward networks, Trans-   specified in the IntervenableConfig. To target\n     formers, and recurrent and convolutional neu-   complete MLP output representations, one simply\n      ral models.                                     leaves out the subspaces argument. The final line\n                                                     of the code block shows how to serialize and share\n  In this paper, we provide two detailed case stud-   an intervened model remotely through a model hub\nies using pyvene as well: (1) we fully reproduce   such as HuggingFace.\nMeng et al. (2022)’s locating factual associations in\nGPT2-XL (Figure 1 in the original paper) in about       1pip install pyvene\n                                                        2https://github.com/stanfordnlp/pyvene20 lines of code, and (2) we show intervention\n                                                        3Code snippets provided in the paper can be run on Google\nand probe training with pyvene to localize gender                                                      Colab at https://colab.research.google.com/github/\nin Pythia-6.9B. pyvene is published through the    stanfordnlp/pyvene/blob/main/pyvene_101.ipynb.\n\n\n                                         2\n\n2.1  Interchange Interventions                     basis for training models to be robust to this noising\n                                                     process.Interchange interventions (Geiger et al., 2020; Vig\net al., 2020; Wang et al., 2023, also known as acti-                                                    2.3  Activation Collection Interventions\nvation patching) fix activations to take on the values\n                                                  This is a pass-through intervention to collect activa-\nthey would be if a different input were provided.\n                                                      tions for operations like supervised probe train-\nWith minor changes to the forward call, we can\n                                                       ing.  Such interventions can be combined with\nperform an interchange intervention on GPT-2:\n                                                    other interventions as well, to support things like\n  # run an interchange intervention                    causal structural probes (Hewitt and Manning,\n  intervened_outputs = pv_gpt2(                     2019; Elazar et al., 2020; Lepori et al., 2023). In    # the base input\n    base=tokenizer(                                    the following example, we perform an interchange\n      \"The capital of Spain is\",\n      return_tensors = \"pt\"),                           intervention at layer 8 and then collect activations\n    #      the source input                                     at layer 10 for the purposes of fitting a probe:    sources=tokenizer(\n      \"The capital of Italy is\",\n      return_tensors = \"pt\"),                                                                     # set up a upstream intervention\n    # the location to intervene at (3rd token)                                                           probe_config = pv.IntervenableConfig ({\n    unit_locations ={\"sources ->base\": 3},                                                             \"layer\": 8,\n    # the individual dimensions targeted                                                             \"component\": \"block_output\",\n    subspaces =[10 ,11 ,12]                                                            \"intervention_type\":  pv.VanillaIntervention })\n  )                                                                     # add downstream collector\n                                                           probe_config = probe_config.add_intervention ({\nThis forward call produces outputs for base but        \"layer\": 10,\n                                                             \"component\": \"block_output\",\nwith the activation values for MLP output dimen-       \"intervention_type\": pv.CollectIntervention })\nsions 10–12 of token 3 at layer 0 set to those that ob-     probe_gpt2probe_config= pv.IntervenableModel(, model=gpt2)\ntained when the model processes the source. Such       # return the activations for 3rd token\n                                                           collected_activations = probe_gpt2(\ninterventions are used in interpretability research to        base=tokenizer(\n                                                                 \"The capital of Spain is\",\ntest hypotheses about where and how information          return_tensors=\"pt\"),\nis stored in model-internal representations.                unit_locations ={\"sources ->base\": 3})\n\n2.2  Addition Interventions                       2.4  Custom Interventions\n\nIn the above examples, we replace values in the   pyvene provides a flexible way of adding new inter-\nbase with other values (VanillaIntervention).   vention types. The following is a simple illustration\nAnother common kind of intervention involves up-    in which we multiply the original representation by\ndating the base values in a systematic way:          a constant value:\n\n\n  noising_config = pv.IntervenableConfig ({                    # multiply base with a constant\n    \"layer\": 0,                                              class MultInt(pv.ConstantSourceIntervention):\n    \"component\": \"block_input\",                                def __init__(self , ** kwargs):\n    \"intervention_type\": pv.AdditionIntervention })             super ().__init__ ()\n  noising_gpt2 = pv.IntervenableModel(                        def forward(self , base , source=None ,\n    config , model=gpt2)                                        subspaces=None):\n  intervened_outputs = noising_gpt2(                            return base * 0.3\n    base=tokenizer(\n      \"The Space Needle is in downtown\",                   pv.IntervenableModel ({\n      return_tensors = \"pt\"),                                \"intervention_type\": MultInt},\n    # target the first four tokens for intervention          model=gpt2)\n    unit_locations ={\"base\": [0, 1, 2, 3]},\n    source_representations = torch.rand(             The above intervention becomes useful when study-      gpt2.config.n_embd , requires_grad=False))\n                                                    ing interpretability-driven models such as the Back-\nAs in this example, we add noise to a represen-   pack LMs of Hewitt et al. (2023). The sense vectors\ntation as a basic robustness check.  The code    acquired during pretraining in Backpack LMs have\nabove does this, targetting the  first four input   been shown to have a “multiplication effect”, and\ntoken embeddings to a Transformer by using   so proportionally decreasing sense vectors could\nAdditionIntervention. This example serves as    effectively steer the model’s generation.\nthe building block of causal tracing experiments as\n                                                    2.5  Trainable Interventionsin Meng et al. 2022, where we corrupt embedding\ninputs by adding noise to trace factual associations.   pyvene interventions can include trainable param-\nBuilding on top of this, we reproduce Meng et al.’s    eters. RotatedSpaceIntervention implements\nresult in Section 3. pyvene allows Autograd on    Distributed Alignment Search (DAS; Geiger et al.\nthe static representations, so this code could be the    2023), LowRankRotatedSpaceIntervention is a\n\n\n                                         3\n\nmore  efficient  version  of  that  model,  and   examples and swapping them into the base’s com-\nBoundlessRotatedSpaceIntervention  imple-   putation graph:\nments the Boundless DAS variant of Wu et al.\n(2023). With these primitives, one can easily train      parallel_config{\"layer\": 3, \"component\":= pv.IntervenableConfig\"block_output\"},([\nDAS explainers.                                           {\"layer\": 3, \"component\": \"block_output\"}],\n                                                                        # intervene on base at the same time\n   In the example below, we show a single gradient        mode=\"parallel\")\nupdate for a DAS training objective that localizes      parallel_gpt2 = pv.IntervenableModel(\nthe capital associated with the country in a one-       parallel_config , model=gpt2)\ndimensional linear subspace of activations from      base = tokenizer(\n                                                               \"The capital of Spain is\",\nthe Transformer block output (i.e., main residual        return_tensors=\"pt\")\nstream) at the 8th layer by training our intervention      sourcestokenizer(\"The= [      language of Spain is\",\nmodule to match the gold counterfactual behavior:         return_tensors=\"pt\"),\n                                                             tokenizer(\"The capital of Italy is\",\n                                                               return_tensors=\"pt\")]\n  das_config = pv.IntervenableConfig ({\n    \"layer\": 8,                                            intervened_outputs = parallel_gpt2(\n    \"component\": \"block_output\",                               base , sources ,\n    \"low_rank_dimension\": 1,                                  {\"sources ->base\": (\n    \"intervention_type\":                                            # each list has a dimensionality of\n      pv.LowRankRotatedSpaceIntervention })                      # [num_intervention , batch , num_unit]\n                                                               [[[1]] ,[[3]]] ,  [[[1]] ,[[3]]])}\n  das_gpt2 = pv.IntervenableModel(                             )\n      das_config , model=gpt2)\n  last_hidden_state = das_gpt2(                       In the example above, we interchange the activa-\n    base=tokenizer(                                      tions from the residual streams on top of the second\n      \"The capital of Spain is\",\n      return_tensors=\"pt\"),                          token from the first example (“language”) as well as\n    sources=tokenizer(\n      \"The capital of Italy is\",                        the fourth token from the second example (“Italy”)\n      return_tensors=\"pt\"),                              into the corresponding locations of the base’s com-    unit_locations ={\"sources ->base\": 3}\n  )[-1]. last_hidden_state [:,-1]                        putation graph. The motivating intuition is that\n  # gold counterfacutual label as \" Rome\"           now the next token might be mapped to a semantic\n  label         = tokenizer.encode(\n    \" Rome\",             return_tensors=\"pt\")                     space that is a mixture of two inputs in the source\n  logits = torch.matmul(                         “The language of Italy”. (And, in fact, “Italian” is\n    last_hidden_state , gpt2.wte.weight.t())\n                                        among the top five returned logits.)\n  m = torch.nn.CrossEntropyLoss ()\n  loss = m(logits , label.view(-1))\n  loss.backward ()                                     2.8  Multi-Source Serial Interventions\n\n                                                    Interventions can also be sequentially applied, so\n2.6  Training with Interventions                    that later interventions are applied to an intervened\n                                           model created by the previous ones:\nInterventions can be co-trained with the intervening\nmodel for techniques like interchange intervention      serial_config = pv.IntervenableConfig ([\ntraining (IIT), which induce specific causal struc-       {\"layer\": 3, \"component\": \"block_output\"},\n                                                             {\"layer\": 10, \"component\": \"block_output\"}],\ntures in neural networks (Geiger et al., 2022):               # intervene on base one after another\n                                                             mode=\"serial\")\n\n  pv_gpt2 = pv.IntervenableModel ({                         serial_gpt2 = pv.IntervenableModel(\n    \"layer\": 8},                                              serial_config , model=gpt2)\n    model=gpt2)\n  # enable gradients on the model                          intervened_outputs = serial_gpt2(\n  pv_gpt2.enable_model_gradients ()                             base , sources ,\n  # run counterfactual forward as usual                          # src_0 intervenes on src_1 position 1\n                                                                        # src_1 intervenes on base position 4\n                                                              {\"source_0 ->source_1\": 1,\nIn the example above, with the supervision signals         \"source_1 ->base\"     : 4}\nfrom the training dataset, we induce causal struc-      )\ntures in the residual stream at 8th layer.\n                                                     In the example above, we first take activations at the\n                                                        residual stream of the first token (“language”) at the\n2.7  Multi-Source Parallel Interventions\n                                                3rd layer from the first source example and swap\nIn the parallel mode, interventions are applied to   them into the same location during the forward run\nthe computation graph of the same base example    of the second source example. We then take the\nat the same time. We can perform interchange inter-    activations of the 4th token (“is”) at layer 10 at\nventions by taking activations from multiple source   upstream of this intervened model and swap them\n\n\n                                         4\n\ninto the same location during the forward run of the    results. Specifically, we restore the Transformer\nbase example. The motivating intuition is that the    block output, MLP activation, and attention output\nfirst intervention will result in the model retrieving    for each token at each layer. For MLP activation\n“The language of Italy” and the second interven-   and attention output, we restore 10 sites centered\ntion will swap the retrieved answer into the output   around the intervening layer (clipping on the edges).\nstream of the base example. (Once again, “Italian”   Our Figure 2 fully reproduces the main Figure 1\nis among the top five returned logits.)                  (p. 2) in Meng et al.’s paper. To replicate their ex-\n                                                     periments, we first define a configuration for causal\n2.9  Intervenable Model                                                         tracing:\nThe IntervenableModel class is the backend for\ndecorating torch models with intervenable config-      def l,tracing_config(c=\"mlp_activation\", w=10, tl=48):\nurations and running intervened forward calls. It         s = max(0, l - w // 2)                                                                        e = min(tl , l - (-w // 2))\nimplements two types of hooks: Getter and Setter        config = IntervenableConfig(\n                                                               [{\"component\": \"block_input\"}] +\nhooks to save and set activations.                            [{\"layer\": l, \"component\": c}\n   Figure 1 highlights pyvene’s support for LMs.         [pv.NoiseIntervention]for l in range(s, e)],+\nInterventions can be applied to any position in the          [pv.VanillaIntervention ]*(e-s))\n                                                               return config\ninput prompt or any selected decoding step.\n  The following involves a model with recurrent   With this configuration, we corrupt the subject to-\n(GRU) cells where we intervene on two unrolled   ken and then restore selected internal activations to\nrecurrent computation graphs at a time step:           their clean value. Our main experiment is imple-\n                                            mented with about 20 lines of code with pyvene:\n  # built -in helper to get a GRU\n  _, _, gru = pv.create_gru_classifier(\n                                                            trace_results = []    pv.GRUConfig(h_dim =32))\n                                                              _, tokenizer , gpt = pv.create_gpt2(\"gpt2 -xl\")  # wrap it with config\n                                                              base = tokenizer(  pv_gru = pv.IntervenableModel ({\n                                                               \"The Space Needle is in downtown\",    \"component\": \"cell_output\",\n                                                             return_tensors=\"pt\")     # intervening on time\n                                                               for s in [\"block_output\", \"mlp_activation\",    \"unit\": \"t\",\n                                                               \"attention_output\"]:    \"intervention_type\": pv.ZeroIntervention},\n                                                                  for l in range(gpt.config.n_layer):    model=gru)\n                                                                    for p in range (7):  # run an intervened forward pass\n                                                                             w = 1 if s == \"block_output\" else 10  rand_b = torch.rand(1,10, gru.config.h_dim)\n                                                                   t_config , n_r = tracing_config(l, s, w)  rand_s = torch.rand(1,10, gru.config.h_dim)\n                                                                    t_gpt = pv.IntervenableModel(t_config , gpt)  intervened_outputs = pv_gru(\n                                                                     _, outs = t_gpt(base , [None] + [base]*n_r ,    base = {\"inputs_embeds\": rand_b},\n                                                                     {\"sources ->base\": ([None] + [[[p]]]*n_r ,    sources = [{\"inputs_embeds\": rand_s}],\n                                                                       [[[0, 1, 2, 3]]] + [[[p]]]* n_r)})     # intervening time step\n                                                                     dist = pv.embed_to_distrib(gpt ,    unit_locations ={\"sources ->base\": (6, 3)})\n                                                                   outs.last_hidden_state , logits=False)\n                                                                 trace_results.append(\nA hook is triggered every time the corresponding              {\"stream\": s, \"layer\": l, \"pos\": p,\n                                                                     \"prob\": dist [0][ -1][7312]})\nmodel component is called. As a result, a vanilla\nhook-based approach, as in all previous libraries\n(Bau, 2022; Lloyd, 2023; Fiotto-Kaufman, 2023;   4  Case Study II: Intervention and Probe\nMossing et al., 2024), fails to intervene on any      Training with Pythia-6.9B\nrecurrent or state-space model. To handle this lim-\n                                 We showcase intervention and probe training with\nitation, pyvene records a state variable for each\n                                           pyvene using a simple gendered pronoun predic-\nhook, and only executes a hook at the targeted time\n                                                       tion task in which we try to localize gender in\nstep.\n                                                hidden representations. For trainable intervention,\n                                    we use a one-dimensional Distributed Alignment3  Case Study I: Locating Factual\n                                                Search (DAS; Geiger et al., 2023), that is, we seek    Associations in GPT2-XL\n                                                       to learn a 1D subspace representing gender. To\nWe replicate the main result in Meng et al. (2022)’s    localize gender, we feed prompts constructed from\nLocating Factual Associations in GPT2-XL with   a template of the form “[John/Sarah] walked be-\npyvene. The task is to trace facts via interventions   cause [he/she]” (a fixed length of 4) where the\non fact-related datasets. Following Meng et al.’s   name is sampled from a vocabulary of 47 typically\nsetup, we first intervene on input embeddings by   male and 10 typically female names followed by\nadding Gaussian noise. We then restore individual    the associated gendered pronoun as the output to-\nstates to identify the information that restores the    ken. We use pythia-6.9B (Biderman et al., 2023)\n\n\n                                         5\n\n      The*                                                                                              The*                                                                                              The*\n         Space*                                                    p(Seattle)      Space*                                                    p(Seattle)      Space*                                                    p(Seattle)\n                                                                                                                                                                                                                                        0.8\n        Need*                                                               0.75        Need*                                                               0.75        Need*                                                                  0.6\n     le*                                                               0.50     le*                                                               0.50     le*                                                                  0.4\n\n   is                                                               0.25   is                                                               0.25   is                                                                  0.2\n\n\n   in                                               in                                               in\n            downtown                                                                                                                                                                                             downtown                                                                                                                                                                                             downtown\n         0        10       20       30       40                           0        10       20       30       40                           0        10       20       30       40\n                single restored layer in GPT2-XL                            center of interval of 10 patched mlp layer                       center of interval of 10 patched attn layer\n\nFigure 2: We reproduce the results in Meng et al. (2022)’s Figure 1 of locating early sites and late sites of factual\nassociations in GPT2-XL in about 20 lines of pyvene code. The causal impact on output probability is mapped for\nthe effect of each Transformer block output (left), MLP activations (middle), and attention layer output (right) .\n\n   Trained Intervention (DAS)                           finds sparser gender representations across layers\n                                            and positions, whereas a linear probe achieves\n EOS                                                               IIA  1                                      100% classification accuracy for almost all compo-\n                                                                     0.75    nents. This shows that a probe may achieve high  <name>\n                                                                     0.50    performance even on representations that are not\n  walked                                                  causally relevant for the task.\n                                                                     0.25\n   because                                                         0                                        5  Limitations and Future Work\n       0             10            20            30\n                          layers                                 We are currently focused on two main areas:\n   Trained Linear Probe\n                                                            1. Expanding the default intervention types and\n EOS                                       ACC 1        model types.  Although pyvene is extensi-\n                                                          ble to other types, having more built-in types\n                                                                          0.9\n                                                        helps us to onboard new users easily.  <name>                                                                      0.8\n                                                                          0.7       2. pyvene is designed to support complex inter-  walked\n   because                                                                      0.60.5         ventioncomputationalschemes,efficiency.but this Ascomeslanguageat the modelscost of\n       0             10            20            30                   get larger, we would like to investigate how to\n                           layers                                                           scale intervention efficiency with multi-node\n                                                 and multi-GPU training.Figure 3: Results of interchange intervention accuracy\n(IIA) with the trainable intervention (DAS) and accu-\nracy with the trainable linear probe on different model   6  Conclusion\ncomponents when localizing gender information.\n                                We introduce pyvene, an open-source Python li-\n                                                   brary that supports intervention-based research on\nin this experiment, which achieves 100% accuracy    neural models. pyvene supports customizable in-\non the task. We then train our interventions and    terventions with complex intervention schemes as\nprobes at the Transformer block output at each   well as different families of model architectures,\nlayer and token position. For intervention training,   and intervened models are shareable with others\nwe construct pairs of examples and train the inter-   through online model hubs such as HuggingFace.\nvention to match the desired counterfactual output   Our hope is that pyvene can be a powerful tool for\n(i.e., if we swap activations from an example with    discovering new ways in which interventions can\na male name into another example with a female    help us explain and improve models.\nname, the desired counterfactual output should be\n“he”). For linear probe training, we use activation\ncollection intervention to retrieve activations to pre-   References\ndict the pronoun gender with a linear layer.                                                David Bau. 2022.   BauKit.   https://github.com/\n  As shown in Figure 3, a trainable intervention      davidbau/baukit.\n\n\n                                         6\n\nStella Biderman, Hailey Schoelkopf, Quentin Gregory    Zhezhi He, Adnan Siraj Rakin, and Deliang Fan. 2019.\n  Anthony, Herbie Bradley, Kyle O’Brien, Eric Hal-      Parametric noise injection: Trainable randomness\n   lahan, Mohammad Aflah Khan, Shivanshu Purohit,       to improve deep neural network robustness against\n  USVSN Sai Prashanth, Edward Raff, Aviya Skowron,       adversarial attack. In IEEE/CVF Conference on Com-\n  Lintang Sutawika, and Oskar Van Der Wal. 2023.      puter Vision and Pattern Recognition (CVPR).\n   Pythia: A suite for analyzing large language models\n   across training and scaling. In International Confer-   John Hewitt and Christopher D Manning. 2019. A struc-\n  ence on Machine Learning (ICML).                          tural probe for finding syntax in word representations.\n                                                          In North American Chapter of the Association for\nLawrence Chan,  Adrià  Garriga-Alonso,  Nicholas      Computational Linguistics (NAACL).\n  Goldowsky-Dill, Ryan Greenblatt, Jenny Nitishin-\n   skaya, Ansh Radhakrishnan, Buck Shlegeris, and    John Hewitt, John Thickstun, Christopher Manning, and\n  Nate Thomas. 2022. Causal scrubbing: a method for      Percy Liang. 2023. Backpack language models. In\n   rigorously testing interpretability hypotheses. Align-      Association for Computational Linguistics (ACL).\n  ment Forum Blog post.\n                                                 Michael A Lepori, Thomas Serre, and Ellie Pavlick.\nArthur Conmy, Augustine N Mavor-Parker, Aengus      2023. Uncovering intermediate variables in trans-\n  Lynch, Stefan Heimersheim, and Adrià Garriga-      formers using circuit probing. arXiv:2311.04354.\n  Alonso. 2023.  Towards automated circuit discov-\n   ery for mechanistic interpretability. In Advances in   Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter\n  Neural Information Processing Systems (NeurIPS).         Pfister, and Martin Wattenberg. 2023a.  Inference-\n                                                       time intervention: Eliciting truthful answers from a\nYanai Elazar, Shauli Ravfogel, Alon Jacovi, and Yoav      language model. In Advances in Neural Information\n  Goldberg. 2020. Amnesic probing: Behavioral ex-      Processing Systems (NeurIPS).\n   planation with amnesic counterfactuals. In Transac-\n   tions of the Association of Computational Linguistics    Maximilian Li, Xander Davies, and Max Nadeau. 2023b.\n  (TACL).                                                   Circuit breaking: Removing model behaviors with\n                                                              targeted ablation. arXiv:2309.05973.\nJaden Fiotto-Kaufman. 2023. nnsight. https://github.\n  com/JadenFiotto-Kaufman/nnsight.                Evan Lloyd. 2023. graphpatch. https://github.com/\n                                                        evan-lloyd/graphpatch.\nAtticus Geiger, Hanson Lu, Thomas Icard, and Christo-\n  pher Potts. 2021. Causal abstractions of neural net-   Kevin Meng, David Bau, Alex Andonian, and Yonatan\n  works. In Advances in Neural Information Process-      Belinkov. 2022. Locating and editing factual associ-\n   ing Systems (NeurIPS).                                   ations in GPT. In Advances in Neural Information\n                                                        Processing Systems (NeurIPS).\nAtticus Geiger, Kyle Richardson, and Christopher Potts.\n  2020. Neural natural language inference models par-   Dan Mossing, Steven Bills, Henk Tillman, Tom Dupré la\n   tially embed theories of lexical entailment and nega-      Tour, Nick Cammarata, Leo Gao, Joshua Achiam,\n   tion. In Proceedings of the Third BlackboxNLP Work-      Catherine Yeh, Jan Leike, Jeff Wu, and William\n  shop on Analyzing and Interpreting Neural Networks      Saunders. 2024.  Transformer debugger.  https:\n   for NLP, Online.                                      //github.com/openai/transformer-debugger.\n\nAtticus Geiger, Zhengxuan Wu, Hanson Lu, Josh    Neel Nanda and  Joseph Bloom.  2022.    Trans-\n  Rozner, Elisa Kreiss, Thomas Icard, Noah Good-      formerlens.    https://github.com/neelnanda-io/\n  man, and Christopher Potts. 2022. Inducing causal      TransformerLens.\n   structure for interpretable neural networks. In Inter-\n   national Conference on Machine Learning (ICML).    Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\n                                                           Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz\nAtticus Geiger, Zhengxuan Wu, Christopher Potts,       Kaiser, and Illia Polosukhin. 2017. Attention is all\n  Thomas Icard, and Noah D. Goodman. 2023. Find-     you need. In Advances in Neural Information Pro-\n   ing alignments between interpretable causal variables       cessing Systems (NeurIPS).\n  and distributed neural representations.  In Causal\n  Learning and Reasoning (CLeaR).                     Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov,\n                                                    Sharon Qian, Daniel Nevo, Yaron Singer, and Stuart\nMor Geva, Jasmijn Bastings, Katja Filippova, and Amir       Shieber. 2020. Investigating gender bias in language\n  Globerson. 2023.  Dissecting recall of factual as-      models using causal mediation analysis. In Advances\n   sociations in auto-regressive language models.  In       in Neural Information Processing Systems (NeurIPS).\n  Empirical Methods in Natural Language Processing\n  (EMNLP), Singapore.                            Kevin Wang, Alexandre Variengien, Arthur Conmy,\n                                              Buck Shlegeris, and Jacob Steinhardt. 2023. Inter-\nNicholas Goldowsky-Dill, Chris MacLeod, Lucas Sato,       pretability in the wild: A circuit for indirect object\n  and Aryaman Arora. 2023. Localizing model behav-       identification in GPT-2 small. In International Con-\n   ior with path patching. arXiv:2304.05969.                ference on Learning Representations (ICLR).\n\n\n                                         7\n\nZhengxuan Wu, Atticus Geiger, Thomas Icard, Christo-\n  pher Potts, and Noah Goodman. 2023. Interpretabil-\n   ity at scale: Identifying causal mechanisms in Alpaca.\n   In Advances in Neural Information Processing Sys-\n  tems (NeurIPS).\n\n\n\n\n\n                                         8\n\n## Claim to Classify\n\"pyvene supports customizable interventions on a range of different PyTorch modules\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Intervention as a library feature (supports activation patching, ablation, etc.)",
    "method_rung": 2,
    "claim_rung": 1,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The claim 'pyvene supports customizable interventions on a range of different PyTorch modules' is a descriptive statement about the library's functionality, not an empirical claim about model internals. It states what the tool enables (interventions), but does not make a claim about causal or mechanistic properties of a model. Thus, it is best classified as Rung 1 (observational/associational) because it describes capabilities without asserting causal or counterfactual relationships. The method used by the paper (intervention techniques like activation patching, ablation, DAS) is Rung 2, but this specific claim is not making a Rung 2 or 3 assertion. No hedging is present, but the claim is appropriately aligned with the method's capabilities. Confidence is high because this is a straightforward description of tool functionality, not an overclaim."
  },
  "metadata": {
    "model": "qwen/qwen3-235b-a22b-2507",
    "usage": {
      "prompt_tokens": 13387,
      "completion_tokens": 242,
      "total_tokens": 13629
    },
    "finish_reason": "stop"
  }
}