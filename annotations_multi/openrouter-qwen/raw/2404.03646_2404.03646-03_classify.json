{
  "timestamp": "2026-02-19T11:04:41.618272+00:00",
  "paper_id": "2404.03646",
  "claim_id": "2404.03646-03",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2404.03646\nTitle: Locating and Editing Factual Associations in Mamba\nFull text:\n                      Published as a conference paper at COLM 2024\n\n\n\n              Locating and Editing Factual Associations in Mamba\n\n\n                   Arnab Sen Sharma∗, David Atkinson, and David Bau\n                    Khoury College of Computer Sciences, Northeastern University\n\n\n                                                 Abstract\n\n                    We investigate the mechanisms of factual recall in the Mamba state space model.\n                          Our work is inspired by previous findings in autoregressive transformer language\n                           models suggesting that their knowledge recall is localized to particular modules\n                                     at specific token locations; we therefore ask whether factual recall in Mamba can\n                            be similarly localized. To investigate this, we conduct four lines of experiments2024\n                           on Mamba. First, we apply causal tracing or interchange interventions to localize\n                            key components inside Mamba that are responsible for recalling facts, revealing\n                                   that specific components within middle layers show strong causal effects at theAug                              last token of the subject, while the causal effect of intervening on later layers is\n                           most pronounced at the last token of the prompt, matching previous findings on2\n                                 autoregressive transformers. Second, we show that rank-one model editing methods\n                            can successfully insert facts at specific locations, again resembling findings on\n                               transformer LMs. Third, we examine the linearity of Mamba’s representations\n                               of factual relations. Finally we adapt attention-knockout techniques to Mamba\n                                  in order to dissect information flow during factual recall. We compare Mamba\n                                    directly to a similar-sized autoregressive transformer LM and conclude that despite[cs.CL]                            significant differences in architectural approach, when it comes to factual recall,\n                                 the two architectures share many similarities.\n\n\n                1  Introduction\n\n                       Studies of autoregressive transformer language models’ (LMs) processing of factual statements such\n                       as The Eiffel Tower is located in Paris, have identified a localized pattern of internal computations\n                  when recalling facts (Meng et al., 2022a;b; Geva et al., 2023; Hernandez et al., 2023; Nanda et al.,\n                       2023), and have further found that those LMs can be edited by making single-layer rank-one changes\n                          in model parameters to alter a specific fact. Although these localized phenomena appear to generalize\n                       across autoregressive transformer LMs, the extent to which similar locality might appear in very\n                          different architectures—such as recurrent networks (RNNs)—has not yet been investigated.\n\n                       In this paper we investigate the internal mechanisms of Mamba (Gu & Dao, 2023), a recently-\n                      proposed state-space language model, a type of RNN that achieves per-parameter performance that is\n                      competitive with transformers. Specifically, we ask whether factual recall within Mamba exhibitsarXiv:2404.03646v2                          locality similar to the patterns observed in autoregressive transformer language models.\n\n                   Our paper is a case study confronting a key methodological challenge that broadly faces interpretabil-\n                            ity researchers: as state-of-the-art neural network architectures evolve, we must ask, can the detailed\n                         analytical methods and tools developed for one neural architecture, such as transformer LMs, be\n                       generalized and applied to a different neural architecture, such as Mamba? In this paper we are able\n                         to answer the question with a qualified “yes”: we find that many of the methods used to analyze\n                        transformers can also provide insights on Mamba. We also discuss mismatches—that is, interpretation\n                    methods (such as path-dependent attention patching) that do not transfer to Mamba as easily due to\n                         architectural constraints.\n\n               We begin by studying whether activation patching (Wang et al., 2022) can be successfully applied\n                         to Mamba. Known variously as causal mediation analysis (Vig et al., 2020), causal tracing (Meng\n                          et al., 2022a), and interchange interventions (Geiger et al., 2021), activation patching techniques\n                     can successfully identify specific model components in transformer LMs that play crucial roles in\n                      performing a task. We ask whether Mamba can be productively studied the same way, even though\n\n                          ∗Correspondence to sensharma.a@northeastern.edu, Code available at romba.baulab.info\n\n\n                                                           1\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n\nthe architectural components of Mamba are very different: for example, instead of attention heads and\nMLP modules, Mamba is composed of convolutions, gates, and state-space modules. To answer, we\nadapt activation patching to Mamba, and ask if any sparsity patterns emerge which provide insights\ninto the respective roles of its components.\n\nWe also study whether rank-one model editing can be applied to Mamba. While studies of trans-\nformers (Meng et al., 2022a;b; Hase et al., 2024) have found that there are a range of MLP modules\nwithin which factual knowledge can be inserted by making a single rank-one change in parameters,\nMamba does not have MLP modules, so we ask if there are any other modules that can be similarly\nedited to insert knowledge. As with previous studies of transformers, the key question is whether\nfactual associations can be edited with both specificity (without interfering with unrelated facts) and\ngeneralization (while remaining robust to rewordings of the edited fact).\n\nFinally, we apply methods for understanding the overall information flows in Mamba. Inspired by the\nfindings of Hernandez et al. (2023), we measure the linearity of the relations between subject and\nobject embeddings. And inspired by Geva et al. (2023), we examine information flow by adapting\nattention-blocking methods to the attention-free Mamba architecture.\n\nIn this work we conduct our experiments on Mamba-2.8b, the largest available LM in Mamba family,\nand for comparison we conduct the same experiments on the similarly sized Pythia-2.8b (Biderman\net al., 2023) autoregressive transformer LM.\n\n2  Background on Mamba\n\nMamba, introduced in Gu & Dao (2023), is a recent family of language models based on state space\nmodels (SSMs). SSMs are designed to model the evolution of a hidden state across time with a\nfirst-order differential equation (Koopman et al., 1999; Durbin & Koopman, 2012), and when they\nare used as the recurrent state of an RNN, they can enable highly efficient parallelized training (Gu\net al., 2021). To achieve good performance in language modeling, the Mamba SSM introduces\ninput-dependent parameterization or selective-SSM instead of the traditional time-invariant SSMs.\nMamba uses a special architecture called MambaBlock1, which is stacked homogeneously, replacing\nboth attention and MLP blocks used in transformer layers. Here, we focus on the different operations\nperformed inside a MambaBlock.\nFormally, Mamba is an autoregressive lan-            ai-1ℓ\nguage model: M  : X →Y over a vo-  hiℓ-1                                        hℓicabulary V that maps a sequence of tokens\nx = [x1, x2, . . . , xT] ∈X ,  xi ∈V to            ℓ      ℓ                              ℓ           ℓ       ℓ\n                                                                                                                                                                                                                                       i                                                                                                                                                i   Conv + SSM   si     Wo   o                               Wa   ay ∈Y ⊂R|V| which is a probability dis-\ntribution over the next token continuations                                                                                                                                ℓ                                                           ℓ        σ       giof x. Similar to other deep LMs, in Mamba,     Wg\na token xi is first embedded to a hidden\n            = emb(xi). Then  Figure 1: Architecture of a MambaBlock. Projection ma-state of size d as h(0)i\n                                                      trices Wℓa and Wℓg have the shape 2d × d, while Wℓo has the      is transformed sequentially by a seriesh(0)i                                           shape d × 2d. h, a, g, s, and o are intermediate states of a to-\n                                           ken representation. σ is SiLU activation and ⊗is elementwiseof MambaBlocks. The hidden state h(ℓ)i\nafter the ℓth (1-indexed) MambaBlock is   multiplication. Conv + SSM operation abstracts the Conv1D\n                                         and selective-SSM operations.\ncomputed as follows:\n\n\n                                                                                                    (1)                                          h(ℓ)i                      = h(ℓ−1)i                           + o(ℓ)i\n\n             is the output of ℓth MambaBlock for the ith tokenwhere o(ℓ)i\n\n\n                                                                                                    (2)             o(ℓ)i                                = W(ℓ)o    s(ℓ)i  ⊗g(ℓ)i        = MambaBlock(ℓ)  h(ℓ−1)1       , h(ℓ−1)2       , . . . , h(ℓ−1)i\n\n                                                                                          is calculated as:Here, ⊗represents element-wise multiplication or Hadamard product. s(ℓ)i\n\n    1In their paper, Gu & Dao (2023) call this component Mamba—the same name as the LM family.\n\n\n                                       2\n\nPublished as a conference paper at COLM 2024\n\n\n\n                                                                              Average IE of restoring hi(l) over 400 facts\n                                                                                                                                                               0.8\n               Clean Run, G                        Patched Run, G*[←hiℓ]               prefix\n      Michael                            [PAD]                                    subject_[:-2]*                                            0.6\n                                                                                                subject_2nd_last*               early site\n        Jordan                                   Pelé                                                                                             0.4\n                                                                                                           subject_last*\n professionally                            professionally                                     further tokens                                   late site       0.2\n        played                                played                                               last token\n                                                                                                                                                               0.0\n                                   basketball                          p(ans)= ?                 0 5 10 15 20 25 30 35 40 45 50 55     IE\n                                                 (answer)                                                                     single restored layer within Mamba-2.8b\n\n                       (a) Activation patching                                                                         (b) Tracing the residual states, h(l)i\nFigure 2: (a) Activation patching. A state from the clean run G is patched into its corresponding position in the\ncorrupted run G∗. This has a downstream effect of potentially changing all the states that depend on the patched\nstate in G∗[←h(ℓ)i   ].                     (b) Average indirect effect of applying causal tracing on residual stream states  h(ℓ)i   in\nFigure 1  across 400 different facts from the RELATIONS dataset (see Appendix A.2).\n\n\n                                                                                                    (3)                   = W(ℓ)a  h(ℓ)i                                      a(ℓ)i\n\n                                                                                                    (4)                       c(ℓ)1   , c(ℓ)2   , . . . , c(ℓ)i                   = SiLU Conv1D  a(ℓ)1   , a(ℓ)2   , . . . , a(ℓ)i\n\n                                                                                                    (5)                                       s(ℓ)i                   = selective-SSM  c(ℓ)1   , c(ℓ)2   , . . . , c(ℓ)i\n\nWe abstract the operations in Equations 4 and 5 as the Conv + SSM operation in Figure 1. At\na high level, Conv + SSM brings information from the past token representations to the current\ntoken representation. The purpose is similar to the attention blocks in transformer LMs. But, unlike\nattention operation, Conv + SSM scales linearly with the context length and thereby enjoys faster\ninference speed and longer context limits. See Gu & Dao (2023) for details.\n\n                                     (that does not pass through Conv + SSM operation) is a gatingThe output of the other path g(ℓ)i\nmechanism that regulates the information flow. This gating mechanism resemble parts of LSTM\n(Hochreiter & Schmidhuber, 1997) and GRU (Cho et al., 2014) networks, where similar gates control\nselective updates of recurrent state.\n\n                                                                                                    (6)                                      g(ℓ)i                    = SiLU W(ℓ)g  h(ℓ−1)i\nIn the remainder of the paper, we aim to characterize the role of the components of Mamba in factual\nrecall by adapting tools that have previously been used to analyze transformers. In Section 3, we\napply activation patching to localize factual recall as in Meng et al. (2022a), testing the roles of states\nsi, gi, and oi at all layers. In Section 4, following Meng et al. (2022a); Hase et al. (2024), we test\nrank-one edits of facts across components Wa, Wg, and Wo at each layer. In Section 5, we collect\nJacobians within Mamba to test the linearity of relational encodings as done by Hernandez et al.\n(2023). And in Section 6 we address the challenge of applying attention patching in Mamba, as used\nin Geva et al. (2023) to isolate information flow in GPT LMs.\n\n3  Locating Key States for Factual Recall\n\nWe begin with activation patching, seeking to understand if there are specific hidden states which play\nimportant roles during factual recall. We select a fact (s, r, o) that the LM knows, where r is a relation\nthat associates a subject entity s with an object entity o. To estimate each state’s contribution towards\na correct factual prediction (s = Michael Jordan, r = professionally played, o = basketball), we\ncollect model activations across three different runs:\n\nclean run  G: In the clean run, we simply run the model on a prompt specifying the fact we are\ninterested in. For example, x = (s, r) = Michael Jordan professionally played. We cache all the\n                                                                                                  | i ∈[1, T], ℓ∈[1, L]  .hidden states during the clean run to be used later:  h(ℓ)i   , a(ℓ)i   , s(ℓ)i   , g(ℓ)i\ncorrupted run  G∗: In the corrupted run, we swap s with a different subject s∗(Pelé) such that the\nLM gives a different answer o∗(soccer) to the modified prompt x∗= (s∗, r) (i.e., o∗̸= o).\n\nThis subject-swapping approach follows the recommendation of Zhang & Nanda (2023) and has the\nadvantage of using natural text perturbations to avoid introducing out-of-domain states to the model’s\n\n\n                                       3\n\nPublished as a conference paper at COLM 2024\n\n\n\n        (a) Average IE of restoring oi(l) over 400 facts           (b) Average IE of restoring gi(l)               (c) Average IE of restoring si(l)\n                                                              0.5                                                0.5                                                0.5\n            prefix\n                                                              0.4                                                0.4                                                0.4\n    subject_[:-2]*\n\nsubject_2nd_last*       early site                             0.3             early site                           0.3                                                0.3\n\n     subject_last*                                            0.2                                                0.2                                                0.2\n\n    further tokens                              late site           0.1                                                0.1                                  late site           0.1\n          last token\n                                                              0.0                                                0.0                                                0.0\n                0 5 10 15 20 25 30 35 40 45 50 55     IE       0 5 10 15 20 25 30 35 40 45 50 55     IE       0 5 10 15 20 25 30 35 40 45 50 55     IE\n                     center of interval of 10 patched layers                center of interval of 10 patched layers               center of interval of 10 patched layers\n\nFigure 3: Average indirect effect of different states o(ℓ)i   , g(ℓ)i   , and s(ℓ)i   over 400 facts from the RELATIONS\ndataset (see Appendix A.2). For each layer ℓ, states for a window of 10 layers around ℓare restored from the\nclean run G.\n\ncomputation, as may happen when corrupting s embeddings with Gaussian noise (the method used in\nMeng et al. (2022a)).\n\n                                     ]: In the patched run, we run the model on the corrupted prompt x∗, butpatched run  G∗[←h(ℓ)i\n              by replacing its value with the corresponding state cached from the clean run G. Theintervene on h(ℓ)i\nremainder of the computation is run normally, meaning that the patched state can have a downstream\neffect of potentially changing all the states that depend on it. See Figure 2a.\n\n                                 denote the probability assigned to the correct answer o in G,Let p(o), p∗(o), and p∗[←h(ℓ)i  ](o)\n                                                                        in recalling the fact (s, r, o),G∗, and G∗[←h(ℓ)i                            ] respectively. To measure the contribution of h(ℓ)i\nwe define its indirect effect (IE) as:\n                                 p∗[←h(ℓ)i  ](o) −p∗(o)\n                                     IEh(ℓ)i =     p(o) −p∗(o)                                     (7)\n\n\n                                                                               across differentIn Figure 2b we plot the average indirect effect of restoring the residual states h(ℓ)i\nlayer-token positions over 400 facts from the RELATIONS dataset (Hernandez et al., 2023). The high\nIE observed at the late site (later layers at the last token) position is natural, as restoring a clean\n     there will restore most of the model computation from G. However, Mamba also shows highh(ℓ)i\ncausality at the early site (early-middle layers at the last subject token position). This is consistent\nwith what Meng et al. (2022a) observed in the GPT family of language models.\n\n                                                                            ,In Figure 3 we plot the average IE for o(ℓ)i                                                                    , g(ℓ)i                                             G*\n                           (Figure 3a) looksand s(ℓ)i             . The plot for o(ℓ)i\nvery similar to Figure 2b, confirming that the\noutput from MambaBlock has strong causal ef-\nfects at both early and late sites. Interestingly,                   ℓ\n                                                                (a) hi from G             (b) Blocking siFigure 3c shows that the selective-SSM outputs\ns(ℓ)i    have high IE only at the late site, resem-  G* [←hiℓ ]\nbling the behavior of attention modules in GPT\nmodels (Meng et al., 2022a). However, there is\nno state that appears to do the opposite; in other\nwords, there is no state with strong effects at the\nearly site and not at the late site (The gate out-           hℓi           gℓi           oℓi        sℓi\n       does have stronger IE at the early site,put g(ℓ)i\nbut these effects are very weak). To compare\n                                              Figure 4: To probe for path-specific effects, (a) h(ℓ)i   iswith autoregressive transformer LMs, activation\n                                                       restored from the clean run G as in Figure 2a. (b) Then,\npatching results for Pythia-2.8b is shown in Fig-\n                                                        to reveal the role of the Conv + SSM contributions, si\nure 10 in Appendix D. This comparison reveals                                                           states from the corrupted run G∗are also patched to\na key way how Mamba differs from transform-  block the contributions from those paths.\ners: while transformer MLP outputs have effects\nin the early site and not the late site, in Mamba there is no similar state that specializes only at the\nearly site, at which factual recall would be expected to occur. This presents the question: which\nparameters in Mamba mediate factual recall?\n\n\n                                       4\n\nPublished as a conference paper at COLM 2024\n\n\n                  IE with hi(l) restored          si blocked           gi blocked             oi blocked\n       1.00\n  IE 0.75  (a) i = subj last\n\n       0.50\n        Average 0.25\n\n       0.00\n          (b) i = prompt last\n       1.00\n  IE\n       0.75\n\n       0.50        Average 0.25\n\n       0.00\n               0       5      10      15      20      25      30      35      40      45      50      55      60\n                                                         Layers\n\nFigure 5: Impact of ablating si, gi, and oi on IEh(ℓ)i  for (a) subject last and (b) prompt last token positions.\nTaken together (a) and (b) show a clear separation roles between early-mid and later layers in Mamba-2.8b.\nh(ℓ)i  up to layer 46 only show strong IE at the subject last token position and have negligible impact after that.\n                jumps to 1.0 after layer 46. (a) also shows that, at the subject last token, before layer 27 −28,Whereas IE of h(ℓ)i\nIEh(ℓ)i   is significantly reduced by blocking either oi, gi, or si paths  sorted in descending order of damaging\nIEh(ℓ)i     . (b) At the prompt last token, ablating oi or si paths can significantly reduce IEh(ℓ)i  in layers 47 −50.\nTo investigate this question, we replicate an experiment from Meng et al. (2022a) to probe path-\nspecific effects (Pearl, 2022) by severing a path from the causal graph and monitoring its effect.\nHere, we are interested in understanding the effect of the contributions from gi, si, and oi (i.e.\nstates that are processed by Wg, Conv + SSM, and Wo respectively) while recalling a fact. First,\nin the corrupted run G∗, at token position i, we cache all the contributions from the si paths as\n                                                                                     that was cached froms∗i = {s∗(ℓ)i                | ℓ∈[1, L]}. Then in the patched run G∗[←h(ℓ)i                                                                                         ], we restore h(ℓ)i\nthe clean run G into its corresponding state (as in Figure 2a), but with an additional modification:\nto understand the contribution from the si paths, we sever those paths by also patching s∗i (cached\nfrom the corrupted run G∗) to their corresponding locations (see Figure 4). The same experiment is\n                                                                                              will severreplicated to understand the contributions of gi and oi states. We note that severing the o(ℓ)i\n             as well (see Figure 1).s(ℓ)i    and g(ℓ)i\nIn Figure 5 we plot the average results of this experiment for token positions (a) i = subject last and\n(b) i = prompt last over 400 examples randomly sampled from the RELATIONS dataset. The key\nfindings can be understood by examining the gap between the purple bars and the green, red, and\nblue bars: a large gap indicates a strong mediating role for Conv + SSM, Wg, or Wo parameters,\nrespectively. At the early site at the subject last token, both the Conv + SSM and Wg have a strong\nrole, but Wo plays an even larger role than either. Yet the strongest mediator at the late site is also\nWo. This experiment highlights the importance of Wo in both stages of predicting a fact. But it also\nsuggests that Mamba does not separate early-site factual recall between these groups of parameters\nas cleanly as transformers. However, Figure 5 reveals a clean separation of roles between early to\nmid and later layers, analogous to the findings of Hernandez et al. (2023) in transformer LMs. We\nalso note that this division of responsibilities between layers can be more sharply noticed in Mamba\nwhen compared to transformers LMs (compare Figure 5 with Figure 11).\n\n4  Editing Facts With ROME\n\nHaving begun to characterize the locations of important states for factual recall, we now investigate\nwhether factual recall behavior can be edited. In particular, we apply the ROME (Rank One Model\nEditing, Meng et al., 2022a) technique to Mamba. ROME begins with the observation that any\nlinear transformation can be considered as an associative memory (Anderson, 1972; Kohonen, 1972),\nmapping a set of keys K = [k1|k2| . . . ] to their corresponding values V = [v1|v2| . . . ], and uses this\nto edit factual associations in transformer LMs. Here, we apply the technique to a particular set of\nlinear transformations within Mamba, and report our editing success on each.2\n\n    2Further motivating these experiments, previous work has shown that the locations identified by activation\npatching techniques are not necessarily those which have the strongest edit performance (Hase et al., 2024).\n\n\n                                       5\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n                                                                                                                             (l)                 (l)                   (l)\n                   (a) ROME performance on Mamba-2.8b     Wa      Wg      Wo\n\n           Efficacy (ES)                 Generalization (PS)                Specificity (NS)                   Score (S)\n100                             100                             100                             100\n\n 75                              75                              75                              75\n\n 50                              50                              50                              50\n\n 25                              25                              25                              25\n\n  0  0  5 10 15 20 25 30 35 40 45 50 55 60       0  0  5 10 15 20 25 30 35 40 45 50 55 60       0  0  5 10 15 20 25 30 35 40 45 50 55 60       0  0  5 10 15 20 25 30 35 40 45 50 55 60\n              Edit Layer                         Edit Layer                         Edit Layer                         Edit Layer\n\n                                                                                                                                                 (l)\n                              (b) ROME performance on Pythia-2.8b       Wdown\n\n           Efficacy (ES)                 Generalization (PS)                Specificity (NS)                   Score (S)\n100                             100                             100                             100\n\n 75                              75                              75                              75\n\n 50                              50                              50                              50\n\n 25                              25                              25                              25\n\n  0                               0                               0                               0\n     0  3  6  9 12 15 18 21 24 27 30         0  3  6  9 12 15 18 21 24 27 30         0  3  6  9 12 15 18 21 24 27 30         0  3  6  9 12 15 18 21 24 27 30\n              Edit Layer                         Edit Layer                         Edit Layer                         Edit Layer\n\nFigure 6: ROME performance in editing facts across different layers (a) by modifying W(ℓ)a   , W(ℓ)g   ,\n                                                  in Pythia-2.8b. Results are reported on the first 2000W(ℓ)o  in Mamba-2.8b, and (b) modifying W(ℓ)down\nexamples in the COUNTERFACT dataset.\n\n\nThe input to ROME is a prompt x = (s, r), where s (Emmanuel Macron) is a subject entity and r\n(is the President of) is a relation. ROME also takes a counterfactual object o∗(England), meant to\nreplace the correct object o (France) in the model’s output. To effect that change, ROME generates\na rank-one update to W(ℓ)   the down-projection matrix of the MLP module for the last token of                        down,\nthe subject at layer ℓ—which plays the role of the associative memory. In generating the rank-one\nupdate, ROME considers the input to W(ℓ)                                            as the key (k∗). Then, with gradient descent ROME                                       down\n                                                                            the model will output o∗.calculates a value (v∗) such that, when v∗is inserted as the output of W(ℓ)down,\nImportantly, while optimizing v∗, ROME attempts to minimize unrelated changes in model outputs\n(Joe Biden, for example, should still be mapped to the United States post-edit). Finally, ROME adds\n                         such that  W(ℓ)a rank-1 matrix ∆to W(ℓ)                       + ∆ k∗≈v∗. (See Meng et al. (2022a) for details.)                      down                                       down\n\n4.1  Applying ROME in Mamba\n\nWe apply ROME on the three different projection matrices of Mamba: W(ℓ)a  which affects only\nthe Conv + SSM path, W(ℓ)g  which affects only the gating path, and W(ℓ)o   , the final output of\nthe MambaBlock, which is added to the residual state. We plot ROME performance on different\nprojection matrices  W(ℓ)a   , W(ℓ)g   , and W(ℓ)o   across all the layers in Figure 6a.\n\nTo evaluate editing performance, we use the COUNTERFACT dataset from Meng et al. (2022a).\nCOUNTERFACT contains 20K counterfactual examples in the form (s, r, o →o∗), where o is the\ncorrect answer to the prompt x = (s, r), and o∗is the object which is to be inserted as the new answer\nto the prompt (See Appendix A.1 for details). We select the first 2000 examples from this dataset for\nour module-layer sweep. We use the original evaluation matrices in Meng et al. (2022a) to measure\nROME edit performance.\n\nThe final score (S) in the ROME evaluation suite is the harmonic mean of three different scores:\n\n 1. Efficacy (ES): For an edit request (s, r, o →o∗), we say the edit is effective if, post-edit, the LM\n    assigns p(o∗) > p(o) in response to the prompt x = (s, r). Efficacy reflects the portion of the\n   examples where the edit was effective.\n\n 2. Generalization (PS): A successful edit should be persistent across different paraphrases of (s, r).\n    For each of the request instances (s, r, o →o∗), p(o∗) > p(o) is checked post-edit with a set of\n    different rephrasings xp ∼Pr(s) of the prompt x = (s, r), where Pr denotes a set of paraphrased\n    templates for the relation r.\n\n\n                                       6\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n 3. Specificity (NS): Finally, the edit should be specific to Pr(s) and should not additionally change\n    the mapping of some nearby subject sn to o∗. To evaluate the specificity of an edit we measure\n    p(on) > p(o∗) with Pr(sn) for a set of nearby factual associations {(sn, r, on) | on ̸= o∗}.\n\nFigure 6a shows that ROME can achieve high scores (S) for a range of early to middle layers by\nmodifying any one of the projection matrices W(ℓ)a   , W(ℓ)g   , or W(ℓ)o   , matching observations made by\nHase et al. (2024) regarding transformer LMs. However, we found that performance does depend on\nthe location of the edit. For example, in the case of W(ℓ)g  and W(ℓ)o   , the score (S) and generalization\n(PS) drops after around layer 43.  This is consistent with our findings from the path-blocking\nexperiment in Figure 5a. We also find that edits to W(ℓ)a  have poor generalization (PS) in early layers,\nwhereas high PS can be achieved at early layers by modifying either W(ℓ)g  or W(ℓ)o   , consistent with\ntheir higher indirect effects as seen in Figure 5a.\nWhere is the right place to apply ROME on Mamba? Figure 3 could suggest W(ℓ)g   , since the causal\neffect of gi states is mostly concentrated at the subject last token, similar to the behavior of MLPs\nin transformers (Meng et al., 2022a).  Consistent with this is the architectural fact that, just as\ntransformers’ W(ℓ)  connects to attention modules only through the residual stream, the output of               down\nW(ℓ)g  does not flow through the Conv + SSM module—a module that other work has suggested might\nplay a role similar to that played by attention heads in transformers (Grazzi et al., 2024). And, indeed,\nwe find that ROME can successfully insert facts by modifying W(ℓ)g   . On the other hand Figure 6a\nreveals sudden drops in efficacy and generalization at middle layer gates, suggesting that W(ℓ)g  may\nbe an unreliable mediator at some layers. Our experiments further show that the best performance for\nROME is empirically achieved by modifying W(ℓ)o   . This is consistent with the fact that oi states show\na stronger causal effect at the subject last token than gi states do (see Figures 3a and 5a). Additionally,\nROME achieves better generalization (PS), competitive specificity (NS), and an overall better score\n(S) with W(ℓ)o   . We hypothesize that the strong performance of W(ℓ)o  may be due to the the separation\nof roles between early-mid and later layers observed in Figures 2b, 3a, and 5. Also see Appendix C\nwhere we isolate the contribution of W(ℓ)o  by subtracting   +     from          , which reveal a                                                                    IEs(ℓ)i     IEg(ℓ)i         IEo(ℓ)i\ncritical role of W(ℓ)o  in early-mid layers at subject last token position while mediating a fact.\n\nWe plot ROME performance for a similar sized Pythia model on Figure 6b for comparison.\n\n5  LINEARITY OF RELATION EMBEDDING (LRE)\n\nWith activation patching we can identify where facts are located inside a LM. We are also interested\nin understanding how LMs extract this information given x = (s, r). Figures 2b and 5 show a clear\nseparation of roles in early-mid and later layers in Mamba. We observe a similar phenomenon in\nautoregressive transformer LMs (Meng et al., 2022a;b; Geva et al., 2023). According to Geva et al.\n(2023), in transformer LMs, the subject entity representation s, at the subject last token position, goes\nthrough an enrichment process, mediated by the MLP in the early-mid layers, where s is populated\nwith different facts/attributes relevant to the subject entity s. Then, at the last token position, attention\nmodules perform a query on the enriched s to extract the answer to the prompt x = (s, r). Hernandez\net al. (2023) approximate the query operation performed on the enriched s for a specific relation r by\ntaking the first order Taylor series approximation (LRE) of the LM computation F as\n\n                                  F(s, r) ≈β Jρs + b\n                     \"      #          \"              #                        ∂F\n            where J = Esi,r                                                                      ,  b = Esi,r  F(s, r) −∂F s             ,               (8)\n                            ∂s  (si,r)                        ∂s     (si,r)\n                       β is a scalar , and  ρ is the rank of J\n\nHernandez et al. (2023) show that for a range of different relations it is possible to achieve a LRE\nthat is faithful to the model computation F by averaging the approximations of J and b calculated\non just n = 5 examples. We utilize LRE to understand the complexity of decoding factual relations\n\n\n                                       7\n\nPublished as a conference paper at COLM 2024\n\n\n\n                LRE faithfulness for factual relations in Mamba-2.8B\n                 1.0\n                 0.9\n                 0.8\n                 0.7\n                 0.6\n                 0.5\n                 0.4                                     Faithfulness 0.3\n                 0.2\n                 0.1\n                 0.0\n                                             city                                                 band\n                        of                               pro                                         language continent language city                                                                                            university sport                                                                                      birth company person currency country hq name         evolution father countryin mother CEO                                                                                                                                    occupation position countryin instrument year                                                                              largest                                                         capital                                    by        from company           archnemesis      person                                                                                                                                                                         person company            on               plays      singer     sport city                               native       country      person                              plays                  superhero country                                                         country              country lead person                                                                                                                                                                                                                                                                                                              constellation       pokemon                                                                                                                                                           president                                                                                                                                                                                                                          landmark                                                                                                                               product        food                                                                                     person                               person landmark                                                      person                        star superhero                                                                         person\nFigure 7: LRE faithfulness with n = 5 samples for all the factual relations. Horizontal red lines indicate random\nchoice baseline (in the RELATIONS dataset).\n\nin Mamba. We find the hyperparameters β, ρ and the layer ℓ(where to extract the enriched s from)\nusing grid search. For mathematical and implementation details, see Hernandez et al. (2023).\n\nWe plot the faithfulness of LRE with n = 5 samples on Figure 7. The metric faithfulness represents\nthe portion of facts (s, r, o) that can be correctly retrieved if the LM computation F(s, r) is replaced\nwith LRE(s), a simple affine transformation.\n\nWe only calculate LRE for the factual relations in the RELATIONS dataset. Figure 7 shows that\nonly for 10 out of 26 factual relations can a linear LRE achieve more than 50% faithfulness. For\ncomparison, in the same sized Pythia-2.8b LRE achives > 50% faithfulness for 11 factual relations\n(see Appendix E). And, in both Mamba and Pythia, LRE fails to achieve good faithfulness for the\nrelations where the range (the number of unique answers) is large. These findings align with what\nHernandez et al. (2023) observed on GPT and LLaMA models; suggesting that, similar to transformer\nLMs, factual knowledge might be heterogeneously represented for different relations in Mamba.\n\n6  Attention Knock-out in Mamba?\n\nAttention modules mediate the flow of information across different token positions in transformer\nLMs. In attention “knock-out” experiments the information that flows through a specific edge (from\nkth token to qth token) via a certain attention head is blocked to understand if critical information\nflows through that edge. This is also a form of causal mediation analysis and it has been effective in\nunderstanding the information flow in transformer LMs (Geva et al., 2023; Wang et al., 2022; Todd\net al., 2023). In Mamba, information from past tokens is retained in the si states, with the Conv +\nSSM operations (see Figure 1 and Equations 3–5). We ask, can we perform experiments similar to\nattention knock-out experiments in Mamba in order to understand how it moves factual information?\n\nWe find that performing similar experiments in Mamba can be difficult. The use of Conv with\na non-linearity in conjunction with selective-SSM make it challenging to remove the information\nretained in the qth token from the kth token (see Appendix B for details). However, it is possible to\nblock the propagation of information from the kth token to all the future tokens via Conv + SSM\noperation by mean-ablation. Specifically, for a layer ℓ, we set a(ℓ)                                                                           k  := E a(ℓ)  , where E a(ℓ)  is the\nmean of a(ℓ) states collected with 10,000 tokens from WikiText-103 by Merity et al. (2016). We\nrecognize that this intervention may not be as surgical as cutting a specific edge. However, with some\ncaveats, this experiment suggests that the factual information flow in Mamba is similar to what Geva\net al. (2023) observed in GPT LMs.\n\nWe randomly sample 700 facts across 6 factual relations from the RELATIONS dataset. For each of\nthose examples we block-out information propagation of the subject, non-subject, and the prompt-last\n\n\n                                       8\n\nPublished as a conference paper at COLM 2024\n\n\n\n\ntoken positions for a window of 10 layers around a specific layer ℓ. The effect of blocking out\nConv + SSM information flow for certain layer-token (ℓ−k) positions is measured as the relative\nchange in p(o) with  p o | a(ℓ)k :=E  a(ℓ)  −p(o) /p(o). Figure 8 shows the averaged result and it leads\nus to draw the following conclusions about how factual information flows in Mamba:\n\n\n\n                0.50\n\n               p(o)  0.25\n         in  0.00\n\n                0.25                          change\n                                   Relative  0.500.75\n\n\n                1.00\n\n                   0    5    10   15   20   25   30   35   40   45   50   55   60\n                                              Layer\n\n                              subject           subj_last           non-subject           prompt_last\n\n                                                                        to future tokens via si paths is blocked,Figure 8: Relative change in p(o) when information flow from a(ℓ)k\nwith k taking the value of either subject, non-subject, or the prompt_last token positions. For each layer ℓ, si\npaths were blocked for a window of 10 layers around ℓ.\n\n\n(a) The purple lines show that blocking out non-subject information flow in early middle layers\n    can bring down p(o) by up to 50%. Non-subject tokens are used to specify the relation r. This\n    observation leads us to believe that Mamba propagates relation specific information to future\n    tokens using Conv+SSM operations in early-middle layers.\n\n(b) Interestingly, the green lines (blocking the subject information flow) shows two valleys:\n\n     1. The first valley at the early layers is not surprising as Mamba needs to collate information\n       from all the subject tokens in early layers to recognize a subject entity s consisting of multiple\n        tokens.\n     2. However, the valley at layers 43-48 suggest that Mamba uses Conv + SSM paths in those\n        layers to propagate critical information from the subject to later tokens. This aligns with\n        Figures 5b and 3c, where si states in those layers show high indirect effects, indicating their\n        crucial role while recalling a fact.\n\n(c) The blue dashed lines indicate the effect of blocking the information of only the subject last\n    token. If the ablation is performed in very early layers, later layers can start to compensate for\n     that. However, the valley around layers 20-21 suggests that Mamba expects to recognize the full\n    subject entity by then in order to recall relevant associations (enrichment). Notably, activation\n    patching results for oi and si—states that we hypothesize take crucial part in the enrichment\n    process—also show strong indirect effect around that region (Figures 3a, 3b, and 5a). The blue\n     line follows the green line after layer 30. The weaker effect observed might be because ablating\n    subject last token is not always enough to remove all the subject information. For example, in\n     Eiffel Tower, Eiffel (tokenized as E, iff, el) is more informative than the last token Tower.\n\n\nThese findings align with how factual information flows through attention modules in autoregressive\ntransformer LMs, as observed by Geva et al. (2023) in GPT. However, unlike Geva et al. (2023), we\ncannot make strong claims about the unique role of the final token position (prompt-last) with this\nexperiment. As we block out information flow to all future tokens, the intermediate states in between\nthe ablated kth token and the last token are affected as well.\n\n\n                                        9\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n7  Related Works\n\nMamba.  Mamba is a recent family of language models that are based on state space models\n(SSMs). Neural SSM-based models have achieved good performance across different modalities,\nincluding vision (Nguyen et al., 2022), audio (Goel et al., 2022), and genomic sequences (Nguyen\net al., 2023). Only recently, however, with Mamba, have they become competitive with the language\nmodeling performance of transformers (Gu & Dao, 2023). Like transformers, Mamba contains factual\nknowledge about real world entities (Grazzi et al., 2024). However, knowledge representation in\nMamba (and other LMs based on SSMs) has up to now remained unexplored.\n\nThere are few works focused on interpreting Mamba. Ali et al. (2024) identify implicit attention-like\nmatrices formed by Mamba’s selective state space layers. Grazzi et al. (2024), while not strictly\nfocused on interpreting Mamba’s internals, apply linear probes to Mamba’s (decoded) intermediate\nstates during in-context regression tasks. Like us, they find substantial similarities between Mamba\nand transformer models: both architectures pursue “iterative” strategies, with the task loss falling\nmore or less monotonically as the layer index increases.\n\nLocating Factual Knowledge in Language Models. To make factually correct statements about the\nworld, a LM has to store factual knowledge about real world entities somewhere in its parameters.\nUnderstanding how and where a neural network stores knowledge is a core problem for interpretability\nand it has thus been studied from several perspectives (Ji et al., 2021; Wang et al., 2014). One line of\nwork trains classifiers to probe for properties encoded in model representations (Ettinger et al., 2016;\nShi et al., 2016; Hupkes et al., 2018; Conneau et al., 2018; Belinkov et al., 2017; Belinkov & Glass,\n2019). However, the flexibility of these classifiers can lead to overestimating model knowledge and\ncapabilites (Belinkov, 2022). Causal mediation analysis methods (Pearl, 2022) attempt to measure the\ncausal contribution of intermediate states to task performance. Meng et al. (2022a;b) use activation\npatching to identify key MLP modules for factual recall, highlighting the middle layers at particular\ntoken positions as being especially important. Similarly, Geva et al. (2023) apply causal mediation\nanalysis to attention modules, seeking to understand the mechanism of cross-token factual information\nflow inside transformer LMs.\n\n8  Discussion\n\nIn this paper we have set out to understand whether the analytical methods and tools developed for\ntransformer LMs can also be applied on the Mamba recurrent state-space architecture. Although\nour experiments have been limited to Mamba-2.8b, the largest available LM of that family, and\ncomparisons to the similarly-sized transformer Pythia-2.8b, the methods we have introduced are\ngeneral, and can be used to analyze to any state-space model.\n\nOur overall comparisons of Mamba and transformers are positive: with activation patching we have\nfound that, similar to autoregressive transformer LMs, Mamba shows signs of localization at the\nlast subject token and at specific layer ranges while recalling a fact. Although, unlike transformers,\nMamba has no MLP modules, we find that their Wo weights can receive rank-one model editing\n(ROME) edits with good generalization and specificity at a range of layers, similar to Wdown in Pythia\nand GPT family of LMs. We have studied the linearity of the embeddings of factual relations in\nMamba and have found that many can be well approximated by LRE, again resembling autoregressive\ntransformer LMs. We have also been able to partially adapt the tools of attention knock-out in Mamba\nby blocking outgoing information from a token, revealing information flows similar to transformer\nLMs during factual recall.\n\nThe similarity that we have observed between factual recall mechanisms in transformers and Mamba\nleads us to speculate that the autoregressive language modeling task itself induces a pattern of\nlocalized factual recall that is independent of modeling architecture. When constraining a model to\nprocess text from beginning to end, the ordering creates a specific bottleneck in the information flows:\nthe end of a subject becomes a singular moment at which recognition of the subject is both possible\nand useful, and we find that both transformers and Mamba arrange their computations to localize\nfactual recall at that moment. We hypothesize that other future autoregressive LMs architectures\nshould expect to see similar locality in factual recall as well.\n\nIn summary, we find that many of the tools used to interpret and edit large transformers can be\nadapted to work with Mamba, and we are optimistic that those tools will continue to be useful as\narchitectures continute to evolve.\n\n\n                                       10\n\nPublished as a conference paper at COLM 2024\n\n\n\n\nEthics\n\nBy exploring the factual recall mechanism in Mamba, we potentially improve its transparency,\nenabling oversight and control. However, the ability to modify facts directly in the model brings with\nit the potential for abuse, such as adding malicious misinformation or bias.\n\nReproducibility\n\nWe ran all experiments on workstations with either 80GB NVIDIA A100 GPUs or 48GB A6000\nGPUs, using the HuggingFace Transformers library (Wolf et al., 2019) and PyTorch (Paszke et al.,\n2019). We make use of publicly available datasets COUNTERFACT and RELATIONS in this work.\n\nAcknowledgements\n\nThis research has been supported by a grant from Open Philanthropy (DB, AS), and an NSF Computer\nand Information Science and Engineering Graduate Fellowship Fellowship (DA). We are also grateful\nto the Center for AI Safety (CAIS) for sharing their compute resources, which supported many of our\nexperiments. Some of our initial analyses were conducted with a beta version of NNsight (Fiotto-\nKaufman et al., 2024) on an implementation of Mamba instrumented for research by Jaden Fiotto-\nKaufmann.\n\nReferences\n\nAmeen Ali, Itamar Zimerman, and Lior Wolf. The hidden attention of mamba models. arXiv preprint\n  arXiv:2403.01590, 2024.\n\nJames A Anderson. A simple neural network generating an interactive memory. Mathematical\n   biosciences, 14(3-4):197–220, 1972.\n\nYonatan Belinkov. Probing classifiers: Promises, shortcomings, and advances. Computational\n   Linguistics, 48(1):207–219, 2022.\n\nYonatan Belinkov and James Glass. Analysis methods in neural language processing: A survey.\n  Transactions of the Association for Computational Linguistics, 7:49–72, 2019.\n\nYonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, and James Glass. What do neural\n  machine translation models learn about morphology? arXiv preprint arXiv:1704.03471, 2017.\n\nStella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric\n  Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al.\n   Pythia: A suite for analyzing large language models across training and scaling. In International\n  Conference on Machine Learning, pp. 2397–2430. PMLR, 2023.\n\nKyunghyun Cho, Bart Van Merriënboer, Dzmitry Bahdanau, and Yoshua Bengio. On the properties of\n   neural machine translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259, 2014.\n\nAlexis Conneau, German Kruszewski, Guillaume Lample, Loïc Barrault, and Marco Baroni. What\n  you can cram into a single vector: Probing sentence embeddings for linguistic properties. arXiv\n   preprint arXiv:1805.01070, 2018.\n\nJames Durbin and Siem Jan Koopman. Time series analysis by state space methods, volume 38. OUP\n  Oxford, 2012.\n\nYanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich Schütze,\n  and Yoav Goldberg. Measuring and improving consistency in pretrained language models. Trans-\n   actions of the Association for Computational Linguistics, 9:1012–1031, 2021.\n\nAllyson Ettinger, Ahmed Elgohary, and Philip Resnik. Probing for semantic evidence of composition\n  by means of simple classification tasks. In Proceedings of the 1st workshop on evaluating vector-\n  space representations for nlp, pp. 134–139, 2016.\n\n\n                                       11\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n\nJaden Fiotto-Kaufman, Alexander R Loftus, Eric Todd, Jannik Brinkmann, Caden Juang, Koyena\n   Pal, Can Rager, Aaron Mueller, Samuel Marks, Arnab Sen Sharma, et al. Nnsight and ndif:\n  Democratizing access to foundation model internals. arXiv preprint arXiv:2407.14561, 2024.\n\nAtticus Geiger, Zhengxuan Wu, Hanson Lu, Josh Rozner, Elisa Kreiss, Thomas Icard, Noah D.\n  Goodman, and Christopher Potts. Inducing causal structure for interpretable neural networks.\n  CoRR, abs/2112.00826, 2021. URL https://arxiv.org/abs/2112.00826.\n\nMor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. Dissecting recall of factual\n  associations in auto-regressive language models. arXiv preprint arXiv:2304.14767, 2023.\n\nKaran Goel, Albert Gu, Chris Donahue, and Christopher Re. It’s raw! Audio generation with state-\n  space models. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu,\n  and Sivan Sabato (eds.), Proceedings of the 39th International Conference on Machine Learning,\n  volume 162 of Proceedings of Machine Learning Research, pp. 7616–7633. PMLR, 17–23 Jul\n  2022. URL https://proceedings.mlr.press/v162/goel22a.html.\n\nRiccardo Grazzi, Julien Siems, Simon Schrodi, Thomas Brox, and Frank Hutter. Is Mamba Capable\n  of In-Context Learning?, 2024. URL http://arxiv.org/abs/2402.03170.\n\nAlbert Gu and Tri Dao. Mamba: Linear-time sequence modeling with selective state spaces. arXiv\n  preprint arXiv:2312.00752, 2023.\n\nAlbert Gu, Karan Goel, and Christopher Ré. Efficiently modeling long sequences with structured\n   state spaces. arXiv preprint arXiv:2111.00396, 2021.\n\nPeter Hase, Mohit Bansal, Been Kim, and Asma Ghandeharioun. Does localization inform editing?\n  surprising differences in causality-based localization vs. knowledge editing in language models.\n  Advances in Neural Information Processing Systems, 36, 2024.\n\nEvan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas,\n  Yonatan Belinkov, and David Bau. Linearity of relation decoding in transformer language models.\n  arXiv preprint arXiv:2308.09124, 2023.\n\nSepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):\n  1735–1780, 1997.\n\nDieuwke Hupkes, Sara Veldhoen, and Willem Zuidema. Visualisation and’diagnostic classifiers’\n  reveal how recurrent and recursive neural networks process hierarchical structure. Journal of\n   Artificial Intelligence Research, 61:907–926, 2018.\n\nShaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. A survey on knowledge\n  graphs: Representation, acquisition, and applications. IEEE Transactions on Neural Networks and\n  Learning Systems, 33(2):494–514, 2021.\n\nTeuvo Kohonen. Correlation matrix memories. IEEE transactions on computers, 100(4):353–359,\n  1972.\n\nSiem Jan Koopman, Neil Shephard, and Jurgen A Doornik. Statistical algorithms for models in state\n  space using ssfpack 2.2. The Econometrics Journal, 2(1):107–160, 1999.\n\nKevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.  Locating and editing factual\n   associations in gpt. Advances in Neural Information Processing Systems, 35:17359–17372, 2022a.\n\nKevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, and David Bau. Mass-editing\n  memory in a transformer. arXiv preprint arXiv:2210.07229, 2022b.\n\nStephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture\n  models. arXiv preprint arXiv:1609.07843, 2016.\n\nNeel  Nanda,  Senthooran  Rajamanoharan,  János  Kramár,  and  Rohin  Shah.      Fact\n   finding:    Attempting   to   reverse-engineer   factual   recall  on   the  neuron   level,\n  2023.     URL  https://www.lesswrong.com/posts/iGuwZTHWb6DFY3sKB/\n  fact-finding-attempting-to-reverse-engineer-factual-recall.\n\n\n                                       12\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n\nEric Nguyen, Karan Goel, Albert Gu, Gordon Downs, Preey Shah, Tri Dao, Stephen Baccus, and\n  Christopher Ré.  S4nd: Modeling images and videos as multidimensional signals with state\n  spaces. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (eds.), Ad-\n  vances in Neural Information Processing Systems, volume 35, pp. 2846–2861. Curran Asso-\n   ciates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/\n  2022/file/13388efc819c09564c66ab2dc8463809-Paper-Conference.pdf.\n\nEric Nguyen, Michael Poli, Marjan Faizi, Armin Thomas, Callum Birch-Sykes, Michael Wornow,\n  Aman Patel, Clayton Rabideau, Stefano Massaroli, Yoshua Bengio, Stefano Ermon, Stephen A.\n  Baccus, and Chris Ré. Hyenadna: Long-range genomic sequence modeling at single nucleotide\n   resolution, 2023.\n\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\n  Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al.  Pytorch: An imperative style,\n  high-performance deep learning library. Advances in neural information processing systems, 32,\n  2019.\n\nJudea Pearl. Direct and indirect effects. In Probabilistic and causal inference: the works of Judea\n  Pearl, pp. 373–392. 2022.\n\nXing Shi, Inkit Padhi, and Kevin Knight. Does string-based neural mt learn source syntax?  In\n  Proceedings of the 2016 conference on empirical methods in natural language processing, pp.\n  1526–1534, 2016.\n\nEric Todd, Millicent L Li, Arnab Sen Sharma, Aaron Mueller, Byron C Wallace, and David Bau.\n  Function vectors in large language models. arXiv preprint arXiv:2310.15213, 2023.\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz\n   Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing\n  systems, 30, 2017.\n\nJesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Yaron Singer,\n  and Stuart Shieber.   Investigating gender bias in language models using causal mediation\n   analysis.  In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Ad-\n  vances in Neural Information Processing Systems, volume 33, pp. 12388–12401. Curran Asso-\n   ciates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/\n  2020/file/92650b2e92217715fe312e6fa7b90d82-Paper.pdf.\n\nKevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. Inter-\n   pretability in the wild: a circuit for indirect object identification in gpt-2 small. arXiv preprint\n  arXiv:2211.00593, 2022.\n\nZhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph embedding by\n   translating on hyperplanes.  In Proceedings of the AAAI conference on artificial intelligence,\n  volume 28, 2014.\n\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi,\n   Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface’s transformers:\n   State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771, 2019.\n\nFred Zhang and Neel Nanda. Towards best practices of activation patching in language models:\n  Metrics and methods. arXiv preprint arXiv:2309.16042, 2023.\n\n\n\n\n\n                                       13\n\nPublished as a conference paper at COLM 2024\n\n\n\n\nA  Datasets\n\nWe use two datasets; COUNTERFACT by Meng et al. (2022a) and RELATIONS by Hernandez et al.\n(2023) in this work.\n\nA.1  COUNTERFACT\n\nMeng et al. (2022a) developed the COUNTERFACT dataset for evaluating the efficacy of counterfactual\nedits in language models. It was prepared by adapting PARAREL (Elazar et al. (2021)) and scraping\nWikidata3. The dataset contains 21, 919 requests {s, r, o, o∗, π∗} where o is the correct answer to\nthe prompt x = (s, r), o∗is the counterfactual edit request, and π∗∼P(s, r) is a paraphrase\nof the prompt x = (s, r) to test for generalizability (PS). Each of the records also contain some\nneighborhood prompts πN to test for specificity (NS) and some generation prompts πG to test if LM\ngeneration post-edit is fluent and consistent with the edit. Please refer to Meng et al. (2022a) for\ndetails on the curation of this dataset.\n\nWe evaluate ROME performance in Mamba-2.8b (Figure 6a) and Pythia-2.8b (Figure 6b) on the first\n2000 records from COUNTERFACT.\n\nA.2  RELATIONS\n\nThe RELATIONS dataset introduced in Hernandez et al. (2023) consists of 47 relations of 4 types:\nfactual, linguistic, bias, and commonsense. A relation r is an association between two entities. For\nexample, the relation, r = professionally played the sport connects the subject s = Michael Jordan\nwith the object o = basketball. The dataset contains a set of (s, o) for each relation r.\n\nIn the scope of this paper, we only utilize the 26 factual relations from this dataset. We evaluate\nLRE in Mamba and Pythia for all the 26 factual relations. We also use this dataset for locating key\nfact-mediating states in Section 3 and Appendix D. We randomly sample 400 examples (s, r, o)\nacross 6 different factual relations - place in city, country capital city, person occupation, plays pro\nsport, company hq, and product by company. For each of these examples we randomly select another\nexample within the same relation (s∗, r, o∗) such that s ̸= s∗and o ̸= o∗. The average indirect effect\n(IE) of applying activation patching over these 400 examples is depicted on Figures 2b, 3, 5 for\nMamba-2.8b) and on Figure 10 (for Pythia-2.8b). We use the same set of 6 relations in Section 6\nwhere we adapt attention knock-out to Mamba.\n\nB  Challenges in Performing Attention Knock-out in Mamba\n\nAttention heads in autoregressive transformer LMs and Conv + SSM operations in Mamba play a\nsimilar role: bringing/retaining information from the past tokens. Attention “knock-out” is a type of\ncausal mediation analysis that tries to understand information flow in transformer LMs by cutting off\ninformation propagation from kth token to qth token position. In transformers, each of the attention\nheads in an attention module attn(ℓ) calculates an attention matrix L, where Lq,k quantifies how\nmuch attention is being paid to the kth token by the qth token with this specific attention head (see\nVaswani et al. (2017) for details on the attention operation). We can block the information flow from\nkth token to qth token via a specific attention head by simply setting Lq,k := −∞in the forward pass.\n\nFor Mamba, Ali et al. (2024) show that the amount of information retained in the qth token state\n                                         (where k < q), after the selective-SSM operations(ℓ)q   , from the convolved state at kth token c(ℓ)k\n(see Equations 4 and 5) can be visualized as an attention matrix per channel. Since the selective-\n                                                          can be calculated accurately asSSM operation is linear, the information retained in s(ℓ)q  from c(ℓ)k\n                                                                                       , and C(ℓ)i   are input-dependent parameters for                                                          , where A(ℓ)i   , B(ℓ)i˜α(ℓ)q,k  = C(ℓ)q  ∏ i=k+1q     A(ℓ)i    B(ℓ)k  c(ℓ)k\nthe ith token. See Gu & Dao (2023) and Ali et al. (2024) for details on selective-SSM operation. We\nask: can we block the information flow from the kth token to the qth token in Mamba by subtracting\n       from s(ℓ)q  ? If so, attention knockout experiments in Mamba become feasible.out ˜α(ℓ)q,k\n\n   3www.wikidata.org/wiki/Wikidata:Main_Page\n\n\n                                       14\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n\nWe find that blocking information flow via Conv + SSM operation through this specific edge from the\nkth token to the qth token can be challenging in Mamba. Note that, since c(ℓ) is a convolved state with                                                                                      k\na receptive field of size 4 in Mamba-2.8b, the states c(ℓ)   c(ℓ)  and c(ℓ)  also retain information from                                                  k+1,  k+2,     k+3\na(ℓ)                                        from s(ℓ)q   , these states can “leak” information about  k      . Which means that even if we subtract ˜α(ℓ)q,k\na(ℓ)     to s(ℓ)q   . To stop this leakage, we would want to subtract from s(ℓ)q   all the information retained  k\nfrom a(ℓ) via c(ℓ)   c(ℓ)  and c(ℓ)  states as well. However, accurately calculating this is challenging        k       k+1,  k+2,     k+3\nbecause of the SiLU non-linearity after Conv1D (see Equation (4)).\n                                               from s(ℓ)q   . But we found that Mamba-2.8bIn our initial experiments we tested subtracting only ˜α(ℓ)q,k\ncould often refer to the kth token from the qth token in copy and factual recall tasks.\n\nC  Isolating The Contribution of W(ℓ)o\n\n                                                                                  are restored asRecall from Figure 1 and Equation (2) that when o(ℓ)i                                                                 is restored, the s(ℓ)i                                                              and g(ℓ)i\nwell. To isolate the contribution of only W(ℓ)o  we subtract out   +      from      and plot the                                                                        IEs(ℓ)i     IEg(ℓ)i         IEo(ℓ)i\nresults on Figure 9. Notice that subtracting IEs(ℓ)i  cancels out the high indirect effect at the late site\nshown by later layers at the last token position. But, together IEs(ℓ)i + IEg(ℓ)i  cannot cancel out high\nIEo(ℓ)i  observed at the early site, that is early-mid layers at the last subject token. This reconfirms the\nmediating role of W(ℓ)o   at the early site while recalling a fact.\n\n\n       (a) Average IE of restoring oi(l) over 400 facts\n                                                              0.5                                                                             (b) Average IE of restoring gi(l)     0.5                (c) Average IE of restoring si(l)    0.5                     IEo(l)i  - ( IEg(l)i + IE s(l)i  )        0.5\n             prefix                                                                                                                                                                                                          prefix\n    subject_[:-2]*                                             0.4                                                             0.4                                                        0.4                  subj_[:-2]*                                            0.4\nsubject_2nd_last*                                             0.3                                                             0.3                                                        0.3                  subj_[-2]*       early site                             0.3     subject_last*                                             0.2                                                             0.2 +                                             0.2 =   sub_last*                                            0.2\n     further tokens                                             0.1                                                             0.1                                                        0.1                other tokens                                            0.1\n          last token                                                                                                                                                                                                                                      last token\n                                                              0.0                                                                                                                              0.0                                                                                                                                                                                         0.0                                                                                                                                                                                                                                                                    0.0\n                                                    IE                                                                                                            IE                                                                                                                                                                  IE                0                  5 10                      15                         20 25 30                                35                                   40                                     45 50 55                                                                      0                                                                        5 10 15                                                                               20                                                                                25 30                                                                                     35                                                                                         40                                                                                          45 50 55                                                                                                                       0                                                                                                                         5 10 15                                                                                                                                20                                                                                                                                  25 30                                                                                                                                        35                                                                                                                                          40                                                                                                                                             45 50 55                                                                                                                                                                                                                                   IE        -(               )               0 5 10 15 20 25 30 35 40 45 50 55                                                                                        center                                                                                           of                                                                                                       interval                                                                                                       of                                                                                        10                                                                                                      patched                                                                                                                          layers                                                                                                                                                    center                                                                                                                                                      of                                                                                                                                                                        interval                                                                                                                                                                  of                                                                                                                                         10                                                                                                                                                             patched                                                                                                                                                                                        layers                     center                           of                                interval                                     of                                 10                                        patched                                                     layers\n\nFigure 9: Isolating the contribution of W(ℓ)o   .    +       subtracted from          . Notice that                                                         IEs(ℓ)i      IEg(ℓ)i                       IEo(ℓ)i\nIEo(ℓ)i −  IEs(ℓ)i + IEg(ℓ)i     still shows higher causal effect at the early site more pronounced than\nIEg(ℓ)i   while the high causal effect at the late site cancels out.\n\nD  Locating Key Modules in Pythia-2.8b\n\n\n     (a) Average IE of restoring hi(l) over 400 prompts         (b) Average IE of restoring MLP           (b) Average IE of restoring ATTN\n                                                              0.8                                                0.8                                                0.8\n            prefix\n\n    subject_[:-2]*                                             0.6                                                0.6                                                0.6\n\nsubject_2nd_last*         early site                                           early site\n                                                              0.4                                                0.4                                                0.4\n     subject_last*\n\n    further tokens                                late site          0.2                                                0.2                              late site                0.2\n\n          last token\n                                                              0.0                                                0.0                                                0.0\n                0    5   10   15   20   25        IE       0    5   10   15   20   25        IE        0    5   10   15   20   25        IE\n                   single restored layer within Pythia-2.8b                center of interval of 10 patched layers                center of interval of 10 patched layers\n\nFigure 10: Average indirect effect of residual state, MLP, and attention outputs in Pythia-2.8b over\n400 facts. For MLP and attention outputs a window of 10 layers around ℓis restored, as restoring just\none layer barely shows visible patterns.\n\n\n\n\n\n                                       15\n\nPublished as a conference paper at COLM 2024\n\n\n\n\n\n                                                                                        (l)\n                        IE with hi restored     ATTNi blocked    MLPi blocked\n       0.75\n  IE     (a) i = subj last\n       0.50\n\n       0.25        Average\n       0.00\n          (b) i = prompt last\n       1.00\n  IE\n       0.75\n\n       0.50        Average 0.25\n\n       0.00\n                0               5              10              15              20              25              30\n                                                         Layers\n\nFigure 11: Impact of ablating ATTNi or MLPi on IEh(ℓ)i  for (a) subject last and (b) prompt last token positions\non Pythia-2.8b\n\nE  LRE in Pythia-2.8b\n\n\n               LRE faithfulness for factual relations in Mamba-3B\n       1.0\n\n       0.9\n\n       0.8\n\n       0.7\n\n       0.6\n\n       0.5\n\n       0.4             Faithfulness\n       0.3\n\n       0.2\n\n       0.1\n\n       0.0\n\n               LRE faithfulness for factual relations in Pythia-3B\n       1.0\n\n       0.9\n\n       0.8\n\n       0.7\n\n       0.6\n\n       0.5\n\n       0.4            Faithfulness\n       0.3\n\n       0.2\n\n       0.1\n\n       0.0\n                                                      city                                                            band\n                              of                                   pro                               language     continent     language  city                                                                                                      university   sport                                                                                                                  birth    company    person     currency    country hq  name                   evolution    father    countryin    mother  CEO                                                                                                                                                                      occupation     position    countryin      instrument  year                                                                                              largest                                                             capital                                                                                                                                                                                                                        company                        archnemesis             person                                                 by               from                                                                                                                                                                                                                                                  person    company           on                           plays             singer           sport  city                       native               country             person                                                  plays                                  superhero    country                                                             country                          country  lead   person                                                                                                                                                                                                                                                                                                                                                                                                                                     constellation               pokemon                                                                                                                                                                                                              president                                                                                                                                                                                                                                                                                                                      landmark                                                                                                                                                                           product               food                                                                                                             person                       person     landmark                                                                                         person                                        star     superhero                                                                                          person\n\nFigure 12: Relation-wise LRE faithfulness to the LM decoding function F. Horizontal red lines per\nrelation indicate random-choice baseline. We only present results for the factual relations in the\nRELATIONS dataset.\n\n\n\n\n                                       16\n\nPublished as a conference paper at COLM 2024\n\n\n\n\nF  LRE Performance Across Different Relations\n\nBesides faithfulness Hernandez et al. (2023) introduced another metric causality to measure the\nperformance of LRE. Since LRE is a linear function, it is invertible. Assume that for a fact (s, r, o)\nLRE can faithfully replace LM computation F(s, r). Then given the representation o∗of another\nobject o, J−1(o∗−o) should give us a ∆s, such that when added to s,  ˜s := s + ∆s, the model\ncomputation F(˜s, r) should generate o∗. See Hernandez et al. (2023) for details on this.\n\n                               Mamba-2.8b\n        country capital city          landmark in country             plays pro sport              person occupation\n   1.0                                       1.0                                       1.0                                       1.0\n\n   0.8                                       0.8                                       0.8                                       0.8\nScore 0.60.4                                       0.60.4                                       0.60.4                                       0.60.4\n\n   0.2                                       0.2                                       0.2                                       0.2\n\n   0.0   6 12 18 24 30 36 42 48   0.0   6 12 18 24 30 36 42 48  0.0   6 12 18 24 30 36 42 48  0.0   6 12 18 24 30 36 42 48         emb                                                 emb                                                  emb                                                  emb\n\n      person plays instrument          company CEO              star constellation name            person mother\n   1.0                                       1.0                                       1.0                                       1.0\n\n   0.8                                       0.8                                       0.8                                       0.8\nScore 0.60.4                                       0.60.4                                       0.60.4                                       0.60.4\n\n   0.2                                       0.2                                       0.2                                       0.2\n\n   0.0   6 12 18 24 30 36 42 48   0.0   6 12 18 24 30 36 42 48  0.0   6 12 18 24 30 36 42 48  0.0   6 12 18 24 30 36 42 48         emb                                                 emb                                                 emb                                                  emb\n\n                                     Pythia-2.8b\n         country capital city          landmark in country             plays pro sport              person occupation\n   1.0                                       1.0                                       1.0                                       1.0\n\n   0.8                                       0.8                                       0.8                                       0.8\nScore 0.60.4                                       0.60.4                                       0.60.4                                       0.60.4\n\n   0.2                                       0.2                                       0.2                                       0.2\n\n   0.0  3 6 9 12 15 18 21 24 27 30   0.0  3 6 9 12 15 18 21 24 27 30   0.0  3 6 9 12 15 18 21 24 27 30   0.0  3 6 9 12 15 18 21 24 27 30         emb                                                  emb                                                  emb                                                  emb\n\n      person plays instrument          company CEO              star constellation name            person mother\n   1.0                                       1.0                                       1.0                                       1.0\n\n   0.8                                       0.8                                       0.8                                       0.8\nScore 0.60.4                                       0.60.4                                       0.60.4                                       0.60.4\n\n   0.2                                       0.2                                       0.2                                       0.2\n\n   0.0  3 6 9 12 15 18 21 24 27 30   0.0  3 6 9 12 15 18 21 24 27 30   0.0  3 6 9 12 15 18 21 24 27 30   0.0  3 6 9 12 15 18 21 24 27 30         emb                                                  emb                                                  emb                                                  emb\n\n                                             Faithfulness         Causality\n\nFigure 13: For Mamba, we only perform sweep till layer 48, as Figure 5 suggests negligible activity\nfor later layers at the subject last token\n\n\n\n\n\n                                       17\n\n                Published as a conference paper at COLM 2024\n\n\n\n\n       G  Activation Patching results on Mamba-2.8b\n\n\n                     restoring hi(l) of a single layer                  restoring oi(l) of 10 layers around l            restoring gi(l) of 10 layers around l            restoring s (l)i of 10 layers around l\n\n                                                                 0.5                                                  0.5                                                 0.5                                                  0.5\n            [PAD]\n\n         Michael/ Pe                                            0.4                                                  0.4                                                 0.4                                                  0.4\n\n             Jordan/le\n        professionally                                            0.3                                                  0.3                                                 0.3                                                  0.3\n              played                                            0.2                                                  0.2                                                 0.2                                                  0.2\n                   the\n                 sport                                            0.1                                                  0.1                                                 0.1                                                  0.1\n\n                   of\n                                                                 0.0                                                  0.0                                                 0.0                                                  0.0\n                   0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE\n\n\n                                                                  0.5                                                 0.5                                                 0.5                                                  0.5\n            [PAD]\n     Harvard/ Oxford                                             0.4                                                 0.4                                                 0.4                                                  0.4\nUniversity/ University\n                         is                                             0.3                                                 0.3                                                 0.3                                                  0.3\n               located\n                     in                                             0.2                                                 0.2                                                 0.2                                                  0.2\n\n                   the\n                    city                                             0.1                                                 0.1                                                 0.1                                                  0.1\n\n                    of                                                                                                                                                                                                                                0.0                                                                                                                                                                         0.0                                                                                                                       0.0                                                                  0.0\n                                                                                                                                                      0 5 10 15 20 25 30 35 40 45 50 55     IE                                                                                                          0 5 10 15 20 25 30 35 40 45 50 55     IE                                                               0 5 10 15 20 25 30 35 40 45 50 55     IE                   0 5 10 15 20 25 30 35 40 45 50 55     IE\n\n\n\n                                                                  0.5                                                 0.5                                                 0.5                                                  0.5\n            [PAD]\n\n             By                                             0.4                                                 0.4                                                 0.4                                                  0.4\n\n           profession\n                                                                  0.3                                                 0.3                                                 0.3                                                  0.3\n       Bruce/ Harper\n                                                                  0.2                                                 0.2                                                 0.2                                                  0.2\n            Lee/ Lee\n\n              was                                             0.1                                                 0.1                                                 0.1                                                  0.1\n\n                   a\n                                                                  0.0                                                 0.0                                                 0.0                                                  0.0\n                   0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE        0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE\n\n\n                                                                  0.5                                                0.5                                                  0.5                                                  0.5\n            [PAD]\n              The                                             0.4                                                0.4                                                  0.4                                                  0.4\n                capital\n                   of                                             0.3                                                0.3                                                  0.3                                                  0.3\n      Canada/ Japan\n                        is                                             0.2                                                0.2                                                  0.2                                                  0.2\n\n                  the\n                   city                                             0.1                                                0.1                                                  0.1                                                  0.1\n\n                   of\n                                                                  0.0                                                0.0                                                  0.0                                                  0.0\n                   0 5 10 15 20 25 30 35 40 45 50 55     IE        0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE\n\n\n                                                                  0.5                                                0.5                                                  0.5                                                 0.5\n            [PAD]\n              The                                             0.4                                                0.4                                                  0.4                                                 0.4\n               head\n               quarter                                             0.3                                                0.3                                                  0.3                                                 0.3\n                   of\n   Microsoft/ Google                                             0.2                                                0.2                                                  0.2                                                 0.2\n\n                         is\n              located                                             0.1                                                0.1                                                  0.1                                                 0.1\n\n                     in\n                                                                  0.0                                                0.0                                                  0.0                                                 0.0\n                   0 5 10 15 20 25 30 35 40 45 50 55     IE        0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE         0 5 10 15 20 25 30 35 40 45 50 55     IE\n\n\n\n\n\n                                                    18\n\n## Claim to Classify\n\"linearity of Mamba's representations of factual relations\"\nLocation in paper: body\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Jacobian-based linear approximation (LRE)",
    "method_rung": 1,
    "claim_rung": 1,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The claim 'linearity of Mamba's representations of factual relations' is made in the context of Section 5, which uses the LINEARITY OF RELATION EMBEDDING (LRE) method. LRE computes Jacobians to approximate the model's computation as a linear function, which is an observational/associational method (Rung 1) as it does not involve any intervention on the model. The linguistic marker 'linearity' aligns with Rung 1 claims about the nature of representations (e.g., 'is linearly decodable'). The claim is stated without hedging, but the method (LRE) directly supports this level of claim, so there is no overclaim. The method and claim both belong to Rung 1, resulting in no gap."
  },
  "metadata": {
    "model": "qwen/qwen3-235b-a22b-2507",
    "usage": {
      "prompt_tokens": 25580,
      "completion_tokens": 219,
      "total_tokens": 25799
    },
    "finish_reason": "stop"
  }
}