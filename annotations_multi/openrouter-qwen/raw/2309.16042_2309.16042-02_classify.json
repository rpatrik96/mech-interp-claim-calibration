{
  "timestamp": "2026-02-19T11:33:42.769279+00:00",
  "paper_id": "2309.16042",
  "claim_id": "2309.16042-02",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2309.16042\nTitle: Towards Best Practices of Activation Patching\nFull text:\n         TOWARDS BEST PRACTICES OF ACTIVATION PATCH-\n           ING IN LANGUAGE MODELS: METRICS AND METHODS\n\n\n                    Fred Zhang∗                           Neel Nanda\n               UC Berkeley                             Independent\n                     z0@berkeley.edu                      neelnanda27@gmail.com\n\n\n\n                                       ABSTRACT\n\n                              Mechanistic interpretability seeks to understand the internal mechanisms of\n                            machine learning models, where localization—identifying the important model2024                     components—is a key step. Activation patching, also known as causal tracing or\n                               interchange intervention, is a standard technique for this task (Vig et al., 2020), but\n                                 the literature contains many variants with little consensus on the choice of hyper-Jan                        parameters or methodology. In this work, we systematically examine the impact\n17                          ofcorruptionmethodologicalmethods.detailsIn severalin activationsettings patching,of localizationincludingand circuitevaluationdiscoverymetricsin lan-and\n                            guage models, we find that varying these hyperparameters could lead to disparate\n                                    interpretability results. Backed by empirical observations, we give conceptual ar-\n                            guments for why certain metrics or methods may be preferred. Finally, we provide\n                            recommendations for the best practices of activation patching going forwards.[cs.LG]                1  INTRODUCTION\n\n                      Mechanistic interpretability (MI) aims to unravel complex machine learning models by reverse en-\n                       gineering their internal mechanisms down to human-understandable algorithms (Geiger et al., 2021;\n                      Olah, 2022; Wang et al., 2023). With such understanding, we can better identify and fix model errors\n                      (Vig et al., 2020; Hernandez et al., 2021; Meng et al., 2022; Hase et al., 2023), steer model outputs\n                        (Li et al., 2023b) and explain emergent behaviors (Nanda et al., 2023a; Barak et al., 2022).\n\n             A basic goal in MI is localization: identify the specific model components responsible for partic-\n                         ular functions. Activation patching, also known as causal tracing, interchange intervention, causal\n                      mediation analysis or representation denoising, is a standard tool for localization in language mod-\n                          els (Vig et al., 2020; Meng et al., 2022). The method attempts to pinpoint activations that causally\n                          affect on the output. Specifically, it involves 3 forward passes of the model: (1) on a clean prompt\n                      while caching the latent activations; (2) on a corrupted prompt; and (3) on the corrupted prompt but\n                        replacing the activation of a specific model component by its clean cache. For instance, the clean\n                    prompt can be “The Eiffel Tower is in” and the corrupted one with the subject replaced by “ThearXiv:2309.16042v2               Colosseum”. If the model outputs “Paris” in step (3) but not in (2), then it suggests that the specific\n                    component being patched is important for producing the answer (Vig et al., 2020; Pearl, 2001).\n\n                      This technique has been widely applied for language model interpretability. For example, Meng\n                           et al. (2022); Geva et al. (2023) seek to understand which model weights store and process factual\n                        information. Wang et al. (2023); Hanna et al. (2023); Lieberum et al. (2023) perform circuit analysis:\n                         identify the sub-network within a model’s computation graph that implements a specified behavior.\n                       All these works leverage activation patching or its variants as a foundational technique.\n\n                      Despite its broad applications across the literature, there is little consensus on the methodological\n                          details of activation patching. In particular, each paper tends to use its own method of generating\n                       corrupted prompts and the metric of evaluating patching effects. Concerningly, this lack of standard-\n                         ization leaves open the possibility that prior interpretability results may be highly sensitive to the\n                      hyperparameters they adopt. In this work, we study the impact of varying the metrics and methods\n                         in activation patching, as a step towards understanding best practices. To our knowledge, this is the\n                               first such systematic study of the technique.\n\n                       ∗Work done while interning at Google.\n\n\n                                                           1\n\n                                                                                                                                                                                                                                        0.4\n                                                                                                                                                       0\n\n                                                                                                                                                       2                                                  0.2\n                         Xclean                                      Xcorrupt                                                                                                Layer 46                                         0\n\n      John                     Bob                                                                                 8\n       and                        and                    ?      Logits                      10                                               −0.2\n      Mary                       Mary                                                                                   0        Head5              10         −0.4\n\n            (a) Activation patching intervenes on latent states               (b) Patching attention heads\n\nFigure 1: The workflow of activation patching for localization: run the intervention procedure (a)\non every relevant component, such as all the attention heads, and plot the effects (b).\n\nSpecifically, we identify three degrees of freedom in activation patching.  First, we focus on the\napproach of generating corrupted prompts and evaluate two prominent methods from the literature:\n\n• Gaussian noising (GN) adds a large Gaussian noise to the token embeddings of the tokens that\n  contain the key information to completing a prompt, such as its subject (Meng et al., 2022).\n• Symmetric token replacement (STR) swaps these key tokens with semantically related ones; for\n  example, “The Eiffel Tower”→“The Colosseum” (Vig et al., 2020; Wang et al., 2023).\n\nSecond, we examine the choice of metrics for measuring the effect of patching and compare prob-\nability and logit difference; both have found applications in the literature (Meng et al., 2022; Wang\net al., 2023; Conmy et al., 2023). Third, we study sliding window patching, which jointly restores\nthe activations of multiple MLP layers, a technique used by Meng et al. (2022); Geva et al. (2023).\n\nWe empirically examine the impact of these hyperparameters on several interpretability tasks, in-\ncluding factual recall (Meng et al., 2022) and circuit discovery for indirect object identification (IOI)\n(Wang et al., 2023), greater-than (Hanna et al., 2023), Python docstring completion (Heimersheim\n& Janiak, 2023) and basic arithmetic (Stolfo et al., 2023). In each setting, we apply methods distinct\nfrom the original studies and assess how different interpretability results arise from these variations.\n\nFindings  Our contributions uncover nuanced discrepancies within activation patching techniques\napplied to language models. On corruption method, we show that GN and STR can lead to incon-\nsistent localization and circuit discovery outcomes (Section 3.1). Towards explaining the gaps, we\nposit that GN breaks model’s internal mechanisms by putting it off distribution. We give tentative\nevidence for this claim in the setting of IOI circuit discovery (Section 3.2). We believe that this is a\nfundamental concern in using GN corruption for activation patching. On evaluation metrics, we pro-\nvide an analogous set of differences between logit difference and probability (Section 4), including\nan observation that probability can overlook negative model components that hurt performance.\n\nFinally, we compare sliding window patching with patching individual layers and summing up their\neffects. We find the sliding window method produces more pronounced localization than single-\nlayer patching and discuss the conceptual differences between these two approaches (Section 5).\n\nRecommendations for practice  At a high-level, our findings highlight the sensitivity of activation\npatching to methodological details. Backed by our analysis, we make several recommendations on\nthe application of activation patching in language model interpretability (Section 6). We advocate for\nSTR, as it supplies in-distribution corrupted prompts that help to preserve consistent model behavior.\nOn evaluation metric, we recommend logit difference, as we argue that it offers fine-grained control\nover the localization outcomes and is capable of detecting negative modules.\n\n2  BACKGROUND\n\n2.1  ACTIVATION PATCHING\n\nActivation patching identifies the important model components by intervening on their latent activa-\ntions. The method involves a clean prompt (Xclean, e.g.,“The Eiffel Tower is in”) with an associated\nanswer r (“Paris”), a corrupted prompt (Xcorrupt, e.g., “The Colosseum is in”), and three model runs:\n\n (1) Clean run: run the model on Xclean and cache activations of a set of given model components,\n    such as MLP or attention heads outputs.\n\n\n                                       2\n\n (2) Corrupted run: run the model on Xcorrupt and record the model outputs.\n (3) Patched run: run the model on Xcorrupt with a specific model component’s activation restored\n    from the cached value of the clean run (Figure 1a).\n\nFinally, we evaluate the patching effect, such as P(“Paris”) in the patched run (3) compared to\nthe corrupted run (2).  Intuitively, corruption hurts model performance while patching restores it.\nPatching effect measures how much the patching intervention restores performance, which indicates\nthe importance of the activation. We can iterate this procedure over a collection of components (e.g.,\nall attention heads), resulting in a plot that highlights the important ones (Figure 1b).\n\nCorruption methods  To generate Xcorrupt, GN adds Gaussian noise N(0, ν) to the embeddings\nof certain key tokens, where ν is 3 times the standard deviation of the token embeddings from\nthe textset. STR replaces the key tokens by similar ones with equal sequence length.  In STR,\nlet r′ denote the answer of Xcorrupt (“Rome”). All implementations of STR in this paper yield in-\ndistribution prompts such that Xcorrupt is identically distributed as a fresh draw of a clean prompt.\n\nMetrics  The patching effect is defined as the gap of the model performance between the corrupted\nand patched run, under an evaluation metric. Let cl, ∗, pt be the clean, corrupted and patched run.\n\n• Probability: P(r); e.g., P(“Paris”). The patching effect is Ppt(r) −P∗(r);\n• Logit difference: LD(r, r′) = Logit(r) −Logit(r′); e.g., Logit(“Paris”) −Logit(“Rome”).\n  The patching effect is given by LDpt(r, r′)−LD∗(r, r′). Following Wang et al. (2023), we always\n  normalize this by LDcl(r, r′) −LD∗(r, r′), so it typically lies in [0, 1], where 1 corresponds to\n   fully restored performance and 0 to the corrupted run performance.\n• KL divergence: DKL(Pcl||P), the Kullback-Leibler (KL) divergence from the probability distri-\n  bution of model outputs in the clean run. The patching effect is DKL(Pcl||P∗) −DKL(Pcl||Ppt).\n\nGN does not provide a corrupted prompt with a well-defined answer r′ (“Rome”). To make a fair\ncomparison, the same r′ is used for evaluating the logit difference metric under GN.\n\n\n2.2  PROBLEM SETTINGS\n\nFactual recall  In the setting of factual association, the model is prompted to fill in factual infor-\nmation, e.g., “The Eiffel Tower is in”. Meng et al. (2022) posits that Transformer-based language\nmodels complete factual recall (i) at middle MLP layers and (ii) specifically at the processing of the\nsubject’s last token. In this work, we do not treat the hypothesis as ground-truth but rather reevaluate\nit using other approaches than what was attempted by Meng et al. (2022).\n\nIOI  An IOI sentence involves an initial dependent clause, e.g., “When John and Mary went to the\noffice”, followed by a main clause, e.g., “John gave a book to Mary.” In this case, the indirect object\n(IO) is “Mary” and the subject (S) “John”. The IOI task is to predict the final token in the sentence\nto be the IO. We use S1 and S2 to refer to the first and second occurrences of the subject (S).\n\nWe let pIOI denote the distribution of IOI sentences of Wang et al. (2023) containing single-token\nnames. GPT-2 small performs well on pIOI and Wang et al. (2023) discovers a circuit within the\nmodel for this task. The circuit consists of attention heads. This is also the focus of our experiments,\nwhere we uncover nuanced differences when using different techniques to replicate their result.\n\n3  CORRUPTION METHODS\n\nIn this section, we evaluate GN and STR on localizing factual recall in GPT-2 XL and discovering\nthe IOI circuit in GPT-2 small.\n\nExperiment setup  For factual recall, we investigate Meng et al. (2022)’s hypothesis that model\ncomputation is concentrated at early-middle MLP layers (by processing the last subject token).\nSpecifically, we corrupt the subject token(s) to generate Xcorrupt. In the patched run, we override\nthe MLP activations at the last subject token. Following Meng et al. (2022); Hase et al. (2023), at\n\n\n                                       3\n\n                                          Probability, window size = 5                    Logit diﬀerence, window size = 5\n\n                                                                                        STR                                                 STR\n                                               0.08                                      GN   0.25                                      GN\n\n\n                                                                                                                   0.2\n                                               0.06\n       Last\n     subject     MLP?                                                                                 0.15\n      token                                   0.04\n                                                                                                                   0.1\n\n                                               0.02\n     END                 Logits                                                                        0.05\n\n                                            0                                                    0\n  (a) Patching MLP at              0             20            40                       0             20            40\n  the last subject token.            (b) Probability as the metric          (c) Logit difference as the metric\n\nFigure 2: Disparate MLP patching effects for factual recall in GPT-2 XL. (a) We patch MLP\nactivations at the last subject token. (b)(c) The patching effects using different corruption methods\nwith a window size of 5. STR suggests much a weaker peak, regardless of the evaluation metric.1\n\n\neach layer we restore a set of 5 adjacent MLP layers. (More results on other window sizes can be\nfound in Section G.1. We examine sliding window patching more closely in Section 5.)\n\nFor IOI circuit discovery, we follow Wang et al. (2023) and focus on the role of attention heads.\nCorruption is applied to the S2 token. Then we patch a single attention head’s output (at all positions)\nand iterate over all heads in this way. To avoid relying on visual inspection, we say that a head is\ndetected if its patching effect is 2 standard deviation (SD) away from the mean effect.\n\n\nDataset and corruption method  STR requires pairs of Xclean and Xcorrupt that are semantically\nsimilar. To perform STR, we construct PAIREDFACTS of 145 pairs of prompts on factual recall. All\nthe prompts are in-distribution, as they are selected from the original dataset of Meng et al. (2022);\nsee Appendix B for details. GPT-2 XL achieves an average of 49.0% accuracy on this dataset.\n\nFor the IOI circuit, we use the pIOI distribution to sample the clean prompts. For STR, we replace\nS2 by IO to construct Xcorrupt such that Xcorrupt is still a valid in-distribution IOI sentence. For GN,\nwe add noise to the S2’s token embedding. The experiments are averaged over 500 prompts.\n\n\n3.1  RESULTS ON CORRUPTION METHODS\n\nDifference in MLP localization  For patching MLPs in the factual association setting, Meng et al.\n(2022) show that the effects concentrate at early-middle layers, where they apply GN as the corrup-\ntion method. Our main finding is that the picture can be largely different by switching the corruption\nmethod, regardless of the choice of metric. In Figure 2, we plot the patching effects for both metrics.\nNotice that the clear peak around layer 16 under GN is not salient at all under STR.\n\nThis is a robust phenomenon: across window sizes, we find the peak value of GN to be 2×–5× higher\nthan STR; see Appendix G.1 for further plots on GPT-2 XL in this setting.\n\nThese findings illustrate potential discrepancies between the two corruption techniques in drawing\ninterpretability conclusions. We do not, though, claim that results from GN are illusory or overly\ninflated. In fact, GN does not always yield sharper peaks than STR. For certain basic arithmetic\ntasks in GPT-J, STR can show stronger concentration in patching MLP activations; see Appendix C.\n\n\nDifference in circuit discovery  We focus on discovering the main classes of attention heads in\nthe IOI circuit, including (Negative) Name Mover (NM), Duplicate Token (DT), S-Inhibition (SI),\nand Induction Heads. The results are summarized in Table 1 and more details in Appendix H.\n\nMost importantly, we observe that STR and GN produce inconsistent discovery results. In particular,\nfor any fixed metric, STR and GN detect different sets of heads as important, highlighted in Table 1.\n\nWe remark that all the detections are in the IOI circuit as found by Wang et al. (2023). However, the\ndiscovery we achieved here appear far from complete, with some critical misses such as NM. This\nsuggests that the extensive manual inspection and the use of path patching, a more surgical patching\nmethod, are both necessary to fully discover the IOI circuit.\n\n   1The effects on the first 3 layers are large simply because MLP0 has significant influence on the model’s\noutputs in GPT-2, regardless of the task (Wang et al., 2023; Hase et al., 2023), so it is not the focus here.\n\n\n                                       4\n\n       Corruption  Metric      NM  DT    SI    Negative NM   Induction\n\n      STR           Probability      1/3  0/2  3/4      1/2        1/2\n     GN †          Probability      0/3  1/2  2/4      2/2        1/2\n\n      STR          Logit difference   1/3  0/2   3/4      2/2         1/2\n     GN           Logit difference   1/3  1/2   3/4      2/2         1/2\n\n      STR      KL divergence    1/3   0/2  3/4      2/2         1/2\n     GN †      KL divergence    0/3   0/2  2/4      2/2         1/2\n\nTable 1: Inconsistency in circuit discovery from activation patching on the IOI task. We patch\nthe attention heads outputs and list the detections of each class. †Also detect 0.10, a fuzzy Duplicate\nToken Head, as negatively influencing model performance. We expect it to be positive (Wang et al., 2023).\n\n         Attention of Name Movers (corrupted)                                                         Attention of Name Movers (patched)\n\n                                               Clean                                                                                                                   Clean\n                                         STR                                                                                                       STR\n          0.6                          GN                                                                                      0.6                          GN\n                                                         V\n                                             K\n          0.4                                                               S-Inhibition     Name Mover             0.4\n                                      Q     Heads          Heads\n\n          0.2                                                                                                                              0.2\n                                           (b) We patch the value ma-\n\n          0     IO         S1         S2        Others                                              trices of  all the SI heads           0     IO         S1         S2        Others\n                                  and examine the impact on\n            (a) Corrupted run         NMs’ attention patterns.                  (c) Patched run\n\n   Figure 3: Attention of the Name Movers from the last token, in corrupted and patched runs.\n\nWe also validate our high-level conclusions on the Python docstring (Heimersheim & Janiak, 2023)\nand the greater-than (Hanna et al., 2023) task. In particular, we find GN can produce highly noisy\nlocalization outcomes in these settings; see Appendix D and Appendix E for details.\n\n\n3.2  EVIDENCE FOR OOD BEHAVIOR IN GAUSSIAN NOISE CORRUPTION\n\nWe suspect that the gaps between the corruption methods can be attributed partly to model’s OOD\nbehavior under GN corruption. In particular, the Gaussian noise may break model’s internal mech-\nanisms by introducing OOD inputs to the layers. We now give some tentative evidence for this\nhypothesis. Following the notation of Wang et al. (2023), a head is denoted by “layer.head”.\n\nNegative detection of 0.10 under GN  Although most localizations we obtain above seem aligned\nwith the findings of Wang et al. (2023), a major anomaly in the GN experiment is the “negative”\ndetection of 0.10. In particular, probability and KL divergence suggest that it contributes negatively\nto model performance. (Logit difference also assigns a negative effect, though to a lesser degree;\nsee Figure 29b.) This is not observed at all in the experiments with STR corruption.\n\nThe detection is in the wrong direction, given the evidence from Wang et al. (2023) that 0.10 helps\nwith IOI; on clean prompts, it is active at S2, attends to S1 and signals this duplication. However,\nby visualizing the attention patterns, we find that this effect largely disappears under GN corruption.\nWe intuit that the Gaussian noise is strongest at influencing early layers, and 0.10’s behavior may be\nbroken here, since it directly receives the noised token embeddings from the residual stream.\n\nAttention of Name Movers  To exhibit the OOD behavior of the model internals under GN cor-\nruptions, we examine the Name Mover (NM) Heads, a class of attention heads that directly affects\nthe model’s logits in the IOI circuit (Wang et al., 2023). NMs are active at the last token and copy\nwhat they attend to. We plot the attention of NMs in clean and corrupted runs in Figure 3a.\n\nIndeed, on 500 clean IOI prompts, the NMs assign an average of 0.58 attention probability to IO.\nIn the corrupted runs, since STR simply exchanges IO by S1, the attention patterns of NMs are\npreserved (with the role of IO and S1 switched). On the other hand, with GN corruption, we see that\nthe attention is shared between IO and S1 (0.26 and 0.21). This suggests that GN not only removes\nthe relevant information but also disrupts the internal mechanism of NMs on IOI sentences.\n\nTo take a deeper dive, Wang et al. (2023) shows that the output of NMs is determined largely by\nthe values of the S-Inhibition Heads.  Indeed, we can fully recover model’s logit on IO in STR\n\n\n                                       5\n\n(logit difference: 1.04) by restoring the values of the S-Inhibition Heads (Figure 3b). The same\nintervention, however, is fairly unsuccessful under GN (logit difference: 0.49).\n\nTowards explaining this gap, we again examine the attention of NMs. Figure 3c shows that patching\nnearly restores the NMs’ in-distribution attention pattern under STR, but fails under GN corruption.\nWe speculate that GN introduces further corrupted information flowing into the NMs such that\nrestoring the clean activations of S-Inhibition Heads cannot correct their behaviors.\n\n4  EVALUATION METRICS\n\nWe now study the choice of evaluation metrics in activation patching. We perform two experiments\nthat highlight potential gaps between logit difference and probability. Along the way, we provide a\nconceptual argument for why probability can overlook negative components in certain settings.\n\n\n4.1  LOCALIZING FACTUAL RECALL WITH LOGIT DIFFERENCE\n\nThe prior work of Meng et al. (2022) hypothesizes that factual association is processed at the last\nsubject token. Motivated by this claim, we extend our previous experiments to patching the MLP\noutputs at all token positions and consider the effect of changing evaluation metrics.\n\nExperimental setup  We apply the same setting as in Section 3. We extend our MLP patching\nexperiments to all token positions and again use logit difference and probability as the metric.\n\nExperimental results  For STR and window size of 5, we plot the patching effects across layers\nand positions in Figure 4. The visualization shows that probability assigns stronger effects at the last\nsubject token than logit difference. Specifically, we calculate the ratio between the sum of effects\n(over all layers) on the last subject token and those on the middle subject tokens. In both corruptions,\nprobability assigns more effects to the last subject token than logit difference:\n\n• Using STR corruption, the ratio is 4.33× in probability > 1.22× in logit difference.\n• Using GN corruption, the ratio is 1.74× in probability > 0.77× in logit difference.\n\nThis observation holds for other window sizes, too, for which we provide details in Appendix G.2.\nWe also validate our findings on GPT-J 6B (Wang & Komatsuzaki, 2021) in Appendix G.5. The\nresults show that the choice of evaluation metrics influences the patching effects across tokens.\n\n\n\n\n                                                                                                                                                    0.02\n                  10                                                                          0.2                     10\n                                                                                                                                                    0.01\n                  20                                                                  20\n                                                              0                                                                  0                                  Layer                                                                                                                                                           Layer\n                  30                                                                  30\n                                                                                                                                      −0.01\n                                                                 −0.2\n\n                  40                                                                  40                                           −0.02\n\n                         Mid                                   The                                                                                       Mid                                    Last                                                       Last                             First                                                                                              The                                                                                                             Last                                                                                                                                Last                                                                                                                        First                                                       Further                                                                                                                                         Further                                                           token                                                                                                                                  token                                     subject                                                                                                                       subject                                             subject                              subject                                                                                                                              subject                                                                                                                subject                                                         tokens                                                                                                                                    tokens                                             tokensubsequent                                 token                                                                                                                     tokensubsequent                                        tokens                                                                                                         token                                                                                                                    tokens                                                      token                                                                   token\n\n                  (a) Logit difference (STR)                           (b) Probability (STR)\n\nFigure 4: Activation patching on MLP across layers and token positions in GPT-2 XL, with a\nsliding window patching of size 5. Note that probability (b) highlights the importance of the last\nsubject token, whereas logit difference (a) displays less effects.\n\n\n4.2  CIRCUIT DISCOVERY WITH PROBABILITY\n\nWang et al. (2023) discovers two Negative Name Mover (NNM) heads, 10.7 and 11.10, that notice-\nably hurt model performance on IOI. In our previous experiments on STR, both are detected, except\nwhen using probability as the metric where 11.10 is overlooked. In fact, the patching effect of 11.10\n\n\n                                       6\n\n  Probability, GN, window = 1            Probability, GN, window = 3          Probability, GN, window = 5          Probability, GN, window = 10\n\n0.08                                                                                                                                                                                            adding\n                                                                                                0.15                                               0.2                                                          sliding\n\n0.06                                                0.1\n                                                                                                                                                 0.15\n                                                                                                      0.1\n\n0.04\n                                                                                                                                                         0.1\n                                                 0.05\n0.02                                                                                            0.05                                            0.05\n\n\n   0                                         0                                         0                                         0\n\n      0             20            40             0            20            40             0            20            40             0            20            40\n\n(a) Single-layer patching   (b) Window size of 3     (c) Window size of 5        (d) Window size of 10\n\nFigure 5: Sliding window patching vs summing up individual patching effects; patching MLP\nactivation at the last subject token in GPT-2 XL on factual recall prompts. Sliding window patching\noffers 1.40×, 1.75× and 1.59× peak value than summation of single-layer patchings. Single-layer\npatching (a) suggests a weak peak.\n\nunder STR in probability is well within 2 SD from the mean (mean 0.003, SD 0.015, and 11.10\nreceives −0.022). Looking closely, the reason is simple:\n\n• In the corrupted run of STR, the average probability of outputting the original IO is 0.03. Hence,\n  the patching effect in probability, Ppt(IO) −P∗(IO), is at least −0.03, as Ppt(IO) is non-negative.\n  This is already close to 2 SD below the mean (−0.027). Hence, for an NNM to be detected via\n  patching, its Ppt(IO) needs to be near 0, which may be hard to reach.\n• By contrast, under GN corruption, the average probability of IO is 0.13. Intuitively, this makes a\n   lot more space for NNMs to demonstrate their effects.\n\nIn general, probability must fail to detect negative model components, if corruption reduces the\ncorrect token probability to near zero. We now give a cleaner experimental demonstration of this\nconcern, using an original approach of Wang et al. (2023).\n\nExperimental setup  We revisit an alternative corruption method proposed by Wang et al. (2023),\nwhere S1, S2 and IO are replaced by three unrelated random names2; for example, “John and Mary\n[...], John” →“Alice and Bob [...], Carol.” We use probability of the original IO as the metric.\nIntuitively, this replacement method would achieve much stronger corruption effect, since it removes\nall the relevant information (S and IO) of the original IOI sentence.\n\nExperimental results   First, we observe that the probability of outputting the IO of the original\nIOI sentence is negligible (5e−4) under this corruption. As a result, using probability detects neither\nNNMs. On the other hand, we find that logit difference still can. See Appendix H.3 for the plots. In\nAppendix F, we confirm the same finding when corruption is applied to S1 and IO only.\n\nAt a high-level, we believe that this is a pitfall of probability as an evaluation metric. Its non-negative\nnature makes it incapable of discovering negative model components in certain settings.\n\n5  SLIDING WINDOW PATCHING\n\nIn this section, we examine the technique of sliding window patching in localizing factual informa-\ntion (Meng et al., 2022). For each layer, the method patches multiple adjacent layers simultaneously\nand computes the joint effects. Hence, one should interpret the result of Meng et al. (2022) as\nthe effects being constrained within a window rather than at a single layer. We argue that such as\nhypothesis can be tested by an alternative approach and we compare the results from these two.\n\nExperimental setup  Instead of restoring multiple layers simultaneously, we patch each individual\nMLP layer one at a time. Then as an aggregation step, for each layer, sum up the single-layer\npatching effects of its adjacent layers. For example, we add up the effect at layer 2 to layer 6 to get\nan aggregated effect for layer 4. We patch the MLP output at the last subject token.\n\nExperimental results  For each window size, we compute the ratio of the maximum patching\neffect at the middle MLP layers between sliding window patching and summation of single-layer\n\n    2This corrupted distribution is denoted by pABC in the original paper of Wang et al. (2023)\n\n\n                                       7\n\npatching. Over the combinations of window sizes, metrics and corruption methods, we find sliding\nwindow patching typically provides at least 20% more peak effect than the summation method.\n\nIn Figure 5, for window sizes of 3, 5, 10, we plot the results using GN corruption and probability as\nthe metric, the original setting as in Meng et al. (2022). We observe significant gaps between the\nsliding window and the summation method. Moreover, for single-layer patching, the peak at layer\n15 is fairly weak (Figure 5a). Sliding window patching appears to generate more pronounced the\nconcentration, as we increase the window sizes.\n\nThe result suggests that sliding window patching tends to amplify weak localization from single-\nlayer patching (see Figure 12 for plots on single-layer MLP patching in GPT-2 XL). We believe this\nmay arise due to certain non-linear effects in joint patching and therefore results from which should\nbe carefully interpreted; see Section 6 for more discussions.\n\n6  DISCUSSION AND RECOMMENDATIONS\n\nWe have observed a variety of gaps between corruption methods and evaluation metrics used in\nactivation patching on language models. In this section, we summarize our findings and provide\nrecommendations.\n\nCorruption methods  We are concerned that GN corruption puts the model off distribution by\nintroducing noise never seen during training. Indeed, in Section 3.2, we provide evidence that in\nthe corrupted run, model’s internal functioning is OOD relative to the clean distribution. This may\ninduce unexpected anomalies in the model behavior, interfering with our ability to localize behavior\nto specific components. Conceivably, GN corruption could even lead to unreliable or illusory results.\n\nMore broadly, this presents a challenge to any intervention techniques that introduce OOD inputs\nto the model or its internal layers, including ablations. In fact, similar concerns have been raised\nearlier in the interpretability literature on feature attribution as well; see e.g. Hooker et al. (2019);\nJanzing et al. (2020); Hase et al. (2021).\n\nIn contrast, STR provides counterfactual prompts (“The Eiffel Tower is in” vs “The Colosseum is\nin”) that are in-distribution and thus induces in-distribution activations, avoiding the OOD issue.\nTherefore, we recommend STR whenever possible. GN may be considered as an alternative when\ntoken alignment or lack of analogous tokens makes STR unsuitable.\n\nEvaluation metrics  We generally recommend avoiding using probability as the metric, given that\nit may fail to detect negative model components.\n\nWe find logit difference a convincing metric for localization in language models. Consider an IOI\nsetting where a model contains an attention head that boosts the logits of all (single-token) names.\nThis head, though important, should not be viewed as part of the IOI circuit, but our interventions\nmay still affect it.3 By measuring Logit(IO) −Logit(S), logit difference controls for such com-\nponents and ensures they are not detected.  This may not be achieved by other metrics, such as\nprobability or Logit(IO) alone.\n\nKL divergence tracks the full model output distributions, rather than focused only on the correct or\nincorrect answer, and can be a reasonable metric for circuit discovery as well (Conmy et al., 2023).\n\nSliding window patching  We speculate that simultaneously patching multiple layers could cap-\nture the following non-linear effects and results in inflated localization plots:\n\n• Joint patching may suppress the flow of corrupted information within the window of patched\n   layers, where single-layer patching offers no such control.\n• A window of patched layers may jointly perform a crucial piece of computation, such as a major\n  boost to the logit of the correct token, which no individual layer can single-handedly achieve.\n\nGenerally, when examining the outcome from sliding window patching, one should be aware of\nthe possibility of multiple layers working together.  Thus, the results from the technique are to\n\n   3We note that if our interventions do not affect the head, then it will not show up on any metric.\n\n\n                                       8\n\nbe interpreted as the joint effects of the full window, rather than of a single layer.  In practice,\nwe recommend experimenting with single-layer patching first and only consider sliding window\npatching when individual layers seem to induce small effects.\n\nWhich tokens to corrupt?  In some problem settings, a prompt contains multiple key tokens, all\nrelevant to completing the task. This would offer the flexibility to choose which tokens to corrupt.\nThis is another important dimension of activation patching. For instance, our experiments on IOI in\nSection 3 corrupt the S2 token. An alternative is to corrupt the S1 and IO. While this may seem an\nimplementation detail, we find that this can greatly affect the localization outcomes.\n\nSpecifically, in Appendix F, we test corrupting S1 and IO in activation patching on IOI sentences,\nby changing their values to random names or adding noise to the token embeddings  . We find\nthat almost all techniques discover the 3 Name Mover (NM) Heads of the IOI circuit (Table 4 and\nFigure 11). These are attention heads that directly contribute to Logit(IO) as shown by Wang et al.\n(2023). In contrast, our prior experiments corrupting S2 miss most of them (Table 1).\n\nWe intuit that corrupting different tokens allows activation patching to trace different information\nwithin the model, thereby suggesting varying localizations results. For instance, in our prior exper-\niments replacing S2 by IO, patching traces the value of IO or its position. On the other hand, in\nchanging the values of S1 and IO while fixing their positions, patching highlights exactly where the\nmodel processes these values.\n\nIn practice, we recommend trying out different tokens to corrupt when the problem setting offers\nsuch flexibility. This may lead to more exhaustive circuit discovery.\n\n7  RELATED WORK\n\nActivation patching  Activation patching is a variant of causal mediation analysis (Vig et al., 2020;\nPearl, 2001), similar forms of which are used broadly in the interpretability literature (Soulos et al.,\n2020; Geiger et al., 2020; Finlayson et al., 2021; Geiger et al., 2022). The specific one with GN\ncorruption was first proposed by Meng et al. (2022) under the name of causal tracing. Wang et al.\n(2023); Goldowsky-Dill et al. (2023) generalize this to a more sophisticated version of path patching.\n\nCircuit analysis   Circuit analysis provides post-hoc model interpretability (Casper et al., 2022).\nThis line of work is inspired by Cammarata et al. (2020); Elhage et al. (2021). Other works include\nGeva et al. (2022); Li et al. (2023a); Nanda et al. (2023a); Chughtai et al. (2023); Zhong et al. (2023);\nNanda et al. (2023b); Varma et al. (2023); Wen et al. (2023); Hanna et al. (2023); Lieberum et al.\n(2023). Circuit analysis often requires manual effort by researchers, motivating recent work to scale\nor automate parts of the workflow (Chan et al., 2022; Bills et al., 2023; Conmy et al., 2023; Geiger\net al., 2023; Wu et al., 2023; Lepori et al., 2023).\n\nMechanistic interpretability (MI)  MI aims to explain the internal computations and representa-\ntions of a model. While circuit analysis is a major direction under this broad theme, other recent\ncase studies of MI in language model include Mu & Andreas (2020); Geva et al. (2021); Yun et al.\n(2021); Olsson et al. (2022); Scherlis et al. (2022); Dai et al. (2022); Gurnee et al. (2023); Merullo\net al. (2023); McGrath et al. (2023); Bansal et al. (2023); Dar et al. (2023); Li et al. (2023c); Brown\net al. (2023); Katz & Belinkov (2023); Cunningham et al. (2023).\n\n8  CONCLUSION\n\nWe examine the role of metrics and methods in activation patching in language models. We find\nthat variations in these techniques could lead to different interpretability results. We provide several\nrecommendations towards the best practice, including the use of STR as the corruption method.\n\nIn terms of limitations, our experiments are on decoder-only language models of size up to 6B. We\nleave it as a future direction to study other architectures and even larger models. Our work tests\noverriding corrupted activations by clean activations. The other direction—patching corrupted to\nclean—has also been used for circuit discovery, and it is interesting to compare these two. In addi-\ntion, we provide tentative evidence that certain corruption methods lead to OOD model behaviors\n\n\n                                       9\n\nand suspect that this can make the resulting interpretability claims unreliable. Future work should\nexamine this hypothesis closely and furnish further demonstrations. Finally, it is interesting to de-\nvelop more principled techniques for activation patching or propose other methods for localization.\n\nACKNOWLEDGMENTS\n\nFZ would like to thank Matthew Farhbach, Dan Friedman, Johannes Gasteiger, Asma Ghandehari-\noun, Stefan Heimersheim, J´anos Kram´ar, Kaifeng Lyu, Vahab Mirrokni, Jacob Steinhardt and Peilin\nZhong for helpful discussions, and Jiahai Feng, Yossi Gandelsman, Oscar Li and Alex Wei for com-\nments on early drafts of the paper.\n\n\nREFERENCES\n\nHritik Bansal, Karthik Gopalakrishnan, Saket Dingliwal, Sravan Bodapati, Katrin Kirchhoff, and\n  Dan Roth. Rethinking the role of scale for in-context learning: An interpretability-based case\n  study at 66 billion scale.  In Annual Meeting of the Association for Computational Linguistics\n  (ACL), 2023.\n\nBoaz Barak, Benjamin Edelman, Surbhi Goel, Sham Kakade, Eran Malach, and Cyril Zhang. Hid-\n  den progress in deep learning: SGD learns parities near the computational limit. In Advances in\n  Neural Information Processing Systems (NeurIPS), 2022.\n\nSteven Bills, Nick Cammarata, Dan Mossing, Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever,\n  Jan Leike, Jeff Wu, and William Saunders. Language models can explain neurons in language\n  models.  https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html,\n  2023.\n\nDavis Brown, Nikhil Vyas, and Yamini Bansal. On privileged and convergent bases in neural net-\n  work representations. arXiv preprint arXiv:2307.12941, 2023.\n\nNick Cammarata, Shan Carter, Gabriel Goh, Chris Olah, Michael Petrov, Ludwig Schubert, Chelsea\n  Voss, Ben Egan, and Swee Kiat Lim. Thread: Circuits. Distill, 5(3):e24, 2020.\n\nStephen Casper, Tilman Rauker, Anson Ho, and Dylan Hadfield-Menell. Toward transparent AI:\n A survey on interpreting the inner structures of deep neural networks. In IEEE Conference on\n  Secure and Trustworthy Machine Learning (SaTML), 2022.\n\nLawrence  Chan,   Adri`a  Garriga-Alonso,   Nicholas  Goldwosky-Dill,  Ryan   Greenblatt,\n  Jenny Nitishinskaya, Ansh Radhakrishnan, Buck  Shlegeris, and Nate Thomas.   Causal\n  scrubbing,  a  method  for  rigorously  testing  interpretability  hypotheses.     AI  Align-\n  ment   Forum,    2022.         https://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/\n  causal-scrubbing-a-method-for-rigorously-testing.\n\nBilal Chughtai, Lawrence Chan, and Neel Nanda. A toy model of universality: Reverse engineering\n  how networks learn group operations. In International Conference on Machine Learning (ICML),\n  2023.\n\nArthur Conmy, Augustine N Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adri`a Garriga-\n  Alonso. Towards automated circuit discovery for mechanistic interpretability.  In Advances in\n  Neural Information Processing Systems (NeurIPS), 2023.\n\nHoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, and Lee Sharkey. Sparse autoen-\n  coders find highly interpretable features in language models. arXiv preprint arXiv:2309.08600,\n  2023.\n\nDamai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons\n   in pretrained transformers. In Annual Meeting of the Association for Computational Linguistics\n  (ACL), 2022.\n\nGuy Dar, Mor Geva, Ankit Gupta, and Jonathan Berant.  Analyzing transformers in embedding\n  space. In Annual Meeting of the Association for Computational Linguistics (ACL), 2023.\n\n\n                                       10\n\nNelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann,\n  Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Deep\n  Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Andy Jones, Jackson Kernion, Liane Lovitt,\n  Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and\n  Chris Olah. A mathematical framework for transformer circuits. Transformer Circuits Thread,\n  2021. https://transformer-circuits.pub/2021/framework/index.html.\n\nMatthew Finlayson, Aaron Mueller, Sebastian Gehrmann, Stuart M Shieber, Tal Linzen, and\n  Yonatan Belinkov. Causal analysis of syntactic agreement mechanisms in neural language mod-\n   els. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics\n  and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP),\n  2021.\n\nAtticus Geiger, Kyle Richardson, and Christopher Potts. Neural natural language inference models\n   partially embed theories of lexical entailment and negation. In Proceedings of the Third Black-\n  boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, 2020.\n\nAtticus Geiger, Hanson Lu, Thomas Icard, and Christopher Potts.  Causal abstractions of neural\n  networks. In Advances in Neural Information Processing Systems (NeurIPS), 2021.\n\nAtticus Geiger, Zhengxuan Wu, Hanson Lu, Josh Rozner, Elisa Kreiss, Thomas Icard, Noah Good-\n  man, and Christopher Potts. Inducing causal structure for interpretable neural networks. In Inter-\n  national Conference on Machine Learning (ICML), 2022.\n\nAtticus Geiger, Zhengxuan Wu, Christopher Potts, Thomas Icard, and Noah D Goodman. Finding\n  alignments between interpretable causal variables and distributed neural representations. arXiv\n  preprint arXiv:2303.02536, 2023.\n\nMor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. Transformer feed-forward layers are\n  key-value memories.  In Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), 2021.\n\nMor Geva, Avi Caciularu, Kevin Wang, and Yoav Goldberg. Transformer feed-forward layers build\n  predictions by promoting concepts in the vocabulary space. In Conference on Empirical Methods\n   in Natural Language Processing (EMNLP), 2022.\n\nMor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson.  Dissecting recall of factual\n  associations in auto-regressive language models. arXiv preprint arXiv:2304.14767, 2023.\n\nNicholas Goldowsky-Dill, Chris MacLeod, Lucas Sato, and Aryaman Arora.  Localizing model\n  behavior with path patching. arXiv preprint arXiv:2304.05969, 2023.\n\nWes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, and Dimitris Bert-\n  simas.  Finding neurons in a haystack:  Case studies with sparse probing.  arXiv preprint\n  arXiv:2305.01610, 2023.\n\nMichael Hanna, Ollie Liu, and Alexandre Variengien. How does GPT-2 compute greater-than?:\n   Interpreting mathematical abilities in a pre-trained language model. In Advances in Neural Infor-\n  mation Processing Systems (NeurIPS), 2023.\n\nPeter Hase, Harry Xie, and Mohit Bansal. The out-of-distribution problem in explainability and\n  search methods for feature importance explanations. In Advances in Neural Information Process-\n  ing Systems (NeurIPS), 2021.\n\nPeter Hase, Mohit Bansal, Been Kim, and Asma Ghandeharioun. Does localization inform editing?\n  Surprising differences in causality-based localization vs. knowledge editing in language models.\n  In Advances in Neural Information Processing Systems (NeurIPS), 2023.\n\nStefan  Heimersheim  and  Jett  Janiak.   A  circuit  for  Python  docstrings  in  a  4-layer\n  attention-only  transformer.      https://www.alignmentforum.org/posts/u6KXXmKFbXfWzoAXn/\n  a-circuit-for-python-docstrings-in-a-4-layer-attention-only, 2023.\n\n\n                                       11\n\nEvan Hernandez, Sarah Schwettmann, David Bau, Teona Bagashvili, Antonio Torralba, and Jacob\n  Andreas. Natural language descriptions of deep visual features. In International Conference on\n  Learning Representations (ICLR), 2021.\n\nSara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, and Been Kim. A benchmark for interpretabil-\n   ity methods in deep neural networks.  In Advances in neural information processing systems\n  (NeurIPS), 2019.\n\nDominik Janzing, Lenon Minorics, and Patrick Bl¨obaum. Feature relevance quantification in ex-\n  plainable ai: A causal problem. In International Conference on Artificial Intelligence and Statis-\n   tics (AISTATS), 2020.\n\nShahar Katz and Yonatan Belinkov. Interpreting transformer’s attention dynamic memory and visu-\n   alizing the semantic information flow of GPT. arXiv preprint arXiv:2305.13417, 2023.\n\nMichael A Lepori, Ellie Pavlick, and Thomas Serre.  NeuroSurgeon: A toolkit for subnetwork\n   analysis. arXiv preprint arXiv:2309.00244, 2023.\n\nKenneth Li, Aspen K Hopkins, David Bau, Fernanda Vi´egas, Hanspeter Pfister, and Martin Watten-\n  berg. Emergent world representations: Exploring a sequence model trained on a synthetic task.\n  In International Conference on Learning Representations (ICLR), 2023a.\n\nKenneth Li, Oam Patel, Fernanda Vi´egas, Hanspeter Pfister, and Martin Wattenberg.  Inference-\n  time intervention:  Eliciting truthful answers from a language model.  In Advances in Neural\n  Information Processing Systems (NeurIPS), 2023b.\n\nYuchen Li, Yuanzhi Li, and Andrej Risteski. How do transformers learn topic structure: Towards a\n  mechanistic understanding. In International Conference on Machine Learning (ICML), 2023c.\n\nTom Lieberum, Matthew Rahtz, J´anos Kram´ar, Geoffrey Irving, Rohin Shah, and Vladimir Miku-\n   lik. Does circuit analysis interpretability scale? Evidence from multiple choice capabilities in\n  Chinchilla. arXiv preprint arXiv:2307.09458, 2023.\n\nThomas McGrath, Matthew Rahtz, Janos Kramar, Vladimir Mikulik, and Shane Legg. The hydra\n   effect: Emergent self-repair in language model computations. arXiv preprint arXiv:2307.15771,\n  2023.\n\nKevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.  Locating and editing factual\n  associations in GPT. In Advances in Neural Information Processing Systems (NeurIPS), 2022.\n\nJack Merullo, Carsten Eickhoff, and Ellie Pavlick. Language models implement simple word2vec-\n   style vector arithmetic. arXiv preprint arXiv:2305.16130, 2023.\n\nJesse Mu and Jacob Andreas.  Compositional explanations of neurons.  In Advances in Neural\n  Information Processing Systems (NeurIPS), 2020.\n\nNeel Nanda and  Joseph Bloom.    TransformerLens.    https://github.com/neelnanda-io/\n  TransformerLens, 2022.\n\nNeel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. Progress measures\n   for grokking via mechanistic interpretability. In International Conference on Learning Represen-\n   tations (ICLR), 2023a.\n\nNeel Nanda, Andrew Lee, and Martin Wattenberg. Emergent linear representations in world models\n  of self-supervised sequence models. arXiv preprint arXiv:2309.00941, 2023b.\n\nChris Olah. Mechanistic interpretability, variables, and the importance of interpretable bases. https:\n  //transformer-circuits.pub/2022/mech-interp-essay/index.html, 2022.\n\nCatherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan,\n  Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli,\n  Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane\n   Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCan-\n   dlish, and Chris Olah.  In-context learning and induction heads. Transformer Circuits Thread,\n  2022.  https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/\n  index.html.\n\n\n                                       12\n\nJudea Pearl. Direct and indirect effects. In Conference on Uncertainty and Artificial Intelligence\n  (UAI), 2001.\n\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language\n  models are unsupervised multitask learners. OpenAI blog, 2019.\n\nAdam Scherlis, Kshitij Sachan, Adam S Jermyn, Joe Benton, and Buck Shlegeris. Polysemanticity\n  and capacity in neural networks. arXiv preprint arXiv:2210.01892, 2022.\n\nPaul Soulos, R Thomas McCoy, Tal Linzen, and Paul Smolensky. Discovering the compositional\n   structure of vector representations with role learning networks. In Proceedings of the Third Black-\n  boxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, 2020.\n\nAlessandro Stolfo, Yonatan Belinkov, and Mrinmaya Sachan. Understanding arithmetic reasoning\n   in language models using causal mediation analysis. arXiv preprint arXiv:2305.15054, 2023.\n\nVikrant Varma, Rohin Shah, Zachary Kenton, J´anos Kram´ar, and Ramana Kumar.  Explaining\n  grokking through circuit efficiency. arXiv preprint arXiv:2309.02390, 2023.\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n  Łukasz Kaiser, and Illia Polosukhin.  Attention is all you need.  In Advances in Neural Infor-\n  mation Processing Systems (NeurIPS), 2017.\n\nJesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Yaron Singer, and\n   Stuart Shieber. Investigating gender bias in language models using causal mediation analysis. In\n  Advances in Neural Information Processing Systems (NeurIPS), 2020.\n\nBen Wang and Aran Komatsuzaki.  GPT-J-6B: A 6 Billion Parameter Autoregressive Language\n  Model. https://github.com/kingoflolz/mesh-transformer-jax, May 2021.\n\nKevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. Inter-\n   pretability in the wild: a circuit for indirect object identification in GPT-2 small. In International\n  Conference on Learning Representations (ICLR), 2023.\n\nKaiyue Wen, Yuchen Li, Bingbin Liu, and Andrej Risteski.  (Un)interpretability of transformers:\n  a case study with Dyck grammars.  In Advances in Neural Information Processing Systems\n  (NeurIPS), 2023.\n\nZhengxuan Wu, Atticus Geiger, Christopher Potts, and Noah D Goodman. Interpretability at scale:\n  Identifying causal mechanisms in alpaca. In Advances in Neural Information Processing Systems\n  (NeurIPS), 2023.\n\nZeyu Yun, Yubei Chen, Bruno Olshausen, and Yann LeCun.  Transformer visualization via dic-\n  tionary learning: contextualized embedding as a linear superposition of transformer factors. In\n  Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction\n  and Integration for Deep Learning Architectures, 2021.\n\nZiqian Zhong, Ziming Liu, Max Tegmark, and Jacob Andreas. The clock and the pizza: Two stories\n   in mechanistic explanation of neural networks. In Advances in Neural Information Processing\n  Systems (NeurIPS), 2023.\n\n\nA  REVIEW OF TRANSFORMER ARCHITECTURE\n\nWe follow the notation of Elhage et al. (2021) and give a review of the Transformer architecture\n(Vaswani et al., 2017). The input x0 ∈RN×d to a transformer model is a sum of position and\ntoken embeddings, where N is the sequence length and d is the dimension of the model’s internal\nstates. The input is the initial value of the residual stream which subsequently gets updated by the\ntransformer blocks.\n\nEach transformer block consists of a multi-head self-attention sublayer and an MLP sublayer. (For\nGPT-J, these two sublayers are parallelized.) The MLP sublayer is a two-layer feedforward network\nthat processes each token position independently in parallel. Following Elhage et al. (2021), the\n\n\n                                       13\n\noutput of the attention sublayer can be decomposed into individual heads. For the ith layer, the\nattention output can be written as yi = PHj=1 hi,j (xi), where hi,j denotes the jth attention head of\n                                                                 H ×d. For                                                     H and WO ∈Rthe layer. Each head has four weight matrices, W Qi,j , WKi,j , WVi,j ∈Rd× d                 d\na residual stream x, we refer to Qi,j = xWQi,j , Ki,j = xWKi,j , V i,j = xWVi,j as the query, key and\nvalue of the head. The attention pattern is given by\n\n                         (xWQi,j )(xWKi,j )T   !                      Ai,j = softmax           + M  ∈RN×N,\n                  pd/H\n\nwhere M is the attention mask. In auto-regressive language models, the attention pattern is masked\nto a lower triangular matrix. The output of the attention sublayer is given by\n\n              x + Concat Ai,1V i,1, . . . , Ai,jV i,j, . . . , Ai,HV i,H WO.                  (1)\n\nB  DETAILS ON EXPERIMENTAL SETTINGS\n\nFor Gaussian noise (GN) corruption, we corrupt the embeddings of the crucial tokens by adding\na Gaussian noise ε ∼N(0; ν), where ν is set to be 3 times the standard deviation of the token\nembeddings from the dataset (Meng et al., 2022).\n\nWe always perform GN and STR experiments in parallel. For STR, there is a natural the incorrect\ntoken r′, since Xcorrupt is also a valid in-distribution prompt. This allows for a well-defined metric\nof logit difference LD(r, r′) = Logit(r)−Logit(r′). To make a fair comparison, the same r′ is used\nfor evaluating the logit difference metric under GN.\n\nThroughout the paper, layers are zero-indexed, numbered from 0 to L −1 rather than 1 to L.\n\nFactual recall  To perform STR in the factual association setting, we construct PAIREDFACTS,\na dataset of 145 pairs of prompts.  Within each pair, the two prompts have the same sequence\nlength (under the GPT-2 tokenizer) but distinct answers.  All the prompts are selected from the\nCOUNTERFACT and KNOWN1000 datasets of Meng et al. (2022). On these prompts,\n\n• GPT-2 XL achieves an average of 49.0% probability on the correct token and 6.85 logit difference.\n\n• GPT-2 large achieves 41.1% and 5.88 logit difference.\n\n• GPT-J achieves 50.1% and 7.36 logit difference.\n\nA few samples of the PAIREDFACTS dataset are listed in Figure 31 of Appendix I.\n\nSince the prompts are perfectly symmetric and all of them are in-distribution, our STR experiments\nconsist of both ways, where a prompt within a pair play the role of both Xcorrupt and Xclean.\n\nOur experiments with GN corruption is performed in the same manner as in Meng et al. (2022);\nHase et al. (2023), with noise applied to all subject tokens’ embeddings.\n\nThe experiments here are implemented via the TransformerLens library (Nanda & Bloom, 2022).\n\nIOI  Unless specified otherwise, GN applies Gaussian noise to the S2 token embedding. Over 500\nprompts, the probability of outputting IO is P∗(r) = 0.129 under GN corruption (with r being IO),\nwhereas it is 0.481 under the clean distribution pIOI.\n\nAll our experiments are performed using the original codebase of Wang et al. (2023), available at\nhttps://github.com/redwoodresearch/Easy-Transformer. The code provides the functionality of\nconstructing Xcorrupt under various definitions of corruptions, including STR.\n\nC  RESULTS ON ARITHMETIC REASONING IN GPT-J\n\nExperimental setup  We follow the setting of Stolfo et al. (2023) and perform localization analysis\non the task of basic arithmetic in GPT-J (Wang & Komatsuzaki, 2021), a decoder-only model with\n\n\n                                       14\n\n6B parameters. For simplicity, we consider addition, subtraction and multiplication up to 3 digits.\nWe provide the model with a 2-shot prompts of the format\n\n                           X1 + Y1 = Z1\n                           X2 + Y2 = Z3\n                           X3 + Y3 =\n\nwhere the numbers Xi, Yi are random integers and the operator can be +, −, ×. Stolfo et al. (2023)\nfinds that this leads to improved accuracy. Since large integers get split into multiple tokens, we draw\nXi, Yi from {1, 2, · · · , 250} for addition and subtraction and from {1, 2, · · · , 23} for multiplication.\nTo obtain a dataset for activation patching, we first draw 200 prompts and discard those on which\nthe model’s top-ranked output token is incorrect.\n\nWe set GN corruption to add noise to the token embeddings at the positions of X3, Y3. Similarly,\nSTR replaces X3, Y3 by two random integers drawn from the same set, which ensures that the\ncorrupted prompt is still in-distribution. We remark that Stolfo et al. (2023) applies the same STR\ncorruption in their patching experiments.\n\nStolfo et al. (2023) devises a new metric to evaluate the patching effects. More precisely, they report:\n\n                        1  Ppt(r) −P∗(r)   P∗(r′) −Ppt(r′)\n                         +                                               (2)\n                        2      P∗(r)             Ppt(r′)\n\nfrom patching the MLP activation at last token of the prompt.4 We compute the patching effect given\nby the metric, as well as probability and logit difference.\n\nFollowing Stolfo et al. (2023), we narrow our focus on localization of MLP layers. All the experi-\nments patch a single MLP layer’s activation at the last token of the prompt.\n\n\nExperimental results  Focused on the logit difference and probability metric, we observe gaps\nbetween GN and STR for addition and subtraction. In particular, STR is found to provide sharper\nconcentration, up to a magnitude of 4×. This in contrast with our results on factual association\n(Section 3.1), where GN appears to induce stronger peak. For multiplication, GN and STR pro-\nvides nearly matching results. This highlights that activation patching can be sensitive to corruption\nmethods in a rather unpredictable way. See Figure 6, Figure 7 and Figure 8 for plots.\n\nFor the metric (2) of Stolfo et al. (2023), we qualitatively replicate their results, similar to Figure 2 of\ntheir paper, and find extremely pronounced peak with STR corruption. Towards understanding this\nobservation, we examine the quantity (2) closely and discover that its first term typically dominates\nthe second. This, in turn, is because the denominator term P∗(r), the probability of outputting the\ncorrect answer in the corrupted run, is usually tiny under STR corruption. The small denominator,\ntherefore, acts as a large multiplier that amplifies the absolute gap between patching different layers.\nWe note that this effect is much smaller under GN since P∗(r) is usually not negligible.\n\n\n    Logit diﬀerence, addition on GPT-J, MLP         Probability, addition on GPT-J, MLP               Stolfo's metric, addition on GPT-J, MLP\n        0.3\n                                                  STR       0.02                                        STR                                                  STR\n      0.25                                   GN                                           GN                                           GN\n                                                                                                                6000\n        0.2                                                       0.015\n\n      0.15                                                                                                       4000\n                                                                    0.01            Probability   0.1                                                                                                                                                                                                                                                Probability                                                                                                                                                                                                                                                                        Probability\n                                                                 0.005                                                 2000\n      0.05\n\n        0                                                     0                                                    0\n         0            10           20                          0           10           20                          0            10           20\n\n                        Layer                                                Layer                                               Layer\n\n   (a) Logit difference as the metric      (b) Probability as the metric       (c) Stolfo et al. (2023)’s metric\n\n          Figure 6: The effects of patching MLP layers in GPT-J on addition prompts.\n\n\n   4Note that our notations here are different from Stolfo et al. (2023).\n\n\n                                       15\n\n    Logit diﬀerence, subtraction on GPT-J, MLP      Probability, subtraction on GPT-J, MLP           Stolfo's metric, subtraction on GPT-J, MLP\n                                                                    0.03                                                 2500\n                                                  STR                                                  STR                                                  STR\n       0.3                                    GN      0.025                                  GN      2000                                   GN\n\n                                                                    0.02\n       0.2                                                                                                        1500\n                                                                 0.015\n\n                                                                                                                1000            Probability 0.1                                                                                                                                                                                                                                                      Probability  0.01                                                                                                                                                                                                                                           Probability\n\n                                                                 0.005                                                  500\n\n       0                                                      0                                                    0\n        0            10            20                           0           10           20                          0            10           20\n\n                       Layer                                                Layer                                               Layer\n\n   (a) Logit difference as the metric      (b) Probability as the metric       (c) Stolfo et al. (2023)’s metric\n\n        Figure 7: The effects of patching MLP layers in GPT-J on subtraction prompts.\n\n    Logit diﬀerence, multiplication on GPT-J, MLP   Probability, multiplication on GPT-J, MLP         Stolfo's metric, multiplication on GPT-J, MLP\n\n                                                                                                                30\n                                                  STR                                                  STR                                                 STR\n                                          GN                                           GN      25                                    GN\n                                                                    0.01\n        0.1\n                                                                                                                20\n\n\n                                                                                                                15\n      0.05                                                       0.005            Probability                                                                                                                                                                                                                                                                        Probability                                                                                                                                                                                                                                                                        Probability 10\n\n\n                                                                                                                 5\n\n        0                                                     0\n                                                                                                                 0\n         0            10           20                          0           10           20                        0            10            20\n\n                        Layer                                                Layer                                              Layer\n\n   (a) Logit difference as the metric      (b) Probability as the metric       (c) Stolfo et al. (2023)’s metric\n\n       Figure 8: The effects of patching MLP layers in GPT-J on multiplication prompts.\n\nD  RESULTS ON PYTHON DOCSTRING CIRCUIT\n\nHeimersheim & Janiak (2023) studies a circuit for Python docstring completion in a pre-trained 4-\nlayer attention-only Transformer.5 We do not aim to fully replicate their results. Rather, we perform\npatching experiments to localize the important attention heads for the purpose of evaluating variants\nof activation patching.\n\nExperimental setup  In Heimersheim & Janiak (2023), a Python docstring completion instance\nconsists of the following prompt:\n\ndef rand0(self , rand1 , rand2 , A_def , B_def , C_def , rand3):\n     \"\"\" rand4 rand5 rand6\n\n    :param A_def: rand7 rand8\n    :param B_def: rand9 rand10\n    :param\n\nwhere rand’s are random single-token English words and the goal is to complete the prompt with\nC def. Heimersheim & Janiak (2023) finds that the 4-layer model solves the docstring task with an\naccuracy of 56% and the logit difference is 0.5.\n\nFollowing their approach, we run activation patching on all attention heads, across all token posi-\ntions. This is more fine-grained than what we did for the IOI circuit, since the outcome would also\nhighlight the token positions that matter for the important heads.\n\nWe apply corruption to the C def token. For STR, it is replaced randomly by a single-token English\nword in the same way specified in Heimersheim & Janiak (2023).\n\nExperimental results  We take 200 instances of the docstring completion task, perform activation\npatching by positions and compute the patching effects. We report all position-head pairs with\npatching effect 2 standard deviations away from the mean. We find that the detections are mostly at\nthe position of C def and the last token of the prompt. The details are given in Table 2.\n\n   5The model is available in the TransformerLens library under the name attn-only-4l (Nanda & Bloom,\n2022).\n\n\n                                       16\n\n   Corruption  Metric          At the position of C def       At the last position\n\n   STR          Logit difference          0.0, 0.1, 0.5                 2.3, 3.0, 3.5, 3.6\n   STR           Probability                                                  3.0, 3.6\n   STR      KL divergence         0.0, 0.1, 0.5, 2.2                 2.3, 3.0, 3.6\n\n  GN †         Logit difference             0.5              1.4, 1.5, 2.2, 2.3, 3.0, 3.6, 3.7\n  GN           Probability                                                  3.0, 3.6\n  GN       KL divergence                                       2.2, 2.3, 3.0, 3.5, 3.6\n\nTable 2: Detections from activation patching of attention heads by position on the Python doc-\nstring completion task. † Also detects two early-layer heads active at other positions and four negative heads\nactive at the last position, which we omit here.\n\n\nWe again find that the localization outcomes are sensitive to the choice of corruption method and\nevaluation metric. The results of GN appear quite noisy, except when using probability as the\nmetric. On the other hand, we remark that 3.0 and 3.6 are consistently highlighted across metrics\nand methods. In fact, they are typically assigned the largest patching effects (at the last position).\nThis appears consistent with the result of Heimersheim & Janiak (2023), where 3.0 and 3.6 are found\nto be directly responsible for moving the C def token.\n\n\nE  RESULTS ON THE GREATER-THAN CIRCUIT IN GPT-2 SMALL\n\n\nHanna et al. (2023) In this section, we study the greater-tan task, specified below, and perform\nactivation patching on the attention heads in GPT-2 small. In this setting, the prior work by Hanna\net al. (2023); Conmy et al. (2023) show that model computation is fairly localized in this setting\nand provide a set of circuit discovery results. We remark that we do not attempt to replicate the\ncircuit discovery results here, but rather to evaluate whether activation helps with localizing certain\nimportant model components.\n\n\nExperimental setup  Following Hanna et al. (2023), an instance of the greater-than task consists\nof an incomplete sentence of the template: “The <noun> lasted from the year XXYY to the year\nXX”, where <noun> is a single-token word and XX and YY are two-digit numbers. For example,\n“The war lasted from year 1745 to 17”. The goal is to complete the prompt with an integer greater\nthan XX (in this case, 45). Across several metrics, Hanna et al. (2023) shows that GPT-2 small\nperforms well on this task.\n\nWe focus on the role of attention heads in our study. To perform corruption, we ensure that the year\nXXYY are tokenized as [XX][YY] by filtering out years and numbers that do not conform to the\nconstraint. GN corruption adds noise to the token embedding of YY. Following Hanna et al. (2023);\nConmy et al. (2023), STR corruption replaces YY by 01. The probability metric, in this setting,\nis defined as the sum of probabilities of the years greater than YY. The logit difference metric is\ndefined as the sum of logits of the years greater than YY minus the sum of logits of the years less\nthan YY.\n\nWe perform activation patching on the attention heads outputs over all token positions.\n\n\nExperimental results  We find significant difference between the results achieved by GN and STR.\nIn fact, the set of heads that are localized by the methods are mostly disjoint.  Specifically, GN\nappears to give extremely noisy results that are not in line with the findings of Hanna et al. (2023);\nConmy et al. (2023). The details are given in Table 3\n\nThe results from STR are fairly reasonable as the heads 6.9, 7.10, 8.11, 9.1 are also discovered by\nHanna et al. (2023); Conmy et al. (2023), using more sophisticated methods. In contrast, the heads\ndiscovered by GN corruption share little overlap with STR, except 7.10 and 9.1. From visualizations,\nwe also see that the plots for GN experiments are fairly noisy and do not yield much localization at\nall (Figure 9). On the other hand, the plots from STR are easily interpretable (Figure 10).\n\n\n                                       17\n\n       Corruption  Metric                        Positive               Negative\n\n      STR          Logit difference        6.9, 7.10, 8.11, 9.1, 10.4\n      STR           Probability                 7.10, 8.11, 9.1\n      STR      KL divergence            6.9, 7.10, 8.11, 9.1            10.7\n\n     GN           Logit difference        0.9, 7.10, 8.10, 9.1, 10.4       6.1, 8.6, 9.5\n     GN           Probability         5.5, 6.1, 6.9, 7.10, 7.11, 8.8, 9.1\n     GN       KL divergence     5.5, 6.1, 6.9, 7.10, 7.11, 8.8, 9.1      5.9, 7.6\n\nTable 3: Detections from activation patching on attention heads for the greater-than task in\nGPT-2 small, averaged across 300 prompts.\n\n\n       Probability, GN                                                      Logit Difference, GN                                          KL, GN\n\n\n        0                                                                           0                                                                           0\n                                                                                   0.15\n\n                                                                                                                                                                                    0.2                                                                          1\n        2                                                                            0.1         2                                                                           2\n\n\n                                                                                                                                                                                    0.1                                                                                         0.5\n        4                                                                         0.05        4                                                                           4\n\n\n\n   11                                                                   0     11                                                                    0    11                                                                    0\n        6                                                                           6                                                                           6\n\n\n                                                                                −0.05\n                                                                                                                                                                         −0.1                                                                                  −0.5\n        8                                                                           8                                                                           8\n\n                                                                                  −0.1\n\n                                                                                                                                                                         −0.2\n       10                                                                          10                                                                                                                                                                10                                                               −1\n                                                                                −0.15\n\n\n           0                      5                      10                            0                       5                      10                            0                       5                      10\n\n                            Head                                                         Head                                                         Head\n\n      (a) Probability as the metric      (b) Logit difference as the metric    (c) KL divergence as the metric\n\nFigure 9: The effects of patching attention heads in GPT-2 small on the greater-than task, using\nGN corruption. We see that the results are fairly noisy and do not appear to be localized.\n\nF  WHICH TOKENS TO CORRUPT MATTERS\n\nIn this section, we revisit the implementation of corruption methods in the setting of IOI (Wang\net al., 2023).\n\nPreviously in our STR experiments in Section 3 and Section 4, the S2 token was corrupted by\nexchanging with IO. Similarly, in GN, we add noise to the token embedding of S2. We notice that\nthe localization results from this approach miss at least 2 out of the 3 Name Mover (NM) Heads\n(Table 1); they directly contribute to the logit of IO as found by Wang et al. (2023). In particular, all\ncombinations of metric and method would miss out on 9.6 and 10.0 (Table 5).\n\nWe show that by varying exactly which tokens to corrupt, the NMs can be discovered, too\n\nExperimental setup  We consider the IOI setting (Wang et al., 2023) using STR and GN corruption\nfor localizing attention heads. Here, we corrupt the S1 and IO tokens. For STR, we simply replace\nS1 and IO by two random unrelated names. In both STR and GN experiments, the S2 token remains\nthe same as in Xclean.\n\nWe perform activation patching across all attention heads. We apply logit difference, probability and\nKL divergence as the metric. All the results are averaged across 500 sampled IOI sentences.\n\nExperimental results  We find that most combinations of metrics and methods are able to notice all\nthe NMs, when corruption applies to S1 and IO. We give the exact detections below and categorize\nthem into positive and negative for simplicity.\n\nFirst, we observe that this corruption seems to precisely target the NMs and their Negative counter-\nparts. Intuitively, this is natural. Wang et al. (2023) finds that NMs write in the direction of the logit\nof the name (IO or S), whereas the Negative NMs do the opposite. Patching the clean activations of\nNMs recover such behavior.\n\nSecond, we confirm our finding that probability will miss out on the Negative NM; see Figure 11 for\nthe plots.\n\n\n                                       18\n\n       Probability, STR                                                     Logit Difference, STR                                         KL, STR\n\n\n        0                                                                           0                                                                           0\n                                                                                                                                                                                                                                                                                0.8\n                                                                                   0.15                                                                                   0.15\n\n\n        2                                                                                    2                                                                            0.1         2                                                                              0.6                                                                                       0.1\n                                                                                                                                                                                                                                                                                0.4\n\n        4                                                                         0.05        4                                                                         0.05        4                                                                              0.2\n\n\n   11                                                                   0     11                                                                   0     11                                                                    0\n        6                                                                           6                                                                           6\n\n                                                                                −0.05                                                                               −0.05                                                                                  −0.2\n\n        8                                                                           8                                                                           8                                                                         −0.4\n                                                                                  −0.1                                                                                  −0.1\n\n                                                                                                                                                                                                                                                               −0.6\n       10                                                                      −0.15      10                                                                      −0.15      10\n                                                                                                                                                                                                                                                               −0.8\n\n\n           0                      5                      10                            0                      5                      10                            0                       5                      10\n\n                            Head                                                         Head                                                         Head\n\n      (a) Probability as the metric      (b) Logit difference as the metric    (c) KL divergence as the metric\n\nFigure 10: The effects of patching attention heads in GPT-2 small on the greater-than task, using\nSTR corruption. This gives clearly localized results.\n\n               Corruption  Metric               Positive      Negative\n\n            STR          Logit difference    9.6, 9.9, 10.0   10.7, 11.10\n            STR           Probability             9.9\n            STR      KL divergence     9.6, 9.9, 10.0   10.7, 11.10\n\n          GN           Logit difference    9.6, 9.9, 10.0   10.7, 11.10\n          GN           Probability         9.6, 9.9, 10.0\n          GN       KL divergence     9.6, 9.9, 10.0   10.7, 11.10\n\nTable 4: Detections from activation patching by corrupting S1 and IO in IOI. The Name Mover\nHeads are 9.6, 9.9, 10.0 and the Negative Name Mover Heads are 10.7 and 11.10, based on Wang\net al. (2023). No other heads, including the S-Inhibition Heads, are noticed with this approach.\n\n\nOverall, the experiment suggests that exactly which token is corrupted affects the localization out-\ncomes. Intuitively, varying the corrupted token(s) allows activation patching to trace different infor-\nmation within the model’s computation paths; see Section 6 for a discussion.\n\n\nG  FURTHER DETAILS ON FACTUAL ASSOCIATION\n\n\nThe plots of subsection Appendix G.1 to G.3 are produced on GPT-2 XL and with the PARIEDFACTS\nas dataset. Following that, we also experiment with the GPT-2 large (Radford et al., 2019) and GPT-J\n(Wang & Komatsuzaki, 2021) model in Appendix G.4 and G.5.\n\n\nG.1  PLOTS ON MLP PATCHING AT THE LAST SUBJECT TOKEN IN GPT-2 XL\n\nFirst, we perform single-layer patching of MLP activation at the last subject token and examine the\neffects in Figure 12. We observe that the experiment suggests weak or no peak at middle MLP\nlayers, across metrics and corruption methods.\n\nAlso, see Figure 13 and Figure 14 for plots with sliding window size of 3 and 10. Again, activation\npatching is applied to the MLP activations at the last subject token. We find again that GN yields\nsignificantly more pronounced peak.\n\n\nG.2  PLOTS ON MLP PATCHING AT ALL TOKEN POSITIONS IN GPT-2 XL\n\nSee Figure 15–Figure 19 to plots on MLP patching at all token positions in GPT-2 XL, across win-\ndow sizes of 3, 5, 10. We observe that the right-side plots, using probability as the metric, highlights\nthe last subject token as important. In contrast, the left-side figure using logit different does it to\nlesser degree.\n\n\n                                       19\n\n      Probability, STR                                             Logit diﬀerence, STR                                      KL, STR\n\n\n\n\n                                                                      0.02\n       0                                                                  0                                                                  0.4        0                                                                  1.5\n\n                                                                    0.015\n       2                                                             0.01         2                                                                  0.2        2                                                       1\n\n       4                                                           0.005        4                                                                  4                                                                  0.5\n\n\n                                                             0                                                                    0                                                                  0       Layer  6                                                                                                                                                Layer  6                                                                                                                                                Layer  6\n\n                                                               −0.005                                                                                                                                        −0.5\n       8\n                                                                          8                                                          −0.2       8                                                                −0.01\n\n                                                                                                                                                                          −1\n      10                                                       −0.015      10                                                                 10\n\n                                                                                                                                         −0.4                                                                  −1.5\n          0                  5                  10            −0.02          0                   5                   10                         0                   5                   10\n                        Head                                                     Head                                                    Head\n\n      (a) Probability as the metric      (b) Logit difference as the metric    (c) KL divergence as the metric\n\nFigure 11: The effects of patching attention heads in GPT-2 small on IOI sentences, using STR\ncorruption on S1 and IO.\n\n       Probability, GN, window = 1           Probability, STR, window = 1          Logit diﬀerence, GN, window = 1      Logit diﬀerence, STR, window = 1\n\n      0.08\n                                                                                                               0.2\n                                                      0.015                                                                                             0.25\n\n      0.06\n                                                                                                         0.15                                                 0.2\n\n                                                         0.01\n      0.04                                                                                                                                                0.15\n                                                                                                               0.1\n\n                                                                                                                                                                   0.1\n      0.02                                            0.005                                            0.05\n                                                                                                                                                          0.05\n\n        0                                           0                                         0                                          0\n\n           0             20            40              0            20            40             0             20            40             0             20            40\n\n      (a) Probability (GN)     (b) Probability (STR)   (c) Logit difference (GN) (d)   Logit   difference\n                                                                 (STR)\n\nFigure 12: Patching single MLP layers at the last subject token in GPT-2 XL on factual recall\nprompts. None of them suggest a strong peak at the middle MLP layers.\n\nG.3  PLOTS ON SLIDING WINDOW PATCHING IN GPT2-XL\n\nWe provide further plots from our experiment that compares the sliding window patching with indi-\nvidual patching aggregated via summation over windows. See Figure 20–Figure 23.\n\n\nG.4  PLOTS ON ACTIVATION PATCHING OF MLP LAYERS ON GPT-2 LARGE\n\nWe perform activation patching on MLP layers of GPT-2 large in the factual association setting.\nFollowing our experiments in Section 3.1, we focus the effects at patching the MLP activation of the\nlast subject token. We validate the high-level finding of Section 3.1, where we observe the disparity\nof GN and STR applied to MLP activation in the factual prediction setting. In particular, GN gives\nmore pronounced concentration at early-middle MLP layers. We apply sliding window patching of\nsize 3 and 5; see Figure 24 and Figure 25 for the resulting plots.\n\n\nG.5  PLOTS ON ACTIVATION PATCHING OF MLP LAYERS IN GPT-J\n\nWe perform activation patching on MLP layers of GPT-J (Wang & Komatsuzaki, 2021) in the factual\nassociation setting. We patch the MLP activations across all token positions and verify that proba-\nbility tends to highlight the importance of the last subject token than logit difference. We focus on\na sliding window patching of size 5 and the plots are given in Figure 27 (GN) and Figure 26 (STR).\nThis complements our results in Section 4.\n\nH  FURTHER DETAILS ON IOI CIRCUIT DISCOVERY\n\nH.1  DETAILED PLOTS ON ACTIVATION PATCHING\n\nWe now provide the detailed plots from the activation patching experiments on the IOI circuit dis-\ncovery task (Wang et al., 2023); see Figure 28 and Figure 29.\n\n\n                                       20\n\n            Probability, window size = 3                          Logit diﬀerence, window size = 3\n\n           0.08                                            STR                                                        STR\n                                                GN          0.25                                      GN\n\n\n           0.06                                                                     0.2\n\n\n                                                                               0.15\n           0.04\n\n                                                                                    0.1\n\n           0.02\n                                                                               0.05\n\n\n            0                                                           0\n\n               0             20            40                             0             20            40\n\n                 (a) Probability as the metric                     (b) Logit difference as the metric\n\nFigure 13: MLP patching effects at the last subject token position in GPT-2 XL on factual recall\nprompts, with window size of 3.\n\n\n            Probability, window size = 10                         Logit diﬀerence, window size = 10\n\n                                                         STR                                                        STR\n                                                GN           0.3                                       GN\n\n             0.1\n\n                                                                                   0.2\n\n\n\n           0.05\n                                                                                   0.1\n\n\n\n\n            0                                                          0\n\n               0             20            40                            0             20             40\n\n                 (a) Probability as the metric                     (b) Logit difference as the metric\n\nFigure 14: MLP patching effects for factual recall at the last subject token position in GPT-2 XL\non factual recall prompts, with window size of 10.\n\n\nH.2  DETAILS ON DETECTIONS\n\nWe provide a detailed list of detection from attention heads patching in the IOI circuit setting (Sec-\ntion 3); see Table 5.\n\n        Corruption  Metric           Negative heads     Positive heads\n\n      STR          Logit difference      10.7, 11.10         5.5, 7.9, 8.6, 8.10, 9.9\n      STR           Probability             10.7            5.5, 7.9, 8.6, 8.10, 9.9\n      STR      KL divergence        10.7, 11.10         5.5, 7.9, 8.6, 8.10, 9.9\n\n     GN           Logit difference      10.7, 11.10      3.0, 5.5, 7.9, 8.6, 8.10, 9.9\n     GN           Probability        0.10, 10.7, 11.10         3.0, 5.5, 7.9, 8.6\n     GN       KL divergence     0.10, 10.7, 11.10           5.5, 7.9, 8.6\n\nTable 5: Detailed results from attention heads patching in GPT-2 small on IOI sentences. A head\nis detected if the patching effect is two standard deviation from the mean effect. Negative heads are\nheads with negative patching effects, suggesting they hurt model performance.\n\n\n\nH.3  DETAILED PLOTS ON FULLY RANDOM CORRUPTION\n\nWe provide the plots on fully random corruption, termed pABC in Wang et al. (2023). We perform\nactivation patching on all attention heads, using both probability and logit difference as the metric\nin order to draw contrasts between them. See Figure 30. In particular, we notice that there is no\nnegative head in the plot. This is natural and totally expected, as we explained in Section 4.\n\n\n                                       21\n\n                                                                0.2\n\n         10                                                                10                                               0.05\n\n                                                                0.1\n\n         20                                                                20\n                                                      0                                                                0              Layer                                                                                                                                                       Layer\n         30                                                                30\n                                                        −0.1\n\n                                                                                                                            −0.05\n         40                                                                40\n                                                        −0.2\n\n                  First  Mid   Last  The   Further Last                                           First  Mid   Last  The   FurtherLast                                                                                                                       token                           subject                                                                                                          subject                                   subject                                                                                                                  subject                     subject                                                  token                                      subject                                                tokens                                                                                                                        tokens                                     tokensubsequent                                                                                                          tokensubsequent                        token                                                                                              token                               tokens                                                                                                        tokens                                              token                                                                 token\n\n                (a) Logit difference (GN)                                  (b) Probability (GN)\n\nFigure 15: Activation patching on MLP across layers and token positions in GPT-2 XL on factual\nrecall prompts. Apply GN corruption and a sliding window of size 3.\n\n\n\n                                                                                                                                        0.02\n\n         10                                                                10\n                                                                0.2\n                                                                                                                                        0.01\n\n         20                                                                20\n                                                      0                                                                0              Layer                                                                                                                                                       Layer\n         30                                                                30\n                                                                                                                            −0.01\n                                                        −0.2\n         40                                                                40                                           −0.02\n\n                  First  Mid   Last  The   Further Last                                           First  Mid   Last  The   FurtherLast                                                                                                                       token                           subject                                                                                                          subject                                   subject                                                                                                                  subject                     subject                                                  token                                      subject                                                tokens                                                                                                                        tokens                                     tokensubsequent                                                                                                          tokensubsequent                        token                                                                                              token                               tokens                                                                                                        tokens                                              token                                                                 token\n\n               (a) Logit difference (STR)                                 (b) Probability (STR)\n\nFigure 16: Activation patching on MLP across layers and token positions in GPT-2 XL on factual\nrecall prompts. Apply STR corruption and a sliding window of size 3.\n\nI  DATASET SAMPLES\n\nFactual data  We list a few dataset examples from the PAIREDFACTS dataset used in the factual\nrecall experiments in Figure 31.6 All the prompts are known true facts.\n\nIOI circuit  The detailed templates of constructing the pIOI data distribution can be found in Ap-\npendix A of Wang et al. (2023). We perform the same procedure of generating the IOI data by\nsimply reusing their original code.\n\n\n\n\n\n   6The full dataset is available at https://www.jsonkeeper.com/b/P1GL.\n\n\n                                       22\n\n                                                                0.2\n         10                                                                10                                               0.05\n                                                                0.1\n\n         20                                                                20\n                                                      0                                                                0              Layer                                                                                                                                                       Layer\n         30                                                                30\n                                                        −0.1\n                                                                                                                            −0.05\n         40                                            −0.2                  40\n\n                  First  Mid   Last  The   Further Last                                           First  Mid   Last  The   FurtherLast                                                                                                                       token                           subject                                                                                                          subject                                   subject                                                                                                                  subject                     subject                                                  token                                      subject                                                tokens                                                                                                                        tokens                                     tokensubsequent                                                                                                          tokensubsequent                        token                                                                                              token                               tokens                                                                                                        tokens                                              token                                                                 token\n\n                (a) Logit difference (GN)                                  (b) Probability (GN)\n\nFigure 17: Activation patching on MLP across layers and token positions in GPT-2 XL on factual\nrecall prompts. Apply GN corruption and a sliding window of size 5.\n\n\n\n\n\n                                                                0.3\n                                                                                                                                               0.1\n         10                                                   0.2                    10\n\n                                                                                                                                        0.05\n                                                                0.1\n         20                                                                20\n                                                      0                                                                0              Layer                                                                                                                                                       Layer\n         30                                            −0.1                  30\n                                                                                                                            −0.05\n\n                                                        −0.2\n         40                                                                40                                           −0.1\n                                                        −0.3\n                  First  Mid   Last  The   Further Last                                           First  Mid   Last  The   FurtherLast                                                                                                                       token                           subject                                                                                                          subject                                   subject                                                                                                                  subject                     subject                                                  token                                      subject                                                tokens                                                                                                                        tokens                                     tokensubsequent                                                                                                          tokensubsequent                        token                                                                                              token                               tokens                                                                                                        tokens                                              token                                                                 token\n\n                (a) Logit difference (GN)                                  (b) Probability (GN)\n\nFigure 18: Activation patching on MLP across layers and token positions in GPT-2 XL on factual\nrecall prompts. Apply GN corruption and a sliding window of size 10.\n\n\n\n\n\n                                                                                                                                        0.04\n         10                                                                10\n                                                                0.2\n                                                                                                                                        0.02\n\n         20                                                                20\n                                                      0                                                                0              Layer                                                                                                                                                       Layer\n         30                                                                30\n                                                                                                                            −0.02\n                                                        −0.2\n\n         40                                                                40                                           −0.04\n\n                  First  Mid   Last  The   Further Last                                           First  Mid   Last  The   FurtherLast                                                                                                                       token                           subject                                                                                                          subject                                   subject                                                                                                                  subject                     subject                                                  token                                      subject                                                tokens                                                                                                                        tokens                                     tokensubsequent                                                                                                          tokensubsequent                        token                                                                                              token                               tokens                                                                                                        tokens                                              token                                                                 token\n\n               (a) Logit difference (STR)                                 (b) Probability (STR)\n\nFigure 19: Activation patching on MLP across layers and token positions in GPT-2 XL. Apply\nSTR corruption and a sliding window of size 10.\n\n\n\n\n                                       23\n\n            Probability, STR, window = 5                           Probability, GN, window = 5\n\n                                                              adding                                                            adding\n          0.025                                                         sliding          0.15                                                          sliding\n\n\n            0.02\n\n                                                                                    0.1\n          0.015\n\n\n            0.01\n                                                                               0.05\n\n          0.005\n\n\n             0                                                          0\n\n                0            20           40                               0            20            40\n\n                      (a) STR corruption                                 (b) GN corruption\n\nFigure 20: MLP patching effects, sliding window vs summing up single-layer patching at last\ntoken position in GPT-2 XL on factual recall prompts, with window size of 5. Apply probability as\nthe metric.\n\n\n\n\n\n           Logit diﬀerence, STR, window = 5                    Logit diﬀerence, GN, window = 5\n                                                                                   0.5\n             0.3                                               adding                                                             adding\n                                                                            sliding                                                                           sliding\n           0.25                                                                    0.4\n\n             0.2                                                                    0.3\n\n           0.15\n                                                                                   0.2\n\n             0.1\n\n                                                                                   0.1\n           0.05\n\n\n            0                                                          0\n\n               0            20            40                              0            20            40\n\n                      (a) STR corruption                                 (b) GN corruption\n\nFigure 21: MLP patching effects, sliding window vs summing up single-layer patching at last\ntoken position in GPT-2 XL on factual recall prompts, with window size of 5. Apply logit difference\nas the metric.\n\n\n\n\n\n            Probability, STR, window = 10                         Probability, GN, window = 10\n\n                                                              adding                                                             adding\n           0.05                                                          sliding           0.2                                                          sliding\n\n\n           0.04\n                                                                               0.15\n\n           0.03\n                                                                                    0.1\n           0.02\n\n                                                                               0.05\n           0.01\n\n\n            0                                                           0\n\n               0            20            40                               0            20            40\n\n                      (a) STR corruption                                 (b) GN corruption\n\nFigure 22: MLP patching effects, sliding window vs summing up single-layer patching at last\ntoken position in GPT-2 XL on factual recall prompts, with window size of 10. Apply probability as\nthe metric.\n\n\n\n\n                                       24\n\n           Logit diﬀerence, STR, window = 10                   Logit diﬀerence, GN, window = 10\n\n                                                              adding          0.6                                                 adding\n                                                                            sliding                                                                           sliding\n           0.3\n                                                                                   0.5\n\n\n                                                                                   0.4\n           0.2\n\n                                                                                   0.3\n\n           0.1                                                                     0.2\n\n                                                                                   0.1\n\n\n           0                                                           0\n\n              0            20            40                              0            20            40\n\n                      (a) STR corruption                                 (b) GN corruption\n\nFigure 23: MLP patching effects, sliding window vs summing up single-layer patching at last\ntoken position in GPT-2 XL on factual recall prompts, with window size of 10. Apply logit differ-\nence as the metric.\n\n\n\n\n\n            Probability, window size = 3                          Logit diﬀerence, window size = 3\n\n                                                         STR         0.25                                            STR\n                                                GN                                                GN\n           0.06\n                                                                                    0.2\n\n\n           0.04                                                                0.15\n\n\n                                                                                    0.1\n\n           0.02\n                                                                               0.05\n\n\n            0                                                           0\n\n               0        10        20        30                             0        10        20        30\n\n                 (a) Probability as the metric                     (b) Logit difference as the metric\n\nFigure 24: MLP patching effects at the last subject token position in GPT-2 large on factual recall\nprompts, with window size of 3.\n\n\n\n\n\n            Probability, window size = 3                          Logit diﬀerence, window size = 3\n\n                                                         STR         0.25                                            STR\n                                                GN                                                GN\n           0.06\n                                                                                    0.2\n\n\n           0.04                                                                0.15\n\n\n                                                                                    0.1\n\n           0.02\n                                                                               0.05\n\n\n            0                                                           0\n\n               0        10        20        30                             0        10        20        30\n\n                 (a) Probability as the metric                     (b) Logit difference as the metric\n\nFigure 25: MLP patching effects at the last subject token position in GPT-2 large on factual recall\nprompts, with window size of 5.\n\n\n\n\n                                       25\n\n          5                                                   0.2                     5                                               0.04\n\n                                                                0.1                                                                        0.02\n         10                                                                10\n\n                                                      0                                                                0              Layer 15                                                                                                                                               Layer 15\n\n                                                        −0.1                                                                −0.02\n         20                                                                20\n                                                        −0.2                                                                −0.04\n         25                                                                25\n\n                  First  Mid   Last  The   Further Last                                           First  Mid   Last  The   FurtherLast                                                                                                                       token                           subject                                                                                                          subject                                   subject                                                                                                                  subject                     subject                                                  token                                      subject                                                tokens                                                                                                                        tokens                                     tokensubsequent                                                                                                          tokensubsequent                        token                                                                                              token                               tokens                                                                                                        tokens                                              token                                                                 token\n\n                (a) Logit difference (GN)                                  (b) Probability (GN)\n\nFigure 26: Activation patching on MLP across layers and token positions in GPT-J on factual\nrecall prompts. Apply STR corruption and a sliding window of size 5.\n\n\n\n\n\n                                                                                                                                        0.04\n          5                                                                 5\n                                                                0.1\n                                                                                                                                        0.02\n         10                                                                10\n\n                                                      0                                                                0              Layer 15                                                                                                                                               Layer 15\n\n                                                                                                                            −0.02\n         20                                            −0.1                  20\n\n                                                                                                                            −0.04\n         25                                                                25\n\n                  First  Mid   Last  The   Further Last                                           First  Mid   Last  The   FurtherLast                                                                                                                       token                           subject                                                                                                          subject                                   subject                                                                                                                  subject                     subject                                                  token                                      subject                                                tokens                                                                                                                        tokens                                     tokensubsequent                                                                                                          tokensubsequent                        token                                                                                              token                               tokens                                                                                                        tokens                                              token                                                                 token\n\n                (a) Logit difference (GN)                                  (b) Probability (GN)\n\nFigure 27: Activation patching on MLP across layers and token positions in GPT-J on factual\nrecall prompts. Apply GN corruption and a sliding window of size 5.\n\n\n\n\n\n      Probability, STR                                             Logit Diﬀerence, STR                                      KL, STR\n\n\n\n                                                                           0.1\n       0                                                                  0                                                                  0.4        0                                                                  1.5\n\n\n                                                                                                                                                                                                     1\n       2                                                              0.05        2                                                                  0.2        2\n\n                                                                                                                                                                                                                                             0.5\n       4                                                                  4                                                                  4\n\n\n                                                               0                                                                   0                                                                  0       Layer  6                                                                                                                                                Layer  6                                                                                                                                                Layer  6\n\n\n                                                                                                                                                                                                               −0.5\n       8                                                                  8                                                                  8\n                                                                 −0.05                                                                  −0.2\n\n                                                                                                                                                                          −1\n      10                                                                 10                                                                 10\n\n          0                   5                  10            −0.1          0                   5                   10            −0.4         0                   5                   10            −1.5\n                         Head                                                    Head                                                    Head\n\n      (a) Probability as the metric      (b) Logit difference as the metric    (c) KL divergence as the metric\n\nFigure 28: The effects of patching attention heads in GPT-2 small using STR corruption on IOI\nsentences.\n\n\n\n\n                                       26\n\n      Probability, GN                                              Logit Diﬀerence, GN                                       KL, GN\n\n                                                                       0.08                                                                                                                                                             0.6\n                                                                                                                                                            0.4\n\n       0                                                              0.06        0                                                                  0\n                                                                                                                                                            0.3                                                                             0.4\n\n       2                                                              0.04        2                                                                  0.2        2\n\n                                                                                                                                                                                                                                             0.2\n       4                                                              0.02        4                                                                  0.1        4\n\n\n                                                               0                                                                   0                                                                  0       Layer  6                                                                                                                                                Layer  6                                                                                                                                                Layer  6\n\n                                                                 −0.02                                                                  −0.1\n       8                                                                  8                                                                  8                                                          −0.2\n                                                                 −0.04                                                                  −0.2\n\n      10                                                                 10                                                          −0.3      10                                                          −0.4\n                                                                 −0.06\n\n          0                   5                  10                          0                   5                   10            −0.4         0                   5                   10\n                         Head                             −0.08                         Head                                                    Head                              −0.6\n\n      (a) Probability as the metric      (b) Logit difference as the metric    (c) KL divergence as the metric\n\nFigure 29: The effects of patching attention heads in GPT-2 small using GN corruption on IOI\nsentences.\n\n\n\n\n\n                (a) Probability as the metric                        (b) Logit difference as the metric\n\nFigure 30: The effects of patching attention heads in GPT-2 small using fully random corruption\non IOI sentences, with S1, S2 and IO replaced by three random names (denoted by pABC in Wang\net al. (2023)).\n\n\n\n\n{                                                                    {\n  \"pair\": [                                                  \"pair\": [\n    \"Honus Wagner professionally plays the sport of\",         \"Wii MotionPlus is developed by\",\n    \"Don Shula professionally plays the sport of\"             \"Chromebook Pixel is developed by\"\n  ],                                                             ],\n  \"answer \": [                                                \"answer \": [\n     \" baseball\",                                                       \" Nintendo\",\n     \" football\"                                                        \" Google\"\n  ],                                                             ],\n  \"length \": 9,                                               \"length \": 8,\n  \"category \": \"athletes\"                                     \"category \": \"developers\"\n}                                                                    }\n\n\n{                                                                    {\n  \"pair\": [                                                  \"pair\": [\n    \"Schreckhorn belongs to the continent of\",                 \"The Eiffel Tower is in the city of\",\n    \"Afghanistan belongs to the continent of\"                 \"Kinkakuji Temple is in the city of\"\n  ],                                                             ],\n  \"answer \": [                                                \"answer \": [\n     \" Europe\",                                                         \" Paris\",\n     \" Asia\"                                                             \" Kyoto\"\n  ],                                                             ],\n  \"length \": 9,                                               \"category \": \"city_landmarks\",\n  \"category \": \"continents\"                                   \"length \": 11\n}                                                                    }\n\n\nFigure 31: Sample text prompts from the PAIREDFACTS dataset. The length field refers to the\nsequence length of the prompt under GPT-2 tokenizer.\n\n\n\n                                       27\n\n## Claim to Classify\n\"varying these hyperparameters could lead to disparate interpretability results\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Systematic comparison of activation patching variants (corruption methods, metrics, sliding window)",
    "method_rung": 2,
    "claim_rung": 2,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The method used is activation patching (interventional, Rung 2) applied systematically across different hyperparameters (corruption methods, metrics, window sizes). The claim 'varying these hyperparameters could lead to disparate interpretability results' is a causal claim about the effect of methodological choices on outcomes, using 'could lead to' which indicates a causal relationship. This matches Rung 2 causal language. The claim is stated definitively without hedging words like 'may' or 'suggest'. The evidence comes from direct interventions comparing different patching configurations, which establishes causal effects of methodological choices on localization outcomes."
  },
  "metadata": {
    "model": "qwen/qwen3-235b-a22b-2507",
    "usage": {
      "prompt_tokens": 30111,
      "completion_tokens": 193,
      "total_tokens": 30304
    },
    "finish_reason": "stop"
  }
}