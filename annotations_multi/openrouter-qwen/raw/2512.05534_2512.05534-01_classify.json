{
  "timestamp": "2026-02-19T11:42:03.850167+00:00",
  "paper_id": "2512.05534",
  "claim_id": "2512.05534-01",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2512.05534\nTitle: On the Theoretical Foundation of Sparse Dictionary Learning in MI\nFull text:\n    A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability:\n                        Piecewise Biconvexity and Spurious Minima\n\n\n\n               Yiming Tang# 1 Harshvardhan Saini 2 Zhaoqian Yao 3 Zheng Lin 4 Yizhen Liao 1 Qianxiao Li 1\n                                      Mengnan Du 5 Dianbo Liu# 1\n\n\n                         Abstract                            and real neural representations.\n\n           As AI models achieve remarkable capabilities\n               across diverse domains, understanding what rep-\n                resentations they learn and how they encode con-        1. Introduction2026                cepts has become increasingly important for both\n                                                     As artificial intelligence systems scale to frontier capabili-                  scientific progress and trustworthy deployment.\n                                                                                         ties, understanding their internal mechanisms has become              Recent works in mechanistic interpretability haveJan                                                                             essential for safe deployment (Lipton, 2017; Rudin, 2019).              widely reported that neural networks represent\n                                        A central insight from mechanistic interpretability is that              meaningful concepts as linear directions in their29                                                                 neural networks encode interpretable concepts as linear di-                representation spaces and often encode diverse\n                                                                          rections in superposition (Park et al., 2024; Elhage et al.,               concepts in superposition. Various sparse dictio-\n                                                                    2022), where individual neurons respond to multiple unre-              nary learning (SDL) methods, including sparse\n                                                                           lated concepts—a phenomenon known as polysemanticity               autoencoders, transcoders, and crosscoders, are\n                                                                   (Bricken et al., 2023; Templeton et al., 2024). To disen-                 utilized to address this by training auxiliary mod-\n                                                                         tangle these superposed representations, Sparse Dictionary                 els with sparsity constraints to disentangle these[cs.LG]                                                           Learning methods, including sparse autoencoders (SAEs)              superposed concepts into monosemantic features.\n                                                          (Cunningham et al., 2023), transcoders (Dunefsky et al.,              These methods are the backbone of modern mech-\n                                                                       2024), and crosscoders (Lindsey et al., 2024), have emerged                  anistic interpretability, yet in practice they consis-\n                                                                      as the dominant paradigm, achieving remarkable empiri-                 tently produce polysemantic features, feature ab-\n                                                                           cal success on frontier language models (Templeton et al.,                 sorption, and dead neurons, with very limited the-\n                                                                 2024; Gao et al., 2024) and enabling applications from fea-                 oretical understanding of why these phenomena\n                                                                            ture steering (Wang et al., 2025) to circuit analysis (Marks                occur. Existing theoretical work is limited to tied-\n                                                                                  et al., 2025) and medical diagnosis (Abdulaal et al., 2024).              weight sparse autoencoders, leaving the broader\n               family of SDL methods without formal grounding.        Despite this empirical success across diverse applications,\n          We develop the first unified theoretical framework      SDL methods consistently exhibit persistent failure modes:\n                  that casts all major SDL variants as a single piece-         learned features remain polysemantic (Chanin et al., 2025),\n              wise biconvex optimization problem, and charac-        ”dead neurons” fail to activate on any data samples (Bricken\n                 terize its global solution set, non-identifiability,          et al., 2023), and ”feature absorption” occurs where one neu-\n             and spurious optima. This analysis yields princi-        ron captures specific sub-concepts while another respondsarXiv:2512.05534v3         pled explanations for feature absorption and dead          to the remaining related concepts (Chanin et al., 2025). Prac-\n               neurons. To expose these pathologies under full          titioners have developed techniques to address these issues,\n                ground-truth access, we introduce the Linear Rep-         including neuron resampling (Bricken et al., 2023), auxiliary\n                resentation Bench.  Guided by our theory, we          losses (Gao et al., 2024), and careful hyperparameter tuning,\n              propose feature anchoring, a novel technique that         yet these fixes remain ad-hoc engineering solutions without\n                 restores SDL identifiability, substantially improv-         principled justification. Critically, these phenomena persist\n               ing feature recovery across synthetic benchmarks        even with careful training on clean data, suggesting they are\n                                                                    not mere implementation artifacts but reflect fundamental\n               1National University of Singapore 2Indian Institute of Technol-\n                                                                                structural properties of the SDL optimization problem itself.          ogy (ISM), Dhanbad 3Chinese University of Hong Kong 4Hong\n         Kong University of Science and Technology 5New Jersey Insti-                                            We argue that the root cause of these failure modes is the\n             tute of Technology.  Correspondence to: Yiming Tang <yim-\n                                                                             non-identifiability of SDL methods: even under the ideal-           ing@nus.edu.sg>, Dianbo Liu <dianbo@nus.edu.sg>.\n                                                                       ized Linear Representation Hypothesis, SDL optimization\n            Preprint. January 30, 2026.                                  admits multiple solutions achieving perfect reconstruction\n\n                                                         1\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nloss, some recovering no interpretable ground-truth features        • We propose a novel technique, feature anchoring, that\nat all, necessitating comprehensive theoretical analysis on        can achieve largely improved feature recovery perfor-\nSDL methods. While classical dictionary learning theory       mance applicable for all SDL methods. We validate\nprovides identifiability guarantees under strict conditions         the effectiveness of feature anchoring with extensive\n(Spielman et al., 2012; Gribonval & Schnass, 2010), and         experiments across diverse SDL methods and settings.\nrecent work establishes necessary conditions for tied-weight\nSAEs (Cui et al., 2025), no unified theoretical framework ex-                                                        2. Preliminaries\nplains why diverse SDL methods, SAEs, transcoders, cross-\ncoders, and their variants, systematically fail in predictable    In this section, we present a unified theoretical framework\nways. Without theoretical grounding, the development of     for Sparse Dictionary Learning (SDL). We begin with the\nimproved SDL methods remains largely empirical, poten-    formal definitions of foundational concepts and the linear\ntially leaving highly effective techniques underexplored.       representation hypothesis. Then we introduce our frame-\n                                                 work and how various SDL methods instantiate it.\nIn this work, we develop a unified theoretical framework that\nformalizes SDL as a general optimization problem, encom-\n                                                                    2.1. Input Distribution and Model Representationpassing various SDL methods (Bussmann et al., 2024; 2025;\nTang et al., 2025b) as special cases. We demonstrate how    Definition 2.1 (Input Distribution). Let D denote the dis-\nthese diverse methods instantiate our framework through     tribution over possible inputs, X, to a neural network. For\ndifferent choices of input-output representation pairs, activa-    example, D could be the distribution of natural images or the\ntion functions, and loss designs. We establish rigorous con-    distribution of text sequences (Notations in Appendix B).\nditions under which SDL methods provably recover ground-\n                                                            Definition 2.2 (Model Representation). For a given model\ntruth interpretable features, characterizing the roles of fea-\n                                                              representation x, let n ∈N be its dimensionality. For each\nture sparsity, latent dimensionality, and activation functions.\n                                                      s ∼D, the network produces a representation vector x(s),\nThrough detailed analysis of the optimization landscape,\n                                                    which is directly observable by running the model on s.\nwe demonstrate that global minima correspond to correct\nfeature recovery and provide necessary and sufficient condi-\n                                                                    2.2. The Linear Representation Hypothesistions for achieving zero loss. We establish the prevalence\nof spurious partial minima exhibiting un-disentangled pol-    Empirical studies in mechanistic interpretability have ob-\nysemanticity, providing novel theoretical explanations for    served that neural network representations encode mean-\nfeature absorption (Chanin et al., 2025) and the effective-    ingful concepts as linear directions, often in superposition\nness of neuron resampling (Bricken et al., 2023). We design    (Marks & Tegmark, 2024; Nanda et al., 2023; Jiang et al.,\nthe Linear Representation Bench, a synthetic benchmark    2024; Park et al., 2025). Following Elhage et al. (2022) and\nthat strictly follows the Linear Representation Hypothesis,    Park et al. (2024), we formalize the hypothesis as follows.\nto evaluate SDL methods with fully accessible ground-truth\n                                                 Assumption 2.3 (Linear Representation Hypothesis). A\nfeatures.  Motivated by our theoretical insights, we pro-\n                                                  model representation xp ∈Rnp satisfies the Linear Repre-pose feature anchoring, a technique applicable to all SDL\n                                                                sentation Hypothesis (LRH) if there exists a feature function\nmethods which achieves improved feature recovery by con-\n                                          x : X →Rn and a feature matrix Wp ∈Rnp×n such that:straining learned features to known anchor directions.\n\nOur main contributions are as follows:                            1. Linear Decomposition: For all s ∼D,\n\n   • We build the first theoretical framework for SDL in                        xp(s) = Wpx(s).\n     mechanistic interpretability as a general optimization\n    problem encompassing diverse SDL methods.               2. Non-negativity: x(s) ∈Rn+.\n\n   • We theoretically prove that SDL optimization is bi-      3. Sparsity: There exists S ∈[0, 1] such that ∀i ∈[n],\n     convex, bridging mechanistic interpretability methods\n    with traditional biconvex optimization theory.                             s∼D(xi(s)Pr    = 0) ≥S.\n\n   • We characterize SDL optimization landscape and prove\n                                                                      4. Interpretability: Each component xi of x corresponds\n       its non-identifiability, providing novel explanations for\n                                                                      to a human-interpretable concept.\n     various phenomena observed empirically.\n\n   • We design the Linear Representation Bench, a bench-  We refer to x(s) as the ground-truth features, where each\n    mark with fully accessible ground-truth features, en-    xi(s) represents the activation level of concept i for input s.\n     abling fully transparent evaluation of SDL methods.    Wp encodes how these features are represented in xp.\n\n                                                2\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nAssumption 2.4 (Representation Assumptions). Follow-    2.4. Instantiations: Existing SDL Methods\ning recent works (Elhage et al., 2022; Park et al., 2024),\n                                       We now demonstrate how existing SDL methods instantiate\nwe assume the following conditions on the model repre-\n                                                         our framework through adopting different choices of input-\nsentations satisfying the Linear Representation Hypothesis,\n                                                                    target pairs (xp, xr) and activation functions σ, and propos-which align with practical use cases:\n                                                           ing variants on the loss function LSDL (See Appendix A).\n  1. Unit Norm: The feature matrix Wp ∈Rnp×n has    Sparse Autoencoders (SAEs). SAEs (Cunningham et al.,\n     unit-norm columns:                                2023) decompose polysemantic activations into monose-\n                                                       mantic components through sparsity constraints.  In our                ∥Wp[:, i]∥2 = 1  ∀i ∈[n]\n                                                      framework, SAEs are characterized by setting xr = xp\n  2. Extreme Sparsity: The sparsity level S approaches 1:    (self-reconstruction).  The encoder projects to a higher-\n                                                         dimensional sparse latent space, encouraging xq(s) to cap-\n                   S →1\n                                                                 ture the underlying ground-truth features x(s) (Figure 1).\n\n  3. Independence: The ground-truth features satisfy: For\n    any input s ∼D, the features {xi(s)}ni=1 are mutually\n     independent and independent of the sparsity level S.\n\n  4. Bounded Interference: Define the maximum interfer-\n    ence as:\n\n       M := max⟨Wp[:, i], Wp[:, j]⟩\n                                i̸=j\n\nwhere Wp[:, i] denotes the i-th column of Wp. In typical\nsuperposition scenarios, M > 0 but remains small (close to    Figure 1. Sparse Autoencoder: encoder WE maps xp to sparse\nzero), characterizing a regime where many interpretable fea-     latents xq, decoder WD reconstructs from xq.\ntures are compressed into fewer dimensions with bounded\nmutual interference.\n                                                      Transcoders. Transcoders (Dunefsky et al., 2024; Paulo\n2.3. General Optimization Framework for SDL              et al., 2025) capture interpretable features in layer-to-layer\n                                                             transformations. Unlike SAEs, transcoders approximate\nNow we formalize SDL as an optimization problem under    the input-output function of a target component, such as a\nthe Linear Representation Hypothesis (Assumption 2.3) and   MLP, using a sparse bottleneck. In our proposed theoretical\nthe Representation Assumptions (Assumption 2.4).           framework, transcoders set xp = xmid(s) and xr = xpre(s),\nDefinition 2.5 (Sparse Dictionary Learning). A SDL model    where xmid(s) denotes the inputs of one MLP block, and\nmaps an input representation xp(s) ∈Rnp to a target repre-    xpre(s) denotes the prediction of MLP’s outputs (Figure 2).\nsentation xr(s) ∈Rnr through a two-layer architecture:\n\n  (i) An encoder layer that maps xp(s) to a latent space:\n\n                  xq(s) = σ(WExp(s))             (1)\n\n (ii) A decoder layer that maps the latents to xr(s):\n\n                       ˆxr(s) = WDxq(s)               (2)\n\nwhere xq(s) ∈Rnq, WE ∈Rnq×np, WD ∈Rnr×nq, and\nσ : Rnq →Rnq is a sparsity-inducing activation function.\n                                                               Figure 2. Transcoder: encoder WE maps xp(s) to sparse latents\nThe SDL objective minimizes mean square error:              xq(s), decoder WD gives xr(s) as a prediction of MLP’s output.\n     LSDL = Es∼D ∥xr(s) −WDσ(WExp(s))∥22     (3)\n                                                       Crosscoders.  Crosscoders (Lindsey et  al., 2024) dis-\nUnder the Linear Representation Hypothesis (Assump-                                                           cover shared features across multiple representation sources\ntion 2.3), both representations admit linear decompositions                                                  by jointly encoding and reconstructing concatenated rep-\nxp(s) = Wpx(s) and xr(s) = Wrx(s) in terms of ground-    resentations.  In our framework, crosscoders set xp =\ntruth features x(s). The loss can thus be expressed as:          [x(1)p  ; . . . ; x(m)p   ] and xr = [x(1)r   ; . . . ; x(m)r    ] where each su-\n  LSDL = Es∼D ∥Wrx(s) −WDσ(WEWpx(s))∥22   (4)    perscript denotes a different source (Figure 3).\n\n                                                3\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\n                                                          subsequent theoretical analysis to apply to the entire family\n                                                            of SDL methods, rather than just a single architecture. We\n                                                               also state a key property for SDL activation functions:\n\n\n                                                                         σ(z)i ∈{0, zi}  ∀i ∈[nq]           (10)\n\n                                                        This property holds for ReLU, JumpReLU, Top-k, Batch\nFigure 3. Crosscoder: encoder WE maps concatenated multi-layer    Top-k, and their compositions, the primary sparsity mech-\ninput xp to xq, decoder WD reconstructs multi-layer output xr.     anisms in practice. Notably, all these activation functions\n                                                        can be expressed in the form σJump(z; c) for some threshold\n                                                           c ≥0: σJump(z; c)i = zi · 1(zi > c).\nVariants of SDL Methods.  Various SDL methods  fit\ninto our theoretical framework but differ in their choices\n                                                        3. Theoretical Resultsof activation functions and loss designs.  Bricken et al.\n(2023) and Templeton et al. (2024) use ReLU activation                                                         Despite the empirical success of SDL methods across di-\nσReLU(z) = max(0, z) with L1 regularization on latents:      verse applications, a significant gap exists between their\n                                                                   practical use and our theoretical understanding of their opti-\nL = Es∼D ∥xr(s) −WDσReLU(WExp(s))∥22 + λ∥xq(s)∥1                                                         mization dynamics. This gap has important consequences:\n                                                          (5)\n                                                                 practitioners employ techniques like dead neuron resam-\nRajamanoharan et al. (2024b) propose to utilize JumpReLU\n                                                            pling (Bricken et al., 2023) and observe phenomena like\nas the activation function:\n                                                                 feature absorption (Chanin et al., 2025) without rigorous ex-\n              σJumpReLU(z) = z · H(z −θ)            (6)    planations for why these occur or how to systematically ad-\n                                                               dress them. Without theoretical grounding, the development\ncombined with a smoothed Heaviside function to directly    of improved SDL methods remains largely empirical, poten-\npenalize the L0 norm. Makhzani & Frey (2014) introduce     tially leaving highly effective techniques underexplored.\nTop-k activation:\n                                                Our theoretical analysis bridges this gap by characterizing\n       (                                                the SDL optimization landscape under the Linear Represen-                 zi   if zi is among the k largest components\nσTop-k(z)i =                                                      tation Hypothesis. Section 3.1 establishes a loss approxima-\n            0   otherwise                                                                 tion enabling tractable analysis (Theorem 3.1). Section 3.2\n                                                          (7)    proves SDL exhibits piecewise biconvex structure within\nBussmann et al. (2024) extend this to Batch Top-k activa-    activation pattern regions (Theorem 3.2). Section 3.3 char-\ntion, which applies Top-k selection across a batch to allow    acterizes the global minimum and shows the optimization\ndifferent samples to have different numbers of activated fea-     is underdetermined (Theorem 3.3 and  3.4). Section 3.4\ntures. Rajamanoharan et al. (2024a) use ReLU activation    establishes the prevalence of spurious partial minima ex-\nwith an additional Heaviside gating function. Gao et al.    hibiting polysemanticity (Theorem 3.7). Section 3.5 shows\n(2024) employ Top-k activation and introduce an auxiliary     that hierarchical concept structures naturally induce feature\nloss using Top-kaux dead latents:                             absorption patterns that manifest as partial minima (Theo-\n                                                 rem 3.10). We provide full proofs in Appendix I.\n               h    L = Es∼D ∥xr(s) −WDσTop-k(WExp(s))∥22\n                                                          (8)     3.1. Approximate Loss with Feature Reconstruction\n                                                 ′                   i        +λaux∥xp(s) −W DσTop-kaux(WExp(s))∥22                                                    Under extreme sparsity, the SDL loss decomposes into inde-\n                                                        pendent per-feature reconstruction terms.\nto resurrect dead neurons. Bussmann et al. (2025) and Tang\n                                             Theorem 3.1 (Loss Approximation). Under Assump-et al. (2025b) use multiple k values with a multi-scale loss:\n                                                                 tions 2.3 and 2.4, define the approximate loss as:\n     m\n                                                                       n\n L = X        λiEs∼D ∥xr(s) −WDσTop-ki(WExp(s))∥22                                                       ˜LSDL(WD, WE) := X                                                    Md wdr −WDσ(WEwdp) 2       i=1\n                                                          (9)                       d=1\n                                                                                                                 (11)\nthat sums reconstruction errors of different sparsity levels.\n                                                    where Md = Pr(x(s) = xd(s)ed) · E[xd(s)2|xd(s) > 0].\nThe variants described above demonstrate that diverse SDL   Then\nmethods can be unified under our general framework (Defi-                |LSDL −˜LSDL| ≤O((1 −S)2)          (12)\nnition 2.5) through specific choices of activation functions\nσ and loss modifications. Critically, this unification enables    This approximation isolates the contribution of each ground-\n\n\n                                                4\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\ntruth feature, making the optimization landscape amenable   Theorem 3.3 provides a constructive global minimum that\nto convex analysis techniques applied subsequently.           recovers ground-truth features, while Theorem 3.4 reveals\n                                                              the complete solution space. This system of n vector equa-\n3.2. SDL Optimization is Piecewise Biconvex                tions is underdetermined when nq > n, admitting multi-\n                                                             ple solutions beyond the feature-recovering configuration.\nWhile the SDL loss is non-convex globally due to activation                                                                      Critically, some solutions achieve zero reconstruction loss\ndiscontinuities, it exhibits favorable convex structure within                                                          without recovering any ground-truth features (Figure 4).\nregions of fixed activation patterns.\nTheorem 3.2 (Bi-convex Structure of SDL). Consider the     3.4. Characterizing Spurious Partial Minima of SDL\napproximate SDL loss ˜LSDL(WD, WE).  Define the acti-\nvation pattern region as ΩA = {WE ∈Rnq×np  : ∀d ∈   Beyond the global minimum, SDL optimization exhibits\n[n], A(d) = {i ∈[nq] : ⟨wiE, wdp⟩> c}} where c ≥0 is    spurious partial minima where neurons exhibit polyseman-\nthe activation threshold and A(d) ⊆[nq] denotes neurons    ticity—responding to multiple unrelated features.\nactivated by feature d.                              Example 3.5 (Spurious Partial Minimum). Consider n =\nThen ˜LSDL exhibits bi-convex structure over Rnr×nq × ΩA:   np = nq = nr = 2, σ = σTop-1 · σReLU, S →1, and\n                                     M1 = M2 = 1. Let:\n  1. For any fixed WE ∈ΩA, WD 7→˜LSDL(WD, WE) is            1          0          1          0\n                                                                                                                                                        ,  w2r =                                                                                                                                   ,  w1r =                                                                                                               ,  w2p =                                              w1p =     convex in WD.                                                                                             1                                                                                  0                                                                       1                                                           0\n  2. For any fixed WD ∈Rnrnq, WE 7→˜LSDL(WD, WE)                                                         (17)\n      is convex in WE over ΩA.                             Consider the configuration where neuron 1 activates for both\n                                                                features while neuron 2 remains dead:\nThis establishes SDL as a biconvex optimization problem,\n                                                                                  1/2  0                                                                   1  1\n                                                                                                                 (18)                                                                                                                                 , WD∗ =bridging mechanistic interpretability with classical bicon-      W E∗ =                                                                   0  0           1/2  0vex optimization theory. This characterization enables both\ntheoretical analysis of the optimization landscape and im-\nplementation of specialized biconvex methods for SDL.      Within the activation pattern region ΩA = {WE    :\n                                                  ⟨w1E, w1p⟩> 0, ⟨w1E, w2p⟩> 0}, direct calculation shows\n3.3. Characterizing the Global Minimum of SDL      ∇WD ˜L = 0 and ∇WE ˜L = 0. By traditional biconvex opti-\n                                                           mization theory (Gorski et al., 2007), (W D,∗ WE)∗  is a partialCharacterizing the global minimum reveals both the success\n                                                    optimum. However, this configuration exhibits polyseman-\nconditions for SDL training and the fundamental underde-                                        ∗    ∗                                                                          ticity with suboptimal loss: ˜LSDL(W D, WE) = 1 > 0.termined nature of the optimization problem.\n                                                           Definition 3.6 (Activation Pattern). An activation patternTheorem  3.3  (Successful  Reconstruction  Achieves\n                                                                           is a collection P = (F1, . . . , FN) where Fi ⊆[n] denotesNear-Zero Loss). Consider the approximate SDL loss\n                                                              the set of ground-truth features that activate neuron i.\n                  n\n ˜LSDL(WD, WE) = X Md wdr −WDσ(WEwdp) 2 (13)   An activation pattern P is called:\n                  d=1\n                                                                            • Polysemantic if ∃i ∈[N] such that |Fi| ≥2 (at leastwhere Md = Pr(x(s) = xd(s)ed) · E[xd(s)2|xd(s) > 0].\n                                                         one neuron responds to multiple features).\nWhen nq ≥n and σ satisfies σ(z)i ∈{0, zi} for all i, the\n                                                                            • Realizable if there exists an encoder σ(WE(·)) ∈configuration\n                                               RN×np such that:\n               ∗                 ∗  W p⊤\n      W D = [Wr, 0], W E =                (14)                  n                 o                             0                        ∀i ∈[N],  Fi =  d ∈[n] : σ(WEwdp)  i > 0\n                                                                                                                 (19)\nwhere 0 denotes zero padding to dimension nq, satisfies:\n                                                           That is, neuron i activates for exactly the features in\n          ˜LSDL(W D,∗ WE)∗ = O((1 −S)M 2)       (15)       Fi when they appear in isolation.\nwhere M is the maximum interference.                  Theorem 3.7 (Prevalence of Spurious Partial Minima). Un-\n                                                        der Assumptions 2.3 and 2.4 with n ≥2 and nq ≥n, forTheorem 3.4 (Necessary and Sufficient Conditions for Zero\n                                                      any activation pattern P = (F1, . . . , Fnq) that is realizable,Loss). The approximate loss satisfies ˜LSDL(WD, WE) = 0\n                                                           polysemantic, and forms a partition of [n], there exists a\nif and only if                                                                      ∗    ∗                                                                   partial minimum (W D, WE) of ˜LSDL exhibiting this pattern\n       wdr = WDσ(WEwdp)   for all d ∈[n]      (16)    with positive loss.\n\n                                                5\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\n\n\n\n\nFigure 4. Zero reconstruction loss without recovering ground-truth features. We design the Linear Representation Bench that enable\nfull knowledge of the ground truth features to study SDL methods. We observe one concerning phenomenon that these methods can\nachieve zero loss without recovering any ground truth features. Left: Four ground-truth feature directions. Middle: Learned encoder\ndirections fail to align with ground truth. Right: Learned decoder directions are rotated accordingly. Although ˜LSDL ≈0, the learned\nfeatures bear no correspondence to interpretable ground-truth concepts, demonstrating the underdetermined nature of SDL optimization.\n\n\nThis establishes that partial minima are pervasive in SDL      If the activation pattern P = (F1, . . . , FM) is realizable,\noptimization: every realizable polysemantic activation pat-    then ∀i∗∈[M], ∃j∗∈[ki∗] such that the following activa-\ntern corresponds to a partial optima point where gradient     tion pattern exhibiting feature absorption is realizable:\ndescent can become trapped, a persistent challenge for SDL.\n                                                    P′ = (F1, . . . , Fi∗\\ {di∗,j∗}, {di∗,j∗}, . . . , FM)  (20)\n\n3.5. Theoretical Explanation for Feature Absorption\n                                                  Theorem 3.10 explains why feature absorption persists even\nFeature absorption—where one neuron captures, or ”ab-                                                        with careful training: hierarchical concept structures natu-\nsorbs”, a specific sub-concept while another responds to                                                                     rally induce realizable polysemantic patterns that manifest\nremaining related concepts—frequently occurs in SDL train-    as partial minima, providing theoretical grounding for this\ning (Chanin et al., 2025). Though prevalently encountered                                                        widely observed empirical phenomenon.\nand unwanted, researchers have limited understanding about\nwhy feature absorption occurs in SDL training. Here we\n                                                        4. Methodshow hierarchical concept structures naturally introduce re-\nalizable activation patterns exhibiting feature absorption and   Our theoretical analysis reveals a fundamental challenge\ntherefore connected with the framework’s partial minima.                                                                in SDL optimization: the underdetermined nature of the\n                                                                  loss landscape (Theorem 3.4), and the solution space admitsExample 3.8 (Feature Absorption). Consider a represen-\n                                                            multiple configurations—some achieving zero reconstruc-tation space with a parent concept ”Dog” and four sub-\n                                                                 tion loss without recovering any interpretable ground-truthconcepts: ”Border Collie”, ”Golden Retriever”, ”Husky”,\n                                                                features (Figure 4). These theoretical findings motivate ourand ”German Shepherd”.  Ideally, SDL learns separate\n                                                      method, feature anchoring, a technique that constrains amonosemantic neurons for Dog, Cat, Horse, and Elephant,\n                                                             subset of features to align with known semantic directions.with each dog breed activating only the Dog neuron. How-\never, feature absorption can result in the pattern in Fig-\nure 5: one neuron exclusively captures ”Border Collie” (ab-    4.1. Anchor Feature Extraction\nsorbed feature), while another responds to the remaining                                                          Feature anchoring requires identifying k anchor features\nthree breeds collectively (main line interpretation).                                                   { ˜w(i)p  , ˜w(i)r }ki=1 that represent semantically meaningful di-\nDefinition 3.9 (Hierarchical Concept Structure). A set of     rections in the representation space. We present two meth-\nground-truth features exhibits hierarchical structure if it is    ods for obtaining these anchors:\ncomposed of a parent concept p and a set of sub-concepts\nc1, . . . , ck satisfying: p(x) > 0 ⇐⇒∃i ∈[k], ci(x) > 0.    Ground-Truth Features (Linear Representation Bench).\n                                           When ground-truth features are available—as in our Linear\nTheorem 3.10 (Feature Absorption from Hierarchical Struc-                                                          Representation Bench where features are known by con-\nture). Suppose there exist M parent concepts with hi-                                                     struction—we directly use a random subset of k ground-\nerarchical decompositions into sub-concepts:  for each                                                                   truth feature directions:\ni ∈[M], parent concept di decomposes into sub-concepts\nFi = {di,1, . . . , di,ki} where ki ≥2.                                    ˜w(i)p = Wptrue [:, i],    ˜w(i)r = Wrtrue [:, i],   i ∈K   (21)\n\n                                                6\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\n               SDL without Feature Absorption                       SDL with Feature Absorption\n                                                                    SDL Feature: Border Collie         SDL Feature: Dog\n                                SDL Feature: Dog                        (Absorbed Feature)               (Main Line Interpretation)\n\n                                                                                   Border Collie   Golden Retriever\n           SDL Feature:                                                                          Husky\n            Elephant                       Dogs\n                             Elephants\n                                                                                      German Shepherd                           O                                    O\n\n                                                 Cats                                                       Cats\n                                Horses                          SDL Feature: Horse     Horses        SDL Feature: Horse\n                                               SDL Feature: Cat                                      SDL Feature: Cat\n\n\nFigure 5. Feature absorption emerges from hierarchical concept structure. Left: Ideal SDL features without absorption. Right:\nhierarchical concept structure exists and only a proportion of the sub-concepts of ”Dog” can activate the SDL feature.\n\n\nwhere K ⊂[n] is a randomly selected subset of size k.          etc.) since it only constrains the encoder WE and decoder\n                                WD matrices that are common to all SDL architectures.\nSubpopulation Mean Embeddings.  For  real-world    This universality makes feature anchoring a broadly useful\ndatasets where ground-truth features are unknown, we iden-    technique for improving performance across SDL methods.\ntify semantic subpopulations Luo et al. (2024) and compute\ntheir mean representations.  Specifically, given a labeled    5. Experimental Results\ndataset D = {(sj, yj)}Nj=1, where yj ∈{1, . . . , C}, we\ncompute the mean of representations for each class:       We first evaluate feature anchoring with various SDL meth-\n                                                      ods on the Linear Representation Bench (Section 5.1), a\n                     1\n               ¯x(c)p =     X xp(sj)       (22)    synthetic benchmark with fully accessible ground-truth fea-\n                    |{j : yj = c}|                                   j:yj=c                        tures that precisely instantiates our theoretical assumptions.\n                                                         Second, we validate feature anchoring on real-world data by\nThen we normalize each mean representation to obtain an-    training SDL methods on CLIP embeddings of ImageNet-\nchor directions:                                       1K. Third, we provide empirical evidence showing that dead\n                                        ¯x(c)p                         neuron resampling helps escape spurious local minima in                       ˜w(c)p =                         (23)\n                                  ∥¯x(c)p ∥2                           large language models. We provide comprehensive ablation\n                                                                studies in Appendix G.\n4.2. SDL Loss Function with Feature Anchoring\n                                                                    5.1. Results on The Linear Representation Bench\nGiven k anchor features {˜w(i)p  , ˜w(i)r }ki=1, we modify the\nSDL optimization objective to include an anchoring penalty   To validate our theoretical predictions, we design the Linear\nthat constrains the first k encoder rows and decoder columns    Representation Bench, a benchmark that precisely instanti-\nto align with these anchors.                                      ates Assumptions 2.3 and 2.4 with fully known GT features.\nThe complete anchored SDL objective is:                 Data Generation. We generate synthetic representations\n                                                       xp(s) = Wptrue x(s) where ground-truth features x(s) ∈Rn\n            LSDL-FA = LSDL + λanchorLanchor         (24)    follow shifted exponential distributions with sparsity S. The\n                                                               feature matrix W ptrue ∈Rnp×n is constructed via gradient-\nwhere LSDL is the standard SDL loss (Equation 3) and the    based optimization (Detailed in Appendix C).\nanchoring loss is:\n                                                           Metrics. Given learned features W plearned = W E⊤ ∈Rnp×nq\n     Lanchor = ∥WE[1:k, :] −[˜w(1)p  , . . . , ˜w(k)p  ]⊤∥2F            and ground truth features W ptrue ∈Rnp×n (columns are unit-\n                                                     (25)   norm feature directions), we compute the similarity matrix\n       + ∥WD[:, 1:k] −[˜w(1)r   , . . . , ˜w(k)r  ]∥2F                           learned⊤    true                                        S = |W p   W p   | ∈Rnq×n. For each ground truth\n                                                                feature i ∈[n], we find its best match: si = maxj Sji.\nThis feature anchoring technique (Equation 25) reduces the\nunderdetermined nature of SDL training, and is method-\nagnostic:  it applies equally to SAEs, transcoders, cross-        • GT Recovery is the fraction of ground truth features\ncoders, and their variants (TopK SAEs, Matryoshka SAEs,        with si > τ, MGT(W plearned ) = n1 Pni=1 1{si > τ}.\n\n                                                7\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nTable 1. Feature recovery on the Linear Representation Bench           Table 2. Feature recovery on the CLIP embeddings.\n(n = 1000, np = nr = 768, nq = 16000, S = 0.99). Feature\nanchoring (FA) consistently improves GT Recovery and Maximum    Method         MGT ↑  MIP ↑  L0-norm↓\nInner Product (MIP) across all SDL methods.\n                                              TopK SAE             0.00%    0.517      64.0\n Method         MGT ↑  MIP ↑  L0-norm↓      + Feature Anchoring  24.13%   0.851      64.0\n ReLU SAE            0.00%    0.205     2787.4      BatchTopK SAE        0.00%    0.508      64.0\n   + Feature Anchoring   0.00%    0.246     1715.1       + Feature Anchoring  24.13%    0.847      64.0\n\n JumpReLU SAE        0.00%    0.237     1572.3      Matryoshka SAE        0.00%    0.683     128.0\n   + Feature Anchoring   0.00%    0.333     1139.6       + Feature Anchoring  24.45%    0.858     128.0\n\n TopK SAE            84.90%    0.983      54.1\n   + Feature Anchoring  87.63%   0.986      54.1\n                                                To validate this, we train SAEs on Llama 3.1 8B Instruct\n BatchTopK SAE        84.80%    0.981      65.0       (layer 12, dimension 4096) with latent dimension 131,072\n   + Feature Anchoring  89.38%    0.988      60.1       for 30,000 steps on FineWeb-Edu (Penedo et al., 2024),\n                                                          processing 4096 token activations per step. We compare Matryoshka SAE       83.70%    0.982      58.9\n                                                             standard training against feature resampling after 5000 steps.   + Feature Anchoring  87.32%    0.985      57.9\n                                             As shown in Figure 6, resampling enables the optimizer to\n Transcoder            23.60%    0.838      50.6      escape spurious local minima, achieving lower final loss.\n   + Feature Anchoring  25.05%   0.838      49.5\n                                                                          Loss Comparison\n Crosscoder            56.42%    0.940      83.4              5\n   + Feature Anchoring  57.71%   0.941     116.3                                           resample\n                                                                                                   no_resample\n                                                                4\n\n   • Maximum Inner Product is the mean of best matches:           3\n   MIP(W plearned ) = n1 Pni=1 si.\n                                                                2\n\nAs shown in Table 1, feature anchoring significantly im-\nproves feature recovery performance for all SDL methods.               0        100       200       300\n\n5.2. Results on CLIP Embeddings of ImageNet             Figure 6. Feature resampling accelerates convergence and im-\n                                                           proves final loss. Training curves on Llama 3.1 8B comparing\nTo validate that feature anchoring generalizes beyond syn-    standard SAE training (blue) with periodic dead neuron resampling\n                                                                             after 5000 steps (in the plot x axis is scaled by 100).thetic benchmarks to real-world representations, we apply\nour method to CLIP embeddings of ImageNet-1K (Rus-\nsakovsky et al., 2015). We extract CLIP-ViT-B/32 (Rad-    6. Conclusion\nford et al., 2021) image embeddings for all ImageNet train-\ning images and compute ground-truth anchor features as   We develop the first unified theoretical framework for Sparse\nnormalized class mean embeddings: ˜w(c)p = ¯x(c)p  /∥¯x(c)p ∥2    Dictionary Learning in mechanistic interpretability, demon-\nwhere ¯x(c)p   is the mean embedding over all images in class     strating how diverse SDL methods instantiate a single opti-\n                                                           mization problem. We prove that SDL exhibits piecewise bi-c. We train TopK, BatchTopK, and Matryoshka SAEs with\n                                                       convex structure, bridging mechanistic interpretability withnp = nr = 768, nq = 16, 384, and use k = 30 anchors\n                                                                  classical optimization theory. We characterize the globalwith λanchor = 1.0. Table 2 shows feature anchoring consis-\n                                             minimum and establish that the optimization is fundamen-tently improves feature recovery (Examples in Appendix H).\n                                                                         tally underdetermined, admitting solutions that achieve zero\n                                                               reconstruction loss without recovering interpretable features.\n5.3. Neuron Resampling Helps Escape Partial Minima\n                                       We demonstrate that spurious partial minima exhibiting pol-\nOur partial minima analysis (Theorem 3.7) proves the preva-    ysemanticity are pervasive, and prove that hierarchical con-\nlence of spurious partial minima and connects them to dead    cept structures naturally induce feature absorption patterns\nneurons (Fi = ∅). To address this, we utilize neuron resam-    that manifest as partial minima. To validate our theory, we\npling (Bricken et al., 2023) to help SDL training overcome    design the Linear Representation Bench with fully accessi-\nthese partial minima. We argue that resampling reinitial-    ble ground-truth features, and propose feature anchoring—a\nizes dead neurons toward under-reconstructed directions,    technique applicable to all SDL methods that addresses the\nperturbing the optimization away from the partial minima.    underdetermined nature of optimization.\n\n                                                8\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nImpact Statement                                      Cui, J., Zhang, Q., Wang, Y., and Wang, Y. On the theoreti-\n                                                                     cal understanding of identifiable sparse autoencoders and\nThis paper presents work whose goal is to advance the field                                                         beyond, 2025. URL https://arxiv.org/abs/\nof Machine Learning. There are many potential societal                                              2506.15963.\nconsequences of our work, none which we feel must be\nspecifically highlighted here.                           Cunningham, H., Ewart, A., Riggs, L., Huben, R., and\n                                                               Sharkey, L. Sparse autoencoders find highly interpretable\nCode Availability                                           features in language models, 2023. URL https://\n                                             arxiv.org/abs/2309.08600.\nWe provide  full  scripts of the Linear Representation\n                                                    Donoho, D. L. Compressed sensing. IEEE Transactions onBench and feature anchoring in this GitHub repository:\n                                                             information theory, 52(4):1289–1306, 2006.The Linear Representation Bench.\n\n                                                        Dunefsky, J., Chlenski, P., and Nanda, N. Transcoders find\nReferences                                                    interpretable llm feature circuits, 2024. URL https:\n                                             //arxiv.org/abs/2406.11944.\nAbdulaal, A., Fry, H., Monta˜na-Brown, N., Ijishakin, A.,\n  Gao, J., Hyland, S., Alexander, D. C., and Castro, D. C.    Elhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan,\n  An x-ray is worth 15 features: Sparse autoencoders for        T., Kravec, S., Hatfield-Dodds, Z., Lasenby, R., Drain,\n   interpretable radiology report generation, 2024. URL       D., Chen, C., Grosse, R., McCandlish, S., Kaplan, J.,\n  https://arxiv.org/abs/2410.03334.           Amodei, D., Wattenberg, M., and Olah, C. Toy models\n                                                               of superposition, 2022. URL https://arxiv.org/\nAharon, M., Elad, M., and Bruckstein, A. K-svd: An algo-     abs/2209.10652.\n  rithm for designing overcomplete dictionaries for sparse\n   representation. IEEE Transactions on signal processing,    Engels,  J., Michaud, E.  J., Liao,  I., Gurnee, W., and\n  54(11):4311–4322, 2006.                               Tegmark, M. Not all language model features are one-\n                                                           dimensionally linear, 2025. URL https://arxiv.\nBereska, L. and Gavves, E. Mechanistic interpretability     org/abs/2405.14860.\n   for ai safety – a review, 2024. URL https://arxiv.\n                                                    Gao, L., la Tour, T. D., Tillman, H., Goh, G., Troll, R.,\n  org/abs/2404.14082.\n                                                           Radford, A., Sutskever, I., Leike, J., and Wu, J. Scaling\n                                                        and evaluating sparse autoencoders, 2024. URL https:\nBricken, T., Templeton, A., Batson, J., Chen, B., Jermyn,\n                                             //arxiv.org/abs/2406.04093.\n  A., Conerly,  T., Turner, N. L., Anil,  C., Denison,\n   C.,  Askell,  A., Lasenby,  R., Wu,  Y., Kravec,  S.,   Ge, R., Lee, J. D., and Ma, T. Matrix completion has no\n   Schiefer, N., Maxwell,  T., Joseph, N., Tamkin, A.,      spurious local minimum, 2018. URL https://arxiv.\n  Nguyen, K., McLean,  B., Burke,  J. E., Hume,  T.,     org/abs/1605.07272.\n   Carter,  S., Henighan,  T., and Olah, C.   Towards\n  monosemanticity: Decomposing language models with    Gorski, J., Pfeuffer, F., and Klamroth, K. Biconvex sets\n   dictionary  learning.   Transformer  Circuits Thread,     and optimization with biconvex functions: a survey and\n  2023. URL https://transformer-circuits.      extensions. Mathematical methods of operations research,\n  pub/2023/monosemantic-features.                66(3):373–407, 2007.\n\n                                                           Gribonval, R. and Schnass, K.  Dictionary identificationBussmann, B., Leask, P., and Nanda, N. Batchtopk sparse\n                                                                             - sparse matrix-factorisation via ℓ1-minimisation, 2010.  autoencoders, 2024. URL https://arxiv.org/\n                                        URL https://arxiv.org/abs/0904.4774.  abs/2412.06410.\n\n                                                              Gujral, O., Bafna, M., Alm, E., and Berger, B. Sparse au-\nBussmann, B., Nabeshima, N., Karvonen, A., and Nanda, N.                                                             toencoders uncover biologically interpretable features in\n  Learning multi-level features with matryoshka sparse au-                                                                 protein language model representations. Proceedings of\n   toencoders, 2025. URL https://arxiv.org/abs/                                                                  the National Academy of Sciences, 122(34):e2506316122,\n  2503.17547.                                                           2025.\n\nChanin, D., Wilken-Smith, J., Dulka, T., Bhatnagar, H.,    Jain, P. and Kar, P. Non-convex optimization for machine\n  Golechha, S., and Bloom, J. A is for absorption: Study-       learning. Foundations and Trends® in Machine Learn-\n  ing feature splitting and absorption in sparse autoen-       ing, 10(3–4):142–336, 2017.  ISSN 1935-8245.  doi:\n   coders, 2025.  URL https://arxiv.org/abs/      10.1561/2200000058. URL http://dx.doi.org/\n  2409.14507.                                 10.1561/2200000058.\n\n                                                9\n\nA Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nJiang, Y., Rajendran, G., Ravikumar, P., Aragam, B., and      and editing interpretable causal graphs in language mod-\n  Veitch, V. On the origins of linear representations in large        els, 2025. URL https://arxiv.org/abs/2403.\n  language models, 2024. URL https://arxiv.org/     19647.\n  abs/2403.03867.\n                                                     Mienye, I. D. and Jere, N. A survey of decision trees:\nKarvonen, A., Wright, B., Rager, C., Angell, R., Brinkmann,      Concepts, algorithms, and applications. IEEE access, 12:\n   J., Smith, L., Verdun, C. M., Bau, D., and Marks, S.     86716–86727, 2024.\n  Measuring progress in dictionary learning for language\n                                                    Nanda, N., Lee, A., and Wattenberg, M. Emergent linear\n  model interpretability with board game models, 2024.\n                                                                representations in world models of self-supervised se-  URL https://arxiv.org/abs/2408.00113.\n                                                       quence models, 2023. URL https://arxiv.org/\nKoh, P. W., Nguyen, T., Tang, Y. S., Mussmann, S., Pierson,     abs/2309.00941.\n   E., Kim, B., and Liang, P.  Concept bottleneck mod-\n                                                           Olah, C., Cammarata, N., Schubert, L., Goh, G., Petrov, M.,\n   els, 2020. URL https://arxiv.org/abs/2007.\n                                                       and Carter, S. Zoom in: An introduction to circuits. Dis-\n  04612.\n                                                                                                  till, 2020. doi: 10.23915/distill.00024.001. URL https:\nLee, D. D., Pham, P., Largman, Y., and Ng, A. Advances     //distill.pub/2020/circuits/zoom-in/.\n   in neural information processing systems 22. Tech Rep,\n                                                         Olsson, C., Elhage, N., Nanda, N., Joseph, N., DasSarma,\n  2009.\n                                                               N., Henighan, T., Mann, B., Askell, A., Bai, Y., Chen,\nLindsey, J., Templeton, A., Marcus, J., Conerly, T., Batson,      A., Conerly, T., Drain, D., Ganguli, D., Hatfield-Dodds,\n   J., and Olah, C. Sparse crosscoders for cross-layer fea-       Z., Hernandez, D., Johnston, S., Jones, A., Kernion, J.,\n   tures and model diffing. Transformer Circuits Thread,       Lovitt, L., Ndousse, K., Amodei, D., Brown, T., Clark,\n  2024. URL https://transformer-circuits.        J., Kaplan, J., McCandlish, S., and Olah, C. In-context\n  pub/2024/crosscoders/index.html.               learning and induction heads, 2022. URL https://\n                                             arxiv.org/abs/2209.11895.\nLipton, Z. C. The mythos of model interpretability, 2017.\n                                                            Park, K., Choe, Y. J., and Veitch, V. The linear representa-  URL https://arxiv.org/abs/1606.03490.\n                                                                    tion hypothesis and the geometry of large language mod-\nLundberg, S. and Lee, S.-I. A unified approach to interpret-        els, 2024. URL https://arxiv.org/abs/2311.\n  ing model predictions, 2017. URL https://arxiv.    03658.\n  org/abs/1705.07874.\n                                                            Park, K., Choe, Y. J., Jiang, Y., and Veitch, V. The ge-\nLuo, Y., An, R., Zou, B., Tang, Y., Liu, J., and Zhang, S. Llm      ometry of categorical and hierarchical concepts in large\n  as dataset analyst: Subpopulation structure discovery with      language models, 2025. URL https://arxiv.org/\n  large language model, 2024. URL https://arxiv.    abs/2406.01506.\n  org/abs/2405.02363.\n                                                           Paulo, G., Shabalin, S., and Belrose, N. Transcoders beat\nMairal, J., Bach, F., Ponce, J., and Sapiro, G. Online dic-      sparse autoencoders for interpretability, 2025. URL\n  tionary learning for sparse coding. In Proceedings of the     https://arxiv.org/abs/2501.18823.\n  26th annual international conference on machine learn-\n                                                         Penedo, G., Kydl´ıˇcek, H., allal, L. B., Lozhkov, A., Mitchell,\n   ing, pp. 689–696, 2009.\n                                                        M., Raffel, C., Werra, L. V., and Wolf, T. The fineweb\nMakhzani, A. and Frey, B. k-sparse autoencoders, 2014.       datasets:  Decanting the web for the finest text data\n  URL https://arxiv.org/abs/1312.5663.           at scale, 2024. URL https://arxiv.org/abs/\n                                              2406.17557.\nMao, Z., Xu, J., Zheng, Z., Zheng, H., Sheng, D., Jin, Y., and\n  Yang, G. Sparse autoencoders bridge the deep learning    Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G.,\n  model and the brain, 2025. URL https://arxiv.     Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark,\n  org/abs/2506.11123.                                               J., Krueger, G., and Sutskever, I. Learning transferable\n                                                                 visual models from natural language supervision, 2021.\nMarks, S. and Tegmark, M. The geometry of truth: Emer-    URL https://arxiv.org/abs/2103.00020.\n  gent linear structure in large language model represen-\n                                                     Rajamanoharan, S., Conmy, A., Smith, L., Lieberum, T.,   tations of true/false datasets, 2024. URL https://\n                                                      Varma, V., Kram´ar, J., Shah, R., and Nanda, N.  Im-  arxiv.org/abs/2310.06824.\n                                                          proving dictionary learning with gated sparse autoen-\nMarks, S., Rager, C., Michaud, E. J., Belinkov, Y., Bau,      coders, 2024a. URL https://arxiv.org/abs/\n  D., and Mueller, A. Sparse feature circuits: Discovering     2404.16014.\n\n                                                10\n\nA Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nRajamanoharan, S., Lieberum, T., Sonnerat, N., Conmy, A.,    Tang, Y., Lagzian, A., Anumasa, S., Zou, Q., Zhu, Y., Zhang,\n  Varma, V., Kram´ar, J., and Nanda, N. Jumping ahead:       Y., Nguyen, T., Tham, Y.-C., Adeli, E., Cheng, C.-Y., Du,\n  Improving reconstruction fidelity with jumprelu sparse        Y., and Liu, D. Human-like content analysis for generative\n  autoencoders, 2024b. URL https://arxiv.org/        ai with language-grounded sparse encoders, 2025a. URL\n  abs/2407.14435.                            https://arxiv.org/abs/2508.18236.\n\nRudin, C.  Stop explaining black box machine learning    Tang, Y., Sinha, A., and Liu, D. How does my model fail?\n  models for high stakes decisions and use interpretable      automatic identification and interpretation of physical\n  models instead, 2019. URL https://arxiv.org/       plausibility failure modes with matryoshka transcoders,\n  abs/1811.10154.                                    2025b.  URL https://arxiv.org/abs/2511.\n                                                10094.\nRussakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S.,\n  Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein,    Templeton, A., Conerly, T., Marcus, J., Lindsey, J., Bricken,\n  M., Berg, A. C., and Fei-Fei, L. Imagenet large scale        T., Chen, B., Pearce, A., Citro, C., Ameisen, E., Jones,\n  visual recognition challenge, 2015. URL https://      A., Cunningham, H., Turner, N., McDougall, C., Mac-\n  arxiv.org/abs/1409.0575.                         Diarmid, M., Freeman, C. D., Sumers, T. R., Rees, E.,\n                                                              Batson, J., Jermyn, A., Carter, S., Olah, C., and Henighan,\nSafran, I. and Shamir, O. Spurious local minima are com-\n                                                                    T. Scaling monosemanticity: Extracting interpretable fea-\n  mon in two-layer relu neural networks, 2018. URL\n                                                                     tures from claude 3 sonnet. Transformer Circuits Thread,\n  https://arxiv.org/abs/1712.08968.\n                                                         2024. URL https://transformer-circuits.\nSelvaraju, R. R., Cogswell, M., Das, A., Vedantam, R.,     pub/2024/scaling-monosemanticity/.\n  Parikh, D., and Batra, D. Grad-cam: Visual explana-\n                                                     Visweswaran, V. and Floudast, C. A global optimization   tions from deep networks via gradient-based localiza-\n                                                              algorithm (gop) for certain classes of nonconvex nlps—ii.   tion.  International Journal of Computer Vision, 128\n                                                                application of theory and test problems. Computers &  (2):336–359, October 2019.  ISSN 1573-1405.  doi:\n                                                           chemical engineering, 14(12):1419–1434, 1990.  10.1007/s11263-019-01228-7. URL http://dx.doi.\n  org/10.1007/s11263-019-01228-7.                                                Wang, M., la Tour, T. D., Watkins, O., Makelov, A., Chi,\n                                                          R. A., Miserendino, S., Wang, J., Rajaram, A., Heidecke,Sharkey, L., Chughtai, B., Batson,  J., Lindsey,  J., Wu,\n                                                                                       J., Patwardhan, T., and Mossing, D. Persona features   J., Bushnaq, L., Goldowsky-Dill, N., Heimersheim, S.,\n                                                                control emergent misalignment, 2025. URL https:  Ortega, A., Bloom, J., Biderman, S., Garriga-Alonso,\n                                             //arxiv.org/abs/2506.19823.  A., Conmy, A., Nanda, N., Rumbelow, J., Wattenberg,\n  M., Schoots, N., Miller, J., Michaud, E. J., Casper, S.,\n  Tegmark, M., Saunders, W., Bau, D., Todd, E., Geiger,\n  A., Geva, M., Hoogland, J., Murfet, D., and McGrath,\n  T. Open problems in mechanistic interpretability, 2025.\n  URL https://arxiv.org/abs/2501.16496.\n\nShu, D., Wu, X., Zhao, H., Rai, D., Yao, Z., Liu, N., and\n  Du, M. A survey on sparse autoencoders: Interpreting\n  the internal mechanisms of large language models, 2025.\n  URL https://arxiv.org/abs/2503.05613.\n\nSimon, E. and Zou, J. Interplm: Discovering interpretable\n  features in protein language models via sparse autoen-\n  coders, 2024.  URL https://arxiv.org/abs/\n  2412.12101.\n\nSpielman, D. A., Wang, H., and Wright, J. Exact recovery\n  of sparsely-used dictionaries, 2012. URL https://\n  arxiv.org/abs/1206.5882.\n\nSun, R. and Luo, Z.-Q. Guaranteed matrix completion via\n  non-convex factorization. IEEE Transactions on Informa-\n   tion Theory, 62(11):6535–6579, November 2016. ISSN\n  1557-9654. doi: 10.1109/tit.2016.2598574. URL http:\n  //dx.doi.org/10.1109/TIT.2016.2598574.\n\n                                                11\n\nA Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nA. Taxonomy for Sparse Dictionary Learning in Mechanistic Interpretability\n\n\n\n\n\n              Figure 7. Hierarchical taxonomy of Sparse Dictionary Learning research in Mechanistic Interpretability.\n\n\n\n\n                                                12\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nB. Notations\n\nWe summarize the key notations used throughout this paper.\n\n\n                    Notation            Description\n\n                       Distributions and Indexing\n            D                     Distribution over inputs\n             X                    Input space\n                   s                  Sample drawn from D\n                   ed                   Standard basis vector (1 in position d, 0 elsewhere)\n\n                      Representations and Dimensions\n                   x(s)                 Ground-truth features for input s ∼D\n                   xp(s)                Input representation to SDL model (observed)\n                    xr(s)                 Target/output representation for SDL model\n                    xq(s)                Latent activations in SDL bottleneck\n               n                Number of ground-truth features (dimension of x)\n                  np                 Dimension of input representation xp\n                  nr                 Dimension of target representation xr\n                  nq                 Dimension of latent space xq\n\n                SDL Architecture\n            WE                Encoder matrix (nq × np)\n           WD                Decoder matrix (nr × nq)\n                      σ(·)                  Sparsity-inducing activation function\n                wiE                     i-th row of encoder WE (encodes to neuron i)\n                wiD                     i-th column of decoder WD (decodes from neuron i)\n\n                     Linear Representation Hypothesis\n             Wp                  Feature matrix for xp (np × n)\n              Wr                   Feature matrix for xr (nr × n)\n              wdp                   d-th column of Wp (feature direction for feature d)\n              wdr                    d-th column of Wr (feature direction for feature d)\n          Wptrue                Ground-truth feature matrix (Linear Representation Bench)\n          Wplearned             Learned feature matrix (WE⊤ )\n\n                       Sparsity and Interference\n               S                     Sparsity level: Pr(xi(s) = 0) ≥S\n         M              Maximum interference: maxi̸=j⟨Wp[:, i], Wp[:, j]⟩\n             Md                Weight for feature d: Pr(x(s) = xd(s)ed) · E[xd(s)2|xd(s) > 0]\n\n                     Feature Anchoring\n                 k                Number of anchor features\n                          ˜w(i)p  , ˜w(i)r                i-th anchor feature pair\n                           λanchor              Anchoring loss weight\n            K                    Set of indices for selected anchor features\n\n                    Loss Functions\n                   LSDL                Standard SDL reconstruction loss\n                       ˜LSDL               Approximate SDL loss (extreme sparsity regime)\n                          Lanchor                Feature anchoring penalty\n                      LSDL-FA             Anchored SDL objective: LSDL + λanchorLanchor\n\n                      Activation Patterns\n             P = (F1, . . . , FN)   Activation pattern\n                  Fi                   Set of ground-truth features activating neuron i\n                 A(d)                 Set of neurons activated by feature d\n             ΩA                   Activation pattern region (fixed activation structure)\n                     c                     Activation threshold for σ\n\n                     Evaluation Metrics\n              MGT           GT Recovery: fraction of features with > τ alignment\n                MIP             Maximum Inner Product: mean best alignment per feature\n                    τ                    Threshold for GT Recovery (typically τ = 0.9 or 0.95)\n              S                      Similarity matrix: |Wplearned⊤ Wptrue |\n\n\n\n                                                13\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nC. The Linear Representation Bench\n\nThe Linear Representation Bench is a synthetic benchmark designed to precisely instantiate the Linear Representation\nHypothesis (Assumption 2.3) and Representation Assumptions (Assumption 2.4) with fully accessible ground-truth features\n(See Figure 8 for a visualization of the benchmark). This enables rigorous evaluation of SDL methods under controlled\nconditions where feature recovery can be directly measured.\n\n             Ground-Truth Features                                Data Samples\n\n\n\n\n\nFigure 8. Visualization of the Linear Representation Bench. The figure illustrates a D = 3 dimensional representation space generated\nusing N = 4 feature directions (Wp).\n\n\nC.1. Ground-Truth Feature Matrix Generation\nWe construct the feature matrix Wp ∈Rnp×n to satisfy the unit-norm and bounded interference conditions (Assumption 2.4).\n\nInitialization.   Initialize Wp with random Gaussian entries and normalize each column to unit ℓ2-norm:\n\n                                    wdp\n                              wdp ←            ,  ∀d ∈[n]                                          (26)\n                                                 ∥wdp∥2\n\n\nInterference Minimization.  We minimize pairwise interference via projected gradient descent. Define the soft-thresholded\ninterference loss:\n\n                Lint(Wp) = X max  0, ⟨wip, wjp⟩−(M −ϵ)  2 + λ X max  0, ⟨wip, wjp⟩  2               (27)\n                                           i̸=j                                                    i̸=j\n\nwhere ϵ > 0 is a tolerance margin and λ > 0 is a small regularization weight encouraging negative interference.\n\nAt each iteration, we compute the gradient with respect to Wp, perform a gradient step, and project back to the unit sphere:\n\n                                             wdp\n                Wp ←Wp −η∇WpLint,  wdp ←            ,  ∀d ∈[n]                            (28)\n                                                              ∥wdp∥2\n\nThis procedure continues until the maximum interference satisfies maxi̸=j⟨wip, wjp⟩≤M.\n\nC.2. Sparse Coefficient Generation\nFor each sample i ∈[N], we generate sparse ground-truth features x(i) ∈Rn+ as follows:\n\n                                                14\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nSparsity Mask.  Each feature d ∈[n] is independently activated with probability (1 −S):\n\n                                           m(i)d  ∼Bernoulli(1 −S)                                           (29)\n\n\nFeature Magnitudes.  Active features follow a shifted exponential distribution:\n\n                                                  x(i)d = m(i)d   · (cmin + Exp(β))                                        (30)\n\nwhere cmin ≥0 is a minimum activation threshold and β > 0 is the scale parameter.\n\nThis construction ensures:\n\n   • Non-negativity: x(i)d ≥0 for all d, i\n   • Sparsity: Pr(x(i)d = 0) = S for all d\n   • Independence: Features {x(i)d }nd=1 are mutually independent\n\nC.3. Data Synthesis\n\nThe observed representations are computed via linear combination:\n\n                                                     n\n                                                 x(i)p = Wpx(i) = X x(i)d wdp                                         (31)\n                                                      d=1\n\n\nBy construction, this dataset exactly satisfies Assumptions 2.3 and 2.4, enabling evaluation of SDL methods with complete\nknowledge of ground-truth features.\n\n\nC.4. Default Configuration\n\nTable 3 lists the default parameters used in our experiments.\n\n                               Table 3. Default configuration for the Linear Representation Bench.\n\n                           Parameter             Symbol   Default Value\n\n                         Number of features         n         1000\n                               Representation dimension     np         768\n                                Superposition ratio         n/np       1.30×\n                         Number of samples      N        100,000\n                                 Sparsity level            S          0.99\n                       Maximum interference    M           0.1\n\n\n\nThis controlled setting enables direct measurement of feature recovery metrics with ground-truth access, complementing\nevaluations on real neural network representations where true features are unknown.\n\n\n\n\n\n                                                15\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nD. Related Works\n\nD.1. Mechanistic Interpretability\n\nInterpretability is crucial for deploying AI in high-stakes domains such as medical diagnosis and financial modeling, where\nunderstanding model decisions is essential for safety and trust (Simon & Zou, 2024; Abdulaal et al., 2024). Traditional\napproaches include interpretability-by-design methods like Concept Bottleneck Models (Koh et al., 2020) and decision trees\n(Mienye & Jere, 2024), and post-hoc explanation methods like GradCAM (Selvaraju et al., 2019) and SHAP (Lundberg &\nLee, 2017). Mechanistic interpretability (Sharkey et al., 2025; Bereska & Gavves, 2024) aims to reverse-engineer neural\nnetworks by understanding their internal computational mechanisms. SAEs (Shu et al., 2025) and related dictionary learning\nmethods (Tang et al., 2025a; Dunefsky et al., 2024) decompose neural activations into sparse, interpretable features. Circuit\nanalysis (Olah et al., 2020; Olsson et al., 2022) investigates how these features compose into computational algorithms.\n\n\nD.2. Sparse Dictionary Learning\n\nSparse dictionary learning has a rich history predating its application to mechanistic interpretability. K-SVD (Aharon et al.,\n2006) established foundational methods for learning overcomplete dictionaries, while theoretical work in compressed sensing\n(Donoho, 2006) characterized recovery conditions, with Spielman et al. (2012) providing polynomial-time algorithms for\nexact reconstruction under sparsity assumptions. Safran & Shamir (2018) demonstrated that spurious local minima are\ncommon even in simple two-layer ReLU networks, highlighting optimization challenges that persist in modern applications.\nRecent work has adapted these principles to mechanistic interpretability. SAEs (Cunningham et al., 2023) apply dictionary\nlearning to language model activations. Various variants are further developed, including transcoders (Dunefsky et al., 2024),\ncrosscoders (Gao et al., 2024), Matryoshka SAEs (Bussmann et al., 2025), and hybrid approaches like Language-Grounded\nSparse Encoders (Tang et al., 2025a). These methods have found applications beyond language models, including protein\nstructure analysis (Simon & Zou, 2024; Gujral et al., 2025), medical imaging (Abdulaal et al., 2024), model evaluation\n(Tang et al., 2025b), board game analysis (Karvonen et al., 2024), and fMRI data analysis Mao et al. (2025).\n\n\nD.3. Biconvex Optimization\n\nBiconvex optimization studies problems where the objective is convex in each variable block when the other is fixed.\nGorski et al. (2007) provide a comprehensive survey establishing theoretical foundations and algorithmic approaches,\nwhile Visweswaran & Floudast (1990) develop the GOP algorithm providing global optimality guarantees via branch-and-\nbound. Matrix factorization problems exhibit similar bilinear structure; Lee et al. (2009) introduce non-negative matrix\nfactorization with multiplicative updates, and subsequent work establishes landscape properties, with Ge et al. (2018) proving\nmatrix completion has no spurious local minima and Sun & Luo (2016) providing convergence guarantees for alternating\nminimization. More broadly, Jain & Kar (2017) survey non-convex optimization in machine learning, while Safran &\nShamir (2018) demonstrate that spurious local minima are common in two-layer ReLU networks. Our work bridges these\noptimization-theoretic foundations with mechanistic interpretability by proving SDL exhibits biconvex structure, enabling\nthe application of established algorithms and analysis techniques to this emerging field.\n\n\n\n\n\n                                                16\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nE. Limitations\n\nWhile our theoretical framework provides valuable insights into SDL methods, several limitations warrant discussion:\n\n\n   • Assumption Violations. Our analysis relies on Assumptions 2.3 and 2.4, which may not hold perfectly in real-world\n     neural networks. In particular, there exists features that are not one-dimentional linear (Engels et al., 2025) .\n\n   • Extreme Sparsity. Several key results, including Theorem 3.1, rely on the extreme sparsity assumption (S →1). The\n    bounds may degrade substantially for moderate sparsity levels commonly observed in practice.\n\n   • Feature Independence. We assume mutual independence among ground-truth features, but real-world concepts often\n     exhibit correlations that our analysis does not capture.\n\n   • Convergence Guarantees. We characterize global and partial minima of the optimization landscape but do not provide\n     guarantees on whether gradient-based methods converge to global minima.\n\n   • Anchor Availability. Feature anchoring requires access to known semantic directions, which may not always be\n     available. The quality and coverage of anchors significantly impact performance.\n\nF. Future Works\n\nOur theoretical framework opens several avenues for future research:\n\n\n   • Global Optimization via GOP. Having established that SDL is piecewise biconvex (Theorem 3.2), applying Global\n     Optimization for biconvex Problems (GOP) (Gorski et al., 2007) could provide certificates of global optimality and\n     systematically escape spurious partial minima.\n\n   • Alternating Convex Search. Alternating convex search (ACS) (Gorski et al., 2007) directly exploits biconvex structure\n    by alternately solving convex subproblems for WD and WE. This may offer faster convergence and better solutions\n     than standard gradient descent.\n\n   • Convergence and Sample Complexity. Building on our landscape characterization, future work should establish\n     convergence rates for gradient descent and sample complexity bounds for feature recovery.\n\n   • Moderate Sparsity Analysis. Extending results beyond the S →1 regime to handle feature co-activation would\n    broaden practical applicability.\n\n   • Classical Dictionary Learning. Adapting established algorithms like K-SVD (Aharon et al., 2006) and online\n     dictionary learning (Mairal et al., 2009) to the SDL setting could yield improved optimization methods.\n\n   • Automatic Anchor Discovery. Developing methods to automatically discover high-quality anchors without external\n     supervision would make feature anchoring more practical.\n\n\n\n\n\n                                                17\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nG. Ablation Studies\n\nOur theoretical analysis reveals that SDL optimization becomes increasingly underdetermined as the number of ground-truth\nfeatures n grows relative to the representation dimension np (Theorem 3.4). To comprehensively validate our theoretical\nframework and assess the robustness of feature anchoring across different conditions, we conduct extensive ablation studies\non the Linear Representation Bench, systematically varying superposition ratio, interference level, sparsity, and activation\nfunction parameters.\n\n\nEffect of Superposition Ratio.  We first examine how feature anchoring performs under varying degrees of superposition\nby training ReLU SAEs with nq = 16, 000 latent dimensions while varying the number of ground-truth features n ∈\n{800, 900, 1000, 1100, 1200, 1300, 1400}. The representation dimension is fixed at np = nr = 768, yielding superposition\nratios from 1.04× to 1.82×. For feature anchoring, we randomly select k = 100 ground-truth features as anchors with\nλanchor = 0.1.\n\nAs shown in Table 4, standard SAE training achieves 0% GT Recovery across all feature counts, demonstrating the severity\nof the underdetermined optimization problem. With feature anchoring, GT Recovery reaches 100% at n = 800 and remains\nhigh (98.89%) at n = 900, confirming that anchoring a small subset of features (12.5% and 11.1% respectively) provides\nsufficient constraint to guide optimization toward the global minimum. As superposition increases, GT Recovery gradually\ndecreases (85.50% at 1.30×, 58.09% at 1.43×, 30.58% at 1.56×), aligning with our theoretical expectation that higher\nsuperposition expands the space of spurious solutions. Notably, feature anchoring consistently improves Maximum Inner\nProduct across all settings, indicating better feature quality even when full recovery is not achieved.\n\nTable 4. Feature recovery under varying superposition ratios. We fix np = nr = 768 and vary n from 800 to 1400. Feature anchoring\nuses k = 100 randomly selected anchors with λanchor = 0.1.\n\n             Method          Num Features  GT Recovery ↑  Max Inner Product ↑\n\n           SAE                      800          0.00%              0.361\n              + Feature Anchoring       800         100.00%             0.436\n\n           SAE                      900          0.00%              0.298\n              + Feature Anchoring       900         98.89%              0.345\n\n           SAE                     1000          0.00%              0.254\n              + Feature Anchoring      1000         85.50%              0.292\n\n           SAE                     1100          0.00%              0.223\n              + Feature Anchoring      1100         58.09%              0.258\n\n           SAE                     1200          0.00%              0.203\n              + Feature Anchoring      1200         30.58%              0.233\n\n           SAE                     1300          0.00%              0.192\n              + Feature Anchoring      1300         15.23%              0.216\n\n           SAE                     1400          0.00%              0.181\n              + Feature Anchoring      1400         8.57%              0.207\n\n\n\nEffect of Maximum Interference.  To examine how feature anchoring performs under different interference levels, we\nfix n = 1000 features in np = nr = 768 dimensions and vary the maximum interference M ∈{0.05, 0.1, 0.2, 0.5} during\nground-truth feature matrix generation. Recall from Assumption 2.4 that M := maxi̸=j⟨Wp[:, i], Wp[:, j]⟩quantifies the\nmaximum dot product between distinct feature directions, characterizing the degree of feature overlap in the representation\nspace.\n\nTable 5 presents results across different interference levels. For TopK, BatchTopK, and Matryoshka SAEs, feature anchoring\nconsistently improves GT Recovery across all interference values, with improvements ranging from 2-7 percentage points.\nFor instance, at M = 0.5, BatchTopK SAE improves from 83.7% to 89.6% with anchoring. ReLU and JumpReLU SAEs,\nwhich struggle with feature recovery even with anchoring (0% GT Recovery), still show improved Maximum Inner Product\n(e.g., ReLU at M = 0.2: 0.204 →0.245), indicating better feature alignment. Interestingly, performance degrades slightly\n\n\n                                                18\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nat very low interference (M = 0.05) compared to moderate interference (M = 0.1, 0.2), likely because extremely low\ninterference creates near-orthogonal features that are easier to recover without additional constraints, making the anchoring\nless critical.\n\nTable 5. Feature recovery under varying maximum interference M. All experiments use n = 1000 features with np = nr = 768 and\nk = 100 anchors.\n\n            Method           Max Interference  GT Recovery ↑  Max Inner Product ↑\n\n           Low Interference (M = 0.05)\n          ReLU SAE                    0.05            0.0%               0.205\n             + Feature Anchoring         0.05            0.0%               0.246\n           JumpReLU SAE               0.05            0.0%               0.239\n             + Feature Anchoring         0.05            0.0%               0.326\n           TopK SAE                     0.05            84.3%              0.982\n             + Feature Anchoring         0.05           87.3%              0.985\n             BatchTopK SAE               0.05            86.1%              0.984\n             + Feature Anchoring         0.05           87.5%              0.986\n             Matryoshka SAE               0.05            83.8%              0.982\n             + Feature Anchoring         0.05           85.8%              0.985\n\n             Moderate Interference (M = 0.2)\n          ReLU SAE                      0.2            0.0%               0.204\n             + Feature Anchoring          0.2            0.0%               0.245\n           JumpReLU SAE                 0.2            0.0%               0.237\n             + Feature Anchoring          0.2            0.0%               0.333\n           TopK SAE                      0.2            85.2%              0.984\n             + Feature Anchoring          0.2           86.8%              0.986\n             BatchTopK SAE                 0.2            84.7%              0.981\n             + Feature Anchoring          0.2           90.7%              0.989\n             Matryoshka SAE                0.2            84.7%              0.983\n             + Feature Anchoring          0.2           87.6%              0.986\n\n             High Interference (M = 0.5)\n          ReLU SAE                      0.5            0.0%               0.203\n             + Feature Anchoring          0.5            0.0%               0.243\n           JumpReLU SAE                 0.5            0.0%               0.237\n             + Feature Anchoring          0.5            0.0%               0.325\n           TopK SAE                      0.5            84.2%              0.982\n             + Feature Anchoring          0.5           88.2%              0.987\n             BatchTopK SAE                 0.5            83.7%              0.981\n             + Feature Anchoring          0.5           89.6%              0.987\n             Matryoshka SAE                0.5            83.9%              0.982\n             + Feature Anchoring          0.5           86.4%              0.985\n\n\n\nEffect of Feature Sparsity. We investigate how feature sparsity S affects SDL performance by varying S ∈\n{0.005, 0.01, 0.05, 0.1} where S denotes the probability that each feature is inactive (Assumption 2.3). Lower S val-\nues correspond to denser activation patterns, while higher S approaches the extreme sparsity regime analyzed in our\ntheoretical results.\n\nTable 6 reveals several key insights. At very low sparsity (S = 0.005), where features co-activate frequently, feature\nanchoring provides the most dramatic improvements. JumpReLU SAE improves from 11.8% to 74.8% GT Recovery, and\nall TopK-family methods show 2-6 percentage point gains. This validates that anchoring is particularly valuable when\nthe extreme sparsity assumption is violated and feature co-occurrence complicates optimization. At moderate sparsity\n(S = 0.05), performance drops significantly across all methods, as increased co-activation creates more complex interference\npatterns. At high sparsity (S = 0.1), approaching our theoretical regime, TopK-family methods achieve near-perfect recovery\n\n\n                                                19\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\n(98.8%-99.7%), with anchoring providing marginal improvements. Interestingly, Matryoshka SAE benefits least from\nanchoring at extreme sparsity, likely because its multi-scale architecture already provides sufficient constraints to recover\nfeatures.\n\nTable 6. Feature recovery under varying sparsity levels S. All experiments use n = 1000 features with np = nr = 768 and k = 100\nanchors.\n\n               Method                Sparsity  GT Recovery ↑  Max Inner Product ↑\n\n                   Very Low Sparsity (S = 0.005)\n              ReLU SAE               0.005        0.0%               0.231\n                 + Feature Anchoring    0.005        0.0%               0.326\n              JumpReLU SAE          0.005       11.8%              0.890\n                 + Feature Anchoring    0.005       74.8%              0.970\n               TopK SAE               0.005       82.2%              0.978\n                 + Feature Anchoring    0.005       84.3%              0.981\n                BatchTopK SAE          0.005       80.5%              0.976\n                 + Feature Anchoring    0.005       83.2%              0.980\n                 Matryoshka SAE          0.005       79.3%              0.974\n                 + Feature Anchoring    0.005       86.1%              0.983\n\n                 Moderate Sparsity (S = 0.01)\n              ReLU SAE                0.01        0.00%              0.205\n                 + Feature Anchoring     0.01        0.00%              0.246\n              JumpReLU SAE           0.01        0.00%              0.237\n                 + Feature Anchoring     0.01        0.00%              0.333\n               TopK SAE                0.01       84.90%              0.983\n                 + Feature Anchoring     0.01       87.63%              0.986\n                BatchTopK SAE           0.01       84.80%              0.981\n                 + Feature Anchoring     0.01       89.38%              0.988\n                 Matryoshka SAE          0.01       83.70%              0.982\n                 + Feature Anchoring     0.01       87.32%              0.985\n\n                 High Sparsity (S = 0.1)\n              ReLU SAE                 0.1         0.0%               0.186\n                 + Feature Anchoring      0.1         0.0%               0.191\n              JumpReLU SAE            0.1         0.0%               0.191\n                 + Feature Anchoring      0.1         0.0%               0.193\n               TopK SAE                  0.1        98.8%              0.981\n                 + Feature Anchoring      0.1        98.4%              0.979\n                BatchTopK SAE            0.1        95.6%              0.975\n                 + Feature Anchoring      0.1        96.2%              0.976\n                 Matryoshka SAE           0.1        99.7%              0.991\n                 + Feature Anchoring      0.1        99.7%              0.991\n\n\n\nEffect of TopK Sparsity Parameter.   Finally, we examine how the sparsity-inducing parameter k in TopK activation\naffects feature recovery. We train TopK SAEs with k ∈{32, 64, 128}, corresponding to average activation rates of 0.2%,\n0.4%, and 0.8% of the nq = 16, 000 latent dimensions.\n\nAs shown in Table 7, both standard and anchored TopK SAEs achieve perfect (100%) GT Recovery at k = 32, where\nextreme sparsity closely matches our theoretical assumptions. At k = 64, GT Recovery remains high (93.4%-93.9%) with\nminimal difference between standard and anchored training, indicating that moderate sparsity provides sufficient constraint\nfor feature recovery without additional anchoring. At k = 128, where activation density increases, feature anchoring\nbecomes beneficial again, improving GT Recovery from 86.7% to 88.0%. The Maximum Inner Product remains consistently\nhigh (> 0.985) across all settings, confirming that TopK activation is generally effective for feature recovery, with anchoring\nproviding incremental benefits at higher k values where the optimization becomes more challenging.\n\n                                                20\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nTable 7. Feature recovery under varying TopK sparsity parameter k. All experiments use n = 1000 features with np = nr = 768,\nnq = 16, 000, and k = 100 anchors.\n\n           Method            TopK Parameter k  GT Recovery ↑  Max Inner Product ↑\n\n           TopK SAE                   32            100.0%              0.999\n             + Feature Anchoring         32            100.0%              0.999\n\n           TopK SAE                   64             93.9%              0.992\n             + Feature Anchoring         64             93.4%              0.991\n\n           TopK SAE                   128            86.7%              0.986\n             + Feature Anchoring         128           88.0%              0.987\n\n\n\nTheoretical Interpretation.  These comprehensive ablation studies validate our theoretical framework across diverse\nconditions. The consistent failure of ReLU and JumpReLU SAEs without sufficient sparsity constraints corroborates\nTheorem 3.4: the underdetermined solution space admits infinitely many configurations achieving low reconstruction loss\nwithout recovering interpretable features. Feature anchoring addresses this by constraining encoder-decoder pairs, reducing\ndegrees of freedom and steering optimization away from spurious partial minima (Theorem 3.7). The varying effectiveness\nacross interference levels, sparsity regimes, and activation functions reflects the fundamental trade-off in Assumption 2.4:\nmore severe feature compression (higher M), denser activations (lower S), or insufficient activation sparsity (higher k)\ncreate more complex optimization landscapes where even anchored methods struggle to disentangle all features completely.\n\n\n\n\n\n                                                21\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nH. Qualitative Examples\n\nBeyond quantitative metrics, we provide qualitative evidence demonstrating how feature anchoring improves feature\nmonosemanticity. Figure 9 shows features learned by Matryoshka SAE with feature anchoring on CLIP embeddings of\nImageNet, while Figure 10 shows features from the same architecture trained without feature anchoring.\n\nWith Feature Anchoring. As shown in Figure 9, the learned features exhibit clear monosemanticity: each feature responds\nto a single, well-defined visual concept. The “African Grey” feature activates exclusively on African Grey parrots, the\n“American Black Bear” feature captures only black bears, and the “Digital Clock” feature responds specifically to digital\ntime displays. This monosemantic behavior aligns with our theoretical prediction that feature anchoring reduces the\nunderdetermined nature of SDL optimization (Theorem 3.4).\n\nWithout Feature Anchoring. In contrast, Figure 10 illustrates the polysemanticity that emerges without anchoring. Features\nrespond to multiple unrelated concepts: one activates on “Various Boxes” (dishwashers, file cabinets, chests), another on\n“Various Screens” (slot machines, scoreboards, televisions). While achieving low reconstruction loss, these features fail to\ncapture semantically meaningful concepts—exactly the spurious partial minima characterized in Theorem 3.7.\n\n\n\n\n\n             Feature from Matryoshka SAE with Feature Anchoring: African Grey.\n\n\n\n\n             Feature from Matryoshka SAE with Feature Anchoring: American Black Bear.\n\n\n\n\n            Feature from Matryoshka SAE with Feature Anchoring: Digital Clock.\n\nFigure 9. Features learned with feature anchoring exhibit monosemanticity. Each row shows the top-activating images for a single\nfeature from Matryoshka SAE trained on CLIP embeddings with feature anchoring.\n\n\n\n\n\n             Feature from Matryoshka SAE without Feature Anchoring: Cab.\n\n\n\n\n             Feature from Matryoshka SAE without Feature Anchoring: Various Screens (slot, scoreboard, television).\n\n\n\n\n            Feature from Matryoshka SAE without Feature Anchoring: Various Boxes (dishwaser, file, chest).\n\nFigure 10. Features learned without feature anchoring exhibit polysemanticity. Each row shows the top-activating images for a single\nfeature from Matryoshka SAE trained without feature anchoring.\n\n\n                                                22\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nI. Proofs of the Theorems\n\nI.1. Proof of Theorem 3.1\n\nProof. We establish how the loss decomposes when S →1. Let Wr = [w1r, w2r, . . . , wnr ] and Wp = [w1p, w2p, . . . , wnp ]\ndenote the column representations of the reconstruction and projection matrices.\n\nUnder extreme sparsity (S →1), we only need to consider situations where at most one component xd(s) is active for any\ngiven input. The expectation decomposes over sparsity levels:\n\n                LSDL = Es ∥Wrx(s) −WDσ(WEWpx(s))∥2                                                  (32)\n                        n\n             = X Pr(∥x(s)∥0 = m) · E[∥xr(s) −WDσ(WExp(s))∥2 | ∥x(s)∥0 = m]               (33)\n                    m=0\n\nWhen ∥x(s)∥0 = 0, both xr(s) = 0 and the reconstruction WDσ(WExp(s)) = 0, contributing zero to the loss.\n\nWhen ∥x(s)∥0 = 1, exactly one feature is active: x(s) = xd(s)ed for some d ∈[n]. In this case:\n\n                                        xr(s) = Wrx(s) = xd(s)wdr                                         (34)\n                                        xp(s) = Wpx(s) = xd(s)wdp                                         (35)\n\n\nTherefore:\n\n                 n\n     X Pr(x(s) = xd(s)ed) · E[∥xr(s) −WDσ(WExp(s))∥2 | x(s) = xd(s)ed]                    (36)\n\n                 d=1\n                   n\n          = X Pr(x(s) = xd(s)ed) · Exd(s) h xd(s)2 wdr −WDσ(WEwdp) 2 | xd(s) > 0i               (37)\n                   d=1\n                   n\n          = X Md wdr −WDσ(WEwdp) 2                                                            (38)\n                   d=1\n\nwhere Md := Pr(x(s) = xd(s)ed) · E[xd(s)2|xd(s) > 0].\nWhen ∥x(s)∥0 ≥2, by Assumption 2.4 (extreme sparsity), Pnm=2 Pr(∥x(s)∥0 = m) ≤(1 −S)2. Since the reconstruction\nerror is bounded by a constant C (due to bounded norms), this contribution is O((1 −S)2).\n\nCombining all terms:\n                                  n\n                          LSDL = X Md wdr −WDσ(WEwdp) 2 + O((1 −S)2)                           (39)\n                                  d=1\n\n\n\nI.2. Proof of Theorem 3.2\n\nProof. Notation. Recall that A(d) ⊆[nq] denotes the set of neurons activated when feature d is active in isolation. Formally,\nfor WE ∈ΩA:\n                                 A(d) = {i ∈[nq] : ⟨wiE, wdp⟩> c}                                      (40)\n\nwhere c ≥0 is the activation threshold.\nPreliminary observation. Within ΩA, the activation zd(WE) := σ(WEwdp) satisfies:\n\n                           (⟨wiE, wdp⟩   if i ∈A(d)                                 zd(WE)i =                                                              (41)\n                                             0              if i /∈A(d)\n\nTherefore, zd(WE) is a linear function of WE within ΩA.\n\n                                                23\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nPer-feature loss decomposition. Define the per-feature reconstruction loss:\n\n                             fd(WD, WE) := ∥wdr −WDσ(WEwdp)∥2                                   (42)\n\nThe approximate SDL loss is a non-negative weighted sum:\n\n                                                  n\n                                 ˜LSDL(WD, WE) = X Mdfd(WD, WE)                                   (43)\n                                                   d=1\n\nwhere Md > 0 for all d ∈[n].\n\nWe prove biconvexity by establishing that each fd is biconvex, from which the result follows since positive linear combina-\ntions preserve biconvexity.\n\nPart 1: fd is convex in WD for fixed WE ∈ΩA.\n\nFix WE ∈ΩA and let zd := zd(WE) be the fixed activation vector. Then:\n\n                                 fd(WD) = ∥wdr −WDzd∥2                                         (44)\n\nGradient. The gradient with respect to WD is:\n\n                             ∇WDfd = −2(wdr −WDzd)z⊤d                                        (45)\n\nHessian. The Hessian (treating WD as vectorized) is:\n\n                               ∇2WDfd = 2Inr ⊗(zdz⊤d )                                          (46)\n\nSince zdz⊤d ⪰0, the Kronecker product with Inr is PSD, confirming fd is convex in WD.\n\nPart 2: fd is convex in WE for fixed WD, within ΩA.\nFix WD ∈Rnr×nq. Within ΩA, using the linearity of zd(WE):\n\n                        WDzd(WE) = X ⟨wiE, wdp⟩wiD =: ud(WE)                                (47)\n                                                   i∈A(d)\n\nwhere ud(WE) is linear (hence affine) in WE. Thus:\n\n                                 fd(WE) = ∥wdr −ud(WE)∥2                                        (48)\n\nSince the squared norm of an affine function is convex, fd is convex in WE.\nVerification via Hessian. For each encoder row wiE with i ∈A(d), the gradient is:\n                             ∇wiEfd = −2(wdr −ud(WE))⊤wiD · wdp                                   (49)\n\nThe Hessian is:\n                              ∇2wiEfd = 2∥wiD∥2(wdp(wdp)⊤)                                        (50)\n\nSince wdp(wdp)⊤⪰0 and ∥wiD∥2 ≥0, we have ∇2wiEfd ⪰0. For i /∈A(d), neuron i does not affect fd, so ∇2wiEfd = 0. The\nfull Hessian ∇2WEfd is block-diagonal with PSD blocks, hence ∇2WEfd ⪰0.\nConclusion. Since each fd is biconvex and Md > 0 for all d, the weighted sum:\n\n                                                  n\n                                 ˜LSDL(WD, WE) = X Mdfd(WD, WE)                                   (51)\n                                                   d=1\n\nis biconvex over Rnr×nq × ΩA, as positive linear combinations preserve biconvexity.\n\n                                                24\n\nA Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nI.3. Proof of Theorem 3.3\nProof. We analyze the approximate loss ˜LSDL(W D,∗ WE)∗  by examining the reconstruction error for each ground-truth\nfeature when active in isolation.\nConsider feature d ∈[n] active in isolation. The encoder output is WEwd∗  p = W p⊤ wdp with k-th component:\n\n                              (W Ewd∗  p)k = ⟨wkp, wdp⟩                                            (52)\n\nUnder Assumption 2.4, the unit-norm condition gives (W Ewd∗  p)d = 1. For k ̸= d, the bounded interference condition implies\n⟨wkp, wdp⟩≤M, where M is the maximum interference. Combined with the Cauchy-Schwarz inequality, we have:\n\n                                   ⟨wkp, wdp⟩∈[−1, M]  ∀k ̸= d                                        (53)\n\nDefine the set of activated neurons for feature d:\n\n                             Ad = {k ∈[n] : σ(WEwd∗  p)k > 0}                                      (54)\n\nSince σ(z)i ∈{0, zi} and typical activation functions satisfy σ(z)i > 0 ⇐⇒zi > c for some threshold c ≥0, we have:\n\n                              Ad = {k ∈[n] : ⟨wkp, wdp⟩> c}                                       (55)\n\nNote that d ∈Ad since (W Ewd∗  p)d = 1 > c ≥0. For k ̸= d, neuron k activates only if ⟨wkp, wdp⟩> c ≥0, which requires\npositive interference. Therefore:\n                          Ad \\ {d} ⊆{k ∈[n] : 0 < ⟨wkp, wdp⟩≤M}                                 (56)\n\nLet Kd = |Ad| denote the number of activated neurons.\nThe activation output satisfies σ(W Ewd∗  p)k = ⟨wkp, wdp⟩for k ∈Ad and zero otherwise, since σ(z)i ∈{0, zi}. The\nreconstruction is therefore W Dσ(W∗   Ewd∗  p) = Pk∈Ad⟨wkp, wdp⟩wkr. The reconstruction error for feature d is\n\n                      wdr −W Dσ(W∗   Ewd∗  p) = wdr − X ⟨wkp, wdp⟩wkr                                     (57)\n                                                  k∈Ad\n                            = wdr −wdr − X  ⟨wkp, wdp⟩wkr                           (58)\n                                                           k∈Ad\\{d}\n                            = − X  ⟨wkp, wdp⟩wkr                                     (59)\n                                                   k∈Ad\\{d}\n\nUnder the unit-norm assumption, ∥wkr∥= 1 for all k. For k ∈Ad \\ {d}, we have ⟨wkp, wdp⟩> 0 (since negative interference\ndoes not activate) and ⟨wkp, wdp⟩≤M by the bounded interference condition. Therefore, using the triangle inequality:\n\n                    wdr −W Dσ(W∗   Ewd∗  p) ≤ X   |⟨wkp, wdp⟩| · ∥wkr∥                                  (60)\n                                               k∈Ad\\{d}\n                           = X  ⟨wkp, wdp⟩· 1   (positive terms)                       (61)\n                                               k∈Ad\\{d}\n                           ≤ X M                                                 (62)\n\n                                               k∈Ad\\{d}\n                           = M(Kd −1)                                                 (63)\n\nSquaring both sides: ∥wdr −W Dσ(W∗   Ewd∗  p)∥2 ≤M 2(Kd −1)2. The approximate loss is\n\n                                      n                        n\n                      ˜LSDL(W D,∗ WE)∗ = X Md · M 2(Kd −1)2 ≤M 2 X Md(Kd −1)2                     (64)\n                                       d=1                       d=1\n\n                                                25\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nSince Kd ≥1 for all d and typically Kd = O(1) for most features (as the activation function provides sparsity), we\nhave (Kd −1)2 = O(1). Under the feature independence and stability assumptions (Assumption 2.4), Pnd=1 Md =\nPnd=1 Pr(x(s) = xd(s)ed) · E[xd(s)2|xd(s) > 0] = O(1 −S), since the probability that exactly one feature is active is\n(1 −S) under extreme sparsity. Therefore:\n                                    ˜LSDL(W D,∗ WE)∗ = O(M 2(1 −S))                                      (65)\n\nThis completes the proof.\n\n\nI.4. Proof of Theorem 3.4\n\nProof. We prove both directions of the equivalence.\nSufficient condition (⇒). Suppose wdr = WDσ(WEwdp) for all d ∈[n]. By definition of the approximate loss:\n\n                                              n\n                             ˜LSDL(WD, WE) = X Md∥wdr −WDσ(WEwdp)∥2                              (66)\n                                              d=1\n                                              n\n                           = X Md∥wdr −wdr∥2                                         (67)\n                                              d=1\n                           = 0                                                           (68)\n\nNecessary condition (⇐). Suppose ˜LSDL(WD, WE) = 0. Then:\n\n                                    n\n            X Md∥wdr −WDσ(WEwdp)∥2 = 0                                     (69)\n                                    d=1\n\nSince Md > 0 for all d ∈[n] (by definition, Md = Pr(x(s) = xd(s)ed) · E[xd(s)2|xd(s) > 0] where both factors are\npositive under Assumptions 2.3 and 2.4):\n\n                              ∥wdr −WDσ(WEwdp)∥2 = 0  ∀d ∈[n]                                   (70)\n\nTherefore:\n                               wdr = WDσ(WEwdp)  ∀d ∈[n]                                       (71)\n\n\n\n\nI.5. Proof of Theorem 3.7\n\nProof. We construct a configuration (W D,∗ WE)∗  exhibiting the polysemanticity pattern and explicitly verify that both\ngradients vanish.\nStep 1: Given encoder W E∗ from realizability.\n\nSince the activation pattern P = (F1, . . . , Fnq) is realizable and forms a partition of [n], by Definition 3.6, there exists an\nencoder W E∗ ∈Rnq×np such that:\n\n                                 n               ∗       o                                ∀i ∈[nq],  Fi =  d ∈[n] : σ(W Ewdp)  i > 0                                (72)\n\nFix this W E∗ and define the activation vectors:\n                                     zd := σ(WEwd∗  p) ∈Rnq,  d = 1, . . . , n                                   (73)\n\nSince P forms a partition, for each feature d there exists a unique neuron i(d) such that d ∈Fi(d), and:\n\n                                            zd = ⟨w∗,i(d)E     , wdp⟩· ei(d)                                           (74)\n\n                                                26\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nThat is, only neuron i(d) activates for feature d.\nStep 2: Construct optimal decoder W D.∗\nFor each neuron i ∈[nq], we construct the decoder column W D∗,i by minimizing the loss over features activating that neuron.\nDead neurons: If Fi = ∅, set W D∗,i = 0.\n\nActive neurons: If Fi ̸= ∅, solve:\n\n                                     min                X Md wdr −W D(zd)ii       2                               (75)               W D∗,i = arg                                                                            i                          W D∈Rnr                                                   d∈Fi\n\nThis is a least squares problem with solution:\n\n                                                                ∗,i Pd∈Fi Md(zd)iwdr\n                    W D =                                                             (76)                      P                                                     d∈Fi Md(zd)2i\n\nStep 3: Verify ∇WD ˜LSDL(W D,∗ WE)∗ = 0.\nThe loss is ˜LSDL(WD, WE) = Pnd=1 Md∥wdr −WDzd∥2. The gradient with respect to column W Di  is:\n\n                                               n\n                                                                i ˜LSDL = −2 X Md(wdr −WDzd)(zd)i                                 (77)                   ∇W D\n                                               d=1\n\nSince P is a partition, (zd)i ̸= 0 only when i = i(d), i.e., when d ∈Fi. Therefore:\n\n                                                    i ˜LSDL(W D,∗ WE)∗ = −2 X Md(wdr −W D∗,i (zd)i)(zd)i                          (78)               ∇W D\n                                                     d∈Fi\n\nBy construction (76), W D∗,i satisfies the normal equation:\n            X Md(zd)i(wdr −W D∗,i (zd)i) = 0                                     (79)\n                                      d∈Fi\n\n                      i ˜LSDL(W D, WE) = 0 for all i ∈[nq].Therefore ∇W D         ∗    ∗\nStep 4: Verify ∇WE ˜LSDL(W D,∗ WE)∗ = 0.\n\nWithin the activation pattern region ΩA, for feature d ∈Fi, the activation is:\n                                               zd = ⟨wiE, wdp⟩· ei                                              (80)\n\nThe gradient with respect to encoder row wiE is:\n\n                                            n\n                                                                                                                 (81)                            ∇wiE ˜LSDL = X Md∇wiE wdr −WDzd  2\n                                             d=1\n\nOnly features d ∈Fi have non-zero contribution. For such d:\n\n                                            ∂zd\n                              = wdp ⊗ei                                               (82)\n                                       ∂wiE\n\nwhere ⊗denotes outer product. Therefore:\n\n                                                   2                       ∂zd\n                     ∇wiE wdr −WDzd  = −2(wdr −WDzd)⊤WD                                      (83)                                                           ∂wiE\n                           = −2(wdr −W D∗,i ⟨w∗,iE  , wdp⟩)⊤W D∗,i wdp                         (84)\n\n\n                                                27\n\nA Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nThe total gradient is:\n                   ∇wiE ˜LSDL = −2 X Md(wdr −W D∗,i ⟨w∗,iE  , wdp⟩)⊤W D∗,i wdp                               (85)\n                                       d∈Fi\n                   = −2(WD∗,i )⊤X Md⟨w∗,iE  , wdp⟩(wdr −W D∗,i ⟨w∗,iE  , wdp⟩)                      (86)\n                                               d∈Fi\n\nFrom the normal equation in Step 3 with (zd)i = ⟨w∗,iE  , wdp⟩:\n           X Md⟨w∗,iE  , wdp⟩(wdr −W D∗,i ⟨w∗,iE  , wdp⟩) = 0                                (87)\n                                 d∈Fi\n\nTherefore:\n                           ∇wiE ˜LSDL(W D,∗ WE)∗ = −2(WD∗,i )⊤· 0 = 0                                 (88)\n\nThis holds for all active neurons. For dead neurons (Fi = ∅), the gradient is automatically zero.\nStep 5: (W D,∗ WE)∗  is a partial optimum.\nBy Theorem 3.2, ˜LSDL is convex in WD for fixed W E,∗ and convex in WE for fixed W D∗ within ΩA.\n\nSince we have verified:\n\n   • ∇WD ˜LSDL(W D,∗ WE)∗ = 0 (Step 3)\n   • ∇WE ˜LSDL(W D,∗ WE)∗ = 0 within ΩA (Step 4)\n\nBy the first-order optimality condition for convex functions:\n\n   • W D∗ minimizes ˜LSDL(·, WE)∗\n   • W E∗ minimizes ˜LSDL(W D,∗  ·) over ΩA\n\nBy standard results in biconvex optimization (Gorski et al., 2007), (W D,∗ WE)∗  is a partial optimum.\n\nStep 6: Non-zero loss.\n\nSince the pattern is polysemantic, there exists i ∈[nq] with |Fi| ≥2. Choose distinct d1, d2 ∈Fi.\n\nBy Theorem 3.4, zero loss requires:\n                        wd1r = W Dzd1∗  = WD∗,i (zd1)i,  wd2r = WDzd2∗  = WD∗,i (zd2)i                         (89)\n\nIf both equations held, then:\n                                        wd1r           ∗,i    wd2r\n                             = W D =                                                  (90)\n                                                 (zd1)i             (zd2)i\n\nSince (zd1)i = ⟨w∗,iE  , wd1p ⟩> 0 and (zd2)i = ⟨w∗,iE  , wd2p ⟩> 0, this requires:\n\n                                                            (zd1)i\n                                          wd1r =      wd2r                                               (91)\n                                                            (zd2)i\n\nThis means wd1r ∝wd2r  , contradicting Assumption 2.4 (distinct features have linearly independent reconstruction vectors).\nTherefore:\n                                               n\n                              ˜LSDL(W D,∗ WE)∗ = X Md∥wdr −W Dzd∥2∗   > 0                                (92)\n                                                d=1\n\nConclusion. We have constructed (W D,∗ WE)∗  exhibiting the polysemanticity pattern, explicitly verified both gradients\nvanish, and shown it achieves positive loss, completing the proof.\n\n                                                28\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nI.6. Proof of Theorem 3.10\n\nProof. We construct a realizable pattern exhibiting feature absorption by scaling down the parent neuron’s encoder until one\nsub-concept separates, then adding a dedicated neuron for the separated feature.\n\nStep 1: Initial configuration and feature geometry.\nSince P = (F1, . . . , FM) is realizable, there exists an encoder WE ∈RM×np and threshold c > 0 such that:\n\n                                  ∀i ∈[M],  Fi = {d ∈[n] : ⟨wiE, wdp⟩> c}                                 (93)\n\nFix any parent neuron i∗∈[M] with sub-concepts Fi∗= {di∗,1, . . . , di∗,ki∗} where ki∗≥2.\n\nFor each sub-concept, compute its activation strength:\n\n                                                                     di∗,j                                       aj := ⟨wi∗E , wp  ⟩> c,  ∀j ∈[ki∗]                                     (94)\n\n\nSince there are finitely many sub-concepts, define:\n\n                                           amin := min aj > c                                            (95)\n                                                                 j∈[ki∗]\n\nLet j∗∈[ki∗] be the index achieving this minimum: aj∗= amin.\n\nStep 2: Scale down parent neuron to separate one sub-concept.\nWe shrink the encoder row wi∗E by multiplying with scaling factor λ ∈(0, 1):\n\n                                                              ˜wi∗E := λ · wi∗E                                                (96)\n\n\nThe new activation strengths become:\n                                                                           di∗,j                                                                 ˜aj := ⟨˜wi∗E , wp  ⟩= λ · aj                                         (97)\n\nChoose λ such that:\n                                                c + amin       c\n                                λ :=       ∈           , 1                                          (98)\n                                              2amin      amin\n\nThis gives:\n\n   • For the minimum-activation feature: ˜aj∗= λamin = c+amin2  < c + ϵ for any small ϵ > 0\n   • For all other features: ˜aj = λaj > λamin = c+amin2\n\nBy choosing the threshold to be c′ = c+amin2     , we have:\n\n                              ˜aj∗= c′   (at boundary),    ˜aj > c′ for all j ̸= j∗                               (99)\n\nSlightly increasing c′ by infinitesimal ϵ > 0 gives c′′ = c′ + ϵ, ensuring:\n\n                                        ˜aj∗< c′′ < ˜aj  ∀j ̸= j∗                                        (100)\n\nTherefore, with encoder row ˜wi∗E and threshold c′′:\n\n                              {d ∈[n] : ⟨˜wi∗E , wdp⟩> c′′} = Fi∗\\ {di∗,j∗}                               (101)\n\n\nStep 3: Construct dedicated neuron for separated feature.\n\n\n                                                29\n\n A Unified Theory of Sparse Dictionary Learning in Mechanistic Interpretability: Piecewise Biconvexity and Spurious Minima\n\nWe create a new encoder row parallel to the separated feature:\n\n                                     wnewE  := α · wpdi∗,j∗                                          (102)\n\nwhere α > 0 is chosen sufficiently large.\n\n                                        di∗,j∗\nBy the unit-norm assumption (∥wp  ∥= 1):\n\n                                 ⟨wnewE   , wpdi∗,j∗ ⟩= α∥wpdi∗,j∗ ∥2 = α                                  (103)\n\nFor any other feature d ̸= di∗,j∗:\n                                 ⟨wnewE   , wdp⟩= α⟨wpdi∗,j∗ , wdp⟩≤αM                                  (104)\n\nwhere M < 1 is the maximum interference from Assumption 2.4.\n\nChoose α large enough such that:\n                                α > c′′, αM < c′′                                          (105)\n\n                                           2c′′\nThis is possible by taking α = 1+M , giving:\n\n                                                      2c′′                2c′′M\n                         α =     > c′′, αM =     < c′′                                (106)\n                                    1 + M              1 + M\n\nwhere the first inequality uses M < 1 and the second uses M < 1.\n\nTherefore:\n\n   • ⟨wnewE   , wpdi∗,j∗ ⟩= α > c′′ (separated feature activates new neuron)\n   • ⟨wnewE   , wdp⟩≤αM < c′′ for all d ̸= di∗,j∗(no other features activate)\n\nStep 4: The new activation pattern.\nConstruct the expanded encoder W E′ ∈R(M+1)×np:\n\n                                     w1 \n                                                                                                                                             E...\n                                                  wi∗−1E\n                                                                                                ′        ˜wi∗E                      W E =                                                     (107)                                                  wi∗+1\n                                                                                                                                                         E...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     wME               \n                                             wnewE\n\nWith threshold c′′, the resulting activation pattern is:\n\n                       P′ = (F1, . . . , Fi∗−1, Fi∗\\ {di∗,j∗}, Fi∗+1, . . . , FM, {di∗,j∗})                      (108)\n\n\nThis pattern is realizable by construction.\n\n\n\n\n\n                                                30\n\n## Claim to Classify\n\"neural networks represent meaningful concepts as directions in their representation spaces\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Literature review / theoretical analysis",
    "method_rung": 1,
    "claim_rung": 3,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The claim 'neural networks represent meaningful concepts as directions in their representation spaces' uses the strong mechanistic verb 'represents', which according to the codebook's decision tree for polysemous terms (specifically 'encodes/represents/stores') defaults to Rung 3 unless evidence shows it's used in a decodability sense. The paper supports this claim through literature review (citing Park et al., 2024; Elhage et al., 2022) and theoretical analysis of optimization landscapes, not direct empirical intervention on models. The methods used (theoretical proofs, synthetic benchmarks with ground truth) are observational/associational in nature, establishing mathematical properties rather than causal effects in real models, thus method_rung=1. This creates a +2 gap. The claim is stated definitively without hedging words like 'may' or 'suggests', so hedge_flag=0. The confidence is high (5) because the linguistic marker 'represents' is a clear Rung 3 indicator and the theoretical methods are clearly Rung 1."
  },
  "metadata": {
    "model": "qwen/qwen3-235b-a22b-2507",
    "usage": {
      "prompt_tokens": 33520,
      "completion_tokens": 280,
      "total_tokens": 33800
    },
    "finish_reason": "stop"
  }
}