{
  "timestamp": "2026-02-19T09:45:18.016604+00:00",
  "paper_id": "2304.14997",
  "claim_id": "2304.14997-04",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2304.14997\nTitle: Towards Automated Circuit Discovery for Mechanistic Interpretability\nFull text:\n                 Towards Automated Circuit Discovery\n                         for Mechanistic Interpretability\n\n\n\n\n                     Arthur Conmy∗  Augustine N. Mavor-Parker∗  Aengus Lynch∗   Stefan Heimersheim\n                         Independent          UCL            UCL        University of Cambridge\n\n                                                  Adrià Garriga-Alonso∗\n                                             FAR AI2023\n\n                                                 AbstractOct\n28                     Through considerable effort and intuition, several recent works have reverse-                              engineered nontrivial behaviors of transformer models. This paper systematizes\n                                the mechanistic interpretability process they followed. First, researchers choose\n                             a metric and dataset that elicit the desired model behavior. Then, they apply ac-\n                                   tivation patching to find which abstract neural network units are involved in the\n                                 behavior. By varying the dataset, metric, and units under investigation, researchers\n                             can understand the functionality of each component.[cs.LG]                 We automate one of the process’ steps: finding the connections between the abstract\n                                neural network units that form a circuit. We propose several algorithms and repro-\n                             duce previous interpretability results to validate them. For example, the ACDC algo-\n                               rithm rediscovered 5/5 of the component types in a circuit in GPT-2 Small that com-\n                                putes the Greater-Than operation. ACDC selected 68 of the 32,000 edges in GPT-2\n                               Small, all of which were manually found by previous work. Our code is available\n                                     at https://github.com/ArthurConmy/Automatic-Circuit-Discovery.\n\n\n                1  Introduction\n\n                     Rapid progress in transformer language modelling (Vaswani et al., 2017; Devlin et al., 2019; OpenAI,\n                      2023, inter alia) has directed attention towards understanding the causes of new capabilities (Wei et al.,\n                     2022) in these models. Researchers have identified precise high-level predictors of model performance\n                     (Kaplan et al., 2020), but transformers are still widely considered ‘black-boxes’ (Alishahi, Chrupała,\n                     and Linzen, 2019) like almost all other neural network models (Fong and Vedaldi, 2017; Buhrmester,\n                   Münch, and Arens, 2021).2 Interpretability research aims to demystify machine learning models, forarXiv:2304.14997v4\n                    example by explaining model outputs in terms of domain-relevant concepts (Zhang et al., 2021).\n\n                     Mechanistic interpretability focuses on reverse-engineering model components into human-\n                       understandable algorithms (Olah, 2022). Much research in mechanistic interpretability views models\n                       as a computational graph (Geiger et al., 2021), and circuits are subgraphs with distinct functionality\n                  (Wang et al., 2023). The current approach to extracting circuits from neural networks relies on a\n                           lot of manual inspection by humans (Räuker et al., 2022). This is a major obstacle to scaling up\n                       mechanistic interpretability to larger models, more behaviors, and complicated behaviors composed\n                        of many sub-circuits. This work identifies a workflow for circuit research, and automates part of it by\n                       presenting several methods to extract computational graphs from neural networks.\n\n                  Our main contributions are as follows. First, we systematize the common workflow prevalent in\n                  many existing mechanistic interpretability works, outlining the essential components of this process\n\n                       ∗Work partially done at Redwood Research. Correspondence to arthurconmy@gmail.com\n                         2Though this perspective is not universal (Lipton, 2016).\n\n\n                        37th Conference on Neural Information Processing Systems (NeurIPS 2023).\n\n            GPT-2 Small                      ACDC Circuit\n\n\n\n\n\nFigure 1: Automatically discovering circuits with ACDC. Left: a computational graph for GPT-2\nSmall, with a recovered circuit for the IOI task highlighted in red. Only edges between adjacent layers\nare shown. Right: the recovered circuit with labelled nodes. All heads recovered were identified as\npart of the IOI circuit by Wang et al. (2023). Edge thickness is proportional to importance.\n\n\n\n(Section 2). One of its steps is to find a subgraph of the model which implements the behavior of\ninterest, which is a step possible to automate. We introduce Automatic Circuit DisCovery (ACDC), a\nnovel algorithm that follows the way in which researchers identify circuits (Section 3), and adapt\nSubnetwork Probing (SP; Cao, Sanh, and Rush, 2021) and Head Importance Score for Pruning (HISP;\nMichel, Levy, and Neubig, 2019) for the same task. Finally, we introduce quantitative metrics to\nevaluate the success of circuit extraction algorithms (Sections 4 and 4.2). We present a detailed\nablation study of design choices in Appendix E and qualitative studies in Appendices F, G, H, I and J.\n\n\n2  The Mechanistic Interpretability Workflow\n\n\nMechanistic interpretability attempts to explain and predict neural network behaviors by understand-\ning the underlying algorithms implemented by models. In the related work section we discuss the\nmechanistic interpretability field and its relationship to ‘circuits’ research (Section 5). Neural network\nbehaviors are implemented by algorithms within the model’s computational graph, and prior work\nhas identified subgraphs (circuits, following Wang et al. (2023)’s definition) that capture the majority\nof particular behaviors. In this section, we describe a workflow that several prior works have followed\nthat has been fruitful for finding circuits in models.\n\nAs a concrete example of an approach taken to finding a circuit, Hanna, Liu, and Variengien (2023)\nprompt GPT-2 Small with a dataset of sentences like “The war lasted from 1517 to 15”. GPT-2\nSmall completes this sentence with “18” or “19” or any larger two digit number, but not with any\ntwo digit number that is at most “17” (from here, we refer to prompt completions like this as the\n“Greater-Than” task). This behavior can be measured by the difference in probability the model places\non a completion “18” or “19” or larger and the probability the model places on a completion “17”\nor smaller. Note that we use the term ‘dataset’ to refer to a collection of prompts that elicit some\nbehavior in a model: we do not train models on these examples, as in this paper we focus on post-hoc\ninterpretability.\n\nThe researchers then create a corrupted dataset of sentences that do not have any bias against particular\ntwo digit completions (the ‘01-dataset’ (Hanna, Liu, and Variengien, 2023)). The researchers\nattribute the greater-than operation to late layer MLPs and then find earlier components that identify\nthe numerical values of years, including attention heads in the model. Finally, Hanna, Liu, and\nVariengien (2023) interpret the role of each set of components. For example, they identify early\nmodel components that respond to the “17” token, and later model components that boost the\nimportance of logits for years greater than 17.\n\nThere are equivalent steps taken in a growing number of additional works (Heimersheim and Janiak,\n2023, the “Docstring” task; Goldowsky-Dill et al., 2023, the “Induction” task; Wang et al., 2023,\n\n\n                                        2\n\nthe “IOI” task), described in brief in Table 1 and in detail in Appendices F, H and J. We identify the\nworkflow that eventually finds a circuit as following three steps. Researchers:\n\n      1. Observe a behavior (or task3) that a neural network displays, create a dataset that reproduces\n         the behavior in question, and choose a metric to measure the extent to which the model\n        performs the task.\n\n      2. Define the scope of the interpretation, i.e. decide to what level of granularity (e.g. attention\n        heads and MLP layers, individual neurons, whether these are split by token position) at which\n        one wants to analyze the network. This results in a computational graph of interconnected\n       model units.\n\n      3. Perform an extensive and iterative series of patching experiments with the goal of removing\n         as many unnecessary components and connections from the model as possible.\n\nResearchers repeat the previous three steps with a slightly different dataset or granularity, until they\nare satisfied with the explanation of the circuit components.\n\nThis work (ACDC) presents a tool to fully automate Step 3. Before we dive into the details of ACDC,\nwe expand on what Steps 1-3 involve, and review examples from previous work that we use to\nevaluate ACDC.\n\n\n2.1  Step 1: Select a behavior, dataset, and metric\n\nThe first step of the general mechanistic interpretability workflow is to choose a neural network\nbehavior to analyze. Most commonly researchers choose a clearly defined behavior to isolate only\nthe algorithm for one particular task, and curate a dataset which elicits the behavior from the model.\nChoosing a clearly defined behavior means that the circuit will be easier to interpret than a mix of\ncircuits corresponding to a vague behavior. Some prior work has reverse-engineered the algorithm\nbehind a small model’s behavior on all inputs in its training distribution (Nanda et al., 2023; Chughtai,\nChan, and Nanda, 2023), though for language models this is currently intractable, hence the focus on\nindividual tasks.\n\nWe identified a list of interesting behaviors that we used to test our method, summarized in Table 1.\nThese include previously analyzed transformer models (1 and 3 on GPT-2 Small, 2 and 6 on smaller\nlanguage transformers) where researchers followed a workflow similar to the one we described above.\nTasks 4 and 5 involve the full behavior of tiny transformers that implement a known algorithm,\ncompiled with tracr (Lindner et al., 2023). For each task, we mention the metric used in previous\nwork to measure the extent to which the model performs the task on the corresponding dataset.\n\n\n2.2  Step 2: Divide the neural network into a graph of smaller units\n\nTo find circuits for the behavior of interest, one must represent the internals of the model as a\ncomputational directed acyclic graph (DAG, e.g. Figure 2a). Current work chooses the abstraction\nlevel of the computational graph depending on the level of detail of their explanations of model\nbehavior. For example, at a coarse level, computational graphs can represent interactions between\nattention heads and MLPs. At a more granular level they could include separate query, key and value\nactivations, the interactions between individual neurons (see Appendix I), or have a node for each\ntoken position (Wang et al., 2023).\n\nNode connectivity has to be faithful to the model’s computation, but that does not fully specify its\ndefinition. For example, following Elhage et al. (2021), many works consider the connections between\nmodel components in non-adjacent layers due to the additivity of the residual stream, even though\nthese are computed with dynamic programming in the actual model implementation. Connectivity\ndefines what is considered a direct or a mediated interaction (Pearl, 2009; Vig et al., 2020). See for\nexample Figure 2a, where component B has both a direct effect on the output node O and an indirect\neffect on the output through component A.\n\n\n   3Section 3 formally defines “task”. We use “behavior” and “task” interchangeably.\n\n\n                                       3\n\n Task             Example Prompt                 Output         Metric\n\n  1: IOI            “When John and Mary went to the   “ John”          Logit\n (Appendix F.2)        store, Mary gave a bottle of milk to”                      difference\n\n  2: Docstring           def f(self, files, obj, state, size,      “ shape”        Logit\n (Appendix H.1)        shape, option):                                            difference\n                              \"\"\"document string example\n\n                              :param state: performance analysis\n                              :param size: pattern design\n                              :param\n  3: Greater-Than     “The war lasted from 1517 to 15”     “18” or “19” or   Probability\n (Appendix G)                                                ...or “99”        difference\n\n  4: tracr-xproportion  [\"a\", \"x\", \"b\", \"x\"]          [0, 0.5,      Mean Squared\n (Appendix I.1)                                    0.33, 0.5]     Error\n\n  5: tracr-reverse      [0, 3, 2, 1]                  [1, 2, 3, 0]  Mean Squared\n (Appendix I.2)                                                               Error\n\n  6: Induction         “Vernon Dursley and Petunia Durs”    “ley”            Negative log-\n (Section 4.2)                                                                     probability\n\nTable 1: Five behaviors for which we have an end-to-end circuit from previous mechanistic in-\nterpretability work, plus Induction. We automatically rediscover the circuits for behaviors 1-5 in\nSection 4. Tokens beginning with space have a “ ” prepended for clarity.\n\n\n\n\n2.3  Step 3: Patch model activations to isolate the relevant subgraph\n\nWith the computational DAG specified, one can search for the edges that form the circuit. We\ntest edges for their importance by using recursive activation patching: i) overwrite the activation\nvalue of a node or edge with a corrupted activation, ii) run a forward pass through the model, and\niii) compare the output values of the new model with the original model, using the chosen metric\n(Section 2.1). One typically starts at the output node, determines the important incoming edges, and\nthen investigates all the parent nodes through these edges in the same way. It is this procedure that\nACDC follows and automates in Algorithm 1.\n\n\nPatching with zeros and patching with different activations  Activation patching methodology\nvaries between mechanistic interpretability projects. Some projects overwrite activation values with\nzeros (Olsson et al., 2022; Cammarata et al., 2021), while others erase activations’ informational\ncontent using the mean activation on the dataset (Wang et al., 2023). Geiger et al. (2021) prescribe\ninterchange interventions instead: to overwrite a node’s activation value on one data point with\nits value on another data point. Chan et al. (2022) justify this by arguing that both zero and mean\nactivations take the model too far away from actually possible activation distributions. Interchange\ninterventions have been used in more interpretability projects (Hanna, Liu, and Variengien, 2023;\nHeimersheim and Janiak, 2023; Wang et al., 2023), so we prefer it. However we also compare all our\nexperiments to replacing activations with zeros (Section 4.2, Appendix E.2).\n\n\n\n2.4  Explaining the circuit components\n\nAfter successfully isolating a subgraph, one has found a circuit (Section 1). The researcher then can\nformulate and test hypotheses about the functions implemented by each node in the subgraph. There\nis early evidence that ACDC is helpful for making novel observations about how language models\ncomplete tasks, such as the importance of surprising token positions that help GPT-2 Small predict\ncorrectly gendered pronouns (Appendix K). In our work we focus on automating the time-consuming\nstep 3 that precedes functional interpretation of internal model components, though we think that\nautomating the functional interpretation of model components is an exciting further research direction.\n\n\n                                       4\n\n                               I                                                                       I                                                                       I\n\n\n\n\n           B                          B                          B\n\n   A                C         A                C         A                C\n\n\n          O                        O                        O\n\n(a) Choose computational graph,     (b) At each head, prune unimpor-      (c) Recurse until the full circuit is\ntask, and threshold τ.                  tant connections.                     recovered.\n\nFigure 2: How ACDC works (Steps 2a-2c). Step 2a: a practitioner specifies a computational graph\nof the model, the task they want to investigate, and a threshold under which to remove connections.\nStep 2b: ACDC iterates over nodes in the computational graph, replacing activations of connections\nbetween a node and its children, and measuring the effect on the output metric. Connections are\nremoved if their measured effect on the metric under corruption is below the threshold τ. Step 2c:\nrecursively apply Step 2b to the remaining nodes. The ACDC procedure returns a subgraph of the\noriginal computational graph.\n\n\n3  Automating circuit discovery (Step 3)\n\nThis section describes algorithms to automate Step 3 of the mechanistic interpretability workflow\n(Section 2.3). In all three cases, we assume that the ‘task’ being studied is defined by a set of prompts\n(xi)ni=1 on which the model’s predictions have a noticeable pattern (see Table 1 for examples) and a\nset of prompts (x′i)ni=1 where this task is not present. We then use the activations of the models on a\nforward pass on the points x′i as corrupted activations (Section 2.3).\n\nAutomatic Circuit DisCovery (ACDC).   Informally, a run of ACDC iterates from outputs to inputs\nthrough the computational graph, starting at the output node, to build a subgraph. At every node it\nattempts to remove as many edges that enter this node as possible, without reducing the model’s\nperformance on a selected metric. Finally, once all nodes are iterated over, the algorithm (when\nsuccessful) finds a graph that i) is far sparser than the original graph and ii) recovers good performance\non the task.\n\nTo formalize the ACDC process, we let G be a computational graph of the model of interest, at a\ndesired level of granularity (Section 2.2), with nodes topologically sorted then reversed (so the nodes\nare sorted from output to input). Let H ⊆G be the computational subgraph that is iteratively pruned,\nand τ > 0 a threshold that determines the sparsity of the final state of H.\nWe now define how we evaluate a subgraph H. We let H(xi, x′i) be the result of the model when\nxi is the input to the network, but we overwrite all edges in G that are not present in H to their\nactivation on x′i (the corrupted input).4 This defines H(xi, x′i), the output probability distribution\nof the subgraph under such an experiment. Finally we evaluate H by computing the KL divergence\nDKL(G(xi)||H(xi, x′i)) between the model and the subgraph’s predictions. We let DKL(G||H)\ndenote the average KL divergence over a set of datapoints. Appendix C discusses alternatives to the\nKL divergence, and Appendix E.1 explores the consequences of optimizing the task-specific metrics\nfrom Table 1 instead.\n\nAlgorithm 1 describes ACDC. The order in which we iterate over the parents w of v is a hyperparame-\nter. In our experiments the order is lexicographically from later-layer MLPs and heads to earlier-layer\nMLPs and heads, and from higher- to lower-indexed heads. We note that in one case in our work, the\norder of the parents affected experimental results (Appendix J).\n\nSubnetwork Probing (SP; Cao, Sanh, and Rush, 2021).  SP learns a mask over the internal model\ncomponents (such as attention heads and MLPs), using an objective that combines accuracy and\n\n   4To implement the computation of H(xi, x′i), we initially run a forward pass with the unmodified model on\nthe input x′i and cache all activations.\n\n\n                                       5\n\n  Algorithm 1: The ACDC algorithm.\n   Data: Computational graph G, dataset (xi)ni=1, corrupted datapoints (x′i)ni=1 and threshold\n         τ > 0.\n   Result: Subgraph H ⊆G.\n 1 H ←G                    // Initialize H to the full computational graph\n 2 H ←H.reverse_topological_sort()                   // Sort H so output first\n 3 for v ∈H do\n 4     for w parent of v do\n 5      Hnew ←H \\ {w →v}             // Temporarily remove candidate edge\n 6           if DKL(G||Hnew) −DKL(G||H) < τ then\n 7      H ←Hnew             // Edge is unimportant, remove permanently\n 8       end\n 9    end\n10 end\n11 return H\n\n\n\n   sparsity (Louizos, Welling, and Kingma, 2018), with a regularization parameter λ. At the end of\n   training, we round the mask to 0 or 1 for each entry, so the masked computation corresponds exactly\n   to a subnetwork of a transformer. SP aims to retain enough information that a linear probe can still\n   extract linguistic information from the model’s hidden states. In order to use it to automate circuit\n   discovery, we make three modifications. We i) remove the linear probe, ii) change the training metric\n   to KL divergence as in Section 2, and iii) use the mask to interpolate between corrupted activations\n  and clean activations (Section 3) rather than zero activations and clean activations. Appendix D.1\n   explains the details of these changes.\n\n\n  Head Importance Score for Pruning (HISP; Michel, Levy, and Neubig, 2019).  HISP ranks the\n   heads by importance scores (Appendix D.2) and prunes all the heads except those with the top k\n   scores. Keeping only the top k heads corresponds to a subnetwork that we can compare to ACDC.\n  We plot the ROC obtained from the full possible range of k. Like SP, this method only considers\n   replacing head activations with zero activations, and therefore we once more generalize it to replace\n   heads and other model components with corrupted activations (for details, see Appendix D.2).\n\n\n  4  Evaluating Subgraph Recovery Algorithms\n\n\n  To compare methods for identifying circuits, we seek empirical answers to the following questions.\n\n           • Q1: Does the method identify the subgraph corresponding to the underlying algorithm\n          implemented by the neural network?\n           • Q2: Does the method avoid including components which do not participate in the elicited\n           behavior?\n\n  We attempt to measure Q1 and Q2 using two kinds of imperfect metrics: some grounded in previous\n  work (Section 4.1), and some that correspond to stand-alone properties of the model and discovered\n   subgraph (Section 4.2).\n\n\n   4.1  Grounded in previous work: area under ROC curves\n\n  The receiver operating characteristic (ROC) curve is useful because a high true-positive rate (TPR)\n  and a low false-positive rate (FPR) conceptually correspond to affirming Q1 and Q2, respectively.\n\n  We consider canonical circuits taken from previous works which found an end-to-end circuit explain-\n   ing behavior for tasks in Table 1. We formulate circuit discovery as a binary classification problem,\n  where edges are classified as positive (in the circuit) or negative (not in the circuit). Appendices F, G,\n  H, I and J describe and depict the canonical circuits for each task. Appendix E.3 considers the node\n   classification problem instead, which is less appropriate for ACDC but more appropriate for other\n   methods.\n\n\n                                          6\n\n                                  IOI                                 tracr-reverse             tracr-xproportion\n                        1         1   1                                                                                                                             HISP\n\n                                                                                                                         SP\n                                              0.5                 0.5                           ACDC\n(edges)   0.75                   0         0\nrate                                                  0        0.5      1    0        0.5      1\n      0.5\n                                                                   Docstring              Greater-Thanpositive                       1         1\nTrue   0.25\n                                              0.5                 0.5\n\n   0                        0         0\n          0        0.25       0.5       0.75       1     0        0.5      1    0        0.5      1\n\n                                                False positive rate (edges)\n\n\nFigure 3: ROC curves of ACDC, SP and HISP identifying model components from previous work,\nacross 5 circuits in transformers. The points on the plot are cases where SP and ACDC return\nsubgraphs that are not on the Pareto frontier. The corresponding AUCs are in Table 2.\n\n\nWe sweep over a range of ACDC thresholds τ, SP regularization parameters λ, or number of HISP\nelements pruned k. We plot pessimistic segments between points on the Pareto frontier of TPR and\nFPR, over this range of thresholds (Fawcett, 2006). ACDC and SP optimize the KL divergence for\ntasks where this makes sense (all but tracr tasks, which use the L2 distance). All methods employ\nactivations with corrupted data. Appendix C describes and Appendix E experiments with different\ndesign choices for the metric and activation patching methodology.\n\nFigure 3 shows the results of studying how well existing methods recover circuits in transformers.\nWe find that i) methods are very sensitive to the corrupted distribution, ii) ACDC has competitive\nperformance (as measured by AUC) with gradient-descent based methods iii) ACDC is not robust,\nand it fails at some settings.\n\nSeveral of the tasks appeared to require specific distributions and metrics for the areas under the\ncurves to be large. For example, ACDC achieved poor performance on both tracr tasks in Fig. 3, but\nthe circuit was perfectly recovered by ACDC at any threshold τ > 0 when patching activations with\nzeros (Appendix I). Furthermore, ACDC achieves a greater AUC on the IOI and Greater-Than and\ntracr-reverse tasks than both of the other methods, and hence overall is the optimal algorithm. As an\nexample of the variable performance of circuit recovery algorithms, on the Docstring task we achieve\nthe high perfomance when using the ACDC algorithm with the docstring metric (Appendix H).\nHowever in other tasks such as the IOI task, ACDC performance was worse when optimizing for\nlogit difference.\n\nFurther research in automated interpretability will likely yield further improvements to the FPR and\nTPR of circuit discovery. We outline limitations with all current methods, but also gesture at likely\nfundamental limitations of the false positive and true positive measures. A limitation with all existing\nmethods is that they optimize a single metric. This means they systematically miss internal model\ncomponents such as the “negative” components found in previous work (IOI, Docstring) that are\nactively harmful for performance. The IOI recovery runs were not able to recover negative heads\nwhen optimizing for logit difference. Even when optimizing for low KL divergence, the negative\ncomponents were only recovered when very small thresholds were used (Figure 15).\n\nAdditionally, a more fundamental limitation to measuring the false and true positive rates of circuit\nrecovery methods is that the ground-truth circuits are reported by practitioners and are likely to have\nincluded extraneous edges and miss more important edges. The language model circuits studied in\nour work (Appendices F-H) involve a large number of edges (1041 in the case of IOI) and the full\nmodels contain more than an order of magnitude more edges. Since these interpretability works are\ncarried out by humans who often report limitations of their understanding, our ‘ground-truth’ is not\n100% reliable, limiting the strength of the conclusions that can be drawn from the experiments in this\nsection.\n\n\n                                       7\n\n                     a) Induction (zero)                         b) Induction (corrupted)\n    15                        15                                                                        HISP\n\n    10                        10                                                           ACDCablated)                                                                                                                      SP\n                                                                                                                                                          Clean\n\n                                                                                                                                                                        Baseline\n   5                5KL(model,\n\n   0                0\n\n     1 2 5 10 20  50  100  200     1 2 5 10 20  50  100  200\n                                           Number of edges\n\nFigure 4: Comparison of ACDC and SP with both zero-input activations (left) and corrupted activa-\ntions (right). We plot the KL Divergence on a held-out test set against the number of edges of each\nhypothesized circuit. Lower KL divergence and fewer edges correspond to better subgraphs. Darker\npoints include more edges in the hypothesis: they use smaller ACDC τ, smaller SP regularization λ\nor a higher percentage of nodes in HISP.\n\n\n\n4.2  Stand-alone circuit properties with a test metric\n\nThis section evaluates the algorithms by studying the induction task. We measure the KL Divergence\nof the circuits recovered with the three methods to the original model. This is an indirect measure of\nQ1, with the advantage of not relying on the completeness or correctness of previous works. As an\nindicator of Q2, we also measure the number of edges that a hypothesized circuit contains. A circuit\nwith fewer edges which still obtains a low KL Divergence is less likely to contain components that do\nnot participate in the behavior. In Appendix L we also introduce and explain experiments on reset\nnetworks that provide more evidence for Q2.\n\nOur mainline experimental setup is to run the circuit recovery algorithms as described in Algorithm 1\nand Section 3 and then measure the KL Divergence for these circuits on the induction task (Ap-\npendix J). In brief, ACDC performs better that the other methods under these experimental conditions\nwith both corrupted and zero activations. For example, the left-hand side of Figure 4 shows that,\nabove 20 edges, ACDC starts having a slight advantage over other methods in terms of behavior\nrecovered per number of edges as all points on the Pareto-frontier with at least this many edges\nare generated from ACDC runs. Appendix E describes many further experiments with variations\non setup to provide a more complete picture of the performance of the circuit recovery algorithms.\nFor example, when we measure the loss (the task-specific induction metric; Table 1) of subgraphs\nrecovered by optimizing KL Divergence, we find very similar qualitative graphs to Figure 4.\n\nIn Appendix L we see that the KL divergence that all methods achieve is significantly lower for\nthe trained networks, indicating that all the methods get signal from the neural network’s ability\nto perform induction (Figure 4). HISP and SP with zero activations, and to some extent SP with\ncorrupted activations are also able to optimize the reset network. This suggests that these methods\nare somewhat more prone to finding circuits that don’t exist (i.e. evidence against Q2).\n\n\n5  Related work\n\n\nMechanistic interpretability encompasses understanding features learnt by machine learning mod-\nels (Olah, Mordvintsev, and Schubert, 2017; Elhage et al., 2022), mathematical frameworks for\nunderstanding machine learning architetures (Elhage et al., 2021) and efforts to find circuits in models\n(Nanda et al., 2023; Cammarata et al., 2021; Chughtai, Chan, and Nanda, 2023; Wang et al., 2023).\nThe higher standard of a mechanistic understanding of a model has already had applications to design-\ning better architectures (Fu et al., 2023), though the speculative goal of mechanistic interpretability is\nto understand the behavior of whole models, perhaps through describing all their circuits and how\nthey compose. Little work has been done to automate interpretability besides Bills et al. (2023) who\nuse language models to label neurons in language models.\n\n\n                                       8\n\nNeural network pruning masks the weights of neural networks to make their connectivity more\nsparse (LeCun, Denker, and Solla, 1989). In contrast to our aims, the pruning literature is typically\nconcerned with compressing neural networks for faster inference or to reduce storage requirements\n(Wang, Wohlwend, and Lei, 2020; Kurtic et al., 2022). Early work (Hassibi and Stork, 1992) hoped\npruning would lead to more interpretable networks, but progress towards interpretability via pruning\nis limited (Grover, Gawri, and Manku, 2022).\n\nPruning techniques may learn masks from data, which is a special case of more generally using\ngradient information. Masks can also be learned from data, with an objective function that balances\nmodel performance and network sparsity (Louizos, Welling, and Kingma, 2018; Wang, Wohlwend,\nand Lei, 2020; Cao, Sanh, and Rush, 2021). This is a useful comparison to ACDC as learnable\nmasks do not change the weights of our model after pruning (Frantar and Alistarh, 2023). Examples\nof gradient information being used more generally includes Michel, Levy, and Neubig (2019)\nwho decide which heads should be pruned by using the absolute value of their gradients, while\n“movement pruning” (Sanh, Wolf, and Rush, 2020) removes parameters that have high velocity to a\nlow magnitude. ACDC is different from pruning and other compression techniques (Zhu et al., 2023)\nsince i) the compressed networks we find are reflective of the circuits that model’s use to compute\noutputs to certain tasks (Section 4) and ii) our goal is not to speed up forward passes, and generally\nour techniques slow forwards passes.\n\nCausal interpretation. Much prior research on understanding language models has drawn inspiration\nfrom causal inference (Pearl, 2009), leading to the development of frameworks that provide causal\nexplanations for model outputs (Pearl, 2009; Feder et al., 2021; Geiger et al., 2021; Wu et al., 2022;\nKaddour et al., 2022). Other work (Vig et al., 2020) discusses the difference between indirect effects\nand direct effects inside language models, and experiments on removing subsets of these heads using\nheads’ direct effects as proxies for the overall contribution of these heads. Goldowsky-Dill et al.\n(2023) introduce ‘path patching’ to analyze the effects of different subsets of edges in computational\ngraphs of models. In parallel to our work, Wu et al. (2023) develop a method to automatically test\nwhether neural networks implement certain algorithms with causal testing. Our work is focused on\nfinding rather than verifying an outline of an algorithm implemented by a model.\n\nComputational subgraphs for interpretability. Training dynamics in residual models can be\nexplained by shallow paths through the computational graph (Veit, Wilber, and Belongie, 2016). MLP\nlayers can be modelled as memory that is able to represent certain properties of the network inputs\n(Geva et al., 2021). Residual transformer models have been modelled as the sum of all different paths\nthrough the network (Elhage et al., 2021). Later work has used insights from looking at subgraphs of\nmodels in order to edit models’ behaviors (Bau et al., 2020; Meng et al., 2022) and test interpretability\nhypotheses (Chan et al., 2022).\n\n\n6  Conclusion\n\nWe have identified a common workflow for mechanistic interpretability. First, pin down a behavior\nusing a metric and data set. Second, conduct activation patching experiments to understand which\nabstract units (e.g. transformer heads) are involved in the behavior. Third, iterate the previous steps\nwith variations of the behavior under study, until the model’s algorithm is understood.\n\nThe main proposed algorithm, ACDC, systematically conducts all the activation patching experiments\nnecessary to find which circuit composed of abstract units is responsible for the behavior. We have\nshown that ACDC and SP recover most of the compositional circuit that implements a language\nmodel behavior, as judged by comparison to previous mechanistic interpretability work (Section 4).\nACDC with zero activations fully recovers the circuit of toy models (Fig. 9). Further, there is early\nevidence of the use of ACDC to help with novel interpretability work, discovering a surprising\noutline of a subgraph of GPT-2 Small that predicts gendered pronoun completion (Appendix K).\nHere, practitioners used ACDC to generate a subgraph including the most important pathway through\na model’s computation, and checked that this reflects the model’s computation in normal (unablated)\nforward passes. This surprising find was an early example of the summarization motif (Tigges et al.,\n2023).\n\nHowever, both ACDC and SP have limitations which prevent them from fully automating step 3 of\nthe identified workflow (activation patching). First, they tend to miss some classes of abstract units\nthat are part of the circuit, for example the negative name mover heads from IOI (Wang et al., 2023).\n\n\n                                        9\n\nSecond, the behavior of the algorithms is very sensitive to hyperparameter and metric choice, leading\nto varied and non-robust performance in some settings (Figure 3).\n\nOn balance, the evidence supports the claim that ACDC can automate part of interpretability work, a\nnovel contribution. Automating interpretability research may be necessary to be able to scale methods\nto the behaviors of the large models which are in use today. We hope that our open-source imple-\nmentation of ACDC (https://github.com/ArthurConmy/Automatic-Circuit-Discovery)\naccelerates interpretability research from the community. For example, future work could systematize\nand automate the problem of varying the corrupting dataset to understand the functionality of different\nparts of the circuit.\n\n7  Acknowledgements\n\nThis work would not have been possible without the generous support of Redwood Research through\ntheir REMIX program. We would like to thank Chris Mathwin, Jett Janiak, Chris MacLeod, Neel\nNanda, Alexandre Variengien, Joseph Miller, Thomas Kwa, Sydney von Arx, Stephen Casper and\nAdam Gleave for feedback on a draft of this paper. Arthur Conmy would like to thank Jacob Steinhardt,\nAlexandre Variengien and Buck Shlegeris for extremely helpful conversations that shaped ACDC.\nWe would also like to thank Haoxing Du for working on an early tool, Nate Thomas for coming\nup with the catchy name, Daniel Ziegler who discussed experiments that inspired our Subnetwork\nProbing analysis, Oliver Hayman who worked on an earlier prototype during REMIX and Lawrence\nChan who helped us frame our contributions and suggested several experiments. Finally we thank\nHofvarpnir Studios, FAR AI and Conjecture for providing compute for this project.\n\nReferences\n\nAlishahi, Afra, Grzegorz Chrupała, and Tal Linzen (2019). “Analyzing and interpreting neural net-\n  works for NLP: A report on the first BlackboxNLP workshop”. In: Natural Language Engineering\n   25.4, pp. 543–557. DOI: 10.1017/S135132491900024X.\nBau, David, Steven Liu, Tongzhou Wang, Jun-Yan Zhu, and Antonio Torralba (2020). Rewriting a\n  Deep Generative Model. URL: https://arxiv.org/abs/2007.15646.\nBills, Steven, Nick Cammarata, Dan Mossing, Henk Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever,\n  Jan Leike, Jeff Wu, and William Saunders (2023). Language models can explain neurons in\n  language models. https://openaipublic.blob.core.windows.net/neuron-explainer/\n  paper/index.html.\nBrundage, Miles, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan\n  Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, et al. (2018). “The malicious use of artificial\n   intelligence: Forecasting, prevention, and mitigation”. In: arXiv preprint arXiv:1802.07228.\nBuhrmester, Vanessa, David Münch, and Michael Arens (2021). “Analysis of Explainers of Black Box\n  Deep Neural Networks for Computer Vision: A Survey”. In: 3.4, pp. 966–989. ISSN: 2504-4990.\n  DOI: 10.3390/make3040048. URL: https://www.mdpi.com/2504-4990/3/4/48.\nCammarata, Nick, Gabriel Goh, Shan Carter, Chelsea Voss, Ludwig Schubert, and Chris Olah (2021).\n  “Curve Circuits”. In: Distill. https://distill.pub/2020/circuits/curve-circuits. DOI: 10 . 23915 /\n  distill.00024.006.\nCao, Steven, Victor Sanh, and Alexander Rush (2021). “Low-Complexity Probing via Finding\n  Subnetworks”. In: Proceedings of the 2021 Conference of the North American Chapter of the\n  Association for Computational Linguistics: Human Language Technologies. Online: Association\n   for Computational Linguistics, pp. 960–966. DOI: 10.18653/v1/2021.naacl-main.74. URL:\n  https://aclanthology.org/2021.naacl-main.74.\nChan, Lawrence, Adria Garriga-Alonso, Nix Goldowsky-Dill, Ryan Greenblatt, Jenny Nitishin-\n  skaya, Ansh Radhakrishnan, Buck Shlegeris, and Nate Thomas (2022). Causal scrubbing: A\n  method for rigorously testing interpretability hypotheses. Alignment Forum. URL: https://www.\n  alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-\n  rigorously-testing.\nChughtai, Bilal, Lawrence Chan, and Neel Nanda (2023). A Toy Model of Universality: Reverse\n  Engineering How Networks Learn Group Operations. URL: https://arxiv.org/abs/2302.\n  03025.\nCuadros, Xavier Suau, Luca Zappella, and Nicholas Apostoloff (2022). “Self-conditioning pre-trained\n  language models”. In: International Conference on Machine Learning. PMLR, pp. 4455–4473.\n\n\n                                       10\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova (2019). “BERT: Pre-training\n  of Deep Bidirectional Transformers for Language Understanding”. In: Proceedings of the 2019\n  Conference of the North American Chapter of the Association for Computational Linguistics:\n  Human Language Technologies, Volume 1 (Long and Short Papers). Minneapolis, Minnesota:\n  Association for Computational Linguistics, pp. 4171–4186. DOI: 10.18653/v1/N19-1423. URL:\n  https://aclanthology.org/N19-1423.\nElhage, Nelson, Tristan Hume, Catherine Olsson, Nicholas Schiefer, Tom Henighan, Shauna Kravec,\n  Zac Hatfield-Dodds, Robert Lasenby, Dawn Drain, Carol Chen, et al. (2022). “Toy Models of\n  Superposition”. In: arXiv preprint arXiv:2209.10652.\nElhage, Nelson, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda\n  Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Deep Ganguli, Zac\n  Hatfield-Dodds, Danny Hernandez, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse,\n  Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah (2021).\n “A Mathematical Framework for Transformer Circuits”. In: Transformer Circuits Thread. URL:\n  https://transformer-circuits.pub/2021/framework/index.html.\nFawcett, Tom (2006). “An introduction to ROC analysis”. In: Pattern Recognition Letters 27.8.\n ROC Analysis in Pattern Recognition, pp. 861–874. ISSN: 0167-8655. DOI: https://doi.org/\n  10.1016/j.patrec.2005.10.010. URL: https://www.sciencedirect.com/science/\n  article/pii/S016786550500303X.\nFeder, Amir, Nadav Oved, Uri Shalit, and Roi Reichart (2021). “CausaLM: Causal Model Explanation\n  Through Counterfactual Language Models”. In: Computational Linguistics 47.2, pp. 333–386. DOI:\n  10.1162/coli_a_00404. URL: https://aclanthology.org/2021.cl-2.13.\nFong, Ruth C. and Andrea Vedaldi (2017). “Interpretable Explanations of Black Boxes by Meaningful\n  Perturbation”. In: IEEE International Conference on Computer Vision, ICCV 2017, Venice, Italy,\n  October 22-29, 2017. IEEE Computer Society, pp. 3449–3457. DOI: 10.1109/ICCV.2017.371.\n  URL: https://doi.org/10.1109/ICCV.2017.371.\nFrantar, Elias and Dan Alistarh (2023). SparseGPT: Massive Language Models Can Be Accurately\n  Pruned in One-Shot.\nFu, Daniel Y, Tri Dao, Khaled Kamal Saab, Armin W Thomas, Atri Rudra, and Christopher Re\n  (2023). “Hungry Hungry Hippos: Towards Language Modeling with State Space Models”. In: The\n  Eleventh International Conference on Learning Representations. URL: https://openreview.\n  net/forum?id=COZDy0WYGg.\nGeiger, Atticus, Hanson Lu, Thomas Icard, and Christopher Potts (2021). Causal Abstractions of\n  Neural Networks. URL: https://arxiv.org/abs/2106.02997.\nGeva, Mor, Roei Schuster, Jonathan Berant, and Omer Levy (2021). “Transformer Feed-Forward\n  Layers Are Key-Value Memories”. In: Proceedings of the 2021 Conference on Empirical Methods\n   in Natural Language Processing. Online and Punta Cana, Dominican Republic: Association for\n  Computational Linguistics, pp. 5484–5495. DOI: 10.18653/v1/2021.emnlp-main.446. URL:\n  https://aclanthology.org/2021.emnlp-main.446.\nGokaslan, Aaron, Vanya Cohen, Ellie Pavlick, and Stefanie Tellex (2019). OpenWebText Corpus.\n  URL: https://Skylion007.github.io/OpenWebTextCorpus.\nGoldowsky-Dill, Nicholas, Chris MacLeod, Lucas Sato, and Aryaman Arora (2023). Localizing\n  Model Behavior with Path Patching. arXiv: 2304.05969 [cs.LG].\nGrover, Jasdeep Singh, Bhavesh Gawri, and Ruskin Raj Manku (2022). “DeepCuts: Single-Shot\n   Interpretability based Pruning for BERT”. In.\nGurnee, Wes, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, and Dimitris Bertsi-\n  mas (2023). Finding Neurons in a Haystack: Case Studies with Sparse Probing. arXiv: 2305.01610\n  [cs.LG].\nHanna, Michael, Ollie Liu, and Alexandre Variengien (2023). How does GPT-2 compute greater-\n  than?: Interpreting mathematical abilities in a pre-trained language model. arXiv: 2305.00586\n  [cs.CL].\nHassibi, Babak and David Stork (1992). “Second order derivatives for network pruning: Optimal\n  brain surgeon”. In: 5.\nHeimersheim, Stefan and Jett Janiak (2023). A circuit for Python docstrings in a 4-layer attention-only\n  transformer. URL: https://www.alignmentforum.org/posts/u6KXXmKFbXfWzoAXn/a-\n  circuit-for-python-docstrings-in-a-4-layer-attention-only.\nHendrycks, Dan and Mantas Mazeika (2022). X-Risk Analysis for AI Research. arXiv: 2206.05862\n  [cs.CY].\n\n\n\n\n                                       11\n\nHendrycks, Dan, Mantas Mazeika, and Thomas Woodside (2023). An Overview of Catastrophic AI\n  Risks. arXiv: 2306.12001 [cs.CY].\nHernandez, Evan, Sarah Schwettmann, David Bau, Teona Bagashvili, Antonio Torralba, and Jacob\n  Andreas (2022). Natural Language Descriptions of Deep Visual Features. arXiv: 2201.11114\n  [cs.CV].\nHubinger, Evan (2020). An overview of 11 proposals for building safe advanced AI. arXiv: 2012.\n  07532 [cs.LG].\nJacovi, Alon and Yoav Goldberg (2020). “Towards Faithfully Interpretable NLP Systems: How\n  Should We Define and Evaluate Faithfulness?” In: Proceedings of the 58th Annual Meeting of the\n  Association for Computational Linguistics. Online: Association for Computational Linguistics,\n  pp. 4198–4205. DOI: 10.18653/v1/2020.acl-main.386. URL: https://aclanthology.\n  org/2020.acl-main.386.\nJang, Eric, Shixiang Gu, and Ben Poole (2017). Categorical Reparameterization with Gumbel-\n  Softmax. arXiv: 1611.01144 [stat.ML].\nKaddour, Jean, Aengus Lynch, Qi Liu, Matt J. Kusner, and Ricardo Silva (2022). Causal Machine\n  Learning: A Survey and Open Problems. URL: https://arxiv.org/abs/2206.15475.\nKaplan, Jared, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott\n  Gray, Alec Radford, Jeffrey Wu, and Dario Amodei (2020). Scaling Laws for Neural Language\n  Models. arXiv: 2001.08361 [cs.LG].\nKurtic, Eldar, Daniel Campos, Tuan Nguyen, Elias Frantar, Mark Kurtz, Benjamin Fineran, Michael\n  Goin, and Dan Alistarh (2022). “The optimal BERT surgeon: Scalable and accurate second-order\n  pruning for large language models”. In.\nLeCun, Yann, John Denker, and Sara Solla (1989). “Optimal brain damage”. In: 2.\nLindner, David, János Kramár, Matthew Rahtz, Thomas McGrath, and Vladimir Mikulik (2023).\n  “Tracr: Compiled Transformers as a Laboratory for Interpretability”. In.\nLipton, Zachary C. (2016). The Mythos of Model Interpretability. URL: https://arxiv.org/abs/\n  1606.03490.\nLouizos, Christos, Max Welling, and Diederik P. Kingma (2018). “Learning Sparse Neural Networks\n  through L_0 Regularization”. In: 6th International Conference on Learning Representations,\n  ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings.\n  OpenReview.net. URL: https://openreview.net/forum?id=H1Y8hhg0b.\nMathwin, Chris, Guillaume Corlouer, Esben Kran, Fazl Barez, and Neel Nanda (2023). Identifying\n  a Preliminary Circuit for Predicting Gendered Pronouns in GPT-2 Small. URL: https://itch.\n  io/jam/mechint/rate/1889871.\nMcDougall, Callum, Arthur Conmy, Cody Rushing, Thomas McGrath, and Neel Nanda (2023). Copy\n  Suppression: Comprehensively Understanding an Attention Head. arXiv: 2310.04625 [cs.LG].\nMeng, Kevin, David Bau, Alex J Andonian, and Yonatan Belinkov (2022). “Locating and editing\n   factual associations in GPT”. In: Advances in Neural Information Processing Systems.\nMichel, Paul, Omer Levy, and Graham Neubig (2019). “Are Sixteen Heads Really Better than\n  One?” In: Advances in Neural Information Processing Systems 32: Annual Conference on Neural\n  Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,\n  Canada. Ed. by Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc,\n  Emily B. Fox, and Roman Garnett, pp. 14014–14024. URL: https://proceedings.neurips.\n  cc/paper/2019/hash/2c601ad9d2ff9bc8b282670cdd54f69f-Abstract.html.\nMu, Jesse and Jacob Andreas (2021). Compositional Explanations of Neurons. arXiv: 2006.14032\n  [cs.LG].\nNanda, Neel (2022). TransformerLens. URL: https : / / github . com / neelnanda - io /\n  TransformerLens.\n– (2023). Attribution Patching: Activation Patching At Industrial Scale. URL: https://www.\n  neelnanda.io/mechanistic-interpretability/attribution-patching.\nNanda, Neel, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt (2023). “Progress\n  measures for grokking via mechanistic interpretability”. In: The Eleventh International Conference\n  on Learning Representations. URL: https://openreview.net/forum?id=9XFSbDPmdW.\nOlah, Chris (2022). Mechanistic Interpretability, Variables, and the Importance of Interpretable\n  Bases. https://www.transformer-circuits.pub/2022/mech-interp-essay.\nOlah, Chris, Alexander Mordvintsev, and Ludwig Schubert (2017). “Feature Visualization”. In: Distill.\n   https://distill.pub/2017/feature-visualization. DOI: 10.23915/distill.00007.\nOlsson, Catherine, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan,\n  Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, et al. (2022). In-context learning and induction\n\n\n\n                                       12\n\n  heads. URL: https://transformer-circuits.pub/2022/in-context-learning-and-\n  induction-heads/index.html.\nOpenAI (2023). GPT-4 Technical Report. arXiv: 2303.08774 [cs.CL].\nPearl, Judea (2009). Causality. Models, Reasoning, and Inference. 2nd ed. Cambridge University\n   Press. ISBN: 978-0-521-89560-6. DOI: 10.1017/CBO9780511803161.\nRadford, Alec, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever (2019).\n  “Language Models are Unsupervised Multitask Learners”. In.\nRamanujan, Vivek, Mitchell Wortsman, Aniruddha Kembhavi, Ali Farhadi, and Mohammad Raste-\n   gari (2020). “What’s Hidden in a Randomly Weighted Neural Network?” In: 2020 IEEE/CVF\n  Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June\n  13-19, 2020. IEEE, pp. 11890–11899. DOI: 10.1109/CVPR42600.2020.01191. URL: https:\n  //doi.org/10.1109/CVPR42600.2020.01191.\nRäuker, Tilman, Anson Ho, Stephen Casper, and Dylan Hadfield-Menell (2022). Toward Transparent\n  AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. URL: https://arxiv.\n  org/abs/2207.13243.\nSanh, Victor, Thomas Wolf, and Alexander M. Rush (2020). “Movement Pruning: Adaptive Sparsity\n  by Fine-Tuning”. In: Advances in Neural Information Processing Systems 33: Annual Confer-\n  ence on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,\n   virtual. Ed. by Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan,\n  and Hsuan-Tien Lin. URL: https : / / proceedings . neurips . cc / paper / 2020 / hash /\n  eae15aabaa768ae4a5993a8a4f4fa6e4-Abstract.html.\nSyed, Aaquib, Can Rager, and Arthur Conmy (2023). Attribution Patching Outperforms Automated\n  Circuit Discovery. arXiv: 2310.10348 [cs.LG].\nTigges, Curt, Oskar John Hollinsworth, Atticus Geiger, and Neel Nanda (2023). Linear Representa-\n   tions of Sentiment in Large Language Models. arXiv: 2310.15154 [cs.LG].\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\n  Lukasz Kaiser, and Illia Polosukhin (2017). “Attention is All you Need”. In: Advances in Neu-\n   ral Information Processing Systems 30: Annual Conference on Neural Information Processing\n  Systems 2017, December 4-9, 2017, Long Beach, CA, USA. Ed. by Isabelle Guyon, Ulrike von\n  Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman\n  Garnett, pp. 5998–6008. URL: https://proceedings.neurips.cc/paper/2017/hash/\n  3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.\nVeit, Andreas, Michael J. Wilber, and Serge J. Belongie (2016). “Residual Networks Behave Like\n  Ensembles of Relatively Shallow Networks”. In: Advances in Neural Information Processing\n  Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10,\n  2016, Barcelona, Spain. Ed. by Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle\n  Guyon, and Roman Garnett, pp. 550–558. URL: https://proceedings.neurips.cc/paper/\n  2016/hash/37bc2f75bf1bcfe8450a1a41c200364c-Abstract.html.\nVig, Jesse, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Simas Sakenis,\n  Jason Huang, Yaron Singer, and Stuart Shieber (2020). Causal Mediation Analysis for Interpreting\n  Neural NLP: The Case of Gender Bias. URL: https://arxiv.org/abs/2004.12265.\nWang, Kevin Ro, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt (2023).\n  “Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small”. In: The\n  Eleventh International Conference on Learning Representations. URL: https://openreview.\n  net/forum?id=NpsVSN6o4ul.\nWang, Ziheng, Jeremy Wohlwend, and Tao Lei (2020). “Structured Pruning of Large Language\n  Models”. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP). Online: Association for Computational Linguistics, pp. 6151–6162. DOI:\n  10.18653/v1/2020.emnlp-main.496. URL: https://aclanthology.org/2020.emnlp-\n  main.496.\nWei, Jason, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\n  Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals,\n  Percy Liang, Jeff Dean, and William Fedus (2022). Emergent Abilities of Large Language Models.\n  arXiv: 2206.07682 [cs.CL].\nWu, Zhengxuan, Atticus Geiger, Christopher Potts, and Noah D. Goodman (2023). Interpretability at\n  Scale: Identifying Causal Mechanisms in Alpaca. arXiv: 2305.08809 [cs.CL].\nWu, Zhengxuan, Atticus Geiger, Joshua Rozner, Elisa Kreiss, Hanson Lu, Thomas Icard, Christopher\n   Potts, and Noah Goodman (2022). “Causal Distillation for Language Models”. In: Proceedings\n   of the 2022 Conference of the North American Chapter of the Association for Computational\n\n\n\n                                       13\n\n   Linguistics: Human Language Technologies. Seattle, United States: Association for Computational\n   Linguistics, pp. 4288–4295. DOI: 10 . 18653 / v1 / 2022 . naacl - main . 318. URL: https :\n  //aclanthology.org/2022.naacl-main.318.\nZhang, Kelly and Samuel Bowman (2018). “Language Modeling Teaches You More than Translation\n  Does: Lessons Learned Through Auxiliary Syntactic Task Analysis”. In: Proceedings of the 2018\n EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. Brussels,\n  Belgium: Association for Computational Linguistics, pp. 359–361. DOI: 10.18653/v1/W18-5448.\n  URL: https://aclanthology.org/W18-5448.\nZhang, Yu, Peter Tiˇno, Aleš Leonardis, and Ke Tang (2021). “A survey on neural network inter-\n   pretability”. In: 5.5, pp. 726–742. DOI: 10.1109/TETCI.2021.3100641.\nZhu, Xunyu, Jian Li, Yong Liu, Can Ma, and Weiping Wang (2023). A Survey on Model Compression\n   for Large Language Models. arXiv: 2308.07633 [cs.CL].\n\n\n\n\n\n                                       14\n\nAppendix\n\n\n\nA  Table of contents\n\n\n\n1  Introduction                                                                 1\n\n\n2  The Mechanistic Interpretability Workflow                                       2\n\n    2.1  Step 1: Select a behavior, dataset, and metric    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    3\n\n    2.2  Step 2: Divide the neural network into a graph of smaller units   .  .  .  .  .  .  .  .  .  .  .    3\n\n    2.3  Step 3: Patch model activations to isolate the relevant subgraph  .  .  .  .  .  .  .  .  .  .  .    4\n\n    2.4  Explaining the circuit components   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    4\n\n\n3  Automating circuit discovery (Step 3)                                            5\n\n\n4  Evaluating Subgraph Recovery Algorithms                                       6\n\n    4.1  Grounded in previous work: area under ROC curves .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    6\n\n    4.2  Stand-alone circuit properties with a test metric   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .    8\n\n\n5  Related work                                                                8\n\n\n6  Conclusion                                                                  9\n\n\n7  Acknowledgements                                                          10\n\n\nA  Table of contents                                                            15\n\n\nB  Impact statement                                                            16\n\n\nC  Discussion of metrics optimized                                                17\n\n   C.1  Changing the metric in ACDC   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   17\n\n   C.2  Limitations of logit difference    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   17\n\n   C.3  Alternatives to minimizing a metric    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   18\n\n\nD  Details of Subnetwork Probing and Head Importance Score for Pruning             19\n\n   D.1  Subnetwork Probing    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   19\n\n   D.2  Head Importance Score for Pruning    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   19\n\n\nE  Experimental study of algorithm design                                         20\n\n   E.1  Minimizing the task-specific metric, rather than the KL divergence  .  .  .  .  .  .  .  .  .   21\n\n   E.2  Activation patching with zeros, instead of corrupted input  .  .  .  .  .  .  .  .  .  .  .  .  .  .   21\n\n   E.3  Node-level ROC curve, rather than edge-level ROC curve  .  .  .  .  .  .  .  .  .  .  .  .  .  .   23\n\n\nF  IOI task: details and qualitative evidence                                       23\n\n\n                                       15\n\n    F.1   Further details on the IOI experiments   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   23\n\n    F.2  The IOI circuit    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   24\n\n    F.3   Limitations of ACDC in recovering the IOI circuit .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   25\n\n\nG Greater-Than task: details and qualitative evidence                               26\n\n\nH  Docstring task: details and qualitative evidence                                  27\n\n   H.1  The docstring circuit    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   27\n\n   H.2  Additional docstring experiments .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   29\n\n\nI  Tracr tasks: details and qualitative evidence                                     30\n\n    I.1   tracr-xproportion   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30\n\n    I.2   tracr-reverse  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30\n\n\nJ  Induction task: details and qualitative evidence                                  31\n\n\nK Gendered pronoun completion: qualitative evidence                              32\n\n\nL  Reset Network Experiments                                                   32\n\n\nM Automated Circuit Discovery and OR gates                                      34\n\n\nN  Connection to Causal Scrubbing                                               35\n\n\nB  Impact statement\n\n\nACDC was developed to automate the circuit discovery step of mechanistic interpretability studies.\nThe primary social impact of this work, if successful, is that neural networks will become more\ninterpretable. ACDC could make neural networks more interpretable via i) removing uninterpretable\nand insignificant components of models (as we reviewed in Section 4.2), ii) assisting practitioners to\nfind subgraphs and form hypotheses for their semantic roles in models (as we found early evidence\nfor in Appendix K) and more speculatively iii) enabling research that finds more interpretable\narchitectures. More generally, better interpretability may allow us to predict emergent properties of\nmodels (Nanda et al., 2023), understand and control out-of-distribution behavior (Mu and Andreas,\n2021) and identify and fix model errors (Hernandez et al., 2022).\n\nHowever it is also possible that the biggest impact of better interpretability techniques will be more\ncapable AI systems or possible misuse risk (Brundage et al., 2018). For example, while interpreting\nneural networks has the steer models towards model bias or other harmful effects (Cuadros, Zappella,\nand Apostoloff, 2022), bad actors could also use interpretability tools to do the opposite: reverse\nengineering neural networks to steer towards harmful behaviors.\n\nFor now, ACDC is a tool for researchers and isn’t mature enough for applications where determining\nthe exact behaviour of a model is societally important. However, the benefits of the adoption of better\ntransparency appear to us to outweigh the externalities of potential negative outcomes (Hendrycks\nand Mazeika, 2022), as for example transparency plays an important role in both specific (Hubinger,\n2020) and portfolio-based (Hendrycks, Mazeika, and Woodside, 2023) approaches to ensuring the\nsafe development of AI systems.\n\n\n                                       16\n\nC  Discussion of metrics optimized\n\nIn this appendix, we discuss the considerations and experiments that support the formulation of\nACDC that we presented in Section 3. We also discuss the metrics and experimental setups for\nSubnetwork Probing (Appendix D.1) and Head Importance Score for Pruning (Appendix D.2).\n\nIn the main text we presented ACDC as an algorithm that minimizes the KL divergence DKL(G||H)\nbetween the model and the subgraphs of the model (Section 3 and Algorithm 1). However, prior\nmechanistic interpretability projects have reported performance on several different metrics at once\n(Wang et al., 2023; Nanda et al., 2023). In this Appendix we discuss our findings choosing different\nmetrics in different ways. We explore the advantages and limitations with Algorithm 1 and other\napproaches. In particular, we have found that optimizing for low KL divergence is the simplest and\nmost robust metric to optimize across different tasks. However, general conclusions about the best\nmethods to use cannot be made because of variability across different tasks, and the large space of\ndesign choices practitioners can make.\n\nWe found that optimizing for low KL divergence was fairly effective across all tasks we considered,\nexcept the Docstring task (Appendix F-J). For example, we were able to exclusively recover heads\nthat are present in the IOI circuit (Figure 1) that have 3 layers of composition sufficient to solve the\ntask, with zero false positives . Additionally, KL divergence can be applied to any task of next-token\nprediction as it doesn’t specify any labels associated with outputs (such as logit difference requiring\nspecifying which tokens we calculate logit difference between).\n\n\nC.1  Changing the metric in ACDC\n\nWe consider generalizations of ACDC in order to further evaluate our patching-based circuit-finding\napproach. The only line of Algorithm 1 that we will modify is Line 6, the condition\n\n\n                       DKL(G||Hnew) −DKL(G||H) < τ                              (1)\n\nfor the removal of an edge. All modifications to ACDC discussed in this Appendix replace Condition\n(1) with a new condition and do not change any other part of Algorithm 1.\n\nIn full generality we let F be a metric that maps subgraphs to reals. We assume throughout this\nAppendix that subgraphs H, such that F(H) is smaller, correspond to subgraphs that implement the\ntask to a greater extent (i.e we minimize F).5\n\nIn practice, we can be more specific about the form that the metric F will always take. We assume\nthat we can always calculate F(H(xi, x′i)), the element-wise result of the metric on individual dataset\nexamples and use F(H) to refer to the metric averaged across the entire dataset (note the similarity\nof this setup to our calculation of DKL in Section 3). The general update rule takes the form\n\n\n                        F(H) −F(Hnew) < τ.                                    (2)\n\nwhich generalizes Equation 1. We discuss further extensions that change Line 6 of the ACDC\nalgorithm in Appendix C.3.\n\n\nC.2  Limitations of logit difference\n\nThe IOI (Appendix F), Docstring (Appendix H) and Gendered Pronoun Identification work (Ap-\npendix K) originally used a variant of logit difference to measure the performance of subgraphs. Logit\ndifference is the difference in logits for a correct output compared to a baseline incorrect output.\nThen, these works compare the change from the logit difference of the model to the logit difference\nof their circuit. However, unlike KL divergence, this metric is not always positive — logit difference\nfor a circuit could be larger or smaller than the logit difference of the model, and so the change\nin logit difference could be positive or negative. We discuss issues that arise with this approach\n\n   5The logit difference and probability difference metrics used by the IOI, Greater-Than and Docstring tasks\nwere intended to be maximised by the respective researchers (Table 1) so we consider negated versions of these\nmetrics.\n\n\n                                       17\n\nin Appendix C.3, the empirical performance decrease when using logit difference can be found in\nFigure 5.\n\nC.3  Alternatives to minimizing a metric\n\nTwo alternatives to minimizing a metric are to 1) match the model’s performance on a metric, or\n2) only include edges that cause a small change in performance. These could be formalised by\nthe following alternatives to Condition 1, where F denotes any metric we could compute from a\nsubgraph:\n\n      1. Matching the model’s performance: |F(Hnew) −F(G)| −|F(H) −F(G)| < τ.\n      2. Only including small changes in performance: |F(Hnew) −F(H)| < τ.\n\nMatching the model’s performance (also referred to as faithfulness by Wang et al. (2023)). Since\nKL divergence is always positive, Alternative 1 is identical to Condition 1 when F  is the KL\ndivergence between a subgraph’s outputs and the models’ outputs, but for metrics such as logit\ndifference this represents a new optimization objective. Empirically we found that matching the\nmodel’s performance was unstable when we ran ACDC. For example, we ran a modified early version\nof ACDC that maximized the logit difference in the IOI circuit, and found that through one ACDC\nrun, logit difference of a subgraph could be as large as 5.0 and as low as 1.5 during a modified ACDC\nrun. The IOI circuit has a logit difference of 3.55, and therefore the subgraph’s logit difference can\nbe both larger and smaller than the model’s logit difference. This issue arises when the subgraph’s\nlogit difference is larger than the model’s. In such cases, ACDC will discard model components that\nit would otherwise include when the subgraph’s logit difference is smaller than the model’s. This\nleads to inconsistencies between runs and further dependence on the order over which parents are\niterated (Section 3).\n\n\n\n                                                                                    Abs Logit DIff\n\n             1\n\n                                                                           (edges)   0.75\n                                           rate\n                                                                                      positive    0.5\n                                           True   0.25\n\n\n             0\n                                   0                              0.25                              0.5                             0.75                          1\n\n                                                                                                                                      False positive rate (edges)\n\n\n\n                                                                                                                   Logit DIff\n\n              1\n\n                                                                                (edges)   0.75\n                                              rate\n                                                                                           positive    0.5\n                                              True   0.25\n\n\n              0\n                                    0                              0.25                              0.5                             0.75                          1\n\n                                                                                                                                        False positive rate (edges)\n\n\n\n                                                                                    KL\n\n              1\n\n                                                                                 (edges)   0.75\n                                              rate\n                                                                                             positive    0.5\n                                              True   0.25\n\n\n              0\n                                     0                              0.25                              0.5                             0.75                          1\n\n                                                                                                                                        False positive rate (edges)\n\n        Figure 5: ROC curves on IOI using Abs Logit Diff, Logit Diff and KL Divergence\n\nOnly including small changes in performance. Alternative 2 ignores the value of the metric for\nthe base model and instead focuses on how much the metric changes at each step that ACDC takes.\n\n\n                                       18\n\nHowever, we found that this was much less effective than KL divergence and even worse than using\nlogit difference on the IOI task (Figure 5), when we used random ablations and recorded ROC curves.\n\nOverall, we found that KL divergence was the least flawed of all metrics we tried in this project, and\nthink more practitioners should use it given i) the problems with other metrics listed, and ii) how\nempirically it can recover several circuits that were found by researchers using other metrics.\n\nD  Details of Subnetwork Probing and Head Importance Score for Pruning\n\nD.1  Subnetwork Probing\n\nThere are 3 modifications we made to Subnetwork Probing (Cao, Sanh, and Rush, 2021, SP) in our\nwork. In this Appendix we provide techincal detail and motivation for these modifications:\n\n      1. We do not train a probe. ACDC does not use a probe. Cao, Sanh, and Rush (2021) train\n        a linear probe after learning a mask for every component. The component mask can be\n        optimized without the probe, so we just omit the linear probing step.\n      2. We change the objective of the SP process to match ACDC’s. ACDC uses a task-specific\n         metric, or the KL divergence to the model’s outputs (Algorithm 1). In order to compare\n         the techniques in equivalent settings we use the same metric (be it KL divergence or task-\n          specific) in SP. Cao, Sanh, and Rush (2021) use negative log probability loss.\n      3. We generalize the masking technique so we can replace activations with both zero\n         activations and corrupted activations. Replacing activations with zero activations6 is\n         useful for pruning (as they improve the efficiency of networks) but are not as commonly\n        used in mechanisitic interpretability (Goldowsky-Dill et al., 2023), so we adapt SP to use\n         corrupted activations. SP learns a mask Z and then sets the weights ϕ of the neural network\n         equal to ϕ ∗Z (elementwise multiplication), and locks the attention mask to be binary at the\n       end of optimization (Jang, Gu, and Poole, 2017). This means that outputs from attention\n        heads and MLPs in models are scaled closer to 0 as mask weights are decreased. To allow\n        comparison with ACDC, we can linearly interpolate between a clean activation when the\n       mask weight is 1 and a corrupted activation (i.e a component’s output on the datapoint x′i,\n         in the notation of Section 3) when the mask weight is 0. We do this by editing activations\n         rather than weights of the model.\n\nAdditionally, we used a constant learning rate rather than the learning rate scheduling used in Cao,\nSanh, and Rush (2021).\n\nThe regularization coefficients λ (in the notation of Cao, Sanh, and Rush (2021)) we used in Figure 4\nwere 0.01, 0.0158, 0.0251, 0.0398, 0.0631, 0.1, 0.158, 0.251, 0.398, 0.631, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n30, 50, 70, 90, 110, 130, 150, 170, 190, 210, 230, 250.\n\nThe number of edges for subgraphs found with Subnetwork Probing are computed by counting the\nnumber of edges between pairs of unmasked nodes.\n\nD.2  Head Importance Score for Pruning\n\nIn Section 4-4.2 we compared ACDC with the Head Importance Score for Pruning (Michel, Levy,\nand Neubig, 2019, HISP). We borrow the author’s notation throughout this section, (particularly from\nSection 4.1) and adapt it so that this Appendix can be read after Section 2.\n\nThe authors use masking parameters ξh for all heads, i.e scaling the output of each attention head by\nξh, similar to the approach in Subnetwork Probing (Appendix D.1), so that each head Atth’s output\nis ξhAtth(xi) on an input xi. The authors keep MLPs present in all networks that they prune. We\ngeneralize their method so that it can be used for any component inside a network for which we can\ntake gradients with respect to its output.\n\nThe authors define head importance as\n\n\n                          n               n\n                       1     ∂L(xi)    1              ∂L(xi)\n                   Ih := X      = X Atth(xi)T                  .                   (3)\n                   n      ∂ξh    n              ∂Atth(xi)                            i=1               i=1\n\n   6Which is generally equivalent to setting weight parameters equal to 0.\n\n\n                                       19\n\n                        (a) Corrupted activations                                  (b) Zero activations\n\nFigure 6: Examples of subgraphs recovered by ACDC on the induction task with different types of\nactivations and threshold τ = 0.5623. These find the two different induction heads (1.5, 1.6) and a\nprevious token head (0.0) as identified by Goldowsky-Dill et al. (2023). (a) shows the result with\ncorrupted activations, while (b) shows the result with zero activations.\n\n\nwhere the equivalence of expressions is the result of the chain rule. We make three changes to this\nsetup to allow more direct comparison to ACDC: i) we use a metric rather than loss, ii) we consider\ncorrupted activations rather than just zero activations and iii) we use the ‘head importance’ metric for\nmore internal components than merely attention head outputs.\n\nSince our work uses in general uses a metric F rather than loss Appendix C, we instead use the\nderivative of F rather than the derivative of the loss. The HISP authors only consider interpolation\nbetween clean and zero activations, so in order to compare with corrupted activations, we can\ngeneralize ξh to be the interpolation factor between the clean head output Atth(x) (when ξh = 1)\nand the corrupted head output Atth(x′) (when ξh = 0). Finally, this same approach works for any\ninternal differentiable component of the neural network.7 Therefore we study the HISP applied to the\nquery, key and value vectors of the model and the MLPs outputs.\n\nIn practice, this means that we compute component importance scores\n\n\n                                n\n                             1                    ∂F(xi)\n                      IC := X (C(xi) −C(x′i))T              .                          (4)\n                        n                   ∂C(xi)                                   i=1\n\nWhere C(xi) is the output of an internal component C of the transformer, which is equivalent to\n‘attribution patching’ (Nanda, 2023) up to the absolute value sign.\n\nTo compute the importance for zero activations, we adjust Equation (4) so it just has a C(xi) term,\nwithout the −Ch(x′i) term. We also normalize all scores for different layers as in Michel, Levy, and\nNeubig (2019). The identical setup to Equation (4) works for outputs of the query, key and value\ncalculations for a given head, as well as the MLP output of a layer. In Section 4 we use query, key\nand value components for each head within the network, as well as the output of all MLPs.\n\nThe number of edges for subgraphs found with HISP is also computed by counting the number of\nedges between pairs of unmasked nodes, like Subnetwork Probing (Appendix D.1).\n\nE  Experimental study of algorithm design\n\nThis section evaluates design choices for ACDC and SP, by re-doing the experiments in Section 4.\nWe explore two axes of variation.\n\n    7In theory. In practice, components need be torch.nn.Modules such that we can calculate the gradient of\nF with respect to the components’ outputs.\n\n\n                                       20\n\n        Table 2: AUCs for corrupted activations, Random Ablation. (E)=Edge, (N)=Node.\n  Metric        Task      ACDC(E)  HISP(E)   SP(E)  ACDC(N)  HISP(N)  SP(N)\n\n              Docstring        0.982      0.805    0.937     0.950      0.881    0.928\n KL        Greaterthan       0.853      0.693    0.806     0.890      0.642    0.827\n                IOI           0.869      0.789    0.823     0.880      0.668    0.842\n\n              Docstring        0.972      0.821    0.942     0.938      0.889    0.941\n             Greaterthan       0.461      0.706    0.812     0.766      0.631    0.811\n  Loss          IOI           0.589      0.836    0.707     0.777      0.728    0.797\n           Tracr-Proportion     0.679      0.679    0.525     0.750      0.909    0.818\n            Tracr-Reverse      0.200      0.577    0.193     0.312      0.750    0.375\n\n\n         Table 3: AUCs for corrupted activations, Zero Ablation. (E)=Edge, (N)=Node.\n  Metric        Task      ACDC(E)  HISP(E)   SP(E)  ACDC(N)  HISP(N)  SP(N)\n\n              Docstring        0.906      0.805    0.428     0.837      0.881    0.420\n KL        Greaterthan       0.701      0.693    0.163     0.887      0.642    0.134\n                IOI           0.539      0.792    0.486     0.458      0.671    0.605\n\n              Docstring        0.929      0.821    0.482     0.825      0.889    0.398\n             Greaterthan       0.491      0.706    0.639     0.783      0.631    0.522\n  Loss          IOI           0.447      0.836    0.393     0.424      0.728    0.479\n           Tracr-Proportion     1.000      0.679    0.829     1.000      0.909    1.000\n            Tracr-Reverse      1.000      0.577    0.801     1.000      0.750    1.000\n\n\n        • Minimizing the task-specific metric, rather than the KL divergence.\n        • Patching activations with zeros, rather than with the result on a corrupted input (interchange\n         intervention).\n        • Looking at node-level TPR and FPR for the ROC curves, rather than edge-level.\n\nThe results paint a mixed picture of whether ACDC or SP is better overall, but reinforce the choices\nwe implicitly made in the main text. A stand-out result is that ACDC with zero-patching is able to\nperfectly detect the tracr circuits (Figs. 9 and 10).\n\nA numerical summary of the results is in Tables 2 and 3, which display the areas under the ROC\ncurve (AUC) for all the design choices we consider.\n\nE.1  Minimizing the task-specific metric, rather than the KL divergence\n\nWe ran ACDC, SP and HISP with the task-specific metric from Table 1, instead of KL divergence.\nThe exact modification is described in Appendix C. The ROC result is in Fig. 7. Compared to\nminimizing KL divergence (Fig. 3), ACDC works better for Docstring, but worse for Greater-Than\nand IOI, indicating that it is not a very robust method.\n\nWe prefer using the KL divergence instead of the task-specific metric, because the task-specific metric\ncan be over-optimized (Appendix C). This means that the recovered circuit ends up performing the\ntask more than the original model, and is thus not accurate. We can observe this effect by comparing\nthe task-specific metric achieved by the methods in Fig. 8.\n\nE.2  Activation patching with zeros, instead of corrupted input\n\nIn the main text experiments that compared using corrupted activations and zero activations (Figure 4),\nall three methods recovered subgraphs with generally lower loss when doing activation patching with\nzeros, in both the experiments with the normal model and with permuted weights. It is unclear why\nthe methods achieve better results with corruptions that are likely to be more destructive. A possible\nexplanation is that there are ‘negative’ components in models (Appendix F.3) that are detrimental\nto the tasks, and the zero activations are more disruptive to these components. A discussion of how\nmethods could be adjusted to deal with this difficulty can be found in Alternative 2 in Appendix C.\n\n\n                                       21\n\n                                  IOI                                 tracr-reverse             tracr-xproportion\n                        1         1   1                                                                                                                             HISP\n\n                                                                                                                         SP\n                                              0.5                 0.5                           ACDC\n(edges)   0.75                   0         0\nrate                                                  0        0.5      1    0        0.5      1\n      0.5\n                                                                   Docstring              Greater-Thanpositive                       1         1\nTrue   0.25\n                                              0.5                 0.5\n\n   0                        0         0\n          0        0.25       0.5       0.75       1     0        0.5      1    0        0.5      1\n\n                                                False positive rate (edges)\n\n\nFigure 7: Edge-wise ROC curves generated by minimizing the task-specific metric in Table 1, rather\nthan KL divergence.\n\n\n\n\n\n                                     IOI                                                           Docstring                                                   Greater-Than\n   0                         6                                                 0.5                                                                                                             HISPHISP (reset)\n\n\n\n                                                                                                                                                                                                                                                     SP                                                                                                                                                                                                                                                                                                                                                                                                                (reset)metric                                                                                                                                                                                                                                                  SP    −5                         4                                                                                                                                                                                                                                       ACDC                                                       0test\n                                                                                                                                                                                                                                       ACDC                                                                                                                                                                                                                                                                                                                                                                                                                   (reset)\n                             2\n     −10\n                             0 Task-specific                                                                                                                   −0.5\n     −15\n                                           −2\n        1        10       100      1000      10k                     2       5   10    2       5   100   2       5  1000   2     −1       10         100        1000        10k\n\n                                                                                              Number of edges\n\nFigure 8: Optimizing the task-specific metric of the subject model, on trained and reset networks. For\neach recovered circuit, we plot its task-specific metric (Table 1) against its number of edges. The\nreset networks metrics don’t change much with the number of edges, which is good. We found that\nfor IOI that extremely large logit differences could be achieved (over 15) but this didn’t happen when\nthe network had a large number of edges.\n\n\n\n\n\n                                 ioi                            greaterthan                         docstring\n\n   1            1            1                                           HISP\n\n                                                                                                                         SP\n(edges)   0.75                                                                                                       ACDC\nrate\npositive    0.5                        0.5                        0.5\nTrue   0.25\n\n\n   0            0            0\n         0    0.25   0.5   0.75   1      0           0.5         1      0           0.5         1\n\n                                                False positive rate (edges)\n\nFigure 9: Edge-wise ROC curves generated by minimizing the KL divergence, but using zero\nactivations.\n\n\n\n\n                                       22\n\n                                  IOI                                 tracr-reverse             tracr-xproportion\n                        1         1   1                                                                                                                             HISP\n\n                                                                                                                         SP\n                                              0.5                 0.5                           ACDC\n(edges)   0.75                   0         0\nrate                                                  0        0.5      1    0        0.5      1\n      0.5\n                                                                   Docstring              Greater-Thanpositive                       1         1\nTrue   0.25\n                                              0.5                 0.5\n\n   0                        0         0\n          0        0.25       0.5       0.75       1     0        0.5      1    0        0.5      1\n\n                                                False positive rate (edges)\n\n\nFigure 10: Edge-wise ROC curves generated by minimizing the task-specific metric in Table 1, using\nzero activations.\n\n\nE.3  Node-level ROC curve, rather than edge-level ROC curve\n\nWe compute the FPR and TPR of classifying whether a node belongs to the circuit. We consider\nthis alternative task because SP and HISP operate at the node-level, whereas ACDC operates at the\nedge-level, so this is fairer to HISP and SP. The results are broadly similar to edge-level ROCs, and\nare described in Figs. 11 and 12 and Tables 2 and 3.\n\n\n                                 ioi                            greaterthan                         docstring\n\n   1            1            1                                           HISP\n\n                                                                                                                         SP\n(nodes)   0.75                                                                                                       ACDC\nrate\npositive    0.5                        0.5                        0.5\nTrue   0.25\n\n\n   0            0            0\n         0    0.25   0.5   0.75   1      0           0.5         1      0           0.5         1\n\n                                                False positive rate (nodes)\n\n   Figure 11: Node-level ROC when optimizing the KL divergence, with corrupted activations.\n\n\nF  IOI task: details and qualitative evidence\n\nF.1  Further details on the IOI experiments\n\nIn the ACDC run in Figure 1, we used a threshold of τ = 0.0575. We also removed all edges\nwhich did not lie on a directed path from the input (which is equivalent in computation since we\nuse corrupted activations). Our library now only supports splitting query, key and input, rather than\nmerely looking at the connections between heads. Additionally, For ease of visualization, in the\ndiagram on the left of Figure 1 we removed all edges between grey nodes more than 2 layers apart,\nand 90% of the edges between grey and red nodes.\n\nOur IOI experiments were conducted with a dataset of N = 50 text examples from one template\nthe IOI paper used (‘ When John and Mary went to the store, Mary gave a bottle of milk to’). The\n\n\n                                       23\n\n                                  IOI                                 tracr-reverse             tracr-xproportion\n                        1         1   1                                                                                                                             HISP\n\n                                                                                                                         SP\n                                              0.5                 0.5                           ACDC\n(nodes)   0.75                   0         0\nrate                                                  0        0.5      1    0        0.5      1\n      0.5\n                                                                   Docstring              Greater-Thanpositive                       1         1\nTrue   0.25\n                                              0.5                 0.5\n\n   0                        0         0\n          0        0.25       0.5       0.75       1     0        0.5      1    0        0.5      1\n\n                                                False positive rate (nodes)\n\n\nFigure 12: Node-level ROC when optimizing the task-specific metric in Table 1, with corrupted\nactivations.\n\n\n\n\n\nFigure 13: The IOI circuit (Figure 2 from Wang et al. (2023)). We include edges between all pairs\nof heads connected here, through the Q or the K+V as indicated. We also include all connections\nbetween MLPs and these heads, the inputs and outputs. See https://github.com/ArthurConmy/\nAutomatic-Circuit-Discovery/blob/main/acdc/ioi/utils.py#L205. The full circuit is\nin Fig. 14.\n\n\n\ncorrupted dataset was examples from the ABC dataset (Wang et al., 2023) — for example ‘When\nAlice and Bob went to the store, Charlie gave a bottle of milk to’.\n\nIn the IOI experiment in Figure 1, we did not split the computational graph into the query, key and\nvalue calculations for each head. This enabled the ACDC run to complete in 8 minutes on an NVIDIA\nA100 GPU. However, the larger experiments that kept >10% of the edges of the original edges in the\ncomputational graph sometimes took several hours. On one hand we don’t expect these cases to be\nvery important for circuit discovery, but they make up the majority of the points of the pareto frontier\nof curves in this paper.\n\n\nF.2  The IOI circuit\n\nWang et al. (2023) find a circuit ‘in the wild’ in GPT-2 small (Radford et al., 2019). The circuit\nidentifies indirect objects (see for example Table 1) by using several classes of attention heads. In this\nsubsection we analyze how successful ACDC’s circuit recovery (Figure 1) is. All nine heads found in\nFigure 1 belong to the IOI circuit, which is a subset of 26 heads out of a total of 144 heads in GPT-2\nsmall. Additionally, these 9 heads include heads from three different classes (Previous Token Heads,\n\n\n                                       24\n\n                                                                           embed\n\n\n                                                       <a0.1_v>     <a0.10>\n\n                                            <a3.0_v>   <a0.10_q>       <a0.1_q>                                             <a4.11>\n                                                                                                               <a2.2_v>\n                                                         <a3.0_k>    <a0.10_v>\n                                  <a0.1>                                                                                                                           <a4.11_q>   <a2.2_q>\n                                                                                                           <a2.2>\n                                               <a3.0>       <a3.0_q>            <a5.5_v>       <a6.9_k>                   <a4.11_k>\n                                                                                                              <a6.9_q>                            <a4.11_v>\n                                        <a0.10_k>\n                                                                     <a5.9_v>                <a5.8_q>                                 <a2.2_k>                                                     <a0.1_k>\n                                                                                                         <a5.8>\n                            <a8.10_k>                                 <a5.5>                <a5.9>                <a5.5_q>\n                                         <a8.10_q>\n                 <a7.3_v>\n                                                           <m0>   <m1>\n          <a8.6_v>               <a7.9>     <a7.3_q>        <m10>                                     <a6.9_v>    <a6.9>\n                     <a7.9_q>                                       <m2>\n                                            <m11>\n                                                       <m3>\n       <a7.3>\n                               <a8.10_v>   <a8.10>         <m6>          <m4>               <a5.9_k>          <a5.8_v>                  <a8.6>\n                           <a8.6_k>         <a7.9_v>           <m5>   <m8>        <a5.8_k>   <a5.5_k>   <a5.9_q>\n               <a7.9_k>\n                                                   <m9>        <m7>        <a9.0>    <a10.1_k>   <a9.7_v>\n\n                           <a7.3_k>    <a8.6_q>    <a11.2_q>\n                                                                     <a10.10_v>               <a11.9_k>   <a9.7_k>    <a9.0_k>              <a9.9_v>     <a10.0>\n\n\n                      <a10.7_v>                                                           <a11.2_v>                                                                                                                     <a10.1_q>   <a9.6_v>   <a10.0_q>                                                                                       <a11.9_v>\n                                   <a11.10>                                                                                                                                                         <a9.9_q>                                                                           <a9.0_v>\n       <a10.7>                                              <a11.2_k>                                                                                                                          <a10.1>\n                                                                                             <a10.6>\n                 <a11.10_q>    <a10.7_q>                                                                                                      <a10.10_q>                                                           <a10.6_q>                                                                                                                                      <a9.9>\n                                               <a10.2_v>\n                                                                                                                                               <a9.6>   <a9.6_k>    <a10.0_v>                                                                                 <a9.7>                                                                                                                   <a11.9_q>\n                                                                    <a9.7_q>             <a11.10_k>\n                                       <a11.10_v>      <a10.10>\n                                                                                             <a10.1_v>\n                                                                                                                                                               <a9.6_q>                                                                                                                <a10.6_v>               <a10.0_k>\n                                                                           <a11.9>                           <a10.7_k>                                                                                                                                                     <a9.9_k>\n                                                                                      <a10.2_k>                <a11.2>\n                                                          <a10.6_k>     <a10.2>                   <a10.2_q>\n\n\n                                                                         <a10.10_k>    <a9.0_q>\n\n\n\n                                                                                        <resid_post>\n\n\nFigure 14: Our low-level implementation of the IOI circuit (Wang et al., 2023), in terms of heads\nsplit by query, key, value; and MLPs. It has 1041 edges. For edge between groups A, B in Fig. 13,\nwe connect each member of group A with each member of group B. The colors of groups in this\nfigure correspond to the group colors in Fig. 13.\n\n\n\nS-Inhibition Heads and Name Mover Heads) and are sufficient to complete the IOI task, showing that\nACDC indeed can recover circuits rather than just subgraphs.\n\nFor our ROC plots, we considered the computational graph of IOI described in Figure 13.\n\nThe ground-truth circuit gets a logit difference of 3.24 compared to the model’s 4.11 logit difference.\nIt has a KL divergence of 0.44 from the original model.\n\n\n\nF.3  Limitations of ACDC in recovering the IOI circuit\n\nThe main figure from the paper Figure 1 shares several features with circuits recovered with similar\nthresholds, even when logit difference rather than KL divergence is minimized. The figure does\nnot include heads from all the head classes that Wang et al. (2023) found, as it does not include\nthe Negative Name Mover Heads or the Previous Token Heads. In Figure 15 we run ACDC with a\nlower threshold and find that it does recover Previous Token Heads and Negative Name Mover Heads,\nbut also many other heads not documented in the IOI paper. This is a case where KL divergence\nperforms better than logit difference maximisation (which does not find Negative Name Movers at any\nthreshold), but still is far from optimal (many extraneous heads are found). Ideally automated circuit\ndiscovery algorithms would find negative components even at higher thresholds, and hence we invite\nfuture empirical and theoretical work to understand negative components and build interpretability\nalgorithms capable of finding negative components. An early case study gaining wide understanding\nof a negative head in GPT-2 Small can be found in McDougall et al. (2023).\n\n\n                                       25\n\nFigure 15: A subset of the 443/32923 edges of GPT-2 Small that ACDC recovered when optimizing\nfor KL divergence at threshold τ = 0.00398. This subset includes edges between Negative Heads\n(10.7 and 11.10). A number of heads not found by the IOI work (9.2 and 11.11 for example) were\nalso found.\n\n\n\n\n\n(a) The ground-truth circuit from Hanna, Liu, and Variengien (2023,           (b) Sample Greater-Than graph re-\nFigure 13).                                                           covered by ACDC\n\n  Figure 16: The ground-truth Greater-Than circuit (16a) and a circuit that ACDC recovers (16b).\n\n\nG  Greater-Than task: details and qualitative evidence\n\n\nWe use a random sample of 100 datapoints from the dataset provided by Hanna, Liu, and Variengien\n(2023).\n\nWe use the circuit from Figure 13 from their paper, including connections between MLPs that are\nin the same group (e.g MLPs 8, 9, 10 and 11) but not including connections connections between\nattention heads in the same group. We also include all Q and K and V connections between attention\nheads present. Their circuit includes all earlier layer connections to the queries of the mid-layer\nattention heads that cause a logit spike (Figure 16a). This would account for more than half of the\nedges in the circuit were we to include all such edges that compute these query vectors, and hence we\ncompromised by just adding all early layer MLPs as connections to these query vectors. Full details\non the circuit can be found in our codebase8 and in Fig. 17. This circuit gets a probability difference\nscore of 72% on a subset of their dataset for which GPT-2 Small had an 84% probability difference\nand a KL divergence from the original model of 0.078.\n\n\n   8https://github.com/ArthurConmy/Automatic-Circuit-Discovery/blob/main/acdc/\ngreaterthan/utils.py#L231\n\n\n                                       26\n\n                                                   embed\n\n\n                                                                    <a0.5_k>                <a0.3_k>\n                                           <a0.1_k>\n\n                                                              <a0.3_q>   <a0.3_v>   <a0.5_q>    <a0.5_v>                                  <a0.1_q>         <a0.1_v>\n\n                                            <a0.1>                       <a0.3>             <a0.5>\n\n                                            <a5.5_k>          <a6.9_q>                 <m2>\n\n                                                                 <m0>\n                               <a6.1_k>   <a6.9>    <a6.9_k>        <a8.11>                <m1>\n\n                                                                     <m3>\n                              <a5.5>                        <a7.10_v>    <a6.1_v>\n                                       <a9.1_q>                                       <m6>\n\n                                                   <a9.1>             <a5.5_q>     <m4>                            <a6.9_v>\n                                                                                  <m5>\n\n                                       <a6.1_q>             <a6.1>       <a7.10>   <m10>\n                                                                           <m7>\n                           <a8.11_k>\n                                             <a8.11_v>                <a7.10_q>\n                                                          <a9.1_k>             <m8>      <m9>                               <a8.11_q>\n\n                                                                       <a9.1_v>       <m11>\n                                               <a5.5_v>    <a7.10_k>\n\n\n                                                                          <resid_post>\n\n\n\nFigure 17: Our low-level implementation of the Greater-Than circuit (Hanna, Liu, and Variengien,\n2023), in terms of heads split by query, key, value; and MLPs. It has 262 edges. For edge between\ngroups A, B in Fig. 16a, we connect each member of group A with each member of group B.\n\n\nAn example subgraph ACDC recovered, including a path through MLP 0, mid-layer attention heads\nand late-layer MLPs, is shown in Figure 16b. This run used the Greater-Than probability difference\nmetric and a threshold of 0.01585 and recovered the results in the abstract.\n\n\nH  Docstring task: details and qualitative evidence\n\nH.1  The docstring circuit\n\nHeimersheim and Janiak (2023) find a circuit in a small language model that is responsible for\ncompleting Python docstrings. The model is a 4-layer attention-only transformer model, trained on\nnatural language and Python code. This circuit controls which variable name the model predicts in\neach docstring line, e.g for the prompt in Table 1 it chooses shape over the other variable names\nfiles, obj, state, size, or option.\n\nThe circuit is specified on the level of attention heads, consisting of 8 main heads (0.2, 0.4, 0.5,\n1.4, 2.0, 3.0, and 3.6) that compose over four layers, although it only makes use of three levels of\ncomposition. It consists of 37 edges between inputs, output, and the attention heads, as we show in\nFigure 18a. We discuss below why we exclude 0.2 and 0.4.\n\nWe apply the ACDC algorithm (Section 2) to this dataset, using the prompts from Heimersheim and\nJaniak (2023) found in their accompanying Colab notebook.9 For our corrupted dataset we use their\nrandom_random dataset which randomizes both the variable names in the function definition as well\nas in the docstring of prompts.\n\nACDC generates the subgraph shown in Figure 18b. We now compare this to the original 8-head\ncircuit from Heimersheim and Janiak (2023), which was the most specific circuit evaluated in that\nwork. We refer to this circuit as the ‘manual’ circuit to distinguish it from the ground truth, which\n\n    9Available at https://colab.research.google.com/drive/17CoA1yARaWHvV14zQGcI3ISz1bIRZKS5\nas of 8th April 2023\n\n\n                                       27\n\n                                      embed\n\n\n\n\n                                                <a0.5_v>\n\n\n\n\n                                                 <a0.5>\n\n\n\n\n       <a3.6_v>     <a1.4_v>     <a2.0_q>     <a2.0_k>     <a1.2_k>     <a1.2_q>     <a3.0_v>\n\n\n\n\n                        <a1.4>\n\n\n\n\n                <a3.6_q>          <a2.0_v>\n\n\n\n\n                          <a3.0_q>          <a2.0>      <a1.2>\n\n\n\n\n                                        <a3.6_k>     <a3.0_k>\n\n\n\n\n                          <a3.6>        <a3.0>\n\n\n\n\n                                <resid_post>\n\n\n       (a) Canonical Docstring circuit (37 edges)            (b) ACDC circuit (KL-divergence, τ = 0.095)\n\nFigure 18: Our implementation of the Docstring circuit (Heimersheim and Janiak, 2023), compared\nto an ACDC-generated circuit.\n\n\n                    Full  ACDC KL  ACDC KL  ACDC LD   Manual     Ground-\n                model   τ = 0.005    τ = 0.095    τ = 0.067   8 heads, all    truth circuit\n     Metric                                 (Fig. 18b)     (Fig. 19)    connections    (Fig. 18a)\n\n  KL-divergence     0        0.33          1.2          0.67         0.83           1.1\n Mean logit diff.    0.48       0.58          -1.7         0.32         -0.62          -1.6\n  Num. of edges   1377      258         34         98         464         37\n\nTable 4: Comparing our ACDC docstring results to the ground-truth from Heimersheim and Janiak\n(2023) using their metrics. We compare (from left to right) the full model, the subgraph from ACDC\nruns optimizing for KL divergence (τ = 0.005 and 0.095) and logit difference (τ = 0.067), as\nwell as the two subgraphs made manually from Heimersheim and Janiak (2023): One including all\nconnections between the given attention heads, and one using only the given circuit. The metrics\nused are KL divergence between full-circuit outputs and resamble-ablated output (lower is better),\nmean logit difference between correct and wrong completions (higher is better), and the number of\nedges in the circuit (lower is better).\n\n\n\n\nincludes the edge connections that the authors speculated were most important but did not evaluate\ndue to a lack of software for edge-editing. We find (a) overlapping heads, (b) heads found by ACDC\nonly, and (c) heads found in the manual interpretation only. In the first class (a) we find heads 0.5, 1.4,\n2.0, 3.0, and 3.6. All these manually identified heads are recovered by ACDC. In class (b) we find\nhead 1.0 which the authors later add to their circuit to improve performance; ACDC shows for the\nfirst time where this head belongs in the circuit. In class (c) we find heads 0.2, 0.4 and 1.2. However,\nthe first two of these are not actually relevant under the docstring distribution and only added by the\nauthors manually. Head 1.2 is considered a non-essential but supporting head by the authors and not\nidentified by ACDC at the chosen threshold of τ = 0.095 (for KL divergence). This might be because\n1.2 is less important than the other heads, and indeed we recover this head in larger subgraphs (such\nas the subgraph in Figure 19).\n\nWe compare the numerical results between the ACDC circuits and the circuit described in Heimer-\nsheim and Janiak (2023) in Table 4. In addition to the τ = 0.095 run (Figure 18b) we perform a run\nwith lower KL divergence threshold of τ = 0.005 recovering a larger circuit (258 edges) containing\nalso head 1.2 that was missing earlier.\n\n\n                                       28\n\nFigure 19: ACDC-found subgraph for docstring task minimizing logit difference (τ = 0.067) instead\nof KL divergence.\n\n\nSince Heimersheim and Janiak (2023) use logit difference as their metric, we add an ACDC run that\noptimizes logit difference rather than KL divergence (see Appendix C for details on this adjustment)\nwith threshold τ = 0.067. This circuit (Figure 19) recovers the relevant manual-interpretation heads\n(including 1.2) as well.10 It is even more specific, containing 93% less edges than the full circuit.\nThis is also 79% less edges than the head-based circuit from Heimersheim and Janiak (2023) while\nachieving a better score on all metrics.\n\nNote that there are two versions of the manual circuit we consider. There is (i) the set of 8 heads\ngiven in Heimersheim and Janiak (2023) that the authors test with a simple methods (not specifying\nedges), and (ii) the circuit of 39 edges as suggested by the authors that they were not able to test\ndue to not having software to implement editable transformer computational graphs in PyTorch. We\nreconstruct this circuit, shown in Figure 18a, from their descriptions and perform tests (Table 4).\n\nIn case (i) the ACDC run (threshold τ = 0.005) achieves better performance in both metrics, Logit\nDifference and KL divergence, while being more specific (258 edges) when compared to the set of\nheads found by Heimersheim and Janiak (2023). In the more specific case (ii) the ACDC run (with\nthreshold τ = 0.095) closely matches the manual interpretation, with a very similar circuit recovered\n(Figure 18). The ACDC run is slightly more specific but has slightly worse KL divergence and Logit\nDifference.\n\nA limitation worth noting is that we applied ACDC to a computational graph of attention heads and\ntheir query, key and value computational nodes, while Heimersheim and Janiak (2023) considered\nthe attention heads outputs into every token position separately. This allowed them to distinguish two\nfunctions fulfilled by the same attention head (layer 1, head 4) at different positions, which cannot\nbe inferred from the output of ACDC alone at any level of abstraction (Section 2.2) we studied in\nthis work. We make this choice for performance reasons (the long sequence length would have made\nthe experiments significantly slower) but this is not a fundamental limitation. In Appendix K we use\nACDC to isolate the effects of individual positions in a different task.\n\nH.2  Additional docstring experiments\n\nLogit difference metric:  To compare ACDC more closely with the docstring work (Heimersheim\nand Janiak, 2023), we added an ACDC run with the objective to maximize the logit difference metric.\nWe used a threshold of τ = 0.067 and found the subgraph shown in Figure 19. We found that ACDC\nperformed better than SP and HISP when using the logit difference metric (Figure 7).\n\nZero activations:  Unlike in the case of induction (Section 4.2), we found that using zero activations\nrather than random (corrupted) activations, lead to far worse results. For example, with τ = 0.067\n\n   10Again, not considering heads 0.2 and 0.4 which are not actually relevant under the docstring distribution.\n\n\n                                       29\n\n(the same threshold that generated Figure 19 except with zero activations) we get a circuit with 177\nedges (Figure 19 has 98), as well as a KL divergence of 3.35 and a logit difference of −2.895. All\nthese metrics are worse than the subgraphs generated with corrupted activations (Table 4).\n\nI  Tracr tasks: details and qualitative evidence\n\nIn this Appendix we discuss the two tracr tasks we studied in Section 4, as well as additional\nexperiments that studied ACDC when applied at a neuron level.\n\nWe used a transformer identical to the one studied in Lindner et al. (2023), and refer to that work for\ndetails on the tracr-xproportion task (called the frac_prevs task in their paper). We also studied the\ntracr-reverse task, described in the tracr Github repository.11\n\nWe make one modification to the traditional ACDC setup. We set the positional embeddings equal to\nrandomized positional embeddings in the corrupted datapoints — otherwise, we don’t recover any of\nthe circuit components that depend only on positional embeddings (and not token embeddings). We\ndescribe the two tasks that we studied in the main text and describe futher results that broke these\ncomputational graphs down into neurons.\n\n\nI.1  tracr-xproportion\n\nWe used the proportion task from the tracr main text, and used as metric the L2 distance between\nthe correct list of proportions and the recovered list of proportions. For the corrupted dataset, we let\n(x′i)ni=1 be a random permuation of (xi)ni=1 with no fixed points.\nWhen we ran ACDC at the neuron level, as shown in Figure 20b, there are no extra nodes present that\nwere not used by this tracr model. In fact, this computational graph visualization produced by ACDC\nis more compact than the complete view of the states of the residual stream which is illustrated in\nFigure 20a (from Lindner et al. (2023)). In this case, the transformer is small enough for a practitioner\nto study each individual state in the forward pass. However, for larger transformers this would be\nintractable, which necessitates the use of different interpretability tools such as ACDC.\n\nSee Fig. 21a for the full circuit (without decomposition into residual stream dimensions).\n\n\n\n\n\n    (a) The magnitude of each layer’s activations. Repro-\n   duced from Lindner et al. (2023) under CC-BY.\n                                                                                 (b) ACDC visualization.\n\nFigure 20: Two visualizations of how a tracr-compiled transformer completes the frac_prevs\ntask. The ACDC circuit is specific to the individual neurons and residual stream components. This is\nmore fine-grained than the ground truth we use throughout the work. This experiment was coded in\nrust_circuit and is not reproducible using the Transformer Lens code yet.\n\n\nI.2  tracr-reverse\n\nTo test ACDC on more than one example of a tracr program, we also used the 3-layer transformer\nthat can reverse lists (the tracr-reverse task). Once more, the outputs of the transformer are not\n\n  11URL: https://github.com/deepmind/tracr, file: README.md\n\n\n                                       30\n\n                                                                                                      <token_embeds>\n\n\n\n\n                                                                                                                           <a0.0_v>\n\n\n\n\n                                                                                            <a3.0_v>                       <a0.0>\n\n\n\n\n                                                                                     <pos_embeds>        <m0>\n              <pos_embeds>     <token_embeds>\n\n\n\n                                                                                       <m1>\n\n                  <a1.0_k>     <a1.0_q>    <m0>\n\n\n                                                                                                 <a3.0_k>    <m2>\n\n\n                                         <a1.0_v>\n\n                                                                                                          <a3.0_q>\n\n\n                                <a1.0>\n                                                                                                  <a3.0>\n\n\n                                <resid_post>                                                     <resid_post>\n\n\n\n    (a) tracr-xproportion canonical circuit (10 edges)        (b) tracr-reverse canonical circuit (15 edges)\n\nFigure 21: The canonical circuits for finding the proportion of ‘x’ in the input and reversing lists.\nACDC recovers these perfectly using zero activations (Table 3 and Figs. 9 and 10).\n\n\ndistributions - in this case they are new lists. We calculate the L2 distance between the one-hot\nvectors for the recovered list and the true reversed list. For the corrupted dataset, we again let (x′i)ni=1\nbe a random permuation of (xi)ni=1 with no fixed points. Again, at the neuron level a perfect graph is\nrecovered, with the minimal components required to reverse lists (Figure 21b).\n\nJ  Induction task: details and qualitative evidence\n\nIn Section 4.2 we use 40 sequences of 300 tokens from a filtered validation set of OpenWebText\n(Gokaslan et al., 2019). We filter the validation examples so that they all contain examples of\ninduction — subsequences of the form “A, B, . . . , A, B”, where A and B are distinct tokens. We\nonly measure KL divergence for the model’s predictions of the second B tokens in all examples of\nthe subsequences A, B, . . . , A, B.\n\nWe use both zero activations and corrupted activations to compare ACDC and the other methods.\nTo use ACDC with zero activations, we apply one change to the procedure described in Section 3:\ninstead of setting activations of edges not present in the subgraph to the activations on a corrupted\ndataset, we set their value equal to 0. We describe how we adapt the methods from Section 4.1 to be\nused with both zero activations and corrupted activations in Appendix D.1 for SP and Appendix D.2\nfor HISP.\n\nOur induction experiments were performed on a 2-layer, 8-head-per-layer attention only transformer\ntrained on OpenWebText (Gokaslan et al., 2019). The model is available in the TransformerLens\n(Nanda, 2022) library.12 We follow Appendix C of Goldowsky-Dill et al. (2023) for the construction\nof the dataset of induction examples.\n\nThe computational graph has a total of 305 edges, and in Figure 4 we only show subgraphs with at\nmost 120 edges.\n\n   12The model can be loaded with transformer_lens.HookedTransformer.from_pretrained(model_name\n= \"redwood_attn_2l\", center_writing_weights = False, center_unembed = False)  (at  least\nfor the repository version of the source code as of 23rd May 2023)\n\n\n                                       31\n\nWhen iterating over the parents of a given node (Line 4 in Algorithm 1), we found that iterating in\nincreasing order of the head index was important to achieve better results in Figure 4. Similar to all\nexperiments in the work, we iterate in decreasing order of layers, so overall we iterate over head 1.0,\n1.1, ... then 1.7, then 0.0, 0.1, ... .\n\nAn example of a circuit found in the process is given in Figure 6.\n\n\nK  Gendered pronoun completion: qualitative evidence\n\n\nMathwin et al. (2023) aim to isolate the subgraph of GPT-2 small responsible for correctly gendered\npronouns in GPT-2 small. They do this by studying prompts such as “So Dave is a really great friend,\nisn’t” which are predicted to finish with “ he”. For that they used ACDC. This presents an example\nof a novel research project based on ACDC. The result of applying the ACDC algorithm (threshold\nτ = 0.05) is shown in Figure 22.\n\nThe computational subgraphs generated by ACDC on the gendered pronoun completion task show\nthat MLP computations are more important than attention head computations in this task than in the\nIOI task (Appendix F.2). Early, middle and late layer MLPs have important roles in the subgraph. For\nexample, MLPs 3 and 5 are the important components at the name position (which must be used to\nidentify the correct gender) as they have multiple incident edges: the MLP 7 at the “ is” position has\nthe most incoming connections of any node in the graph, and the late layer MLPs 10 and 11 have\nthe largest direct effect on the output. MLP 7’s importance at the “ is” position is an example of a\ndiscovery that could not have been made with simpler interpretability tools such as saliency maps.\nThis was early evidence of the summarization motif (Tigges et al., 2023).\n\nACDC’s output shows that the important internal information flow for predicting the correct gender\nhas three steps. Firstly, Layer 0 attention head 0.4 and MLP0 use the name embedding which they\npass (through intermediary MLPs) via key- and value-composition (Elhage et al., 2021) to attention\nheads 4.3 and 6.0. Secondly, heads 4.3 and 6.0 attend to the name position to compose with 0.4 and\nMLP0. Finally, through value-composition with attention heads 6.0 and 4.3 (via MLP7), the outputs\nof 10.9 and 9.7 output the expected gendered completion to the output node. Mathwin et al. (2023)\nthen verified that indeed in a normal forward pass of GPT-2 Small, 0.4 has an attention pattern to\nitself at the name token, attention heads 4.3 and 6.0 attend to the previous name token, and 10.9 and\n9.7 attend to the ‘ is’ token. They also perform path patching experiments on intermediate nodes to\nprovide further evidence of the importance of the pathway through the ‘ is’ token.\n\nWe used the dataset of N = 100 examples from Mathwin et al. (2023) . The corrupted dataset was a\nset of prompts with a similar structure to the sentence “That person is a really great friend, isn’t”,\nfollowing the authors’ approach.\n\nWe defined a computational graph that featured nodes at the specificity of attention heads split by\nquery, key and value vectors, and further split by token position (where the tokens are present in the\nnodes in Figure 22). From the input sentence ‘So Sarah is a really nice person, isn’t’, we chose to\nadd nodes representing the model internal operations at the tokens “ Sarah”, “ is”, “ person”, “ isn”\nand “’t”, while other positions were grouped together as in Mathwin et al. (2023) . The resulting\nsubgraph can be found in Figure 22.\n\n\nL  Reset Network Experiments\n\nOur reset network experiment setup is motivated by the concern that interpretability explanations\nmay not accurately represent the reasoning process behind models’ predictions (Jacovi and Goldberg,\n2020). This is particularly relevant to work on subnetworks as empirically some subnetworks in\nmodels with randomized weights do not accurately represent such reasoning (Ramanujan et al., 2020).\n\nTo this end, we study the task-specific metrics on models with permuted weights (which we call reset\nnetworks (Zhang and Bowman, 2018; Cao, Sanh, and Rush, 2021)) and verify that the circuit recovery\nalgorithms perform worse on these models that do not have underlying algorithms. Specifically, we\ncreate the reset network by permuting the head dimension of each layer’s Q, K, V matrices, and each\nMLP’s bias term. This disrupts the functionality of the subject model, without changing many facts\nabout the distribution of the activations (e.g. the average magnitude at every layer). In our experiment\n\n\n                                       32\n\nFigure 22: Gendered pronoun completion circuit found by ACDC.\n\n\n\n\n\n                          33\n\nin Figure 8 the metric used by each algorithm is the KL divergence between the original trained\nnetwork (with no edges patched), and the activation-patched reset network.\n\nThe reset network does not exhibit the original network’s behavior, and thus it should not be possible\nto explain the presence of the behavior. This is a strong measure of the negation of Q2:  if the\nalgorithm is able to find a circuit that performs the behavior on a network that does not exhibit the\nbehavior, then it will likely hallucinate circuit components in normal circumstances.\n\n\nM  Automated Circuit Discovery and OR gates\n\n\nIn this appendix we discuss an existing limitation of the three circuit discovery methods we introduced\nin the main text: the methods we study do not identify both inputs to ‘OR gates’ inside neural\nnetworks.\n\nOR gates can arise in Neural networks from non-linearities in models. For example, if x, y ∈{0, 1}\nthen 1 −ReLU(1 −x −y) is an OR gate on the two binary inputs x, y.13 To study a toy transformer\nmodel with an OR gate, we take a 1-Layer transformer model two heads per layer, ReLU activations\nand model dimension 1. If both heads output 1 into the residual stream, this model implements an OR\ngate.14 Our dataset (Section 2) is then equal to a single prompt where the heads output 1, and we use\nzero activations to test whether the circuit discovery methods can find the two inputs to the OR gate.\n\n\n\n\n\n           Figure 23: OR gate recovery. a) the ground truth, b) ACDC, c) HISP, d) SP.\n\n\nThe results can be found in Figure 23. The ground truth in a) is our toy model of an OR gate, where\nMLP0 performs OR on the bias terms of a0.0 and a0.1. These are the only edges that should be\nincluded. b) ACDC only recovers one OR gate input. This is because the iterative algorithm prunes\nthe first input to the OR gate it iterates over and then keeps the other. c) HISP recovers neither OR\ngate input (and also recovers the unnecessary input node). d) SP recovers only one OR gate input, and\nseveral additional nodes. SP and HISP found extra edges since they include the input node by default.\nHISP doesn’t include either attention head showing the limitations of gradients in this idealized case.\nWe are unsure why SP finds the a0.0’s key and value inputs. This shows the limitations of node-based\nmethods for finding circuits, though ACDC is also limited. Of course, many easy fixes exist to this\nproblem, but the priority of future work should be to explain in-the-wild language models, where it is\nless clear which algorithmic improvements will be most helpful. For example, follow up work found\nthat using gradient approximations on the edges of a computational graph was very effective (Syed,\nRager, and Conmy, 2023), despite not being more effective at finding OR gates.\n\n   13This construction is similar to the AND gate construction from Gurnee et al. (2023) Appendix A.12.\n   14For specific details of the TransformerLens (Nanda, 2022) implementation, see https://github.com/\nArthurConmy/Automatic-Circuit-Discovery/blob/main/acdc/logic_gates/utils.py#L15.\n\n\n                                       34\n\nN  Connection to Causal Scrubbing\n\nThis work was inspired by work on Causal Scrubbing (Chan et al., 2022). The scope of each algorithm\nis quite different, however.\n\nCausal Scrubbing (CaSc; Chan et al., 2022) aims primarily at hypothesis testing. It allows for detailed\nexamination of specified model components, facilitating the validation of a preconceived hypothesis.\n\nACDC, on the other hand, operates at a broader scale by scanning over model components to generate\nhypotheses, each of which is tested using CaSc. ACDC chooses to remove an edge if according to\nthe CaSc criterion, the new hypothesis isn’t much worse.\n\nWhy is testing every hypothesis with Causal Scrubbing not incredibly inefficient? The reason is that\nACDC only considers a small class of CaSc hypotheses, where paths through the model either matter,\nor don’t matter. In effect, the CaSc hypotheses considered by ACDC don’t allow any interchanges if\nthe node “matters” (by having a unique value for each possible input), and the nodes that don’t matter\nare each replaced by the same second data point.\n\nBoth methods currently face computational inefficiencies, albeit for different reasons and at different\nscales. Causal Scrubbing is impractical for somewhat complicated causal hypotheses because of\ntreeification: there are exponentially many paths through a branching DAG, and each needs part of a\nforward pass. For ACDC, each hypothesis is quick to test, but the number of edges to search over\ncan be quite large, so it still takes a while to search over circuits for realistic models. This problem\nis partially addressed by using gradient-based approcahes like Attribution Patching (Syed, Rager,\nand Conmy, 2023) or perhaps an edge-based version of Subnetwork Probing (Cao, Sanh, and Rush,\n2021).\n\nIn summary, ACDC and Causal Scrubbing are complementary tools in the analysis pipeline. ACDC\ncan do an initial coarse search over hypotheses and, while it is built on Causal Scrubbing, only\nconsiders a small class of hypotheses so it stays relatively efficient. In contrast, Causal Scrubbing\noffers a methodical way to test hypotheses, which can also specify the information represented in\neach node.\n\n\n\n\n\n                                       35\n\n## Claim to Classify\n\"finding the connections between abstract neural network units that form a circuit\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Activation patching",
    "method_rung": 2,
    "claim_rung": 2,
    "confidence": 4,
    "hedge_flag": 0,
    "reasoning": "The claim describes 'finding connections between abstract neural network units that form a circuit,' which directly references activation patching (an interventional Rung 2 method) as the core technique. The claim focuses on identifying causal connections (e.g., 'connections that form a circuit'), aligning with Rung 2 linguistic markers like 'mediates' or 'influences' without asserting uniqueness or mechanistic computation (Rung 3). No hedging language is present. Confidence is 4 due to clear alignment with Rung 2, though minor ambiguity arises from the term 'circuit' potentially implying mechanism, but context confirms a causal-not-unique interpretation."
  },
  "metadata": {
    "model": "deepseek/deepseek-r1",
    "usage": {
      "prompt_tokens": 34868,
      "completion_tokens": 1229,
      "total_tokens": 36097
    },
    "finish_reason": "stop"
  }
}