{
  "timestamp": "2026-02-19T11:55:22.713511+00:00",
  "paper_id": "2509.06608",
  "claim_id": "2509.06608-02",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2509.06608\nTitle: Small Vectors Big Effects: RL-Induced Reasoning via Steering\nFull text:\n                              Small Vectors, Big Effects:\n        A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n\n\n                   Viacheslav Sinii 1 Nikita Balagansky 1 Gleb Gerasimov 1  Daniil Laptev 1 Yaroslav Aksenov 1\n                    Vadim Kurochkin 1 Alexey Gorbatovski 1 Boris Shaposhnikov 1  Daniil Gavrilov 1\n\n\n                         Abstract                     Rimsky et  al., 2024) has demonstrated that reasoning-\n                                                                 connected behaviors such as backtracking are represented\n            The mechanisms by which reasoning training\n                                                                            linearly inside the model and can be extracted from con-\n               reshapes LLMs’ internal computations remain\n                                                                                    trastive pairs (Venhoff et al., 2025; Ward et al., 2025). Later,\n                unclear. We study lightweight steering vectors2026                                                                      Sinii et al. (2025) showed that trainable steering vectors                inserted into the base model’s residual stream\n                                                                  can match the performance of fully fine-tuned models while\n             and trained with a reinforcement-learning objec-\n                                                                      involving a small, isolated set of parameters with the po-\n                   tive.  These vectors explain a large portion ofFeb                                                                          tential for interpretability. We build on this line of work\n                  full fine-tuning performance increase while pre-\n                                                          by interpreting the effects of trainable steering vectors on2         serving the interpretability of small, additive in-\n                                                    LRMs’ behavior and on the circuitry they activate.\n                terventions. We find that (i) the last-layer steer-\n               ing vector acts like a token-substitution bias con-           First, to isolate inter-layer effects, we train a single steering\n                centrated on the first generated token, consis-         vector per model at a specific layer. Its performance pro-\n                 tently boosting tokens such as “To” and “Step”;         vides an upper bound on what can be achieved by a linear\n                     (ii) the penultimate-layer vector leaves atten-         intervention at that layer. We then present the following[cs.LG]          tion patterns largely intact and instead operates          findings:\n              through the MLP and unembedding, preferen-\n                                                                                      • Early-layer steering does not express later-layer steer-                   tially up-weighting process words and structure\n                                                                    ing directions. Although many layers achieve similar              symbols; and (iii) the steering vectors transfer\n                                                                     performance, the induced shifts diffuse as they propa-                to other models from the same family. Taken\n                                                                            gate and become nearly orthogonal to later-layer steering                together, these results deepen understanding of\n                                                                               vectors.           how trained steering vectors shape computation\n                                                                                      • Two mechanisms for steering. The last-layer steering              and should inform future work in activation engi-\n                                                                         vector induces a shift in the output hidden states that               neering and the study of reasoning models. The\n                                                                                           is directionally dissimilar from the shifts induced by             code is available at https://github.com/\n                                                                              steering vectors at earlier layers.           corl-team/steering-reasoning.\n                                                                                      • Last layer behaves like first-token substitution. The\n                                                                                     final-layer vector acts at the unembedding, boosting open-\n                                                                       ing tokens (e.g., “To”/“Step”); simply prefixing these          1. Introduction\n                                                                       tokens recovers ∼10-11 points – about three quarters ofarXiv:2509.06608v4    Large reasoning models (LRMs) have recently shown re-       the explicit last-layer gain.\n          markable performance (Jaech et al., 2024; Guo et al., 2025)      • Penultimate-layer vector acts through the MLP. The\n         by being trained to produce effective chain-of-thoughts (Wei       induced effect is mediated almost entirely by the MLP,\n            et al., 2022) before providing a final answer. Many open       with minimal reliance on attention.\n           reproductions are trained on mathematical datasets with ver-      • Steering vectors transfer across related models.\n             ifiable rewards (Hu et al., 2025; Liu et al., 2025a). However,      Across multiple model families and sizes, steering vec-\n       we still lack a mechanistic understanding of the source of        tors trained in one model often retain a non-trivial frac-\n           these gains.                                                       tion of their performance when inserted into a closely\n                                                                matched model, suggesting that the underlying steering\n          Recent work in activation engineering (Turner et al., 2023b;\n                                                                             directions are largely preserved under fine-tuning and\n               1T-Tech. Correspondence to: Viacheslav Sinii <v.siniy@t-       instruction tuning.\n           tech.dev>.\n\n            Preprint. February 3, 2026.\n\n\n                                                         1\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n   45                                                                        Full Model           27.5                                                                      Full Model\n   40                                                                                     25.0\n   35                                                                                     22.5                                                Base Model\nAcc.                                                                                                Acc.\n   30                                                                                     20.0\n                                                      Base ModelMean25                                                                                              Mean17.5\n\n   20                                                                                     15.0\n                                                 Base Model. = 1                                                                                           12.5                                           Base Model. = 1   15\n\n        0          5         10         15         20         25                       0        5        10       15       20       25       30\n                                   Layer                                                                        Layer\n\n                  Qwen2.5-Math-7B                                            LLaMa3.1-8B-It\n\nFigure 1. Single-layer steering. Mean accuracy on six benchmarks when training a single steering vector sℓat layer ℓ(all other layers\nfrozen). Many layers recover a substantial fraction of the gain from full fine-tuning, implying they captured reasoning-relevant information.\n\n\n2. Background                                       Setup.  In each training run, we selected a single layer ℓ\n                                                    and injected a steering vector sℓinto the residual stream at\nRecent work has shown that training lightweight steering                                                                  that layer’s output. All other layers remained unchanged.\nvectors can match the performance of fully tuned models                                      We initialized sℓto zero and trained it using the standard\n(Sinii et al., 2025).  Concretely, zero-initialized steering                                        RLVR pipeline.\nvectors sℓ∈Rd are added to the output residual stream\nof each layer ℓ, while all other weights remain fixed. The   We studied two base models – Qwen2.5-Math-7B (Yang\nvectors are trained with the RLOO (Ahmadian et al., 2024)     et al., 2024) and Llama3.1-8B-It (Grattafiori et al., 2024).\nobjective in a standard RLVR setup (Hu et al., 2025; Zeng    Models were trained on the DeepScaleR dataset (Luo et al.,\net al., 2025; Liu et al., 2025a). For a policy πθ, the policy-    2025) with the sampling temperature τ = 1.0, a 4K context\ngradient update is                                   window for Qwen2.5-Math-7B, and 8K for Llama3.1-8B-It.\n                                                  Rewards were assigned with Math-Verify1. We used\n  ∇θJ = Ex∼D, y∼πθ(·|x) a(x, y) ∇θ log πθ(y | x)  ,      128 prompts and 16 generations per gradient step. We used\n                                                             the Adam optimizer (Kingma, 2014) with no weight de-\nwhere the advantage is defined as                                                                  cay. Evaluation spanned six math benchmarks: AIME24/25,\n                                            AMC23, MATH500 (Hendrycks et al., 2021), MinervaMath                                  1\n  a(x, y) = r(x, y) −b(x),     b(x) = X r(x, y).     (Lewkowycz et al., 2022), and OlympiadBench (He et al.,                     N\n                                             y               2024). We report the mean score across these benchmarks\n                                                                  in the main text and provide the raw numbers in Appendix B.\nHere r(x, y) is the scalar reward for completion y on prompt\n                                                      For MATH500, MinervaMath, and OlympiadBench we\nx, N is the number of generated completions, and b(x) is a\n                                                              report PASS@1; for AIME24/25 and AMC23 we report\nper-prompt baseline used for variance reduction.\n                                      AVG@32 due to their smaller sizes. During evaluation,\nSinii et al. (2025) argue that this parameterization localizes    models decoded with sampling at τ = 1.0 following Zeng\ntraining-induced changes in the model’s internal computa-     et al. (2025). Evaluation context length was 4K and 32K for\ntions, making the intervention easier to interpret. We adopt    Qwen2.5-Math-7B and Llama3.1-8B-It, respectively. All\nthis setup to learn per-layer steering vectors for our inter-    metrics were averaged over three evaluation seeds.\npretability study.\n\n                                                           Result.  Figure 1 reports per-layer results for both mod-\n3. Single-layer steering vectors                             els, compared with (i) all-layer steering, (ii) the base model\n                                                        with greedy decoding, and (iii) the base model sampled at\nWhile all-layer steering vectors can match the performance\n                                                          τ = 1.0 (the training initialization). Most layers improve\nof fully fine-tuned models, joint training couples layers\n                                                         over the initialization, but none matches all-layer steering;\nthrough inter-layer interactions, making it difficult to at-\n                                                       under greedy decoding, several do (Appendix A), suggest-\ntribute improvements to any single layer. To isolate layer-\n                                                          ing that single-layer vectors target the right mechanisms\nspecific effects, we trained a steering vector at one layer at a\n                                                             yet cannot on their own sufficiently reduce the next-token\ntime and report its performance. This per-layer setting both\n                                                                  distribution’s entropy. In Qwen2.5-Math-7B, s23 and s24clarifies the object of our mechanistic analysis and provides\na reference point – an upper bound on what can be achieved      1https://github.com/huggingface/\nby a single linear intervention at a fixed layer.             Math-Verify\n\n                                                2\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n    1.0                                                               1.0\n\n    0.8                                                               0.8\n\n    0.6                                                               0.6CosSim                                                                                                      CosSim\n\n    0.4                                                               0.4Mean                                                                    Mean\n\n    0.2                                                               0.2\n\n    0.0                                                               0.0\n       0       5      10      15      20      25              0       5      10      15      20      25\n                          Layer                                                  Layer\n\n                        Diff-Diff CosSim                                                 Diff-Vector CosSim\n                                            Qwen2.5-Math-7B\n\n    1.0                                                               1.0\n\n    0.8                                                               0.8\n\n    0.6                                                               0.6CosSim                                                                                                      CosSim\n\n    0.4                                                               0.4Mean                                                                    Mean\n\n    0.2                                                               0.2\n\n    0.0                                                               0.0\n       0      5     10     15     20     25     30            0      5     10     15     20     25     30\n                          Layer                                                  Layer\n\n                        Diff-Diff CosSim                                                 Diff-Vector CosSim\n                                                   Llama3.1-8B-It\n\nFigure 2. Steering Vector Persistence. For each steering layer i (color encodes i; warm = early, cool = late) and each later layer ℓon the\nx-axis, we measure how similar the steering-induced hidden-state shift at layer ℓis across tokens. Left: similarity between token’s shift\nand the average shift over the dataset, quantifying how consistently the perturbation points in the same direction as it propagates. Right:\nsimilarity between each token’s shift and the steering vector trained at layer ℓ, quantifying whether the propagated effect aligns with that\nlayer’s own steering direction.\n\n\nunderperform their neighboring layers; we trace the issue    hidden state induced by steering at layer i:\nto vectors passing through the input layer-norm in layer 25\n(Appendix C).                                                  ∆F<ℓ,i(x) = F<ℓ(x; si) −F<ℓ(x),\n\n                                                    where F<ℓ(x) is the output of the first ℓlayers of the trans-\n4. Steering Vector Persistence                                                             former, and si is the steering vector injected at layer i.\nFigure 1 shows that, in our experiments, steering at different   We then calculated two summary statistics:\nlayers yielded similar performance. One possible explana-\ntion is that an early steering vector could propagate through     1. Diff-Diff CosSim: the average cosine similarity between\nthe network into a ”virtual” linear steering vector at a later      ∆F<ℓ,i(x) and the mean effect Ex[∆F<ℓ,i(x)] over the\nlayer, targeting the same mechanism. We designed the next        dataset (how consistently the intervention pointed in the\nexperiment to test this hypothesis.                         same direction).\n                                                                    2. Diff-Vector CosSim: the average cosine similarity be-\nFor each input x, we computed the change in the layer-ℓ                                                      tween ∆F<ℓ,i(x) and the layer-ℓsteering vector sℓ\n                                                           (whether the propagated effect aligned with that layer’s\n\n                                                3\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n                                                             1.0       reached its minimum in the middle layers and then rose to-    0\n    2                                               ward later layers, suggesting a tighter concentration around\n    4                                                   a shared direction in the second half of the model. See\n                                                             0.9      Appendix D for raw cosine similarity scores.    6\n    8                                                            Finally, Diff-Diff CosSim jumped at the final transformer\n   10                                                           layer (indexed as L), suggesting convergence to a more uni-\n                                                             0.8\n   12                                               form effect at the unembedding. Figure 3 shows pairwise\n                                                             cosine similarities between Ex[∆F<L,i(x)] across injectionLayer14                                                             0.7CosSim\n   16                                                            layers, revealing roughly three direction groups. First, the\n                                                             0.6        last-layer steering effect was the most dissimilar from all   18\n   20                                                       0.5        others, with cosine similarity around 0.21. Effects from\n                                                             other layers were much more similar, with a minimum co-   22                                                       0.4\n                                                               sine similarity of 0.75, but still formed two clusters: layers   24\n                                                             0.3       0-17 and layers 18-26. In the next two sections, we inspect\n   26\n                                                             0.2      two representative layers and study their behavioral effects\n      0  2  4  6  8  10 12 14 16 18 20 22 24 26           on generation, as well as the mechanisms that produced\n                         Layer\n                                                        them.\nFigure 3. Similarity of steering-induced unembedding biases\n(Qwen2.5-Math-7B). Each cell shows the cosine similarity be-\n                                                        5. Last Layer – Token Substitutiontween the average hidden-state shift at the final transformer layer\ninduced by steering at layers i and j. High similarity among\n                                                           Figure 1 shows that training only the last-layer vector s27 ini, j < L indicates that steering from most layers produces a simi-\nlar bias at the unembedding, largely independent of the injection    Qwen2.5-Math-7B closed over 50% of the gap between the\npoint. In contrast, steering at the last layer directly yields a qualita-    base model and full training. Since it accounts for a large\ntively different shift, implying a distinct mechanism.                part of the performance gain, we expected it to implement\n                                                        a simple and efficient strategy. With no subsequent layers\n                                                                  to process it, s27 acts directly at the unembedding and does\n  own steering direction).                                  not change earlier hidden states. This makes it behave like\n                                                         token substitution: it boosts logits of tokens it aligns with.\nFigure 2 (top) shows the results for Qwen2.5-Math-7B. Diff-\n                                      We read out these preferences using a logit-lens pro-Diff CosSim indicates that (a) alignment of the induced shifts\n                                                                jection (nostalgebraist, 2020), multiplying s27 by the un-gradually decayed as the perturbation propagated; (b) the\n                                                   embedding matrix (omitting the pre-unembed layer norm).next layer received an almost uniform shift (cosine similari-\n                                                The top token was ”To”, with cosine similarity 0.37; seeties were always ≥0.8); (c) the shifts never became orthog-\n                                                   Appendix G for the top-10 tokens.onal (consistently > 0.3); and (d) alignment increased again\nin later layers. Taken together, these observations suggest   We next validated the behavioral impact on the model’s\nthat the induced shifts drifted as they traversed the network,    generations. Although the vector is added unconditionally,\nbut remained clustered around a common direction.           the softmax nonlinearity means its effect depends on the\n                                                                             initial logits. Let x be the prefix (prompt plus the generatedIn contrast, Diff-Vector CosSim dropped rapidly with dis-\n                                                          tokens so far). The next-token distribution istance from the injection layer: the propagated shifts were\nnearly orthogonal to each layer’s own steering vector. Note\n                                                                   p(x) = Softmax(g(F<L(x))),\nthat this alone does not imply different behaviors – orthogo-\nnal steering directions could still induce the same behavior                                                     where g is the unembedding matrix, and F<L(x) is the final\n(Jacob & Turner, 2024). To test this possibility, we trained                                                       hidden state. With steering at the last layer, the induced\ntwo steering vectors constrained to be orthogonal to the                                                      change is\noriginal vector at layers 14 and 15, and found that neither\n                                                 ∆p = p(x; sL) −p(x).\northogonal vector matched the performance of the original\none (Appendix F). Together with the Diff-Diff CosSim re-  We estimated ∆p on 1000 DeepScaleR prompts, obtaining\nsults, these findings suggest that earlier-layer steering does    a score per token at each generation position.\nnot simply express the later-layer steering directions, and\n                                                    Grouping by token, the largest increases were again for\nthat steering at different layers relies on different learned\n                                          \"To\" and \" To\", concentrated at the first generated token\nmechanisms.\n                                                           (Figure 4, top-left). To test causality, we appended \"To\"\nWe observed a similar pattern for Llama3.1-8B-It (Figure 2,    to each prompt and evaluated the base model: accuracy\nbottom). The main difference was that Diff-Diff CosSim    increased by 10–11 points under both greedy decoding and\n\n                                                4\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n                                                                              Base          Base + \"To\"            Last Steering\n                                                                  40                        38.7                                                                                                         35.5\n    0.8                                                                                                                                               29.4                                                                  30                                                                                                24.8                                         25.5Difference0.6\n                                                                  20                                         14.3    0.4                                                                                                                                                                                                                                   Performance    0.2                                                            10Probability    0.0                                                                   0\n            \"To\"       \" To\"       \":\\n\"        \").\"       \" the\"      \"To\"                         Greedy                      Sampling\n                                                              at Pos. 0\n\n                                               Qwen2.5-Math-7B\n\n                                                                              Base         Base + \"Step\"           Last Steering\n                                                                                                         22.4      21.6                                                                                                21.5\n    0.8                                                            20\n    0.6                                                            15                                                  13.4      14.7Difference                                                                                                                               11.7\n    0.4                                                            10    0.2                                                                                                                                                                                                               Performance                                                                   5Probability    0.0                                                                   0\n          \"Step\"    \" final\"  \" solution\"    \" =\"      \".\\n\\n\"    \"Step\"                        Greedy                      Sampling\n                                                              at Pos. 0\n\n                                                      Llama3.1-8B-It\n\nFigure 4. Last-layer steering vector. Left: distribution of token-level probability change induced by the last-layer vector over 1000\nDeepScaleR prompts. We include the top-5 tokens by maximum change and highlight the most affected token at the zeroth generation\n position. Right: prefixing this token to each prompt reproduces a substantial fraction of the vector’s accuracy gain under both greedy\ndecoding and sampling.\n\n\nsampling, which is about 75% of the gain from s27 (Figure 4,    6. Penultimate Layer – Circuit\n top-right).\n                                                              Steering the penultimate layer s26 yielded a larger accuracy\nThe Llama3.1-8B-It results follow the same qualitative pat-    gain than steering the last layer, while remaining tractable to\n tern as Qwen2.5-Math-7B, but the effect is weaker. In Fig-    analyze because the modified activations traversed only one\nure 1, the last-layer vector closes only a modest fraction    remaining block. Here we identify which parts of that block\nof the gap to full training, and a logit-lens readout of    converted the steering signal into improved performance.\ns31 shows weak alignment with any single token (max co-\n                                                       For a given residual input X, the layer computes Y = sine similarity 0.12; Appendix G). Nonetheless, the highest-\n                               X + MHA(LN(X)) and Z = Y + MLP(LN(Y )), wherescoring tokens were variants of \"Step\" and \"final\",\n                                     LN denotes layer normalization. The Multi-Head Attentionand the induced probability changes were concentrated at\n                                           (MHA) mechanism consists of several attention heads, eachthe first generated position, primarily promoting \"Step\"\n                                                             defined as(Figure 4, bottom-left). Appending \"Step\" to each prompt\nimproved the base model under both sampling and greedy              UW iQ (UW iK )⊤ !    V\n                                                                                                                                                                  i  ,decoding. Interestingly, under greedy decoding this prefix       Hi(U) = Softmax      √dk    UW\neven outperformed last-layer steering, plausibly because a\n last-layer vector cannot condition its influence on position         Q   K        V                                                   where W i  , W i  , and W i  are the query, key, and value\nand thus also perturbs later steps.                                                               projection matrices for head i. The outputs of all heads are\n Finally, we note that the same conclusions hold for mod-    concatenated and linearly transformed using an output pro-\n els trained on a different dataset. In Appendix H we reran     jection matrix W O, forming the complete attention output:\nthe experiment with models trained on open-s1 (Dang &                                          MHA(U) = [H1(U); H2(U); . . . ; Hh(U)]W O.\nNgo, 2025). Again, the last-layer vectors emphasized \"To\"\n(Qwen) and \"Step\" (Llama), primarily at the first genera-   The Multi-Layer Perceptron (MLP) sublayer applies a two-\n tion position.                                                  layer feedforward transformation of the form\n\n                                               MLP(U) = f(UW1 + b1)W2 + b2,\n\n                                                 5\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n               Steer Q-Proj                      Steer K-Proj                      Steer V-Proj\n   38                                          s26                                           s26                                           s26\n\n   36\n\nAcc.34                                 Skip-Attn                                  Skip-Attn                                  Skip-Attn\nMean32\n                                                s27                                           s27                                           s27   30\n   28                              Skip-Layer                               Skip-Layer                               Skip-Layer\n\n      0   3   6   9   12  15  18  21  24  27     0        1        2        3          0        1        2        3\n                   Head                             Head                             Head\n\nFigure 5. Penultimate-layer steering in Qwen2.5-Math-7B. Mean accuracy when injecting s26 into a single projection of the final block:\n(Q: left, K: center, V : right). Injecting only into value head V1 closes the gap between Skip-Attn and s26, indicating that the gain is\ncarried by the value-output path and is largely independent of changes to the attention patterns.\n\n\n\n\n\nFigure 6. Case study for Qwen2.5-Math-7B. Token-level probability shifts (∆p) induced by penultimate-layer steering. Three patterns\nemerge: row 1 amplifies the first generated token \"To\"; row 2 promotes process words (\"solution\" to \"calculations\"); row 3\nfavors structural tokens that start Python code comments and newlines, instead of continuing the current sentence.\n\n\nwhere f(·) is a nonlinear activation function. To understand     effect, whereas placing s26 only in V1 closes the gap to the\nthe contribution of each submodule, we inserted or omit-     full s26 result.\nted the steering vector sL−1 at specific points within the\n                                                          Since neither Q nor K projections are affected by the steer-\nlayer and measured the resulting change in mean accuracy.\n                                                          ing vector, the resulting QK circuit (Elhage et al., 2021)\nSpecifically, we analyzed the following setups:\n                                                         remains unchanged, preserving the attention pattern and the\n • Unmodified: X ←X + sL−1;                          flow of information between tokens. Moreover, because\n • Skip-Attn: Y ←Y + sL−1;                           s L−1W 1V W 1O enters the residual regardless of attention\n • Skip-Layer: Z ←Z + sL−1;                           weights (Appendix I), this is equivalent to adding the pro-\n                                Q/K/V               jected vector just before the MLP, i.e., skipping attention. In- • Steer-Q/K/V-Proj: for a head i, (UW i       ) 7→(U +\n         Q/K/V                                           deed, a vector trained directly on the post-attention residual\n  sL−1)W i           .                                                        reached 38.8 ± 0.6 mean accuracy, matching s26. Overall,\nIf the change was significant, we marked the corresponding    the penultimate vector in Qwen2.5-Math-7B acts via two\nblock as being important for processing the steering vector.    routes: a direct effect on the unembedding and an interaction\n                                                         with the MLP, largely bypassing attention.\nFigure 5 gives three takeaways for the Qwen2.5-Math-\n7B: (i) Skip-Layer reduces accuracy relative to passing s26    Figure 6 shows how adding the steering vector to the post-\nthrough the block, showing an effect on the unembedding     attention residual stream shifts token probabilities. Beyond\ncomparable to s27; (ii) Skip-Attn preserves over half of the    boosting the probability of the first token \"To\",  it pro-\ns26 gain, pointing to the MLP as the main contributor; (iii)    motes process words (e.g., replacing \"solution\" with\npatching any single Q or K, or a Vj with j ̸= 1, has little   \"calculations\"), possibly to deter premature endings.\n\n\n                                                6\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n                   Q-Proj                               K-Proj                               V-Proj\n                                                s30                                           s30                                           s30\n   20\n\n   19\n                                       Skip-Attn                                  Skip-Attn                                  Skip-Attn   18\nAcc.\n   17\nMean   16\n   15                                          s31                                           s31                                           s31\n   14                              Skip-Layer                               Skip-Layer                               Skip-Layer\n\n      0    4    8   12   16   20   24   28      0    1    2    3    4    5    6    7     0    1    2    3    4    5    6    7\n                   Head                             Head                             Head\n\nFigure 7. Penultimate-layer steering in Llama3.1-8B-It. Mean accuracy when injecting the penultimate-layer vector s30 into a single\nprojection of the final block (Q: left, K: center, V : right). Injecting into any single projection remains close to Skip-Attn and falls short of\nthe full s30 result.\n\n              Skip-Head                          Steer-Head                                            s30                                                  s30\n   20                                           20\nAcc.18                                                    Acc.18\n                                    Skip-Attn                                        Skip-Attn\n   16                                           16Mean                                                       Mean                                            s31                                                  s31                                 Skip-Layer                                     Skip-Layer\n   14                                           14\n      0   4   8   12  16  20  24  28             0   4   8   12  16  20  24  28\n                  Head                                  Head\n\nFigure 8. Penultimate-layer steering in Llama3.1-8B-It. Mean accuracy when patching whole heads in the final block with s30:\nSkip-Head (left, steer all heads except head i) and Steer-Head (right, steer only head i). No single head closes the gap between Skip-Attn\nand s30, indicating a cooperative multi-head effect.\n\n\nIt also favors structural tokens such as Python comment     post-attention residual stream yielded performance indistin-\nmarkers and newlines, which often precede math blocks and    guishable from s30 (mean accuracy 19.9 ± 0.1), suggesting\nmay support in-code reasoning.                                 either that the vector effectively bypasses attention or that\n                                                                   attention contributes through a cooperative multi-head route.\nIn contrast to Qwen, in Llama the projection-level patching\n(Steer–Q/K/V) did not reveal the source of the gain (Fig-\nure 7). We therefore went further and patched entire heads    7. Transfer of Steering Vectors Across Models\nusing two setups:\n                                                                  Finally, we tested whether the improvements induced by\n • Steer-Head: (Hi(U)7→Hi(U + s L−1))                    steering vectors transferred to other models within the same\n • Skip-Head: (leave Hi(U) unchanged while steering all     family. In this experiment, we used all-layer steering vectors,\n   other heads).                                           following the setup of Sinii et al. (2025). We considered\n                                                               three model groups:\nIn Figure 8, two baselines mirror the Qwen result: Skip-\nLayer performs close to s31, indicating a direct unembed-      • {Qwen2.5-7B, Qwen2.5-7B-Instruct, Qwen2.5-Math-\nding effect, and Skip-Attn retains about 70% of the s30     7B}\ngain, suggesting that much of the impact bypasses atten-      • {Qwen2.5-1.5B,  Qwen2.5-1.5B-Instruct,  Qwen2.5-\ntion. No single head closes the remaining gap between s30      Math-1.5B}\nand Skip–Attn, pointing to a cooperative multi-head mech-      • {Llama3.1-8B, Llama3.1-8B-Instruct}\nanism and the importance of the attention layer for s30’s\n                                                   where models within a group share hidden size and depth.\nperformance. Still, training the steering vector directly in the\n\n\n                                                7\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nTable 1. Transferability of steering vectors within model fami-    obtain them is contrastive extraction from activation pairs\nlies. Each cell reports the normalized gain when steering vectors\n                                                                           (e.g., positive vs. negative sentiment) (Turner et al., 2023a;\ntrained on the Donor model are applied to the Recipient model.\nValues are normalized such that the recipient equipped with its    Panickssery et al., 2023; Liu et al., 2023; Zou et al., 2023).\nown vectors equals 1.0, and the base model (no vectors) equals 0.0;   Beyond extraction, steering directions can also be trained:\nnegative values indicate degradation. “—” denotes not applicable    optimized with preference data for controllable generation\n(no Math checkpoint available).                             (Cao et al., 2024), or learned as simple additive vectors that\n                                                            surface latent behaviors such as step-by-step reasoning or\n                               Donor                                                                   self-reflection (Mack & Turner, 2024; Engels et al., 2025;\n Family         Recipient  Base   Instruct  Math     Betley et al., 2025).\n\n                Base        1.00     0.38     0.32      In this work, we interpret steering vectors trained with\n Qwen2.5-1.5B   Instruct     0.94     1.00     0.31     GRPO-like objective using standard tools from mechanis-\n               Math       0.36     0.21     1.00       tic interpretability – logit-lens to read out token-level\n                                                                   effects (nostalgebraist, 2020), path patching to localize cir-                Base        1.00     0.36     0.74\n                                                                  cuits (Wang et al., 2022), and circuit-style analyses in the Qwen2.5-7B     Instruct     0.55     1.00     -0.34\n                                         QK/OV framework (Elhage et al., 2021).               Math       0.32     0.05     1.00\n\n                Base        1.00     0.28   —\n Llama-3.1-8B                                          9. Conclusion                    Instruct     0.74     1.00   —\n\n                                       We presented a mechanistic interpretation of trainable steer-\n                                                          ing vectors for mathematical reasoning. Across Qwen2.5-\nFor Llama3.1-8B-Instruct, we used the same chat template   Math-7B and Llama3.1-8B-It, our results show three re-\nas the Llama3.1-8B. For each ordered pair within a group,    curring patterns. First, last-layer steering behaves like first-\nwe swapped the donor model’s steering vectors into the    token biasing at the unembedding: it preferentially promotes\nrecipient and report the relative gain: scores are normalized     specific opening tokens (e.g., \"To\"/\"Step\"), and simple\nby the gap between the base model and the same model    prefixing recovers a large fraction of the last-layer gain in\nequipped with its own vectors. Raw (unnormalized) scores   Qwen and a smaller but consistent effect in Llama. Second,\nare provided in Appendix J.                                   penultimate-layer steering achieves most of its benefit while\n                                                               largely bypassing attention: in Qwen the gain is carriedTable 1 summarizes the results. In most cases, the trans-\n                                                              primarily by a value-output path (with little dependence onfer yielded in a non-trivial gain, suggesting that the direc-\n                                                                  attention-pattern changes), while in Llama no single projec-tions associated improved math performance are largely pre-\n                                                                   tion or head explains the full effect, pointing to a cooperativeserved after under fine-tuning and instruction tuning. Also,\n                                                           multi-head contribution even though post-attention steeringreusing steering vectors trained on a related base model\n                                                      can match the penultimate-layer result. Third, steering ef-can be a simple, low-cost way to improve performance on\n                                                                  fects do not propagate as a “virtual” later-layer direction:closely matched models.\n                                                             as perturbations travel forward, their directions diffuse and\n                                                become nearly orthogonal to later-layer steering vectors,\n8. Related Work                                          indicating distinct learned mechanisms across layers. In\n                                                                addition, our single-layer training setup provides a simpleReinforcement learning with verifiable rewards. Jaech\n                                                 community baseline: training one vector at a time isolateset al. (2024) demonstrated the striking performance of RL-\n                                                                   layer-specific effects and enables reproducible comparisonstuned reasoning models, sparking a wave of follow-ups that\n                                                                to any linear intervention at the same layer across modelsdevelop these models (Guo et al., 2025; Zeng et al., 2025;\n                                                     and datasets.Liu et al., 2025a; Hu et al., 2025). Subsequent work has\nexamined why this training is effective, analysing model    Although most of these qualitative findings hold in both\nbehaviour and the sources of its gains (Wang et al., 2025;    models, the effects are consistently stronger and cleaner in\nYe et al., 2025; Shao et al., 2025; Liu et al., 2025b). We   Qwen than in Llama (e.g., larger last-layer gains and clearer\ncontribute with a mechanistic study of the changes induced     localization in the final block), suggesting model-specific\nby reasoning training.                                      implementations of similar high-level behaviors. Systematic\n                                                       comparisons across architectures and training recipes maySteering vectors are small additive perturbations to the\n                                                          help explain these differences. A promising direction isresidual stream that modulate model behavior. They are\n                                                                to pin down the precise mechanisms of mid-layer steeringwidely viewed as feature amplifiers – strengthening existing\n                                                                vectors, which often yield strong improvements but arecomputations rather than introducing new mechanisms – and\n                                                            harder to localize to a single submodule.have been used to toggle or amplify reasoning-like behaviors\n(Venhoff et al., 2025; Ward et al., 2025). A common way to\n\n\n                                                8\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nOverall, steering vectors provide a compact and informative    He, C., Luo, R., Bai, Y., Hu, S., Thai, Z. L., Shen, J., Hu, J.,\nprobe of reasoning-trained models, offering concrete insight      Han, X., Huang, Y., Zhang, Y., et al. Olympiadbench: A\ninto how RL-induced changes manifest in token preferences       challenging benchmark for promoting agi with olympiad-\nand internal circuitry.                                              level bilingual multimodal scientific problems.  arXiv\n                                                                 preprint arXiv:2402.14008, 2024.\nImpact Statement                                   Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart,\n                                                                            S., Tang, E., Song, D., and Steinhardt, J. Measuring math-\nThis paper presents work whose goal is to advance the field\n                                                             ematical problem solving with the math dataset. arXiv\nof machine learning.  There are many potential societal\n                                                                 preprint arXiv:2103.03874, 2021.\nconsequences of our work, none of which we feel must be\nspecifically highlighted here                             Hu, J., Zhang, Y., Han, Q., Jiang, D., Zhang, X., and Shum,\n                                                            H.-Y.  Open-reasoner-zero: An open source approach\nReferences                                                    to scaling up reinforcement learning on the base model.\n                                                           arXiv preprint arXiv:2503.24290, 2025.\nAhmadian, A., Cremer, C., Gall´e, M., Fadaee, M., Kreutzer,\n                                                           Jacob, G.-W. and Turner, A.  I found >800 “orthogonal”   J., Pietquin, O.,  ¨Ust¨un, A., and Hooker, S.  Back\n                                                            write-code steering.  https://www.lesswrong.   to basics:  Revisiting reinforce style optimization for\n                                            com/posts/CbSEZSpjdpnvBcEvc/  learning from human feedback in llms. arXiv preprint\n                                           i-found-greater-than-800-orthogonal-write-code-st  arXiv:2402.14740, 2024.\n                                                           2024. LessWrong. Accessed 2025-09-24.\nBetley, J., Bao, X., Soto, M., Sztyber-Betley, A., Chua, J.,                                                            Jaech, A., Kalai, A., Lerer, A., Richardson, A., El-Kishky,\n  and Evans, O. Tell me about yourself: Llms are aware of                                                               A., Low, A., Helyar, A., Madry, A., Beutel, A., Car-\n   their learned behaviors. arXiv preprint arXiv:2501.11120,                                                                ney, A., et al. Openai o1 system card. arXiv preprint\n  2025.                                                           arXiv:2412.16720, 2024.\n\nCao, Y., Zhang, T., Cao, B., Yin, Z., Lin, L., Ma, F., and    Kingma, D. P. Adam: A method for stochastic optimization.\n  Chen, J. Personalized steering of large language mod-      arXiv preprint arXiv:1412.6980, 2014.\n   els: Versatile steering vectors through bi-directional pref-\n                                                 Lewkowycz, A., Andreassen, A., Dohan, D., Dyer, E.,\n  erence optimization. Advances in Neural Information\n                                                         Michalewski, H., Ramasesh, V., Slone, A., Anil, C.,\n  Processing Systems, 37:49519–49551, 2024.\n                                                             Schlag, I., Gutman-Solo, T., et al. Solving quantitative\n                                                             reasoning problems with language models. Advances in\nDang, Q.-A. and Ngo, C. Reinforcement learning for rea-\n                                                            neural information processing systems, 35:3843–3857,\n  soning in small llms: What works and what doesn’t, 2025.\n                                                           2022.\n  URL https://arxiv.org/abs/2503.16219.\n                                                             Liu, S., Ye, H., Xing, L., and Zou, J.  In-context vec-\nElhage, N., Nanda, N., Olsson, C., Henighan, T., Joseph,        tors: Making in context learning more effective and con-\n  N., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly, T.,       trollable through latent space steering. arXiv preprint\n   et al. A mathematical framework for transformer circuits.      arXiv:2311.06668, 2023.\n  Transformer Circuits Thread, 1(1):12, 2021.\n                                                             Liu, Z., Chen, C., Li, W., Pang, T., Du, C., and Lin, M.\nEngels, J., Nanda, N., and Rajamanoharan, S.  Interim      There may not be aha moment in r1-zero-like training\n   research report: Mechanisms of awareness. AI Alignment   — a pilot study. https://oatllm.notion.site/\n  Forum, 2025.  https://www.alignmentforum.    oat-zero, 2025a. Notion Blog.\n  org/posts/m8WKfNxp9eDLRkCk9/                                                             Liu, Z., Chen, C., Li, W., Qi, P., Pang, T., Du, C., Lee,\n  interim-research-report-mechanisms-of-awareness.                                               W. S., and Lin, M. Understanding r1-zero-like training:\n                                    A critical perspective. arXiv preprint arXiv:2503.20783,\nGrattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian,                                                         2025b.\n  A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A.,\n  Vaughan, A., et al. The llama 3 herd of models. arXiv    Luo,  M.,  Tan,  S.,  Wong,   J.,  Shi,  X.,  Tang,  W.,\n   preprint arXiv:2407.21783, 2024.                         Roongta, M., Cai,  C., Luo,  J., Zhang,  T.,  Li,  E.,\n                                                         Popa, R. A., and Stoica,  I.   Deepscaler:  Surpass-\nGuo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R.,      ing o1-preview with a  1.5b model by  scaling  rl.\n  Zhu, Q., Ma, S., Wang, P., Bi, X., et al. Deepseek-r1: In-    https://pretty-radio-b75.notion.site/\n   centivizing reasoning capability in llms via reinforcement     DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Mode\n   learning. arXiv preprint arXiv:2501.12948, 2025.            2025. Notion Blog.\n\n                                                9\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nMack, A. and Turner, A. Mechanistically eliciting latent    Ward, J., Lin, C., Venhoff, C., and Nanda, N. Reasoning-\n  behaviors  in language models.   AI Alignment Fo-       finetuning repurposes latent representations in base mod-\n  rum,  2024.   https://www.alignmentforum.       els. arXiv preprint arXiv:2507.12638, 2025.\n  org/posts/ioPnHKFyy4Cw2Gr2x/\n                                                        Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi,  mechanistically-eliciting-latent-behaviors-in-language-1.\n                                                                        E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting\nnostalgebraist.      interpreting  gpt:    the  logit  lens,        elicits reasoning in large language models. Advances in\n  2020.       https://www.alignmentforum.      neural information processing systems, 35:24824–24837,\n  org/posts/AcKRB8wDpdaN6v6ru/                   2022.\n  interpreting-gpt-the-logit-lens.\n                                                        Yang, A., Zhang, B., Hui, B., Gao, B., Yu, B., Li, C., Liu, D.,\nPanickssery, N., Gabrieli, N., Schulz, J., Tong, M., Hubinger,      Tu, J., Zhou, J., Lin, J., Lu, K., Xue, M., Lin, R., Liu, T.,\n   E., and Turner, A. M. Steering llama 2 via contrastive      Ren, X., and Zhang, Z. Qwen2.5-math technical report:\n   activation addition.  arXiv preprint arXiv:2312.06681,     Toward mathematical expert model via self-improvement.\n  2023.                                                    arXiv preprint arXiv:2409.12122, 2024.\n\nRimsky, N., Gabrieli, N., Schulz, J., Tong, M., Hubinger, E.,    Ye, Y., Huang, Z., Xiao, Y., Chern, E., Xia, S., and Liu,\n  and Turner, A. Steering llama 2 via contrastive activation        P. Limo: Less is more for reasoning.  arXiv preprint\n   addition. In Proceedings of the 62nd Annual Meeting of      arXiv:2502.03387, 2025.\n   the Association for Computational Linguistics (Volume 1:\n                                                      Zeng, W., Huang, Y., Liu, Q., Liu, W., He, K., Ma, Z.,\n  Long Papers), pp. 15504–15522, 2024.\n                                                      and He, J. Simplerl-zoo: Investigating and taming zero\n                                                             reinforcement learning for open base models in the wild.Shao, R., Li, S. S., Xin, R., Geng, S., Wang, Y., Oh, S.,\n                                                           arXiv preprint arXiv:2503.18892, 2025.  Du, S. S., Lambert, N., Min, S., Krishna, R., et al. Spu-\n  rious rewards: Rethinking training signals in rlvr. arXiv                                                      Zou, A., Phan, L., Chen, S., Campbell, J., Guo, P., Ren, R.,\n  preprint arXiv:2506.10947, 2025.                                                             Pan, A., Yin, X., Mazeika, M., Dombrowski, A.-K., et al.\n                                                             Representation engineering: A top-down approach to aiSinii, V., Gorbatovski, A., Cherepanov, A., Shaposhnikov,\n                                                                 transparency. arXiv preprint arXiv:2310.01405, 2023.   B., Balagansky, N., and Gavrilov, D. Steering llm rea-\n  soning through bias-only adaptation.  arXiv preprint\n  arXiv:2505.18706, 2025.\n\nTurner, A. M., Thiergart, L., Leech, G., Udell, D., Vazquez,\n   J.  J., Mini, U., and MacDiarmid, M.  Steering lan-\n  guage models with activation engineering. arXiv preprint\n  arXiv:2308.10248, 2023a.\n\nTurner, A. M., Thiergart, L., Leech, G., Udell, D., Vazquez,\n   J.  J., Mini, U., and MacDiarmid, M.  Steering lan-\n  guage models with activation engineering. arXiv preprint\n  arXiv:2308.10248, 2023b.\n\nVenhoff, C., Arcuschin, I., Torr, P., Conmy, A., and Nanda,\n  N. Understanding reasoning in thinking language models\n  via steering vectors. arXiv preprint arXiv:2506.18167,\n  2025.\n\nWang, K., Variengien, A., Conmy, A., Shlegeris, B., and\n  Steinhardt, J. Interpretability in the wild: a circuit for\n   indirect object identification in gpt-2 small. arXiv preprint\n  arXiv:2211.00593, 2022.\n\nWang, Y., Yang, Q., Zeng, Z., Ren, L., Liu, L., Peng, B.,\n  Cheng, H., He, X., Wang, K., Gao, J., et al. Reinforce-\n  ment learning for reasoning in large language models with\n  one training example. arXiv preprint arXiv:2504.20571,\n  2025.\n\n                                                10\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nA. Per-Layer Steering with Greedy Decoding\n\n                                                                               Full Model           30.0                                                                      Full Model\n   45                                                                                           27.5\n   40                                                                                           25.0\nAcc.35                                                                                              Acc.22.5                                                Base Model\nMean30                                                  Base Model         Mean20.0\n   25                                                                                     17.5\n   20                                                                                     15.0\n                                                 Base Model. = 1   15                                                                                           12.5                                           Base Model. = 1\n\n        0          5         10         15         20         25                       0        5        10       15       20       25       30\n                                   Layer                                                                        Layer\n\n                  Qwen2.5-Math-7B                                                Llama3.1-8B-It\n\n Figure 9. Single-layer steering with τ = 0. We re-evaluated the single-layer steering vectors from Section 3 under greedy decoding.\n\n\nB. Raw Benchmark Scores. Layers\n\n                               Table 2. Raw benchmark scores for Qwen2.5-Math-7B in Figure 1.\n\n          Setup        AIME25    AIME24   AMC23   MATH500   MinervaMath   OlympiadBench     Avg.\n\n       Base Model       3.3 ± 0.0    16.7 ± 0.0   45.8 ± 0.0   52.2 ± 0.0    12.3 ± 0.0       18.6 ± 0.0      24.8 ± 0.0\n    Base Model. τ = 1    2.2 ± 1.6    10.0 ± 4.7   25.0 ± 8.2   37.7 ± 6.1     8.3 ± 1.5        10.2 ± 2.9      14.3 ± 1.7\n        Full-Tune       13.3 ± 2.7   30.0 ± 4.7   64.2 ± 3.1   79.6 ± 1.2    37.3 ± 0.8       41.7 ± 0.5      43.8 ± 0.4\n          Steering        17.8 ± 6.3   18.9 ± 1.6   63.3 ± 4.2   79.8 ± 0.3    35.8 ± 1.1       42.8 ± 1.1      42.9 ± 0.2\n         Layer-0         7.8 ± 1.6    12.2 ± 1.6   54.2 ± 4.2   69.5 ± 1.6    29.4 ± 1.0       33.7 ± 1.1      35.1 ± 0.5\n         Layer-1         5.6 ± 1.6    14.4 ± 6.3   55.8 ± 9.2   72.9 ± 2.1    27.7 ± 2.0       35.9 ± 0.4      35.8 ± 0.4\n         Layer-2         7.8 ± 1.6    21.1 ± 6.8   50.8 ± 4.7   70.4 ± 1.1    29.4 ± 2.3       34.3 ± 0.6      35.6 ± 0.6\n         Layer-3         6.7 ± 2.7    17.8 ± 1.6   50.0 ± 7.4   71.5 ± 1.0    30.1 ± 1.9       36.9 ± 1.1      36.4 ± 0.4\n         Layer-4         7.8 ± 1.6    23.3 ± 2.7   57.5 ± 4.1   71.5 ± 0.7    31.6 ± 0.8       37.1 ± 0.5      36.7 ± 0.1\n         Layer-5        12.2 ± 1.6   16.7 ± 2.7   58.3 ± 3.1   75.1 ± 0.8    28.6 ± 1.2       36.4 ± 1.0      36.9 ± 0.4\n         Layer-6        12.2 ± 4.2   17.8 ± 3.1   55.8 ± 3.1   72.7 ± 1.1    27.6 ± 1.4       36.3 ± 0.6      36.4 ± 0.4\n         Layer-7        11.1 ± 1.6   17.8 ± 3.1   55.0 ± 2.0   73.5 ± 0.7    30.3 ± 1.0       37.4 ± 0.7      37.3 ± 0.2\n         Layer-8        11.1 ± 4.2   20.0 ± 9.8   54.2 ± 1.2   74.1 ± 1.5    30.1 ± 2.9       35.4 ± 0.5      37.0 ± 0.7\n         Layer-9         8.9 ± 1.6    15.6 ± 1.6   55.8 ± 5.1   75.2 ± 0.6    28.7 ± 3.0       38.6 ± 0.3      37.6 ± 0.5\n        Layer-10        12.2 ± 1.6   15.6 ± 9.6   51.7 ± 2.4   72.5 ± 0.4    31.0 ± 1.9       36.5 ± 1.4      37.2 ± 0.1\n        Layer-11         8.9 ± 1.6    18.9 ± 5.7   55.0 ± 7.4   74.7 ± 0.7    30.4 ± 2.2       37.0 ± 1.3      37.4 ± 0.5\n        Layer-12        11.1 ± 5.7   18.9 ± 1.6   58.3 ± 4.2   75.5 ± 0.8    28.4 ± 2.2       38.0 ± 1.1      38.1 ± 0.6\n        Layer-13        15.6 ± 3.1   23.3 ± 4.7   51.7 ± 5.1   75.7 ± 0.8    29.4 ± 1.5       38.4 ± 0.9      38.4 ± 0.6\n        Layer-14        10.0 ± 4.7   23.3 ± 5.4   55.0 ± 3.5   76.2 ± 0.6    29.7 ± 1.5       38.7 ± 0.6      40.0 ± 0.3\n        Layer-15        13.3 ± 2.7   15.6 ± 4.2   61.7 ± 6.2   75.1 ± 0.2    30.9 ± 3.0       39.2 ± 0.8      39.2 ± 0.7\n        Layer-16        13.3 ± 2.7   17.8 ± 4.2   65.0 ± 4.1   76.6 ± 1.8    32.4 ± 1.3       40.3 ± 0.7      40.1 ± 0.6\n        Layer-17         8.9 ± 4.2    17.8 ± 5.7   56.7 ± 5.1   72.9 ± 0.7    27.7 ± 1.0       36.9 ± 1.4      36.6 ± 0.3\n        Layer-18        11.1 ± 1.6   11.1 ± 4.2   57.5 ± 3.5   74.7 ± 0.6    28.2 ± 2.0       39.8 ± 1.4      37.5 ± 0.5\n        Layer-19        14.4 ± 3.1   13.3 ± 0.0   59.2 ± 3.1   74.9 ± 0.9    33.0 ± 0.5       39.7 ± 0.7      38.4 ± 0.2\n        Layer-20         7.8 ± 3.1    15.6 ± 1.6   56.7 ± 5.1   74.0 ± 0.7    30.9 ± 1.8       37.0 ± 0.6      36.6 ± 0.2\n        Layer-21         6.7 ± 2.7    12.2 ± 1.6   61.7 ± 1.2   75.1 ± 0.9    30.3 ± 1.1       39.1 ± 0.7      37.5 ± 0.1\n        Layer-22         8.9 ± 1.6    16.7 ± 4.7   53.3 ± 3.1   72.3 ± 1.0    28.1 ± 0.9       35.6 ± 1.4      35.5 ± 0.2\n        Layer-23         5.6 ± 1.6    14.4 ± 6.3   35.8 ± 1.2   46.8 ± 5.0    13.6 ± 2.6       20.1 ± 5.4      20.9 ± 2.1\n        Layer-24         6.7 ± 2.7    12.2 ± 1.6   39.2 ± 2.4   47.7 ± 5.6    12.0 ± 2.6       20.4 ± 5.2      21.1 ± 2.2\n        Layer-25         7.8 ± 1.6    27.8 ± 1.6   60.8 ± 1.2   72.9 ± 0.8    31.6 ± 2.4       36.7 ± 0.7      38.2 ± 0.5\n        Layer-26        10.0 ± 2.7   15.6 ± 6.8   56.7 ± 7.2   72.9 ± 1.1    27.7 ± 4.1       37.1 ± 0.5      36.9 ± 0.6\n        Layer-27         5.6 ± 3.1    11.1 ± 1.6   49.2 ± 8.2   60.9 ± 0.4    20.5 ± 0.3       29.6 ± 1.3      29.4 ± 0.4\n\n\n\n\n\n                                                11\n\n          Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n\n\n\n\n                            Table 3. Raw benchmark scores for Llama3.1-8b-It in Figure 1.\n\n      Setup       AIME25   AIME24   AMC23   MATH500   MinervaMath   OlympiadBench     Avg.\n\n   Base Model       0.0 ± 0.0   10.0 ± 0.0   27.5 ± 0.0   52.5 ± 0.0    20.5 ± 0.0       18.6 ± 0.0      21.5 ± 0.0\nBase Model. τ = 1   0.0 ± 0.0    0.0 ± 0.0    11.7 ± 2.4   34.6 ± 0.7    12.3 ± 1.5        9.6 ± 0.6      11.7 ± 0.5\n    Full-Tune        0.0 ± 0.0    8.9 ± 3.1    36.7 ± 1.2   57.6 ± 1.6    30.4 ± 2.3       22.4 ± 0.1      26.4 ± 0.8\n     Steering         0.0 ± 0.0   11.1 ± 5.7   35.0 ± 6.1   57.6 ± 1.9    29.9 ± 0.6       23.4 ± 0.5      25.8 ± 0.2\n     Layer-0         0.0 ± 0.0   10.0 ± 2.7   23.3 ± 6.6   50.7 ± 0.5    21.7 ± 0.9       19.1 ± 0.8      21.0 ± 0.4\n     Layer-1         1.1 ± 1.6    3.3 ± 2.7    30.8 ± 2.4   52.1 ± 0.9    24.5 ± 1.1       19.0 ± 1.3      22.0 ± 0.4\n     Layer-2         0.0 ± 0.0   10.0 ± 2.7   35.0 ± 2.0   53.1 ± 1.9    25.6 ± 1.5       18.7 ± 0.6      22.6 ± 0.4\n     Layer-3         0.0 ± 0.0    6.7 ± 2.7    30.0 ± 6.1   53.9 ± 0.4    28.6 ± 0.5       18.8 ± 0.6      22.6 ± 0.1\n     Layer-4         0.0 ± 0.0    7.8 ± 1.6    23.3 ± 3.1   50.8 ± 0.5    26.2 ± 1.0       19.0 ± 0.9      21.6 ± 0.2\n     Layer-5         0.0 ± 0.0    6.7 ± 2.7    29.2 ± 4.7   52.7 ± 1.0    26.2 ± 2.3       19.3 ± 0.3      22.3 ± 0.3\n     Layer-6         1.1 ± 1.6    4.4 ± 3.1    30.0 ± 5.4   50.8 ± 0.7    25.6 ± 1.2       19.8 ± 1.1      22.0 ± 0.1\n     Layer-7         0.0 ± 0.0    4.4 ± 3.1    27.5 ± 7.1   53.3 ± 0.5    27.5 ± 1.5       20.2 ± 0.2      22.6 ± 0.2\n     Layer-8         0.0 ± 0.0    7.8 ± 4.2    30.8 ± 5.1   53.3 ± 1.4    27.5 ± 1.4       19.7 ± 0.4      23.1 ± 0.2\n     Layer-9         1.1 ± 1.6    5.6 ± 1.6    30.8 ± 3.1   56.9 ± 0.7    27.7 ± 1.0       21.9 ± 0.3      24.7 ± 0.1\n     Layer-10        0.0 ± 0.0    4.4 ± 4.2    33.3 ± 4.7   55.5 ± 1.2    27.7 ± 1.0       21.3 ± 0.9      23.4 ± 0.1\n     Layer-11        1.1 ± 1.6    4.4 ± 1.6    33.3 ± 2.4   55.1 ± 1.4    25.9 ± 0.6       20.6 ± 0.8      24.2 ± 0.1\n     Layer-12        1.1 ± 1.6    7.8 ± 3.1    32.5 ± 2.0   54.3 ± 1.3    29.0 ± 1.4       22.3 ± 0.7      24.5 ± 0.4\n     Layer-13        1.1 ± 1.6    7.8 ± 4.2    24.2 ± 1.2   54.7 ± 1.9    27.6 ± 2.9       20.1 ± 0.7      23.1 ± 0.1\n     Layer-14        0.0 ± 0.0   11.1 ± 4.2   31.7 ± 1.2   55.1 ± 0.4    28.4 ± 0.2       20.9 ± 0.1      24.0 ± 0.1\n     Layer-15        1.1 ± 1.6    4.4 ± 1.6    27.5 ± 2.0   54.0 ± 1.1    27.3 ± 1.4       21.8 ± 1.0      23.5 ± 0.4\n     Layer-16        0.0 ± 0.0    7.8 ± 3.1    25.8 ± 3.1   52.9 ± 0.1    26.8 ± 0.6       20.6 ± 0.3      22.7 ± 0.1\n     Layer-17        0.0 ± 0.0    5.6 ± 1.6    26.7 ± 1.2   52.1 ± 0.9    25.7 ± 0.5       18.6 ± 0.7      22.0 ± 0.2\n     Layer-18        0.0 ± 0.0   10.0 ± 5.4   18.3 ± 6.6   51.5 ± 1.2    25.5 ± 1.4       19.3 ± 1.2      21.6 ± 0.5\n     Layer-19        1.1 ± 1.6    6.7 ± 2.7    30.0 ± 3.5   52.9 ± 1.1    25.7 ± 2.0       19.3 ± 0.7      22.3 ± 0.6\n     Layer-20        0.0 ± 0.0    6.7 ± 2.7    22.5 ± 4.1   52.9 ± 1.1    27.1 ± 1.7       19.3 ± 1.1      21.9 ± 0.1\n     Layer-21        0.0 ± 0.0    4.4 ± 1.6    25.8 ± 2.4   51.7 ± 1.0    27.0 ± 0.2       18.6 ± 0.4      21.2 ± 0.3\n     Layer-22        1.1 ± 1.6    7.8 ± 5.7    22.5 ± 2.0   54.9 ± 0.4    25.4 ± 2.5       18.1 ± 0.6      22.5 ± 0.6\n     Layer-23        1.1 ± 1.6    6.7 ± 2.7    25.8 ± 1.2   52.1 ± 0.2    25.7 ± 0.8       19.0 ± 1.5      21.1 ± 0.2\n     Layer-24        2.2 ± 1.6    5.6 ± 3.1    22.5 ± 7.4   50.6 ± 2.2    27.0 ± 2.5       18.8 ± 1.0      21.4 ± 0.6\n     Layer-25        0.0 ± 0.0    6.7 ± 2.7    27.5 ± 2.0   52.1 ± 0.5    26.6 ± 1.1       20.3 ± 1.5      21.9 ± 0.4\n     Layer-26        2.2 ± 1.6    5.6 ± 1.6    27.5 ± 2.0   50.5 ± 1.4    28.1 ± 1.8       17.8 ± 1.3      21.6 ± 0.5\n     Layer-27        1.1 ± 1.6    4.4 ± 1.6    24.2 ± 4.2   50.5 ± 0.1    28.1 ± 0.9       18.2 ± 0.2      21.5 ± 0.2\n     Layer-28        1.1 ± 1.6    5.6 ± 1.6    20.0 ± 3.5   50.5 ± 1.7    25.5 ± 1.1       17.4 ± 0.3      20.9 ± 0.1\n     Layer-29        0.0 ± 0.0    6.7 ± 2.7    30.0 ± 3.5   50.5 ± 0.8    25.7 ± 2.1       16.9 ± 0.6      21.1 ± 0.6\n     Layer-30        0.0 ± 0.0    7.8 ± 4.2    24.2 ± 2.4   50.4 ± 1.0    25.0 ± 0.8       15.8 ± 1.4      20.1 ± 0.5\n     Layer-31        1.1 ± 1.6    1.1 ± 1.6    18.3 ± 1.2   39.0 ± 0.7    18.1 ± 2.5       11.7 ± 0.4      14.7 ± 0.5\n\n\n\n\n\n                                            12\n\n          Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n\n\n\n\n                   Table 4. Raw benchmark scores for Qwen2.5-Math-7B in Figure 9 (greedy decoding).\n\n      Setup        AIME25    AIME24   AMC23   MATH500   MinervaMath   OlympiadBench     Avg.\n\n   Base Model       3.3 ± 0.0    16.7 ± 0.0   45.8 ± 0.0   52.2 ± 0.0    12.3 ± 0.0       18.6 ± 0.0      24.8 ± 0.0\nBase Model. τ = 1    2.2 ± 1.6    10.0 ± 4.7   25.0 ± 8.2   37.7 ± 6.1     8.3 ± 1.5        10.2 ± 2.9      14.3 ± 1.7\n    Full-Tune       18.9 ± 1.6   31.1 ± 1.6   67.5 ± 0.0   80.1 ± 0.1    34.9 ± 0.0       43.2 ± 0.2      46.0 ± 0.5\n     Steering        16.7 ± 0.0   24.4 ± 1.6   59.2 ± 1.2   79.1 ± 0.2    33.9 ± 0.3       42.0 ± 0.1      42.6 ± 0.4\n     Layer-0         8.9 ± 1.6    13.3 ± 0.0   57.5 ± 0.0   75.3 ± 0.1    29.7 ± 0.2       39.9 ± 0.2      37.4 ± 0.2\n     Layer-1        13.3 ± 2.7   20.0 ± 0.0   68.3 ± 1.2   77.5 ± 0.2    28.4 ± 0.2       39.3 ± 0.1      41.1 ± 0.6\n     Layer-2        16.7 ± 2.7   20.0 ± 0.0   65.0 ± 0.0   77.9 ± 0.2    30.8 ± 0.2       39.7 ± 0.1      41.7 ± 0.4\n     Layer-3        10.0 ± 0.0   26.7 ± 0.0   60.8 ± 1.2   76.2 ± 0.5    29.8 ± 0.0       40.6 ± 0.1      40.7 ± 0.2\n     Layer-4        11.1 ± 1.6   10.0 ± 0.0   65.0 ± 0.0   75.3 ± 0.5    30.9 ± 0.3       39.9 ± 0.3      38.7 ± 0.3\n     Layer-5        15.6 ± 1.6   20.0 ± 0.0   57.5 ± 0.0   76.7 ± 0.1    29.2 ± 0.2       39.3 ± 0.3      39.7 ± 0.3\n     Layer-6        16.7 ± 0.0   18.9 ± 1.6   58.3 ± 1.2   78.6 ± 0.3    27.3 ± 0.2       38.7 ± 0.1      39.7 ± 0.3\n     Layer-7        13.3 ± 0.0   23.3 ± 0.0   60.8 ± 1.2   79.2 ± 0.2    29.0 ± 0.0       41.9 ± 0.1      41.3 ± 0.2\n     Layer-8         7.8 ± 1.6    16.7 ± 0.0   67.5 ± 0.0   78.9 ± 0.1    27.6 ± 0.3       39.7 ± 0.1      39.7 ± 0.3\n     Layer-9        13.3 ± 0.0   23.3 ± 0.0   55.0 ± 0.0   79.3 ± 0.2    30.4 ± 0.3       41.4 ± 0.2      40.5 ± 0.1\n     Layer-10        16.7 ± 0.0   26.7 ± 0.0   57.5 ± 2.0   77.5 ± 0.1    31.2 ± 0.3       39.3 ± 0.1      41.5 ± 0.3\n     Layer-11        12.2 ± 1.6   30.0 ± 0.0   58.3 ± 1.2   78.5 ± 0.2    33.5 ± 0.0       41.7 ± 0.3      42.4 ± 0.1\n     Layer-12        16.7 ± 0.0   21.1 ± 1.6   65.8 ± 1.2   77.8 ± 0.0    33.5 ± 0.0       41.9 ± 0.4      42.8 ± 0.2\n     Layer-13        16.7 ± 0.0   16.7 ± 0.0   55.8 ± 1.2   79.3 ± 0.3    31.1 ± 0.2       41.3 ± 0.1      40.1 ± 0.3\n     Layer-14        15.6 ± 1.6   26.7 ± 0.0   62.5 ± 0.0   79.2 ± 0.2    31.6 ± 0.0       44.3 ± 0.3      43.3 ± 0.3\n     Layer-15        16.7 ± 0.0   23.3 ± 0.0   70.0 ± 0.0   78.4 ± 0.2    32.8 ± 0.2       42.4 ± 0.1      43.9 ± 0.0\n     Layer-16         8.9 ± 1.6    26.7 ± 0.0   60.0 ± 0.0   79.1 ± 0.1    36.4 ± 0.0       39.8 ± 0.3      41.8 ± 0.3\n     Layer-17        13.3 ± 0.0   30.0 ± 0.0   57.5 ± 0.0   78.1 ± 0.1    34.6 ± 0.0       42.7 ± 0.1      42.7 ± 0.0\n     Layer-18        12.2 ± 1.6   13.3 ± 0.0   65.0 ± 0.0   78.6 ± 0.0    29.4 ± 0.0       40.3 ± 0.1      39.8 ± 0.3\n     Layer-19        16.7 ± 0.0   13.3 ± 0.0   49.2 ± 2.4   77.8 ± 0.2    30.5 ± 0.3       42.1 ± 0.1      38.3 ± 0.4\n     Layer-20         0.0 ± 0.0    13.3 ± 0.0   62.5 ± 0.0   75.9 ± 0.1    30.1 ± 0.0       37.3 ± 0.1      36.5 ± 0.0\n     Layer-21        10.0 ± 0.0   13.3 ± 0.0   62.5 ± 0.0   78.5 ± 0.1    32.7 ± 0.0       39.1 ± 0.1      39.4 ± 0.0\n     Layer-22         8.9 ± 3.1    13.3 ± 0.0   59.2 ± 1.2   75.5 ± 0.2    27.3 ± 0.2       38.7 ± 0.1      37.1 ± 0.3\n     Layer-23         4.4 ± 1.6    23.3 ± 0.0   57.5 ± 0.0   60.4 ± 0.0    17.4 ± 0.2       25.1 ± 0.1      31.4 ± 0.3\n     Layer-24        16.7 ± 0.0   20.0 ± 0.0   49.2 ± 1.2   65.1 ± 0.1    18.6 ± 0.5       31.1 ± 0.3      33.4 ± 0.2\n     Layer-25        16.7 ± 0.0   23.3 ± 0.0   60.0 ± 0.0   77.0 ± 0.0    30.4 ± 0.2       37.5 ± 0.1      40.8 ± 0.0\n     Layer-26         6.7 ± 0.0    30.0 ± 0.0   60.0 ± 2.0   74.5 ± 0.2    27.6 ± 0.0       38.9 ± 0.1      39.6 ± 0.3\n     Layer-27        13.3 ± 0.0   17.8 ± 1.6   55.8 ± 1.2   72.5 ± 0.1    34.1 ± 0.3       38.6 ± 0.4      38.7 ± 0.3\n\n\n\n\n\n                                             13\n\n          Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n\n\n\n\n                    Table 5. Raw benchmark scores for Llama3.1-8b-It in Figure 9 (greedy decoding).\n\n      Setup       AIME25   AIME24   AMC23   MATH500   MinervaMath   OlympiadBench     Avg.\n\n   Base Model       0.0 ± 0.0   10.0 ± 0.0   27.5 ± 0.0   52.5 ± 0.0    20.5 ± 0.0       18.6 ± 0.0      21.5 ± 0.0\nBase Model. τ = 1   0.0 ± 0.0    0.0 ± 0.0    11.7 ± 2.4   34.6 ± 0.7    12.3 ± 1.5        9.6 ± 0.6      11.7 ± 0.5\n    Full-Tune        3.3 ± 0.0   14.4 ± 3.1   41.7 ± 2.4   57.7 ± 0.2    30.9 ± 0.6       22.3 ± 0.3      28.4 ± 0.7\n     Steering         0.0 ± 0.0   11.1 ± 5.7   35.0 ± 6.1   57.6 ± 1.9    29.9 ± 0.6       23.4 ± 0.5      25.8 ± 0.2\n     Layer-0         3.3 ± 0.0    6.7 ± 0.0    33.3 ± 1.2   53.7 ± 0.2    24.9 ± 0.2       19.6 ± 0.0      23.6 ± 0.2\n     Layer-1         6.7 ± 0.0    8.9 ± 1.6    35.8 ± 1.2   50.8 ± 0.0    27.5 ± 0.2       18.7 ± 0.2      24.7 ± 0.5\n     Layer-2         0.0 ± 0.0    3.3 ± 0.0    44.2 ± 1.2   51.6 ± 0.0    25.9 ± 0.2       20.0 ± 0.3      24.2 ± 0.2\n     Layer-3         0.0 ± 0.0    5.6 ± 1.6    32.5 ± 2.0   53.9 ± 0.1    28.9 ± 0.6       19.8 ± 0.1      23.5 ± 0.4\n     Layer-4         0.0 ± 0.0    6.7 ± 0.0    29.2 ± 1.2   53.1 ± 0.5    27.1 ± 0.2       18.2 ± 0.2      22.4 ± 0.3\n     Layer-5         0.0 ± 0.0   10.0 ± 0.0   36.7 ± 1.2   53.5 ± 0.1    27.2 ± 0.3       20.9 ± 0.1      24.7 ± 0.2\n     Layer-6         0.0 ± 0.0    6.7 ± 0.0    28.3 ± 1.2   54.4 ± 0.2    27.7 ± 0.2       18.3 ± 0.3      22.6 ± 0.2\n     Layer-7         6.7 ± 0.0    6.7 ± 0.0    37.5 ± 0.0   54.3 ± 0.3    28.1 ± 0.2       22.2 ± 0.2      25.9 ± 0.1\n     Layer-8         3.3 ± 0.0    3.3 ± 0.0    45.8 ± 1.2   50.7 ± 0.2    28.1 ± 0.2       22.0 ± 0.3      25.6 ± 0.3\n     Layer-9         3.3 ± 0.0   15.6 ± 1.6   30.0 ± 0.0   54.7 ± 0.2    27.9 ± 0.3       21.6 ± 0.2      25.5 ± 0.3\n     Layer-10        0.0 ± 0.0   13.3 ± 2.7   40.0 ± 0.0   56.8 ± 0.0    28.3 ± 0.3       20.9 ± 0.3      26.6 ± 0.4\n     Layer-11        0.0 ± 0.0   11.1 ± 1.6   30.0 ± 2.0   52.7 ± 0.1    29.0 ± 0.0       20.9 ± 0.1      24.0 ± 0.4\n     Layer-12        3.3 ± 0.0    4.4 ± 1.6    39.2 ± 1.2   56.7 ± 0.2    29.5 ± 0.3       23.9 ± 0.3      26.2 ± 0.4\n     Layer-13        3.3 ± 0.0    7.8 ± 1.6    25.0 ± 0.0   56.6 ± 0.0    29.3 ± 0.2       21.1 ± 0.2      23.8 ± 0.3\n     Layer-14        0.0 ± 0.0   10.0 ± 0.0   30.0 ± 0.0   55.4 ± 0.5    27.6 ± 0.0       22.3 ± 0.3      24.2 ± 0.1\n     Layer-15        6.7 ± 0.0    6.7 ± 0.0    38.3 ± 1.2   54.5 ± 0.2    29.2 ± 0.3       21.3 ± 0.1      26.1 ± 0.2\n     Layer-16        0.0 ± 0.0    6.7 ± 0.0    34.2 ± 1.2   52.5 ± 0.5    29.5 ± 0.2       18.9 ± 0.1      23.6 ± 0.2\n     Layer-17        0.0 ± 0.0    3.3 ± 0.0    37.5 ± 0.0   51.4 ± 0.3    26.3 ± 0.2       19.2 ± 0.3      23.0 ± 0.0\n     Layer-18        3.3 ± 0.0    7.8 ± 3.1    29.2 ± 1.2   51.1 ± 0.2    27.2 ± 0.3       19.9 ± 0.1      23.1 ± 0.7\n     Layer-19        0.0 ± 0.0    3.3 ± 0.0    32.5 ± 0.0   51.6 ± 0.3    24.4 ± 0.2       19.9 ± 0.2      21.9 ± 0.1\n     Layer-20        3.3 ± 0.0    6.7 ± 0.0    34.2 ± 1.2   54.6 ± 0.3    26.7 ± 0.2       17.8 ± 0.3      23.9 ± 0.1\n     Layer-21        3.3 ± 0.0    3.3 ± 0.0    25.8 ± 2.4   54.4 ± 0.2    27.3 ± 0.2       16.5 ± 0.1      21.8 ± 0.4\n     Layer-22        0.0 ± 0.0   10.0 ± 0.0   32.5 ± 0.0   53.0 ± 0.3    27.0 ± 0.2       22.4 ± 0.1      24.1 ± 0.0\n     Layer-23        0.0 ± 0.0    7.8 ± 1.6    30.0 ± 2.0   51.9 ± 0.3    29.9 ± 0.5       17.5 ± 0.2      22.8 ± 0.6\n     Layer-24        0.0 ± 0.0    3.3 ± 0.0    30.0 ± 0.0   51.5 ± 0.1    27.2 ± 0.0       16.8 ± 0.1      21.5 ± 0.0\n     Layer-25        0.0 ± 0.0   10.0 ± 0.0   29.2 ± 1.2   52.3 ± 0.2    24.3 ± 0.0       18.7 ± 0.1      22.4 ± 0.2\n     Layer-26        0.0 ± 0.0    4.4 ± 1.6    42.5 ± 0.0   52.8 ± 0.0    28.2 ± 0.2       17.3 ± 0.0      24.2 ± 0.3\n     Layer-27        0.0 ± 0.0    3.3 ± 0.0    34.2 ± 1.2   51.5 ± 0.2    27.1 ± 0.2       18.0 ± 0.1      22.3 ± 0.2\n     Layer-28        0.0 ± 0.0    4.4 ± 1.6    29.2 ± 1.2   50.3 ± 0.1    27.2 ± 0.3       16.6 ± 0.1      21.3 ± 0.1\n     Layer-29        0.0 ± 0.0    3.3 ± 0.0    36.7 ± 1.2   52.9 ± 0.1    28.1 ± 0.2       15.8 ± 0.1      22.8 ± 0.2\n     Layer-30        0.0 ± 0.0    6.7 ± 0.0    36.7 ± 4.7   52.3 ± 0.1    24.9 ± 0.2       18.2 ± 0.2      23.1 ± 0.7\n     Layer-31        0.0 ± 0.0   10.0 ± 0.0   28.3 ± 1.2   50.5 ± 0.3    25.1 ± 0.2       15.8 ± 0.1      21.6 ± 0.2\n\n\n\n\n\n                                            14\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nC. Ineffective Layers in Qwen2.5-Math-7B\n\nAs noted in Section 3, single-layer steering on layers 23 and 24 underperforms their neighbors. To pinpoint where this loss\narises, we trained vectors inserted immediately after each subcomponent between the layer-24 MLP and the layer-25 MLP.\nFigure 10 shows that placing s24 after the input LayerNorm of layer 25 closes the gap with s25. Thus the input LayerNorm\nis the problematic step – passing through it limits the effect of the steering vector.\n\n\n\n\n\n                                                                   38.2 ± 0.5   40                                               37.2 ± 0.6                                      36.2 ± 0.4                       35.2 ± 0.2\n\n   30\n        21.1 ± 2.2\n   20Performance\n   10\n\n    0\n      24       LN         Attn       LN       25    Layer        Input      25                      Layer           25         Layer          Post-Attn          Layer                25                                 Layer\n\nFigure 10. Steering of a specific component’s output. We trained steering vectors on intermediate component outputs between layers 24\n(where performance dropped) and 25 (where it recovered). Steering after the layer-25 input LayerNorm largely restored performance,\nindicating that the drop was mitigated once the intervention was carried past this normalization step.\n\n\n\n\n\n                                                15\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nD. Steering Vector Persistence. Raw Numbers\n\n\n\n\n\n                             Table 6. Qwen2.5-Math-7B. Raw scores for the plots in Figure 2 (top).\n\n                                                           Diff-Diff CosSim\n\n Layer  0   1    2    3    4    5    6    7    8    9    10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27\n\n   0   1  0.96  0.91  0.84  0.8  0.75  0.67  0.59  0.54  0.54  0.52  0.49  0.47  0.45  0.43  0.42  0.4  0.37  0.37  0.37  0.35  0.34  0.34  0.33  0.33  0.31  0.37  0.57\n   1       1   0.95  0.85  0.8  0.74  0.65  0.58  0.51  0.51  0.49  0.45  0.43  0.42  0.39  0.38  0.36  0.34  0.33  0.33  0.31  0.32  0.32  0.31  0.31  0.29  0.29  0.41\n   2            1   0.96  0.91  0.86  0.78  0.7  0.64  0.64  0.61  0.57  0.54  0.52  0.5  0.48  0.45  0.42  0.42  0.41  0.39  0.37  0.37  0.37  0.36  0.34  0.38  0.55\n   3                  1   0.93  0.87  0.78  0.69  0.64  0.63  0.61  0.57  0.55  0.53  0.51  0.49  0.47  0.44  0.43  0.41  0.39  0.37  0.35  0.34  0.32  0.3  0.32  0.57\n   4                       1   0.92  0.82  0.73  0.67  0.67  0.64  0.6  0.58  0.56  0.53  0.51  0.49  0.46  0.45  0.44  0.41  0.39  0.37  0.36  0.34  0.32  0.34  0.61\n   5                            1   0.88  0.77  0.71  0.69  0.66  0.62  0.59  0.56  0.53  0.51  0.49  0.46  0.44  0.43  0.4  0.38  0.37  0.36  0.35  0.32  0.36  0.62\n   6                                 1   0.82  0.72  0.7  0.65  0.61  0.58  0.55  0.52  0.5  0.47  0.44  0.44  0.42  0.39  0.38  0.36  0.35  0.33  0.32  0.33  0.59\n   7                                      1   0.85  0.81  0.74  0.67  0.63  0.6  0.56  0.54  0.51  0.47  0.46  0.45  0.41  0.39  0.38  0.37  0.35  0.33  0.36  0.64\n   8                                           1   0.87  0.77  0.69  0.64  0.6  0.56  0.54  0.51  0.47  0.46  0.45  0.41  0.4  0.38  0.37  0.36  0.33  0.36  0.64\n   9                                                 1   0.85  0.75  0.7  0.64  0.59  0.55  0.52  0.48  0.47  0.45  0.42  0.41  0.39  0.39  0.37  0.35  0.37  0.68\n  10                                                     1   0.85  0.76  0.69  0.64  0.6  0.57  0.52  0.51  0.49  0.46  0.45  0.43  0.42  0.39  0.37  0.4   0.7\n  11                                                          1   0.84  0.75  0.67  0.63  0.58  0.53  0.51  0.51  0.48  0.47  0.45  0.43  0.41  0.39  0.4  0.68\n  12                                                                1   0.85  0.76  0.71  0.66  0.58  0.56  0.55  0.52  0.5  0.48  0.48  0.45  0.44  0.44  0.72\n  13                                                                     1   0.86  0.78  0.72  0.63  0.6   0.6  0.58  0.56  0.54  0.52  0.49  0.47  0.48  0.73\n  14                                                                          1   0.86  0.77  0.66  0.63  0.63  0.6  0.59  0.56  0.55  0.51  0.5   0.5  0.71\n  15                                                                               1   0.85  0.74  0.68  0.67  0.64  0.62  0.59  0.59  0.55  0.55  0.56  0.75\n  16                                                                                    1    0.8  0.73  0.72  0.69  0.68  0.64  0.65  0.62  0.59  0.58  0.7\n  17                                                                                         1   0.81  0.73  0.67  0.64  0.6  0.62  0.58  0.57  0.55  0.57\n  18                                                                                              1   0.87  0.79  0.74  0.68  0.66  0.62  0.63  0.67  0.71\n  19                                                                                                    1   0.88  0.81  0.74  0.7  0.66  0.67  0.71  0.75\n  20                                                                                                         1    0.9  0.83  0.78  0.72  0.72  0.72  0.76\n  21                                                                                                              1    0.9  0.85  0.79  0.75  0.72  0.81\n  22                                                                                                                   1   0.93  0.86  0.81  0.72  0.66\n  23                                                                                                                        1    0.9  0.81  0.71  0.55\n  24                                                                                                                             1   0.83  0.74  0.49\n  25                                                                                                                                   1    0.9  0.92\n  26                                                                                                                                        1   0.92\n  27                                                                                                                                             1\n\n                                                       Diff-Vector CosSim\n\n\n Layer  0   1    2    3    4    5    6      7       8       9       10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27\n   0   1  0.31  0.33  0.29  0.24  0.23  0.18    0.14     0.12     0.11     0.11      0.1       0.1    9 · 10−2  8 · 10−2  7 · 10−2  7 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  4 · 10−2  2 · 10−2  2 · 10−2  2 · 10−2  4 · 10−2    0.12\n   1       1   0.33  0.3  0.17  0.16  0.12  9 · 10−2  9 · 10−2  8 · 10−2  8 · 10−2  8 · 10−2  7 · 10−2  7 · 10−2  6 · 10−2  6 · 10−2  6 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2  3 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2  3 · 10−2  8 · 10−2\n   2            1   0.55  0.47  0.38  0.3    0.23     0.19     0.18     0.18     0.15     0.14     0.13     0.11      0.1    9 · 10−2  7 · 10−2  7 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2  5 · 10−2  4 · 10−2  3 · 10−2  2 · 10−2  3 · 10−2    0.11\n   3                  1   0.56  0.44  0.32    0.26     0.23     0.22     0.21     0.18     0.17     0.16     0.14     0.13     0.11   8 · 10−2  8 · 10−2  7 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  3 · 10−2  5 · 10−2    0.12\n   4                       1   0.51  0.36    0.29     0.26     0.24     0.23     0.19     0.18     0.16     0.14     0.13     0.12   9 · 10−2  8 · 10−2  7 · 10−2  6 · 10−2  6 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  3 · 10−2  5 · 10−2    0.13\n   5                            1   0.43    0.32     0.26     0.25     0.23      0.2      0.17     0.16     0.13     0.13     0.12   8 · 10−2  8 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  3 · 10−2  5 · 10−2    0.13\n   6                                 1     0.43     0.32     0.28     0.25     0.22     0.19     0.18     0.14     0.13     0.12   9 · 10−2  8 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  3 · 10−2  4 · 10−2    0.12\n   7                                        1       0.48      0.4      0.34     0.28     0.24     0.21     0.17     0.16     0.14      0.1    9 · 10−2  8 · 10−2  6 · 10−2  6 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  3 · 10−2  5 · 10−2    0.14\n   8                                                1       0.47     0.37      0.3      0.25     0.22     0.18     0.16     0.14      0.1    9 · 10−2  7 · 10−2  5 · 10−2  6 · 10−2  6 · 10−2  6 · 10−2  5 · 10−2  3 · 10−2  5 · 10−2    0.14\n   9                                                        1       0.47     0.36     0.29     0.26      0.2      0.18     0.16     0.11      0.1    8 · 10−2  7 · 10−2  6 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  5 · 10−2    0.14\n  10                                                                1       0.51     0.38     0.32     0.24     0.21     0.18     0.13     0.12   9 · 10−2  7 · 10−2  7 · 10−2  7 · 10−2  7 · 10−2  7 · 10−2  4 · 10−2  6 · 10−2    0.15\n  11                                                                        1       0.49     0.39     0.29     0.26     0.21     0.13     0.12      0.1    7 · 10−2  7 · 10−2  7 · 10−2  8 · 10−2  7 · 10−2  4 · 10−2  7 · 10−2    0.14\n  12                                                                                1       0.56      0.4      0.31     0.24     0.16     0.13      0.1    7 · 10−2  7 · 10−2  8 · 10−2  8 · 10−2  7 · 10−2  4 · 10−2  7 · 10−2    0.15\n  13                                                                                        1       0.55     0.41      0.3       0.2      0.16     0.12   9 · 10−2  9 · 10−2  8 · 10−2  9 · 10−2  8 · 10−2  5 · 10−2  8 · 10−2    0.15\n  14                                                                                                 1       0.53     0.37     0.23     0.18     0.13     0.11      0.1    9 · 10−2  9 · 10−2  9 · 10−2  5 · 10−2  9 · 10−2    0.15\n  15                                                                                                         1       0.55     0.35     0.27     0.19     0.15     0.12     0.12     0.13     0.12   6 · 10−2    0.12     0.16\n  16                                                                                                                 1       0.44     0.29     0.19     0.13     0.11      0.1      0.11      0.1    5 · 10−2    0.1      0.15\n  17                                                                                                                         1       0.33     0.18     0.13     0.11   9 · 10−2    0.1       0.1    4 · 10−2  8 · 10−2    0.11\n  18                                                                                                                                 1       0.36     0.28      0.2      0.19     0.21     0.19      0.1       0.2      0.13\n  19                                                                                                                                          1       0.42     0.27     0.24     0.26     0.23     0.13     0.24     0.14\n  20                                                                                                                                                  1       0.41     0.36     0.35      0.3      0.18     0.26     0.15\n  21                                                                                                                                                          1       0.38     0.33     0.28     0.24     0.29     0.17\n  22                                                                                                                                                                  1       0.48     0.37     0.32     0.22     0.15\n  23                                                                                                                                                                          1       0.68     0.17     0.22      0.1\n  24                                                                                                                                                                                   1       0.17     0.22   7 · 10−2\n  25                                                                                                                                                                                           1       0.48     0.23\n  26                                                                                                                                                                                                   1       0.24\n  27                                                                                                                                                                                                           1\n\n\n                                                16\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n                            Table 7. Llama3.1-8B-It. Raw scores for the plots in Figure 2 (bottom).\n\n                                                          Diff-Diff CosSim\n\n\nLayer  0   1    2    3    4    5    6    7    8    9    10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31\n\n  0   1  0.84  0.68  0.55  0.46  0.38  0.34  0.31  0.3  0.29  0.26  0.24  0.27  0.34  0.35  0.37  0.4  0.42  0.43  0.46  0.44  0.46  0.46  0.46  0.45  0.45  0.46  0.46  0.44  0.42  0.53  0.57\n  1       1   0.77  0.61  0.51  0.42  0.36  0.32  0.29  0.28  0.25  0.24  0.25  0.33  0.34  0.36  0.4  0.43  0.45  0.47  0.45  0.48  0.48  0.49  0.48  0.47  0.48  0.48  0.47  0.44  0.62  0.57\n  2            1   0.74  0.61  0.5  0.44  0.38  0.34  0.32  0.29  0.27  0.28  0.33  0.33  0.36  0.38  0.41  0.42  0.44  0.43  0.45  0.45  0.45  0.44  0.44  0.44  0.46  0.45  0.43  0.58  0.56\n  3                  1   0.78  0.62  0.51  0.44  0.38  0.35  0.31  0.29  0.31  0.37  0.39  0.4  0.45  0.46  0.47  0.49  0.48  0.5   0.5  0.51  0.5  0.49  0.5   0.5   0.5  0.47  0.54  0.58\n  4                       1   0.75  0.61  0.5  0.44  0.38  0.33  0.3  0.31  0.43  0.44  0.47  0.51  0.52  0.53  0.55  0.53  0.56  0.56  0.58  0.56  0.55  0.56  0.55  0.54  0.5  0.53  0.53\n  5                            1   0.77  0.62  0.52  0.47  0.42  0.38  0.36  0.39  0.37  0.38  0.42  0.44  0.45  0.46  0.45  0.47  0.47  0.48  0.47  0.46  0.47  0.47  0.46  0.43  0.55  0.57\n  6                                 1    0.8  0.66  0.58  0.52  0.47  0.46  0.47  0.45  0.46  0.48  0.51  0.51  0.52  0.51  0.53  0.54  0.55  0.54  0.53  0.54  0.59  0.57  0.55  0.58  0.64\n  7                                      1   0.77  0.66  0.55  0.48  0.45  0.51  0.5  0.52  0.54  0.56  0.57  0.58  0.56  0.59  0.59  0.6  0.59  0.57  0.6  0.59  0.58  0.54  0.53  0.56\n  8                                           1   0.82  0.68  0.58  0.53  0.51  0.48  0.47  0.51  0.53  0.53  0.54  0.52  0.54  0.54  0.54  0.53  0.51  0.52  0.52  0.51  0.48  0.48  0.55\n  9                                                 1   0.82  0.7  0.62  0.58  0.55  0.53  0.55  0.57  0.56  0.56  0.55  0.57  0.57  0.58  0.56  0.55  0.55  0.55  0.53  0.5   0.5  0.59\n  10                                                     1   0.82  0.71  0.64  0.59  0.56  0.58  0.59  0.58  0.58  0.56  0.59  0.59  0.6  0.59  0.58  0.59  0.58  0.57  0.54  0.54  0.62\n  11                                                          1   0.85  0.76  0.67  0.6   0.6  0.59  0.57  0.55  0.53  0.56  0.56  0.56  0.54  0.53  0.53  0.52  0.51  0.49  0.5  0.59\n  12                                                                1   0.83  0.71  0.64  0.64  0.63  0.61  0.6  0.58  0.6   0.6   0.6  0.58  0.56  0.57  0.56  0.55  0.52  0.52  0.58\n  13                                                                     1   0.83  0.74  0.7  0.67  0.64  0.63  0.6  0.63  0.63  0.64  0.62  0.61  0.62  0.61  0.61  0.57  0.55  0.56\n  14                                                                          1   0.81  0.74  0.71  0.68  0.66  0.63  0.65  0.64  0.64  0.62  0.61  0.6  0.59  0.58  0.54  0.54  0.59\n  15                                                                               1   0.88  0.8  0.75  0.7  0.66  0.65  0.63  0.62  0.59  0.57  0.57  0.56  0.55  0.53  0.55  0.59\n  16                                                                                    1   0.86  0.79  0.74  0.69  0.67  0.65  0.62  0.59  0.57  0.57  0.56  0.55  0.52  0.59  0.59\n  17                                                                                         1    0.9  0.84  0.78  0.74  0.72  0.69  0.66  0.63  0.61  0.6  0.61  0.58  0.66  0.65\n  18                                                                                              1   0.91  0.85  0.8  0.77  0.73  0.7  0.68  0.66  0.64  0.64  0.61  0.66  0.66\n  19                                                                                                    1   0.91  0.85  0.8  0.77  0.73  0.7  0.67  0.66  0.65  0.63  0.66  0.62\n  20                                                                                                         1   0.91  0.86  0.82  0.77  0.74  0.71  0.69  0.68  0.65  0.71  0.69\n  21                                                                                                              1   0.93  0.88  0.84  0.81  0.78  0.76  0.75  0.71  0.75  0.67\n  22                                                                                                                   1   0.95  0.9  0.87  0.84  0.81  0.8  0.75  0.76  0.67\n  23                                                                                                                        1   0.94  0.89  0.86  0.83  0.82  0.76  0.77  0.7\n  24                                                                                                                             1   0.92  0.88  0.85  0.83  0.77  0.78  0.68\n  25                                                                                                                                   1   0.93  0.88  0.81  0.75  0.73  0.6\n  26                                                                                                                                        1   0.92  0.8  0.73  0.71  0.62\n  27                                                                                                                                             1    0.9  0.81  0.74  0.7\n  28                                                                                                                                                  1   0.86  0.81  0.66\n  29                                                                                                                                                       1   0.87  0.72\n  30                                                                                                                                                            1   0.78\n  31                                                                                                                                                                 1\n\n                                                       Diff-Vector CosSim\n\n\nLayer  0   1    2      3       4       5       6       7       8       9       10      11      12      13      14      15      16      17      18      19      20      21      22      23      24      25      26      27       28       29      30      31\n  0   1  0.17  0.13  8 · 10−2  5 · 10−2  3 · 10−2  3 · 10−2  3 · 10−2  3 · 10−2  1 · 10−2  1 · 10−2  1 · 10−2  3 · 10−2  5 · 10−2  5 · 10−2  5 · 10−2  5 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2  1 · 10−2     0        0        0.1    2 · 10−2\n  1       1   0.18    0.1    6 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2  1 · 10−2  1 · 10−2  1 · 10−2  3 · 10−2  5 · 10−2  5 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  4 · 10−2  4 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2  1 · 10−2     0        0       0.15   1 · 10−2\n  2            1      0.2      0.11   7 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  2 · 10−2  2 · 10−2  2 · 10−2  3 · 10−2  5 · 10−2  5 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2  5 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2     0        0       0.13   1 · 10−2\n  3                   1       0.19      0.1    7 · 10−2  6 · 10−2  5 · 10−2  3 · 10−2  2 · 10−2  2 · 10−2  4 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  4 · 10−2  5 · 10−2  3 · 10−2  3 · 10−2  4 · 10−2  4 · 10−2  3 · 10−2  2 · 10−2  1 · 10−2     0        0        0.1    2 · 10−2\n  4                           1       0.21     0.13   9 · 10−2  7 · 10−2  5 · 10−2  3 · 10−2  3 · 10−2  5 · 10−2  7 · 10−2  6 · 10−2  7 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  5 · 10−2  3 · 10−2  3 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2  1 · 10−2 −1 · 10−2    0    6 · 10−2  1 · 10−2\n  5                                    1       0.21     0.15   9 · 10−2  7 · 10−2  6 · 10−2  4 · 10−2  5 · 10−2  7 · 10−2  6 · 10−2  7 · 10−2  7 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2  2 · 10−2  1 · 10−2     0        0       0.11   2 · 10−2\n  6                                            1       0.25     0.12   9 · 10−2  8 · 10−2  4 · 10−2  6 · 10−2  7 · 10−2  7 · 10−2  8 · 10−2  8 · 10−2  8 · 10−2  7 · 10−2  6 · 10−2  7 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  3 · 10−2  3 · 10−2  2 · 10−2     0    6 · 10−2  2 · 10−2\n  7                                                    1       0.24     0.17     0.12   8 · 10−2  9 · 10−2    0.1    8 · 10−2  9 · 10−2  9 · 10−2  8 · 10−2  7 · 10−2  5 · 10−2  6 · 10−2  4 · 10−2  4 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2  2 · 10−2  2 · 10−2     0     1 · 10−2  5 · 10−2  2 · 10−2\n  8                                                            1       0.28     0.16      0.1      0.12      0.1    9 · 10−2  9 · 10−2    0.1    9 · 10−2  8 · 10−2  6 · 10−2  7 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  2 · 10−2  2 · 10−2  1 · 10−2  1 · 10−2  6 · 10−2  2 · 10−2\n  9                                                                    1       0.27     0.19     0.17     0.12     0.11     0.11     0.11   9 · 10−2  8 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  2 · 10−2  2 · 10−2  1 · 10−2  1 · 10−2  6 · 10−2  2 · 10−2\n 10                                                                            1       0.21     0.17     0.12     0.12     0.12     0.11      0.1    9 · 10−2  7 · 10−2  7 · 10−2  5 · 10−2  5 · 10−2  6 · 10−2  5 · 10−2  5 · 10−2  3 · 10−2  2 · 10−2     0     1 · 10−2  6 · 10−2  2 · 10−2\n 11                                                                                    1       0.24      0.2      0.16     0.14     0.12      0.1    9 · 10−2  8 · 10−2  7 · 10−2  6 · 10−2  6 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  2 · 10−2  3 · 10−2  1 · 10−2  2 · 10−2  7 · 10−2  2 · 10−2\n 12                                                                                            1       0.25     0.21     0.17     0.15     0.12      0.1    9 · 10−2  9 · 10−2  7 · 10−2  6 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  3 · 10−2  3 · 10−2  1 · 10−2  2 · 10−2  7 · 10−2  2 · 10−2\n 13                                                                                                     1       0.27     0.19     0.18     0.14     0.12      0.1    9 · 10−2  7 · 10−2  7 · 10−2  7 · 10−2  6 · 10−2  5 · 10−2  3 · 10−2  2 · 10−2  1 · 10−2  2 · 10−2  7 · 10−2  2 · 10−2\n 14                                                                                                             1       0.29     0.22     0.15     0.13     0.12     0.12   9 · 10−2  8 · 10−2  8 · 10−2  7 · 10−2  6 · 10−2  4 · 10−2  3 · 10−2  2 · 10−2  2 · 10−2  8 · 10−2  2 · 10−2\n 15                                                                                                                     1       0.28     0.21     0.17     0.15     0.14     0.12      0.1       0.1    9 · 10−2  7 · 10−2  5 · 10−2  4 · 10−2  3 · 10−2  3 · 10−2    0.1    2 · 10−2\n 16                                                                                                                             1       0.29     0.25     0.19     0.17     0.15     0.13     0.13     0.11   8 · 10−2  6 · 10−2  5 · 10−2  4 · 10−2  4 · 10−2    0.15   3 · 10−2\n 17                                                                                                                                     1       0.35     0.28     0.25     0.22     0.19      0.2      0.16     0.13     0.11   9 · 10−2  8 · 10−2  7 · 10−2    0.18   3 · 10−2\n 18                                                                                                                                              1       0.36     0.31     0.28     0.22     0.23     0.21     0.14      0.1       0.1    9 · 10−2  7 · 10−2    0.18   4 · 10−2\n 19                                                                                                                                                      1       0.36     0.31     0.29     0.23     0.21     0.16     0.11      0.1        0.1    8 · 10−2    0.18   5 · 10−2\n 20                                                                                                                                                              1       0.44     0.33     0.32     0.31     0.19     0.15     0.12      0.13    8 · 10−2    0.2    5 · 10−2\n 21                                                                                                                                                                      1       0.46     0.43     0.41     0.24     0.19     0.17      0.17    9 · 10−2    0.2    5 · 10−2\n 22                                                                                                                                                                              1       0.49     0.47      0.3      0.23     0.22       0.2       0.12     0.24   7 · 10−2\n 23                                                                                                                                                                                      1       0.57     0.34     0.28     0.23      0.21      0.12     0.24   6 · 10−2\n 24                                                                                                                                                                                               1       0.38     0.32     0.29      0.25      0.12     0.25   6 · 10−2\n 25                                                                                                                                                                                                       1        0.3      0.21      0.17      0.11     0.17   4 · 10−2\n 26                                                                                                                                                                                                               1        0.3       0.18       0.1      0.17   5 · 10−2\n 27                                                                                                                                                                                                                       1        0.26      0.15      0.2       0.1\n 28                                                                                                                                                                                                                                1        0.27      0.3    7 · 10−2\n 29                                                                                                                                                                                                                                         1        0.3    6 · 10−2\n 30                                                                                                                                                                                                                                                 1       0.22\n 31                                                                                                                                                                                                                                                          1\n\n\n\n\n\n                                               17\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nE. Steering Vector Persistence. Mean shift alignment on the last layer. Llama3.1-8B-It\n\n                                                                                        1.0                     0\n                     2\n                     4\n                     6\n                     8                                                              0.8\n                    10\n                    12\n                    14\n                                                                                        0.6                            Layer16                                                                                                                                                     CosSim\n                    18\n                    20\n                                                                                        0.4                    22\n                    24\n                    26                                                                                        0.2\n                    28\n                    30\n                       0  2  4  6  8  10 12 14 16 18 20 22 24 26 28 30\n                                            Layer\n\nFigure 11. Similarity of steering-induced unembedding biases (Llama3.1-8B-It). Each cell shows the cosine similarity between the\naverage hidden-state shift at the final transformer layer induced by steering at layers i and j. High similarity among i, j < L indicates\nthat steering from most layers produces a similar bias at the unembedding, largely independent of the injection point. In contrast, steering\nat the last layer directly yields a qualitatively different shift, implying a distinct mechanism.\n\n\nF. Orthogonal Steering Vectors\n\n                         Original             First Ortho         Second Ortho\n                       Vector            Vector              Vector                      40.0                                39.2          40\n                               30.1\n          30                                                  27.4\n                                         23.2\n                                                                            20.9\n          20                           Performance          10\n\n           0\n                         Layer-14                       Layer-15\n\n\nFigure 12. Orthogonal steering vectors. Performance of three mutually orthogonal steering vectors trained at layers 14 and 15. Contrary\nto the findings of Jacob & Turner (2024) in our setup the orthogonal vectors do not achieve comparable performance: accuracy decreases\nmonotonically as additional orthogonal vectors are trained.\n\n\n\n                                                18\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nG. Last Layer. Logit Lens\n\n\nTable 8. Last Layer – logit-lens. Cosine similarities and dot-product scores between the last-layer steering vector (trained in isolation)\nand the unembedding vectors of the top-10 tokens for Qwen2.5-Math-7B and Llama3.1-8B-It.\n\n                                               Qwen2.5-Math-7B\n\n                    To      ]     To     So     to       \\       }    For   .To    -to\n\n             Cos. Sim.    0.37     0.16     0.16     0.15     0.14     0.14     0.13     0.13    0.12     0.12\n           Dot Prod.    42.5    19.12    18.62    19.12    16.88    19.75    15.69    14.19    17.0    18.62\n\n\n                                                      Llama3.1-8B-It\n\n           final   Step   format   Final   final   final   Steps   Final    final   solution\n\n  Cos. Sim.       0.12      0.11        0.09       0.09       0.08       0.08       0.08       0.08        0.08           0.08\n  Dot Prod.       1.69      1.32        1.17       1.09       0.71       1.01       1.02       0.93        0.83           0.95\n\n\nH. Last Layer Steering. Open-s1 dataset\n\n\n                                                                              Base          Base + \"To\"            Last Steering\n                                                                                                                   40.8\n                                                                  40    0.8                                                                                                  35.5\n    0.6                                                            30     24.8                                         25.5      28.2Difference\n    0.4                                                            20                                         14.3    0.2                                                                                                                                                                                                               Performance10Probability    0.0                                                                   0\n            \"To\"       \" To\"        \")\"         \").\"         \".\"        \"To\"                         Greedy                      Sampling\n                                                              at Pos. 0\n\n                                               Qwen2.5-Math-7B\n\n                                                                              Base         Base + \"Step\"           Last Steering\n                                                                                                         22.4                                                                                                21.5\n                                                                  20                        18.2\n    0.6\n                                                                  15                                                  13.4      13.8Difference                                                                                                                               11.7    0.4\n                                                                  10    0.2                                                                                                                                                                                                               Performance\n                                                                   5Probability    0.0                                                                   0\n          \"Step\"    \" step\"    \" final\"    \" Step\"     \" the\"    \"Step\"                        Greedy                      Sampling\n                                                              at Pos. 0\n\n                                                      Llama3.1-8B-It\n\nFigure 13. Last-layer steering vector. Left: distribution of token-level probability change induced by the last-layer vector over 1000\nOpen-s1 prompts. We include the top-5 tokens by maximum change and highlight the most affected token at the zeroth generation position.\nRight: prefixing this token to each prompt reproduces a substantial fraction of the vector’s accuracy gain under both greedy decoding and\n sampling.\n\n\n I. Value Steering Adds a Linear Term to MHA\n\nThe following derivation holds when we ignore the pre-attention LayerNorm (LN). While this is a strong assumption – that\nLN does not alter the steering vector’s trajectory – the experiment in Section 6 shows that a post-attention steering vector\n attains the same performance as a pre-attention one, indicating that the pre-attention vector indeed does not act through\n attention.\n\n                                                19\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nClaim. Let U ∈RT ×dmodel and define the (row-wise) attention\n\n                                  Q   K  !                       UW i (UW i )⊤      ×T\n                    A(U) = Softmax      √dk     ∈RT     ,  A(U)1 = 1.\n\nFor head i,\n                                    Hi(U) = A(U) UWiV .\nLet a steering vector s ∈Rdmodel be added to the values of head i for every token, and set S = 1s⊤∈RT ×dmodel. Then\n\n                           H(+s)i   (U) = A(U) (U + S)WiV\n                       = A(U)UWiV + A(U)SWiV\n                       = Hi(U) + SW iV     (since A(U)1 = 1).\n\n          W 1O \n                           · ·Writing W O =                              · by heads, the multi-head output satisfies                       O\n        W h\n\n                       MHA(U + S) = MHA(U) + S WiV W iO\n\nand is independent of the attention pattern.\n\nJ. Unnormalized Transfer Performance\n\nTable 9. Transferability of steering vectors within the Qwen2.5 family. Each cell shows the mean performance change when the\nsteering vector trained for the Donor model is applied to the Recipient model. The ”None” column denotes the non-trained models’\nperformance. Llama3.1-8B∗denotes the transferring experiments where we used ”Qwen-Math” template for Llama3.1-8B-Instruct as in\nthe main experiments.\n\n                                                      Donor\n\n            Family         Recipient     None         Base         Instruct      Math\n\n                           Base        0.52 ± 0.12   22.72 ± 0.53   9.02 ± 1.66    7.57 ± 0.67\n            Qwen2.5-1.5B   Instruct     13.44 ± 1.17   23.22 ± 0.35   23.82 ± 0.28   16.64 ± 0.27\n                         Math       11.33 ± 1.09   19.48 ± 1.18   16.09 ± 1.48   34.11 ± 0.28\n\n                           Base       12.04 ± 5.85   36.44 ± 0.15   20.78 ± 3.43   30.0 ± 0.14\n            Qwen2.5-7B     Instruct     35.82 ± 0.14   37.51 ± 0.44   38.89 ± 0.27   34.78 ± 0.07\n                         Math       14.33 ± 1.75   23.42 ± 1.76   15.84 ± 1.96   42.82 ± 0.25\n\n                           Base        0.91 ± 0.11    9.18 ± 0.22    3.24 ± 0.27    —\n            Llama3.1-8B\n                                  Instruct      3.33 ± 0.16   17.03 ± 0.34   21.76 ± 0.29   —\n\n                           Base        0.91 ± 0.11    9.18 ± 0.22    0.95 ± 0.11    —\n            Llama3.1-8B∗\n                                  Instruct     11.81 ± 0.43   11.66 ± 0.46   26.14 ± 0.43   —\n\n\n\n\n\n                                                20\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n\nTable 10. Transferability of steering vectors within the Qwen2.5 family – AIME24. Each cell shows the performance change when\nthe steering vector trained for the Donor model is applied to the Recipient model. The ”None” column denotes the non-trained models’\nperformance. Llama3.1-8B∗denotes the transferring experiments where we used ”Qwen-Math” template for Llama3.1-8B-Instruct as in\nthe main experiments.\n\n                                                      Donor\n\n            Family         Recipient     None         Base        Instruct      Math\n\n                           Base          0.0 ± 0.0     2.81 ± 0.09   1.70 ± 0.10    0.73 ± 0.0\n             Qwen2.5-1.5B   Instruct      0.83 ± 0.09    2.60 ± 0.0    3.30 ± 0.13   0.87 ± 0.05\n                         Math        2.92 ± 0.0    5.21 ± 0.09   4.83 ± 0.05   12.08 ± 0.0\n\n                           Base        4.44 ± 6.29   12.78 ± 0.05   6.77 ± 0.0    8.78 ± 0.13\n            Qwen2.5-7B     Instruct     11.11 ± 0.18   13.65 ± 0.0   14.79 ± 0.0   10.87 ± 0.13\n                         Math        6.70 ± 0.18   11.11 ± 0.13   8.06 ± 0.18   24.31 ± 0.20\n\n                           Base         0.10 ± 0.0    0.28 ± 0.13   0.24 ± 0.05   —\n             Llama3.1-8B\n                                   Instruct      0.45 ± 0.10    1.08 ± 0.05   6.63 ± 0.05   —\n\n\n\nTable 11. Transferability of steering vectors within the Qwen2.5 family – AIME25. Each cell shows the performance change when\nthe steering vector trained for the Donor model is applied to the Recipient model. The ”None” column denotes the non-trained models’\nperformance. Llama3.1-8B∗denotes the transferring experiments where we used ”Qwen-Math” template for Llama3.1-8B-Instruct as in\nthe main experiments.\n\n                                                      Donor\n\n             Family         Recipient    None        Base        Instruct      Math\n\n                            Base        0.10 ± 0.00   1.46 ± 0.00   1.35 ± 0.09   0.10 ± 0.00\n              Qwen2.5-1.5B   Instruct     0.31 ± 0.09   1.60 ± 0.05   2.15 ± 0.05   0.83 ± 0.09\n                          Math       1.81 ± 0.10   2.53 ± 0.05   2.57 ± 0.13   8.12 ± 0.09\n\n                            Base        0.00 ± 0.00   7.12 ± 0.32   3.54 ± 0.15   5.49 ± 0.05\n             Qwen2.5-7B     Instruct     6.74 ± 0.13   7.19 ± 0.09   8.72 ± 0.05   4.38 ± 0.09\n                          Math       1.74 ± 0.13   4.41 ± 0.18   3.23 ± 0.00   12.64 ± 0.26\n\n                            Base        0.00 ± 0.00   0.28 ± 0.05   0.10 ± 0.00   —\n              Llama3.1-8B\n                                    Instruct     0.07 ± 0.05   0.62 ± 0.00   1.88 ± 0.15   —\n\n\n\nTable 12. Transferability of steering vectors within the Qwen2.5 family – AMC-23. Each cell shows the performance change when\nthe steering vector trained for the Donor model is applied to the Recipient model. The ”None” column denotes the non-trained models’\nperformance. Llama3.1-8B∗denotes the transferring experiments where we used ”Qwen-Math” template for Llama3.1-8B-Instruct as in\nthe main experiments.\n\n                                                      Donor\n\n           Family         Recipient     None         Base         Instruct      Math\n\n                          Base         0.73 ± 0.10    33.91 ± 0.11   11.61 ± 0.13   8.49 ± 0.21\n            Qwen2.5-1.5B   Instruct     16.64 ± 0.36   33.91 ± 0.17   31.82 ± 0.13   21.90 ± 0.10\n                        Math        18.41 ± 0.16   32.08 ± 0.39   26.54 ± 0.21   48.96 ± 0.16\n\n                          Base       17.50 ± 12.42   49.90 ± 0.13   32.45 ± 0.27   41.02 ± 0.33\n           Qwen2.5-7B     Instruct     50.29 ± 0.16   50.39 ± 0.17   54.24 ± 0.15   46.25 ± 0.33\n                        Math        21.30 ± 0.38   35.60 ± 0.42   25.57 ± 0.37   62.14 ± 0.30\n\n                          Base         0.94 ± 0.11    8.83 ± 0.06    2.81 ± 0.39    —\n            Llama3.1-8B\n                                 Instruct      4.84 ± 0.34    22.60 ± 0.22   24.92 ± 0.19   —\n\n\n\n                                                21\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\n\nTable 13. Transferability of steering vectors within the Qwen2.5 family – MATH-500. Each cell shows the performance change when\nthe steering vector trained for the Donor model is applied to the Recipient model. The ”None” column denotes the non-trained models’\nperformance. Llama3.1-8B∗denotes the transferring experiments where we used ”Qwen-Math” template for Llama3.1-8B-Instruct as in\nthe main experiments.\n\n                                                      Donor\n\n           Family         Recipient     None         Base         Instruct       Math\n\n                          Base         1.20 ± 0.28    56.80 ± 0.75   20.80 ± 5.58   21.87 ± 2.19\n           Qwen2.5-1.5B   Instruct     39.93 ± 5.32   57.60 ± 1.18   61.13 ± 1.04   46.33 ± 1.24\n                        Math        24.00 ± 4.14   44.40 ± 3.10   31.87 ± 5.03   71.47 ± 0.93\n\n                          Base       30.00 ± 11.75   74.07 ± 0.62   48.00 ± 11.54   66.33 ± 2.35\n           Qwen2.5-7B     Instruct     74.40 ± 1.18   76.20 ± 0.71   78.40 ± 1.56   74.80 ± 0.59\n                        Math        37.67 ± 6.09   54.00 ± 4.14   37.80 ± 7.11   80.20 ± 0.33\n\n                          Base         1.87 ± 0.25    26.13 ± 1.06   11.33 ± 1.47    —\n           Llama3.1-8B\n                                 Instruct      7.33 ± 0.66    44.47 ± 0.41   55.00 ± 0.33    —\n\n\n\nTable 14. Transferability of steering vectors within the Qwen2.5 family – Minerva-Math. Each cell shows the performance change\nwhen the steering vector trained for the Donor model is applied to the Recipient model. The ”None” column denotes the non-trained\nmodels’ performance. Llama3.1-8B∗denotes the transferring experiments where we used ”Qwen-Math” template for Llama3.1-8B-\nInstruct as in the main experiments.\n\n                                                      Donor\n\n            Family         Recipient     None         Base         Instruct      Math\n\n                           Base        0.61 ± 0.17   18.75 ± 2.38   7.60 ± 2.29    5.27 ± 0.35\n            Qwen2.5-1.5B   Instruct      9.68 ± 1.05   19.49 ± 1.08   20.59 ± 1.83   13.24 ± 0.79\n                         Math        5.39 ± 1.71    9.56 ± 2.96    9.44 ± 2.72   27.70 ± 1.05\n\n                           Base        7.11 ± 2.88   37.13 ± 0.60   12.99 ± 2.44   25.74 ± 1.50\n            Qwen2.5-7B     Instruct     35.54 ± 1.42   37.75 ± 1.54   35.54 ± 0.87   34.68 ± 0.46\n                         Math        8.33 ± 1.51   11.52 ± 2.55   7.84 ± 0.96   34.44 ± 1.76\n\n                           Base        1.47 ± 0.52   12.62 ± 0.35   3.19 ± 0.69    —\n            Llama3.1-8B\n                                  Instruct      4.41 ± 0.60   18.87 ± 1.05   21.20 ± 1.48   —\n\n\n\nTable 15. Transferability of steering vectors within the Qwen2.5 family – OlympiadBench. Each cell shows the performance change\nwhen the steering vector trained for the Donor model is applied to the Recipient model. The ”None” column denotes the non-trained\nmodels’ performance. Llama3.1-8B∗denotes the transferring experiments where we used ”Qwen-Math” template for Llama3.1-8B-\nInstruct as in the main experiments.\n\n                                                      Donor\n\n            Family         Recipient     None         Base         Instruct      Math\n\n                           Base        0.44 ± 0.32   22.62 ± 0.55   11.06 ± 3.98   8.99 ± 1.48\n            Qwen2.5-1.5B   Instruct     13.23 ± 1.14   24.10 ± 0.60   24.00 ± 1.05   16.64 ± 0.18\n                         Math       15.46 ± 0.85   23.11 ± 1.19   21.28 ± 1.39   36.35 ± 0.69\n\n                           Base       13.19 ± 6.40   37.63 ± 0.44   20.94 ± 6.50   32.64 ± 1.84\n            Qwen2.5-7B     Instruct     36.84 ± 0.18   39.90 ± 0.74   41.68 ± 0.30   37.73 ± 0.55\n                         Math       10.22 ± 2.94   23.85 ± 4.39   12.54 ± 3.34   43.21 ± 0.14\n\n                           Base        0.54 ± 0.14    7.21 ± 0.28    1.78 ± 0.64    —\n            Llama3.1-8B\n                                  Instruct      2.86 ± 0.62   14.52 ± 0.74   20.94 ± 0.07   —\n\n\n\n                                                22\n\n              Small Vectors, Big Effects: A Mechanistic Study of RL-Induced Reasoning via Steering Vectors\n\nK. Chat Templates\n\nFollowing Liu et al. (2025b), we used two chat templates. For models that support special chat-template tokens, we\nadopted the Qwen-Math template; special tokens for Qwen2.5-Math-7B are shown as a representative example. For\nLlama3.1-8B – which does not include pretrained special chat-template tokens – we used the R1 template.\n\n   Chat Template – Qwen-Math\n\n   <|im start|>system Please reason step by step, and put your final\n   answer within \\boxed{}.<|im end|> <|im start|>user TASK<|im end|>\n   <|im start|>assistant\n\n\n   Chat Template – R1\n\n   A conversation between User and Assistant.  The User asks a question, and\n   the Assistant solves it.  The Assistant first thinks about the reasoning\n   process in the mind and then provides the User with the answer.  The\n   reasoning process is enclosed within <think> </think> and answer is\n   enclosed within <answer> </answer> tags, respectively, i.e., <think>\n   reasoning process here </think> <answer> answer here </answer>.  \\nUser:\n   TASK\\nAssistant:  <think>\n\n\nL. LLM Use\n\nWe used ChatGPT to check grammar and clarity during the writing of this paper.\n\n\n\n\n\n                                                23\n\n## Claim to Classify\n\"the penultimate-layer vector operates through the MLP and unembedding preferentially up-weighting process words\"\nLocation in paper: body\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Steering vectors (activation engineering) with path patching/ablation analysis",
    "method_rung": 2,
    "claim_rung": 2,
    "confidence": 4,
    "hedge_flag": 0,
    "reasoning": "The claim 'the penultimate-layer vector operates through the MLP and unembedding preferentially up-weighting process words' is from a section analyzing penultimate-layer steering vectors using path patching (steering specific projections) and ablation (Skip-Attn, Skip-Layer). The methods involve interventions (patching vectors into specific components) to measure causal effects on performance, which is Rung 2 (Interventional). The claim uses language like 'operates through' and 'preferentially up-weighting' which describes a causal mechanism (how the vector affects the model's behavior via specific components). This is a causal claim about the vector's effect, not a uniqueness or full mechanistic explanation claim (Rung 3). There is no hedge present. Confidence is 4 because the claim is clearly causal but there is minor ambiguity about whether 'operates through' implies a full mechanistic explanation; however, the context suggests it's describing the causal pathway identified via interventions."
  },
  "metadata": {
    "model": "deepseek/deepseek-v3.2",
    "usage": {
      "prompt_tokens": 40704,
      "completion_tokens": 262,
      "total_tokens": 40966
    },
    "finish_reason": "stop"
  }
}