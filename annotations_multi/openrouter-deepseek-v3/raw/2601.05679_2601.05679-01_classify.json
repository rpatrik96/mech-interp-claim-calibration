{
  "timestamp": "2026-02-19T11:54:05.919745+00:00",
  "paper_id": "2601.05679",
  "claim_id": "2601.05679-01",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2601.05679\nTitle: Falsifying SAE Reasoning Features in Language Models\nFull text:\n           Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n\n\n                          George Ma 1 Zhongyuan Liang 1 2 Irene Y. Chen 1 2 Somayeh Sojoudi 1\n\n\n                         Abstract                             capabilities are often enabled by chain-of-thought (CoT)\n                                                               prompting and other inference-time strategies, which en-          We study how  reliably  sparse autoencoders\n                                                                 courage LLMs to generate intermediate reasoning traces             (SAEs) support claims about reasoning-related\n                                                                              prior to producing a final answer (Wei et al., 2022; Yao et al.,                 internal features in large language models. We\n                                                                    2023). Motivated by these advances, a growing body of                     first give a stylized analysis showing that sparsity-\n                                                          work has explored mechanistic interpretability approaches                regularized decoding can preferentially retain sta-\n                                                                              to identify and interpret the internal representations underly-2026         ble low-dimensional correlates while suppressing                                                                      ing reasoning in LLMs (Chen et al., 2025; Li et al., 2025b).               high-dimensional within-behavior variation, mo-\n                 tivating the possibility that contrastively selected     A prominent interpretability approach in this area is theFeb        “reasoning” features may concentrate on cue-like        use of sparse autoencoders (SAEs). SAEs learn sparse de-\n                 structure when such cues are coupled with reason-        compositions that disentangle polysemantic neuron activa-8\n               ing traces. Building on this perspective, we pro-          tions into more monosemantic and human-interpretable fea-\n              pose a falsification-based evaluation framework          tures (Bricken et al., 2023; Templeton et al., 2024). When\n                 that combines causal token injection with LLM-        studying reasoning with SAEs, many prior works rely on\n              guided counterexample construction. Across 22         contrastive methods to identify reasoning features. In this\n                configurations spanning multiple model families,        paradigm, SAE features are evaluated on contrastive datasets\n                 layers, and reasoning datasets, we find that many         constructed from reasoning and non-reasoning text (e.g.,[cs.LG]\n                 contrastively selected candidates are highly sensi-      CoT responses versus direct answers), and features exhibit-\n                 tive to token-level interventions, with 45%–90%         ing large activation differences are interpreted as reasoning\n                activating after injecting only a few associated          features that encode reasoning processes (Chen et al., 2025;\n               tokens into non-reasoning text. For the remaining         Galichin et al., 2025; Venhoff et al., 2025; Li et al., 2025b).\n               context-dependent candidates, LLM-guided falsi-\n                                                                   Despite their widespread use, these contrastive activation-                 fication produces targeted non-reasoning inputs\n                                                                based methods suffer from fundamental ambiguities. Be-                 that trigger activation and meaning-preserving\n                                                                  cause CoT responses differ systematically from direct an-               paraphrases of top-activating reasoning traces that\n                                                                 swers not only in their underlying reasoning processes but               suppress it. A small steering study yields minimal\n                                                                         also in surface lexical usage and stylistic patterns, features              changes on the evaluated benchmarks. Overall,\n                                                                  with large activation differences may reflect shallow lex-              our results suggest that, in the settings we study,\n                                                                                 ical confounds, such as recurring discourse tokens (e.g.,                sparse decompositions can favor low-dimensional\n                                                                       Wait, But, Let) rather than the model’s internal reasoning                correlates that co-occur with reasoning, under-\n                                                                   computations. Therefore, activation differences alone are                scoring the need for falsification when attributing\n                                                                               insufficient to determine whether an SAE feature capturesarXiv:2601.05679v6         high-level behaviors to individual SAE features.                                                                  genuine reasoning behavior.            Code is available at https://github.com/\n           GeorgeMLP/reasoning-probing.             To address this ambiguity, we present a theoretical analysis\n                                                               showing that sparsity in SAE decoding can induce an asym-\n                                                               metry between low- and high-dimensional structure. In a\n          1. Introduction                                            stylized setting where a high-level behavior admits many\n                                                                     semantically equivalent realizations but co-occurs with a\n         Recent advances in large language models (LLMs) have                                                                              stable low-dimensional lexical cue, sparse decoding can pre-\n          demonstrated strong performance on tasks that require multi-                                                                      serve the cue coordinate while suppressing the remaining\n           step reasoning (Huang et al., 2024; Ahn et al., 2024). These                                                                           distributed variation. Notably, we do not treat lexical pat-\n                                                                              terns and reasoning as opposing: they are often coupled, and           1UC Berkeley 2UCSF. Correspondence  to:  George Ma\n          <george ma@berkeley.edu>.                                      sparsity can cause SAE features to preferentially capture the\n                                                                   low-dimensional part of that coupled signal.\n            Preprint. February 10, 2026.\n\n                                                         1\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n\n             Contrastive Feature Selection                        Causal Token Injection\n   Reasoning text (Chain-of-Thought)              SAE Feature Activations       Non-reasoning                 Non-reasoning input\n                                                                                   input                        with injected tokens\n     Let us reason step by step.\n       First, we analyze the problem.                                                Plain sentence                       Let sentence\n     Therefore, the answer is…                                                                              Wait sentence\n\n   Non-reasoning text                                                              45–90% of features\n                                          Language                                                      exhibit significant\n     Paris is the capital of France.                                            Model                                                      activation increases\n     This article describes a method.\n                                                                                                                             Low feature                                   Low feature         High feature\n                                                                                                                          Candidates                                             activation                                                     activation             activation\n       Standard contrastive methods select features based on activation differences                      Lexical cues are sufficient to trigger most candidate features\n\n            LLM-Guided Falsification                  Steering (Sanity Check)        Conclusion\n\n                            LLM proposes hyp-\n                                    otheses about what\n                                       the feature detects\n   Non-reasoning text                           Reasoning text\n    with similar style                             with different style        Amplify\n                                     Activation decoupled                                       feature                           Reasoning-\n    Okay, the biggest                                              Let's assume x is a\n                                   from reasoning                                                                                                     direction                           associated SAE    issue with this coffee                                                                       rational number. If that\n                                       behavior\n    machine is the noise…                                                                                 is true, it can be…                            Transformer                    features are often\n          False positive:       0 genuine                False negative:                                   minimal or slightly       attributable to\n            activates without       reasoning                       fails to activate                                degraded performance                                                                                                         linguistic\n           reasoning          features found            on reasoning                Performance changes do not\n          LLM generates feature semantics and falsifying counterexamples                        imply reasoning representation             correlates\n\nFigure 1. Overview of our falsification-based evaluation framework for reasoning features. We begin with SAE features identified by\ncontrastive methods. We then test whether lexical cues are sufficient to induce activation via causal token injection. Remaining features\nare subjected to LLM-guided adversarial counterexample generation, which decouples reasoning behavior from feature activation. Across\nall configurations, this process fails to identify any feature that satisfies our criteria for genuine reasoning behavior.\n\n\nMotivated by this mechanism, we introduce a falsification-    2. Related Work\nbased evaluation framework that probes whether con-\ntrastively selected “reasoning features” reflect cue-like struc-    2.1. Mechanistic Interpretability and SAEs\nture or remain robust under increasingly targeted tests. We    Mechanistic interpretability aims to reverse-engineer LLMs\nstart from contrastive candidates and perform causal token    by analyzing and decomposing their internal representations\ninjection by inserting a few feature-associated tokens into    (Sharkey et al., 2025).  Building on the linear represen-\nnon-reasoning text to test whether lexical cues alone are     tation hypothesis (Elhage et al., 2022; Park et al., 2024),\nsufficient to elicit activation. We then apply LLM-guided   SAEs have emerged as a prominent tool for disentangling\nfalsification to construct counterexamples: non-reasoning    polysemantic neurons into more monosemantic, human-\nfalse positives (FP) that instantiate hypothesized lexical,    interpretable features, by learning a sparse decomposition of\nsyntactic, or discourse patterns, and false negatives (FN)   model activations (Bricken et al., 2023; Cunningham et al.,\nobtained by paraphrasing a feature’s top-activating reason-    2023; Templeton et al., 2024). Recent work has further ex-\ning traces to preserve meaning while suppressing activation.    plored a range of SAE variants and training strategies, lead-\nWe also include a small steering study as a supplementary    ing to improved feature quality and interpretability (Chanin\nbehavioral check. Figure 1 summarizes the pipeline.            et al., 2025; Leask et al., 2025; Li et al., 2025a). Empirical\n                                                                 studies report that SAE features can align with semanticallyAcross 22 configurations, token injection shows that many\n                                                          coherent content patterns, including programming-relatedcontrastive candidates are elicited by inserting only a few\n                                                                      text (Bricken et al., 2023), arithmetic concepts (Engels et al.,associated tokens or short contexts into non-reasoning text.\n                                                            2025), and safety-related content (O’Brien et al., 2025). De-For the remaining features, LLM-guided falsification reli-\n                                                                    spite these findings, the interpretability of SAE features hasably constructs targeted FPs and meaning-preserving FNs\n                                                               primarily been shown through easily identifiable textual pat-that separate activation from the presence of a reasoning\n                                                                    terns, leaving open the question of whether these featurestrace in the input. Under our operational criteria, we do not\n                                                            capture deeper, higher-level aspects of model behavior.observe features that robustly track reasoning across these\nprobes. Together, these results suggest sparse decomposi-\ntions can favor low-dimensional correlates that co-occur     2.2. SAEs for Reasoning in LLMs\nwith reasoning, underscoring the need for falsification when                                                      Recent LLMs, such as OpenAI o1 (Jaech et al., 2024) and\nattributing high-level behaviors to individual SAE features.                                                  DeepSeek-R1 (Guo et al., 2025), are trained to elicit multi-\n\n\n                                                2\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nstep reasoning, yielding substantial performance gains on    reconstruction error) by projecting onto this basis. This lets\ncomplex tasks (Wang et al., 2023; Wei et al., 2022). Moti-    us attribute any loss of the high-dimensional component to\nvated by these advances, several recent works apply SAEs    the sparsity objective rather than dictionary mismatch. Let\nto identify internal features associated with reasoning pro- W := [v1, . . . , vk] ∈Rd×k and consider the ℓ1-regularizedcesses. One line of work applies contrastive activation-based    code\nmethods to identify features that exhibit large activation dif-\nferences or correlate with the presence of reasoning text.         z⋆(h) ∈arg minz∈Rk∥h −Wz∥2                                                                                                        2 + λ∥z∥1.    (2)Steering such features has been shown to increase reasoning\nlength and model confidence (Venhoff et al., 2025; Chen                                                The following theorem shows that, for fixed sparsity level\net al., 2025; Li et al., 2025b). Complementary approaches                                                          λ/b, the recovered energy from the high-dimensional com-\ndefine sets of reasoning-related vocabularies and then iden-                                                       ponent bg is exponentially suppressed as the intrinsic di-\ntify reasoning features either by selective activation on these\n                                                     mension k −1 grows. In contrast, Appendix B.2 shows thattokens (Galichin et al., 2025) or by exhibiting strong posi-                                                              the v1 coordinate is comparatively easy to retain.\ntive logit contributions to them (Fang et al., 2026). However,\nexisting approaches implicitly assume that features corre-   Theorem 3.1 (High-dimensional residual is suppressed by\nlated with reasoning-style text reflect underlying reasoning    ℓ1 decoding). Fix integers k ≥2 and d ≥k. Let W =\nprocesses. In practice, it remains unclear whether such cor-    [v1, . . . , vk] have orthonormal columns. Let h be generated\nrelations reflect the model’s internal reasoning computations    by (1), and z⋆(h) be any minimizer of (2). Define z⋆2:k :=\n                                                                              λ√k−1\n                                                                                                               2b    , we haveor instead arise from superficial token-level confounds.       (z⋆2, . . . , z⋆k) ∈Rk−1. Then with u :=\n\n\n                                                                               23. Theory: Sparsity Biases SAEs Toward                                                            ≤b2Ψ(u),    Ψ(u) := 2ϕ(u)/u,                                         E ∥z⋆2:k∥2\n  Low-Dimensional Correlates                                                     where ϕ is the standard normal density. In particular,\nSAEs minimize reconstruction error under an explicit spar-\nsity pressure, commonly implemented as an ℓ1 penalty on             Ψ(u) = p 2/π exp −u2/2 /u,\nfeature activations (Tibshirani, 1996; Olshausen & Field,\n1997). In this section, we use a minimal model to motivate    so the expected recovered energy from the (k −1)-\nwhy this objective can preferentially surface token-level    dimensional component decays exponentially in (k −1)λ2.\ncorrelates of reasoning traces, even when the underlying\n                                                Theorem 3.1 captures the core asymmetry underlying ourreasoning behavior is present and correlated with those cues.\n                                                           empirical pipeline. When a high-level behavior co-occursThis motivates the falsification pipeline developed later.\n                                                        with a stable cue, sparse decoding can explain a large por-\nWe model reasoning activations as having two parts that     tion of the contrastive signal using the low-dimensional\nco-occur in typical CoT data. The first is a stable low-    coordinate alone, while distributing the remaining behavior-\ndimensional cue that reliably appears in reasoning traces,    specific variation across many small coordinates that are\nsuch as a recurring token like wait. The second is a high-    individually penalized. This provides a concrete mecha-\ndimensional component that varies across semantically    nism by which contrastive feature detection can identify\nequivalent realizations of a reasoning trace, capturing dif-    features that separate reasoning from non-reasoning, yet\nferences in phrasing, decomposition into steps, and local      still fail to isolate a single feature that tracks reasoning it-\n                                                                            self. Unlike feature absorption (Chanin et al., 2025) (nested-rhetorical structure. Formally, let {v1, . . . , vk} ⊂Rd be an\northonormal set and define a reasoning activation vector       feature competition), our analysis isolates a dimensionality\n                                                                     effect: sparsity penalizes representing high-dimensional\n     h := av1 + bg,  g ∈span{v2, . . . , vk}      (1)    within-behavior variability more than retaining a stable low-\n                                            k−1   .    dimensional correlate, even under a perfect dictionary. Fullwhere a ≥0 and b > 0 are scalars and g ∼N 0, Ik−1We interpret v1 as a cue direction shared across many rea-    proofs and an analogous theorem for Top-K activations are\nsoning traces, while the remaining component is distributed    provided in Appendix B.\nacross the other k −1 directions. The Gaussian model for    Our model is intentionally simplified. It abstracts reasoningg serves as a tractable proxy for high-dimensional within-                                                            as high-dimensional variation within a subspace and ana-reasoning variability.                                                               lyzes an idealized sparse decoding objective rather than full\nTo isolate the effect of sparsity, we analyze the decoding   SAE training dynamics. The value of the theory is therefore\nstep induced by an ℓ1 objective. Concretely, we consider    motivational: it isolates a sparsity-driven failure mode that\nthe best-case setting where the decoder columns span the    makes token-level correlates attractive to SAEs when they\ntrue reasoning subspace, so that without any sparsity pres-    co-occur with richer behavior, which is precisely what our\nsure the least-squares code would recover h exactly (zero     falsification experiments are designed to test.\n\n                                                3\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n4. Methodology                                              4.2. Identifying Candidate Reasoning Features\n\nThis section specifies (i) an operational definition of genuine    Following prior work (Venhoff et al., 2025; Chen et al.,\nreasoning features in SAEs, (ii) a contrastive method for    2025; Li et al., 2025b), we start by identifying candidate fea-\nidentifying candidate reasoning features, and (iii) causal     tures that satisfy Reasoning specificity using contrastive\ninjection and LLM-based falsification experiments to distin-    activation-based methods applied to reasoning and non-\nguish genuine reasoning features from superficial correlates.    reasoning text. We then consider a range of metrics to\n                                                                   select top-ranked features as reasoning-related candidates.\n4.1. Defining Reasoning Features in SAEs                 Let    and      denote corpora of reasoning and non-                                            DR    DNR\nIn this section, we define what we term a genuine reasoning    reasoning text, respectively. For each input sequence x, we\nfeature in SAEs. Such a feature should reflect underlying    aggregate each feature’s activation across token positions\nreasoning processes, such as logical deduction or counter-   by taking the maximum: ai(x) = maxt fi(x, t), where\nfactual reasoning, rather than surface-level correlates of    fi(x, t) denotes the activation of feature i at token posi-\nreasoning-style text. Crucially, it is defined at the level of     tion t for input x. We use a maximum aggregator to retain\nsemantic computation rather than lexical form.                the single most salient activation while reducing sensitivity\n                                                                to sequence length and repeated occurrences of the same\nFormally, let x         denote a residual stream activation                                                             cue. Applying this aggregation to all samples yields two               ∈Rdmodelat layer ℓof a transformer language model, and let f =                                                             empirical                                                                            activation                                                                                           distributions,                                                                                         j=1 and                                                                                                            k=1,                                                                                         {aNRi,k}nNR                                                                              {aRi,j}nRSAEenc(x)        be the output of an SAE encoder. We                                                           corresponding                                                                                  to reasoning                                                                             and non-reasoning                                                                                                            corpora.                                                                                                   Can-         ∈RdSAErefer to fi as feature i. We say that fi is a genuine reasoning                                                              didate reasoning features are those whose activation distri-\nfeature iff it satisfies all of the following criteria:                                                             butions differ substantially between these two sets.\nReasoning specificity.  The feature activates reliably on   Our primary metric for selecting candidate features is Co-\ntext that involves reasoning behavior, while exhibiting sub-    hen’s d, which measures the standardized mean difference\nstantially lower activation on non-reasoning text.            between two distributions (Cohen, 2013). Specifically, for\n                                                       each feature i, we compute\nNon-spurious correlation.  The feature does not activate\n                                                                                                             ¯aRi       ion non-reasoning text that merely contains phrases associ-                                                                                    di =   −¯aNR ,\nated with reasoning corpora, including discourse markers                                       spooled\nsuch as “therefore” or “let us consider,” as well as other\n                                                                                                                                         i )2+(nNR−1)(sNRi )2                                                                                                                                                                           , and ¯aRi andsurface-level lexical artifacts frequently found in CoT text.    where spooled = q (nR−1)(sRnR+nNR−2\n                                                                    ¯aNRi  denote the sample means of      j=1 and      k=1,Semantic invariance.  The feature remains stable under                              {aRi,j}nR     {aNRi,k}nNR\n                                                                 respectively, with sRi and sNRi  denoting the correspondingparaphrases and stylistic transformations that preserve the\n                                                      sample standard deviations.underlying reasoning structure. That is, changing tone, vo-\ncabulary, or presentation style without altering the logical    Cohen’s d provides a scale-invariant measure of effect size,\ncontent should not substantially alter the feature’s activation.    reflecting the practical significance of activation differences.\n                                        We rank all SAE features by di and select the top k features\nThis definition is intentionally strict:  it excludes features                                                             as candidate reasoning features, with k = 100 in all experi-\nwhose apparent “reasoning selectivity” is explained by shal-                                                           ments. In addition to Cohen’s d, we assess robustness using\nlow lexical or stylistic regularities, rather than by a stable                                                    two additional metrics: (i) ROC-AUC when using ai(x) as a\nrepresentation of the underlying reasoning process. This                                                             score to discriminate between reasoning and non-reasoning\ndistinction matters because SAE features can sharply sepa-                                                         samples; and (ii) activation frequency ratio on reasoning\nrate reasoning from non-reasoning while encoding only a                                                    and non-reasoning samples. We observe consistent results\nlow-dimensional cue. For example, a feature that primarily                                                              across metrics, and provide detailed definitions and analyses\ndetects a token such as “wait” can score highly under con-                                                                 for these additional metrics in Appendix D.\ntrastive selection, and steering it can increase the model’s\ntendency to emit that cue, potentially changing downstream                                                                    4.3. Causal Token Injection Framework\ngeneration style without implying that the feature represents\nreasoning computations such as reflection or backtracking.    In this section, we test whether the candidate features iden-\nWe therefore treat contrastive correlations as hypotheses     tified in Section 4.2 satisfy the Non-spurious correlation\nand use causal and adversarial tests to evaluate whether     criterion through causal token injection experiments. Our\nan interpretation survives meaning-preserving paraphrase     central hypothesis is straightforward: if a feature encodes\nand cue-matched counterexamples; see Appendix A for a    genuine reasoning, then inserting a small number of its\ndetailed discussion.                                   most activating tokens into non-reasoning text should not\n\n                                                4\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nsubstantially increase its activation.                              1. Token-driven: d ≥0.8 with p < 0.01, corresponding to                                                            a large effect.\nFor each candidate feature fi, we start by identifying the                                                                    2. Partially token-driven: 0.5   < 0.8 with p < 0.01,tokens and short token sequences that most strongly activate                 ≤d                                                            corresponding to a medium effect.it on the reasoning corpus.\n                                                                    3. Weakly token-driven: 0.2 ≤d < 0.5 with p < 0.05,                                                            corresponding to a small effect.\nUnigram ranking.  For each unique token t, we compute\n                                                                    4. Context-dependent: d < 0.2 or p ≥0.05, indicating aits mean activation                                                                   negligible effect.\n                   1\n                        ¯fi,t =  X  fi(x, j),\n                         |It| (x,j)∈It                               4.4. LLM-Guided Falsification\n                                                 The token injection experiments described above eliminate\nwhere It = {(x, j): tokenx,j = t} denotes the set of all    a large class of lexical and short-range contextual confounds.token positions at which token t occurs in the reasoning    Features classified as context dependent, however, are not\ncorpus. Tokens are then ranked by ¯fi,t in descending order.    well explained by token-level triggers alone and may instead\n                                                       respond to higher-level semantic patterns that are difficult\nBigram and trigram ranking.  We extend the same pro-    to probe through token manipulations. We therefore ap-\ncedure to contiguous bigrams and trigrams. We restrict    ply LLM-guided falsification to test whether these features\nattention to bigrams that appear at least three times and tri-    satisfy the Semantic invariance criterion by constructing tar-\ngrams at least two times. Mean activations are computed    geted counterexamples that attempt to falsify proposed ex-\nanalogously and ranked within each n-gram category.          planations. These counterexamples include non-reasoning\n                                                                    text designed to induce spurious activation, as well as para-\nWe then evaluate whether the lexical patterns identified                                                          phrases of previously activating reasoning text that fail to\nabove are sufficient to drive feature activation outside rea-                                                                            elicit activation. We detail this process next.\nsoning contexts. For each feature fi, we construct two sets\nof samples: Baseline, consisting of non-reasoning inputs\n                                                     Hypothesis generation.  The LLM is first provided with\ndrawn from DNR, and Injected, consisting of the same non-    three sources of information: the top-activating tokens iden-reasoning inputs with top-activating tokens inserted.\n                                                                         tified in Section 4.3, a small set of reasoning samples that\n                                                             strongly activate the feature, and token-level activation\nInjection strategies.  To probe different forms of lexical                                                                traces within those samples. Using this information, the\nsensitivity, we consider various injection strategies. First,                                   LLM proposes an explicit hypothesis describing what lin-\nsimple token injection inserts three top-ranked tokens ei-                                                                   guistic or structural pattern the feature may be detecting.\nther by prepending them to the text, uniformly interspersing\nthem throughout the text, or replacing randomly selected\n                                                   Counterexample construction.  Given a proposed hypoth-words. Second, n-gram injection inserts either two top-\n                                                                       esis, the LLM generates two complementary types of testranked bigrams or one top-ranked trigram at uniformly sam-\n                                                               cases.  First, it produces non-reasoning text that instanti-pled positions within the text. Third, contextual injection\n                                                                ates the hypothesized pattern, serving as candidate falseinserts tokens along with their frequent preceding context\n                                                                positives (FP). Second, for false negatives (FN), it para-to preserve local co-occurrence structure.\n                                                            phrases the feature’s top-activating reasoning samples while\n                                                                  explicitly preserving their semantic content and reasoning\nFeature Classification.  For each feature i, we quantify                                                                     intent, but altering surface form such as vocabulary, syn-\nthe activation shift induced by injection using Cohen’s d:                                                                    tax, or presentation style. Each candidate is evaluated by\n                                                          running it through the target model and measuring the maxi-\n                                     ¯ainjectedi             i                    dinjectedi   =          −¯abaseline ,           mum activation of the feature. A non-reasoning candidate\n                                     spooled                                is considered a valid FP if its activation exceeds a threshold\n                                                          τ                                                                                                             ),                                                                                while                                                                                      a                                                                                        paraphrased                                                                                                      reasoning                                                       maxj                                                                  ai(xRj                                  = 0.5 ×where ¯ainjectedi     and ¯abaselinei     denote the mean activations on                                                           candidate                                                                                        is                                                                      considered                                                                              a                                                                                          valid                                                           FN                                                                                                                                 if                                                                                                                               its activation                                                                                                     remains\ninjected and baseline samples, respectively, and spooled is    below 0.1τ, where the maximum is taken over the original\nthe pooled standard deviation.                                                            reasoning samples. The generation steps are repeated for up\nWe assess statistical significance using independent two-    to T = 10 iterations, with early termination if at least three\nsample t-tests comparing injected and baseline activations.    valid FP and three valid FN are obtained.\nFollowing standard conventions for effect size interpreta-\ntion (Cohen, 2013), each feature is classified based on the    Final classification.  Given the constructed counterexam-\nstrongest effect observed across all injection strategies:         ples, the LLM produces a consolidated interpretation of\n\n                                                5\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nthe feature, including the linguistic or structural pattern it                   0.9                                 Analyzed layers        0.40\n                                                                                                                                                                                                                                                                                                                                                                                                                                                      Entropy 0.35appears to detect and the conditions under which it acti-                   0.80.7\n                                                                                                                                                                                                                    0.30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Concentration 0.6vates or fails to activate. A final classification is then made                                                                                                                                                             0.5                                                                                                                                                                    Normalizedusing all evidence accumulated during the procedure, in-                    Token                                                              0.25                                                                                                                                                                                                                    0.20\ncluding the success or failure of generated counterexamples,                 Mean 0.4                                                                  Mean 0.15                                 Analyzed layers\nactivation measurements on those candidates, and consis-                     0           10   Layer 20           30                0           10   Layer 20           30\ntency across iterations. To ensure reliability, we report all\nLLM-generated interpretations and counterexamples for a    Figure 2. Token concentration ratio and normalized activation\n                                                                  entropy for SAE features across all layers of Gemma-3-4B-Instructrepresentative experiment in Appendix G.\n                                                         on the s1K dataset. Middle layers exhibit lower concentration and\n                                                                  higher entropy, indicating reduced reliance on specific tokens.\n4.5. Steering Experiments\n\nAs a supplementary analysis, we conduct steering experi-\nment to probe whether amplifying candidate features identi-   dominated by lexical processing, while late layers are in-\nfied in Section 4.2 has a measurable effect on downstream    creasingly specialized toward output token prediction (Ma\nreasoning task performance.                                      et al., 2025). To further support this choice, we analyze\n                                            how concentrated SAE feature activations are on individ-\nFeature Steering.  For a feature fi with decoder direction    ual tokens. Specifically, we compute a token concentration\nWdec,i ∈Rdmodel, we intervene onmaxthe residual stream at     ratio, defined as the fraction of a feature’s activation masslayer ℓaccording to x′ = x +                       γfi   Wdec,i, where γ ∈R     attributable to its 30 most activating tokens, and the normal-                       maxis the steering strength and fi     is the maximum activation    ized entropy of the activation distribution across tokens.\nof fi on the reasoning corpus.                                                         Figure 2 shows diagnostics for Gemma-3-4B-Instruct on\n                                                             the s1K dataset. Middle layers consistently exhibit lower\n5. Experiments                                         concentration ratios and higher entropy than early or late\n                                                                  layers. Similar trends are observed across models. If gen-\n5.1. Experimental Setup                                                            uine reasoning exists at the level of individual features, these\nWe conduct experiments on six open-weight transformer    layers constitute the most plausible candidates.\nlanguage models. Our primary models are Gemma-3-12B-                                        We conduct all experiments on a single NVIDIA A100 GPU\nInstruct and Gemma-3-4B-Instruct (Gemma Team et al.,                                                        with 80 GB VRAM. Feature detection and token injection\n2025).  For both, we analyze a subset of middle-to-late                                                          experiments require around 1 hour per configuration, while\nlayers and use SAEs from the GemmaScope-2 release (Mc-                                                 LLM-guided falsification requires approximately 2 hours.\nDougall et al., 2025), each with 16,384 features trained\non residual stream activations.  We additionally study                                                                    5.2. Feature Detection Results\nDeepSeek-R1-Distill-Llama-8B (Guo et al., 2025), analyz-\ning a representative middle layer using an SAE trained on   We apply the contrastive procedure described in Section 4.2\nreasoning-oriented corpora, specifically LMSys-Chat-1M     to identify candidate reasoning features. For each configu-\n(Zheng et al., 2024) and OpenThoughts-114k (Guha et al.,    ration, we rank SAE features by Cohen’s d and select the\n2025), with 65,536 features (Galichin et al., 2025). Results    top 100 features. Results obtained using alternative metrics,\nfor Llama-3.1-8B (Grattafiori et al., 2024), Gemma-2-2B    including ROC-AUC and activation frequency ratios, are\nand Gemma-2-9B (Gemma Team et al., 2024) are reported    reported in Appendix D and are qualitatively consistent.\nin Appendix C.                                                         Table 1 reports the mean Cohen’s d of the top 100 features\nFor reasoning corpora, we use s1K-1.1, which consists of     for each configuration. Mean effect sizes range from 0.675\n1,000 challenging mathematics problems with detailed CoT    to 1.043, corresponding to medium to large effects under\ntraces (Muennighoff et al., 2025), and the General Inquiry    standard conventions (Cohen, 2013). This indicates that\nThinking Chain-of-Thought dataset, which contains 6,000   SAE features can reliably distinguish between reasoning\nquestion-answer pairs spanning diverse domains with ex-   and non-reasoning text at a statistical level.\nplicit reasoning annotations (Wensey, 2025). As a non-                                                         Figure 3 shows the full distribution of Cohen’s d valuesreasoning corpus, we use an uncopyrighted subset of the                                                                for Gemma-3-12B-Instruct at layer 22 on the s1K dataset.Pile (Gao et al., 2020), a large-scale collection of general                                                The distribution exhibits a long tail, with a small subset ofweb text. From each corpus, we uniformly sample 1,000                                                                features achieving substantially larger effect sizes than thetexts and chunk inputs to 64 tokens.                                                                 majority. These top-ranked features form a clearly separated\nWe focus on middle-to-late layers, motivated by both prior    region in the right tail, motivating their selection for further\nwork and empirical analysis.  Early layers are typically     falsification analyses.\n\n                                                6\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n\n\n\n                                                                                                                                                                                                                                                                                                                     Weakly                                                                                                                                                                                                                                               TD    Table 1. Mean Cohen’s d values for the top 100 features.                           100                                                                                                                               Token-drivenPartially TD                                                                                                                                                                                                                                                                                                                                                              Context-dependent\n\n Model                  Layer   s1K   General Inquiry CoT                 (%)  80\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Features  60 Gemma-3-12B-Instruct     17    0.775         0.947                       of\n\n                                                                                                                                                                                 40 Gemma-3-12B-Instruct     22    0.835         0.924                                                                                                                    Percentage Gemma-3-12B-Instruct     27    0.805         0.995\n Gemma-3-4B-Instruct      17    0.909         0.984                                       20\n\n\n\n                                                                                                                                                                                                                                                           G3-12b Gemma-3-4B-Instruct      22    0.892         1.043                                        0            G3-12bL17s1K Gemma-3-4B-Instruct      27    0.888         1.010                                                                              GenInqL17        G3-12bL22s1K        G3-12bGenInqL22        G3-12bL27s1K        G3-12bGenInqL27        G3-4bL17s1K        GenInqG3-4bL17        G3-4bL22s1K        GenInqG3-4bL22        G3-4bL27s1K        GenInqG3-4bL27        DS-8bL19s1K        GenInqDS-8bL19\n DS-R1-Distill-Llama-8B    19    0.675         0.781                                                                 Figure 4. Distribution of token injection classifications across con-\n                                                                          figurations. Each bar corresponds to a model-layer configuration,\n                                                              with segments indicating the proportion of features classified as\n          104                                                         Other features              token-driven (TD), partially TD, weakly TD, or context-dependent.\n                                                               Top 100 features\n                                                                       Threshold (d ≥0.3)          103\n               Features                                                     Additional statistics are reported in Appendix E. Overall,\n    of 102                                                       these results indicate that most candidate reasoning features\n                                                              are driven by superficial lexical patterns. We therefore sub-           Number 101\n                                                                      ject the remaining context-dependent features to the LLM-\n                                                        guided falsification analysis described next.          100\n                 −1           0            1            2            3\n                                     Cohen’s d                              5.4. LLM-Guided Falsification Results\n\nFigure 3. Distribution of Cohen’s d values across SAE features for   We apply the LLM-guided falsification procedure described\nGemma-3-12B-Instruct at layer 22.                                in Section 4.4 to features that remain context dependent\n                                                                    after token injection. For configurations with more than\n                                                  20 such features, we randomly sample 20 for analysis. All\n5.3. Token Injection Results                                      falsification experiments are conducted using Gemini 3 Pro\n                                                             as the LLM hypothesis generator and interpreter.We apply the token injection procedure described in Sec-\ntion 4.3 to the top 100 candidate reasoning features per    Table 3 and 4 summarize the results for the s1K and General\nconfiguration. For each feature, we test whether inserting    Inquiry CoT datasets, respectively. For each configuration,\nits most activating tokens into non-reasoning text is suffi-   we report the number of analyzed features, the number\ncient to elicit strong activation, and assign the feature to the     classified as genuine reasoning features, and the number\nstrongest classification observed across all injection strate-    classified as confounds with high confidence.\ngies, following Section 4.3.                                                      Across all 248 context-dependent features analyzed, none\nTable 2 summarizes the resulting classifications. Across all    are classified as genuine reasoning features. Each feature\nmodels, layers, and datasets, the majority of features exhibit    admits systematic false positives and false negatives under\nsubstantial activation increases under token injection alone,    the LLM-guided protocol, with most classified as confounds\nindicating strong sensitivity to token-level patterns.           with high confidence due to repeated success in generating\n                                                                   falsifying counterexamples. These outcomes are consistentAcross configurations, between 45% and 90% of features are                                                          with the interpretation that feature activations can be drivenclassified as token-driven, partially token-driven, or weakly                                                  by correlated linguistic or discourse patterns rather thantoken-driven, demonstrating statistically significant activa-                                                                  reliably tracking reasoning behavior.tion increases induced by token injection alone. Only a\nminority of features remain context-dependent after injec-    Qualitative analysis reveals recurring categories of con-\ntion. As reported in Appendix E.3, mean Cohen’s d values    founds. Many features respond to instructional or planning-\nrange from 0.521 to 1.471 across configurations, indicating    oriented discourse openers, such as “Let’s break down” or\nthat inserting a small number of tokens into non-reasoning   “I need to figure out”, while others are triggered by formal\ntext is sufficient to produce substantial activation changes.    academic framing common in explanatory writing, includ-\n                                                            ing phrases like “We are given” or “The problem asks”. InFigure 4 visualizes these results across all configurations.                                                      each case, the feature activates on non-reasoning text thatThe overall pattern is consistent across models and lay-                                                     matches the pattern and fails to activate on reasoning texters. Gemma-3-12B-Instruct evaluated on the s1K dataset                                                                     that avoids it. All interpretations and counterexamples for aexhibits the largest fraction of context-dependent features                                                                representative experiment are reported in Appendix G.at 55%, while several Gemma configurations on the same\ndataset exhibit fewer than 12%.                               Overall, even features that are not explained by simple to-\n\n                                                7\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nTable 2. Token injection classification results for the top 100 features per configuration. TD denotes token-driven, PTD partially\ntoken-driven, WTD weakly token-driven, and CD context-dependent.\n\n                                                   s1K                General Inquiry CoT\n               Model                   Layer  TD  PTD  WTD  CD  TD  PTD  WTD  CD\n                 Gemma-3-12B-Instruct     17    54    10     15    21   47    11     25    17\n                 Gemma-3-12B-Instruct     22    23    6     16    55   33    8     15    44\n                 Gemma-3-12B-Instruct     27    38    16     21    25   29    16     19    36\n                 Gemma-3-4B-Instruct      17    58    13     19    10   46    15     18    21\n                 Gemma-3-4B-Instruct      22    63    9     18    10   47    13     18    22\n                 Gemma-3-4B-Instruct      27    66    9     14    11   39    15     18    28\n                  DS-R1-Distill-Llama-8B    19    46    12     19    23   25    14     20    41\n\n\nTable 3. LLM-guided falsification results for context-dependent    a reliable indicator of whether a feature encodes reason-\nfeatures on the s1K dataset.                                                                  ing. Prior work shows that simple lexical interventions can\n Model                  Layer   Analyzed  Genuine  High Conf.      substantially improve these benchmarks without engaging\n                                                          reasoning mechanisms (Muennighoff et al., 2025). Con- Gemma-3-12B-Instruct     17       20        0         20\n Gemma-3-12B-Instruct     22       20        0         18          sistent with our broader results, steering yields minimal\n Gemma-3-12B-Instruct     27       20        0         20        changes or degradations in accuracy.\n Gemma-3-4B-Instruct      17       10        0         10\n Gemma-3-4B-Instruct      22       10        0         10\n Gemma-3-4B-Instruct      27       11        0         11        6. Summary\n DS-R1-Distill-Llama-8B    19       20        0         14\n                                                            In this work, we study whether SAEs identify genuine rea-\nTable 4. LLM-guided falsification results for context-dependent    soning features in LLMs. Motivated by a stylized analysis\nfeatures on the General Inquiry CoT dataset.                     suggesting that sparsity can favor stable low-dimensional\n                                                                correlates over high-dimensional within-reasoning varia-\n Model                  Layer   Analyzed  Genuine  High Conf.\n                                                                     tion, we develop a falsification-oriented evaluation frame-\n Gemma-3-12B-Instruct     17       17        0         17       work that combines causal token injection with LLM-guided Gemma-3-12B-Instruct     22       20        0         19\n Gemma-3-12B-Instruct     27       20        0         18        counterexample generation. Across 22 configurations, most\n Gemma-3-4B-Instruct      17       20        0         20         contrastively selected candidates are highly sensitive to in-\n Gemma-3-4B-Instruct      22       20        0         20         jecting only a few associated tokens, and the remaining\n Gemma-3-4B-Instruct      27       20        0         20\n DS-R1-Distill-Llama-8B    19       20        0         19         features admit targeted counterexamples that decouple ac-\n                                                                  tivation from the presence of a reasoning trace. Overall,\n                                                        our results suggest that contrastive correlations are not, by\nken injection can still admit targeted counterexamples under    themselves, sufficient evidence for monosemantic reasoning\nfalsification, suggesting that caution is warranted when at-    features, and that causal validation is important when at-\ntributing such features to reasoning itself.                       tributing high-level behaviors to individual SAE directions.\n\n5.5. Steering Results                                     7. Limitations\nWe report a small-scale steering experiment as a supple-   Our conclusions are scoped to the contrastive candidate\nmentary analysis, following the setup in Section 4.5. We     features and experimental settings we study, and primarily\nfocus on Gemma-3-12B-Instruct at layer 22 and select the    address monosemantic interpretations of individual SAE fea-\ntop three features on the s1K dataset. For each feature fi,    tures selected by activation-based criteria. They do not rule\nwe apply steering to the residual stream with γ ∈{0, 2}.    out non-monosemantic features that mix cue-like patterns\nTable 5 reports one-shot accuracy under these conditions.     with aspects of reasoning, nor the possibility that reasoning-\n                                                               relevant information is distributed across many features or\nTable 5. Steering results on Gemma-3-12B-Instruct at layer 22                                                           represented nonlinearly in ways that resist single-featureusing the top three features on the s1K dataset.\n                                                                       attribution. Accordingly, we view our results as guidance on\n  Feature  AIME Baseline  AIME Steered  GPQA Baseline  GPQA Steered     what current contrastive pipelines reliably establish, and we\n  1053       26.7%         20.0%         37.9%         13.6%      recommend treating contrastive correlations as hypotheses\n    0        26.7%         10.0%         37.9%         20.2%         that warrant causal and adversarial validation.   578       26.7%         26.7%         37.9%         33.3%\n\nAs discussed in Section 4.1, steering performance is not\n\n                                                8\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nImpact Statement                                    One-Dimensionally Linear. In Proceedings of the 13th\n                                                                International Conference on Learning Representations,\nThis paper presents work whose goal is to advance the field                                                           2025.\nof Machine Learning. There are many potential societal\nconsequences of our work, none which we feel must be    Fang, Y., Wang, W., Xue, M., Deng, B., Xu,  F., Liu,\nspecifically highlighted here.                                   D., and Feng, F.  Controllable LLM Reasoning via\n                                                          Sparse Autoencoder-Based Steering.  arXiv preprint\n                                                           arXiv:2601.03595, 2026.References\n                                                           Ferrando, J., Obeso, O. B., Rajamanoharan, S., and Nanda,Ahn, J., Verma, R., Lou, R., Liu, D., Zhang, R., and Yin,\n                                                     N. Do I Know This Entity? Knowledge Awareness and  W. Large Language Models for Mathematical Reason-\n                                                              Hallucinations in Language Models. In Proceedings of   ing: Progresses and Challenges. In Proceedings of the\n                                                                  the 13th International Conference on Learning Represen-  18th Conference of the European Chapter of the Associ-\n                                                                       tations, 2025.  ation for Computational Linguistics: Student Research\n  Workshop, pp. 225–237, 2024.                             Galichin, A., Dontsov, A., Druzhinina, P., Razzhigaev, A.,\n                                                       Rogov, O. Y., Tutubalina, E., and Oseledets, I.  I Have\nBricken, T., Templeton, A., Batson, J., Chen, B., Jermyn,                                                        Covered All the Bases Here: Interpreting Reasoning Fea-\n  A., Conerly, T., Turner, N. L., Anil, C., Denison, C.,                                                                     tures in Large Language Models via Sparse Autoencoders.\n  Askell, A., Lasenby, R., Wu, Y., Kravec, S., Schiefer,                                                           arXiv preprint arXiv:2503.18878, 2025.\n  N., Maxwell, T., Joseph, N., Tamkin, A., Nguyen, K.,\n  McLean, B., Burke, J. E., Hume, T., Carter, S., Henighan,   Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T.,\n   T., and Olah, C. Towards Monosemanticity: Decompos-       Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N.,\n  ing Language Models With Dictionary Learning. Trans-       et al. The Pile: An 800GB Dataset of Diverse Text for\n  former Circuits Thread, 2023.                           Language Modeling. arXiv preprint arXiv:2101.00027,\n                                                           2020.\nChanin, D., Wilken-Smith, J., Dulka, T., Bhatnagar, H.,\n                                        Gemma Team, Riviere, M., Pathak, S., Sessa, P. G., Hardin,  Golechha, S., and Bloom, J. I. A is for Absorption: Study-\n                                                                  C., Bhupatiraju, S., Hussenot, L., Mesnard, T., Shahri-  ing Feature Splitting and Absorption in Sparse Autoen-\n                                                                               ari, B., Ram´e, A., et al. Gemma 2: Improving Open   coders. In Proceedings of the 39th Annual Conference on\n                                                    Language Models at a Practical Size.  arXiv preprint  Neural Information Processing Systems, 2025.\n                                                           arXiv:2408.00118, 2024.\nChen, X., Plaat, A., and van Stein, N. How does Chain of\n                                        Gemma Team, Kamath, A., Ferret, J., Pathak, S., Vieillard,  Thought Think? Mechanistic Interpretability of Chain-\n                                                               N., Merhej, R., Perrin, S., Matejovicova, T., Ram´e, A.,  of-Thought Reasoning with Sparse Autoencoding. arXiv\n                                                                         Rivi`ere, M., et al. Gemma 3 Technical Report. arXiv   preprint arXiv:2507.22928, 2025.\n                                                                 preprint arXiv:2503.19786, 2025.\nCohen, J.  Statistical Power Analysis for the Behavioral                                                                   Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian,\n  Sciences. Routledge, 2013.                                                               A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A.,\n                                                       Vaughan, A., et al. The Llama 3 Herd of Models. arXivCunningham, H., Ewart, A., Riggs, L., Huben, R., and\n                                                                 preprint arXiv:2407.21783, 2024.  Sharkey, L.  Sparse Autoencoders Find Highly Inter-\n   pretable Features in Language Models. arXiv preprint    Guha, E., Marten, R., Keh, S., Raoof, N., Smyrnis, G.,\n  arXiv:2309.08600, 2023.                                   Bansal, H., Nezhurina, M., Mercat, J., Vu, T., Sprague,\n                                                                      Z., et al. OpenThoughts: Data Recipes for Reasoning\nDong, F., Yan, Z., Ge, X., Xu, Z., Zhang, M., Chen, X.,                                                         Models. arXiv preprint arXiv:2506.04178, 2025.\n  He, B., Xin, X., Chen, Z., and Zhou, Y.  Identifying\n  and Transferring Reasoning-Critical Neurons: Improving    Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R.,\n LLM Inference Reliability via Activation Steering. arXiv      Zhu, Q., Ma, S., Wang, P., Bi, X., et al. DeepSeek-R1:\n   preprint arXiv:2601.19847, 2026.                             Incentivizing Reasoning Capability in LLMs via Rein-\n                                                         forcement Learning. arXiv preprint arXiv:2501.12948,\nElhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan,      2025.\n   T., Kravec, S., Hatfield-Dodds, Z., Lasenby, R., Drain,\n                                                     He, Z., Shu, W., Ge, X., Chen, L., Wang, J., Zhou, Y., Liu,   D., Chen, C., et al. Toy Models of Superposition. arXiv\n                                                                               F., Guo, Q., Huang, X., Wu, Z., et al. Llama Scope:   preprint arXiv:2209.10652, 2022.\n                                                                Extracting Millions of Features from Llama-3.1-8B with\nEngels,  J., Michaud, E.  J., Liao,  I., Gurnee, W., and      Sparse Autoencoders. arXiv preprint arXiv:2410.20526,\n  Tegmark, M. Not All Language Model Features Are      2024.\n\n                                                9\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nHe, Z., Zhao, H., Qiao, Y., Yang, F., Payani, A., Ma, J.,    McDougall, C., Conmy, A., Kram´ar, J., Lieberum, T., Raja-\n  and Du, M. SAIF: A Sparse Autoencoder Framework      manoharan, S., and Nanda, N. Gemma Scope 2 - Techni-\n   for Interpreting and Steering Instruction Following of       cal Paper. Google DeepMind Blog, 2025.\n  Language Models.  arXiv preprint arXiv:2502.11356,\n  2025.                                               Muennighoff, N., Yang, Z., Shi, W., Li, X. L., Fei-Fei,\n                                                                      L., Hajishirzi, H., Zettlemoyer, L., Liang, P., Cand`es,\nHe, Z., Xiong, G., Liu, B., Sinha, S., and Zhang, A. Rea-       E., and Hashimoto, T. B. s1: Simple test-time scaling.\n  soning Beyond Chain-of-Thought: A Latent Computa-      In Proceedings of the 2025 Conference on Empirical\n   tional Mode in Large Language Models. arXiv preprint      Methods in Natural Language Processing, pp. 20286–\n  arXiv:2601.08058, 2026.                                 20332, 2025.\nHuang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian,                                                        O’Brien, K., Majercak, D., Fernandes, X., Edgar, R. G.,\n  D., Wang, Y., Tang, R., and Chen, E. Understanding                                                               Bullwinkel, B., Chen, J., Nori, H., Carignan, D., Horvitz,\n  the planning of LLM agents: A survey. arXiv preprint                                                                        E., and Poursabzi-Sangdeh, F. Steering Language Model\n  arXiv:2402.02716, 2024.                                                             Refusal with Sparse Autoencoders. In ICML 2025 Work-\n                                                       shop on Reliable and Responsible Foundation Models,Jaech, A., Kalai, A., Lerer, A., Richardson, A., El-Kishky,\n                                                          2025.  A., Low, A., Helyar, A., Madry, A., Beutel, A., Car-\n  ney, A., et al. OpenAI o1 System Card. arXiv preprint\n                                                        Olshausen, B. A. and Field, D. J. Sparse Coding with an  arXiv:2412.16720, 2024.\n                                                       Overcomplete Basis Set: A Strategy Employed by V1?\nLeask, P., Bussmann, B., Pearce, M. T., Bloom, J. I., Tigges,      Vision research, 37(23):3311–3325, 1997.\n   C., Al Moubayed, N., Sharkey, L., and Nanda, N. Sparse\n                                                            Park, K., Choe, Y. J., and Veitch, V. The Linear Represen-  Autoencoders Do Not Find Canonical Units of Analysis.\n                                                                     tation Hypothesis and the Geometry of Large Language  In Proceedings of the 13th International Conference on\n                                                         Models. In Proceedings of the 41st International Confer-  Learning Representations, 2025.\n                                                         ence on Machine Learning, 2024.\nLi, C., Zhang, K., Xu, H., Shi, Y., Zhang, Z., Song, K.,\n  and Ren, K. Interpreting and Controlling LLM Reason-    Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y.,\n  ing through Integrated Policy Gradient. arXiv preprint       Dirani, J., Michael, J., and Bowman, S. R. GPQA: A\n  arXiv:2602.02313, 2026.                                  Graduate-Level Google-Proof Q&A Benchmark. In Pro-\n                                                           ceedings of the 1st Conference on Language Modeling,\nLi, Y., Michaud, E. J., Baek, D. D., Engels, J., Sun, X., and                                                          2024.\n  Tegmark, M. The Geometry of Concepts: Sparse Autoen-\n  coder Feature Structure. Entropy, 27(4):344, 2025a.        Sharkey, L., Chughtai, B., Batson, J., Lindsey, J., Wu, J.,\n                                                       Bushnaq, L., Goldowsky-Dill, N., Heimersheim, S., Or-\nLi, Z., Wang, X., Yang, Y., Yao, Z., Xiong, H., and Du, M.                                                                      tega, A., Bloom, J., et al. Open Problems in Mechanistic\n  Feature Extraction and Steering for Enhanced Chain-of-                                                                        Interpretability. arXiv preprint arXiv:2501.16496, 2025.\n  Thought Reasoning in Language Models. arXiv preprint\n  arXiv:2505.15634, 2025b.                                                         Templeton, A., Conerly, T., Marcus, J., Lindsey, J., Bricken,\n                                                                              T., Chen, B., Pearce, A., Citro, C., Ameisen, E., Jones, A.,Lieberum, T., Rajamanoharan, S., Conmy, A., Smith, L.,\n                                                     Cunningham, H., Turner, N. L., McDougall, C., MacDi-  Sonnerat, N., Varma, V., Kram´ar, J., Dragan, A., Shah,\n                                                             armid, M., Tamkin, A., Durmus, E., Hume, T., Mosconi,   R., and Nanda, N. Gemma Scope: Open Sparse Au-\n                                                                               F., Freeman, C. D., Sumers, T. R., Rees, E., Batson, J.,  toencoders Everywhere All At Once on Gemma 2. In\n                                                           Jermyn, A., Carter, S., Olah, C., and Henighan, T. Scaling  Proceedings of the 7th BlackboxNLP Workshop: Ana-\n                                                           Monosemanticity: Extracting Interpretable Features from  lyzing and Interpreting Neural Networks for NLP, pp.\n                                                        Claude 3 Sonnet. Transformer Circuits Thread, 2024.  278–300, 2024.\nMa, G., Pfrommer, S., and Sojoudi, S. Revising and Fal-    Tibshirani, R. Regression Shrinkage and Selection via the\n  sifying Sparse Autoencoder Feature Explanations.  In      Lasso. Journal of the Royal Statistical Society Series B:\n  Proceedings of the 39th Annual Conference on Neural        Statistical Methodology, 58(1):267–288, 1996.\n  Information Processing Systems, 2025.\n                                                           Venhoff, C., Arcuschin, I., Torr, P., Conmy, A., and Nanda,\nMann, H. B. and Whitney, D. R. On a Test of Whether      N. Understanding Reasoning in Thinking Language Mod-\n  one of Two Random Variables is Stochastically Larger       els via Steering Vectors.  In ICLR 2025 Workshop on\n  than the Other. The Annals of Mathematical Statistics,      Reasoning and Planning for Large Language Models,\n  pp. 50–60, 1947.                                         2025.\n\n                                                10\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nWang, S., Asilis, J., Akg¨ul, ¨O. F., Bilgin, E. B., Liu, O.,\n  Fu, D., and Neiswanger, W. Resa: Transparent Reason-\n  ing Models via SAEs. arXiv preprint arXiv:2506.09967,\n  2025.\n\nWang, X., Wei,  J., Schuurmans, D., Le, Q. V., Chi,\n  E. H., Narang, S., Chowdhery, A., and Zhou, D. Self-\n  Consistency Improves Chain of Thought Reasoning in\n  Language Models. In Proceedings of the 11th Interna-\n   tional Conference on Learning Representations, 2023.\n\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F.,\n  Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-Thought\n  Prompting Elicits Reasoning in Large Language Models.\n  In Proceedings of the 36th Annual Conference on Neural\n  Information Processing Systems, volume 35, pp. 24824–\n  24837, 2022.\n\nWensey, M. R. General Inquiry Thinking Chain-of-Thought\n  Dataset. HuggingFace Dataset, 2025.\n\nYao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao,\n   Y., and Narasimhan, K. Tree of Thoughts: Deliberate\n  Problem Solving with Large Language Models. In Pro-\n  ceedings of the 37th Annual Conference on Neural Infor-\n  mation Processing Systems, volume 36, pp. 11809–11822,\n  2023.\n\nYeo, W. J., Prakash, N., Neo, C., Lee, R. K.-W., Cambria,\n   E., and Satapathy, R.  Understanding Refusal in Lan-\n  guage Models with Sparse Autoencoders. arXiv preprint\n  arXiv:2505.23556, 2025.\n\nZhang, Y. and Math-AI Team. American Invitational Math-\n  ematics Examination (AIME) 2024, 2024.\n\nZhang, Z., Zhang, S., Lambert, J., Zhou, W., Wang, Z.,\n  Chen, M., Hard, A., Mathews, R., and Wang, L. Fantastic\n  Reasoning Behaviors and Where to Find Them: Unsuper-\n  vised Discovery of the Reasoning Process. arXiv preprint\n  arXiv:2512.23988, 2025.\n\nZheng, L., Chiang, W.-L., Sheng, Y., Li, T., Zhuang, S., Wu,\n   Z., Zhuang, Y., Li, Z., Lin, Z., Xing, E., et al. LMSYS-\n  Chat-1M: A Large-Scale Real-World LLM Conversation\n   Dataset. In Proceedings of the 12th International Confer-\n  ence on Learning Representations, 2024.\n\n\n\n\n\n                                                11\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n\nAppendix\n\nTable of Contents\n\n    A On interpreting high-level behaviors with sparse autoencoders                                        13\n\n    B  Theory: Sparsity suppresses high-dimensional within-reasoning variation                              15\n         B.1  Setting and notation  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   15\n         B.2  Main theorems .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   15\n         B.3  Proofs   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   16\n\n    C  Experiment results on additional models                                                          21\n         C.1  Llama-3.1-8B   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   21\n         C.2  Gemma-2-9B    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   21\n         C.3  Gemma-2-2B    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   22\n\n    D  Experiment results on alternative ranking metrics                                                  23\n         D.1 ROC-AUC based selection    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   23\n         D.2  Frequency ratio based selection   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   23\n         D.3  Comparison across ranking metrics   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   24\n\n    E  Additional experimental statistics                                                                25\n         E.1  Token dependency statistics across configurations .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   25\n         E.2  Injection strategy performance    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   25\n         E.3  Average injection effect sizes across configurations  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   27\n         E.4  Activation magnitude analysis  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   27\n         E.5  LLM-guided falsification convergence    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   28\n         E.6  Feature overlap across reasoning datasets  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   28\n\n     F  Hyperparameter settings                                                                       30\n          F.1   Feature detection    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30\n          F.2  Token injection    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30\n          F.3  LLM-guided falsification   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30\n          F.4   Steering experiments    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30\n          F.5  Model and SAE configuration  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   31\n\n    G LLM-guided feature interpretation results                                                         32\n\n    H  Dataset details                                                                                46\n         H.1  s1K-1.1    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   46\n         H.2  General Inquiry Thinking Chain-of-Thought   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   46\n         H.3  Pile Uncopyrighted    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   46\n\n       I  Benchmark details                                                                             47\n            I.1  AIME 2024   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   47\n            I.2  GPQA Diamond  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   47\n\n     J  Licenses and responsible use                                                                    48\n\n\n\n                                                12\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nA. On interpreting high-level behaviors with sparse autoencoders\n\nA growing body of work uses sparse autoencoders (SAEs) to study reasoning in large language models by identifying\nfeatures whose activations differ between reasoning and non-reasoning corpora and then interpreting these directions as\nreasoning-related features (Galichin et al., 2025; Venhoff et al., 2025; Chen et al., 2025; Li et al., 2025b; Wang et al., 2025;\nFang et al., 2026; Zhang et al., 2025; Dong et al., 2026; He et al., 2026; Li et al., 2026). These results provide strong\nevidence that SAEs surface directions that reliably separate reasoning-style text from other generations, and they have\nenabled detailed case studies and interventions. Our results refine how to read such separations. In the main text, we present\na stylized theoretical analysis showing that sparsity regularization intrinsically favors stable low-dimensional correlates over\nhigh-dimensional within-behavior variation, even when the dictionary contains the relevant directions. When a high-level\nbehavior is tightly coupled with a recurring cue, sparse coding can retain the cue cheaply while suppressing the remaining\ndistributed component. This mechanism motivates why contrastive separability can coexist with a lack of monosemantic\nfeatures that track the underlying reasoning process. Figure 5 illustrates the core intuition: an SAE feature that detects a cue\ntoken can separate reasoning from non-reasoning and can be steered to increase the probability of emitting that cue, yet still\nencode no semantic information about the reasoning itself. Consistent with this picture, our falsification experiments go\nbeyond distributional contrasts by combining causal token injection with LLM-guided counterexamples, constructing both\nfalse positives that elicit activation in non-reasoning text via associated token-level patterns and false negatives obtained\nby paraphrasing top-activating reasoning samples to preserve meaning while suppressing activation. Together, these tests\nprovide direct evidence that many contrastively selected features are better explained as linguistic correlates than as isolated\nrepresentations of reasoning computations. This perspective also aligns with observations from test-time scaling, where\nsubstantial gains on reasoning benchmarks can arise from simple inference-time manipulations that change token usage and\ngeneration length (Muennighoff et al., 2025).\n\n\n        Token-level confounds can mimic 'reasoning features' in SAEs\n\n    (a) Contrastive selection can pick token-cue features\n                                                                                                                    SAE Toy SAE feature fi     Reasoning samples (contain cue token)\n                                                                                             High activation when token = 'Wait'\n           Wait, let's bound the error term. If x ≥ 0, then log(1+x) ≤ x, so the remainder is at most ε.\n                                                                                                     Activation on example inputs\n\n           Wait, we can do a case split. If n is even, the parity argument applies; otherwise we reduce\n             to the even case.\n                                                                                                                  Wait, …             This recipe …     Non-reasoning samples (no cue token)                                                                                                                                                                                                                                                                                                                                                                            Activation\n\n                                                                                       Separates reasoning vs. non-reasoning,\n           This recipe uses olive oil, garlic, and lemon. Roast the vegetables for 25 minutes.\n                                                                                               yet encodes a low-dimensional lexical cue.\n\n         The laptop arrived on time. The screen is bright and the battery lasts about nine hours.           A contrastive method can rank fi highly even if it\n                                                                                                       does not represent reasoning computations.\n\n\n    (b) Steering may change behavior without encoding reasoning\n                                                                                      Observed output (example)\n                  Steer the feature                      Effect on next-token probability           Before steering\n                                                                              (illustrative)\n                                                                         We compute the value directly. The answer is 42.\n                   Amplify feature fi                                            0.25                   0.23                                                      After steering\n      LLM       Add                       a                             small                                      positive     Updated\n       internal                                                internal                    0.10             0.12  0.08                   Wait, I should double-check. If I substitute back,                    push                                  in                               the feature\n                                                                               0.02                                             the result changes. The answer is 41.        state               direction             state\n                             (strength γ)                                      wait therefore the       wait therefore the             Behavior change is driven by the base LLM's\n                                                                     Before                After                              learned dynamics.\n                  Goal: increase activation of fi                   Amplifying fi increases P(next token = 'wait')      The SAEnotfeaturethe underlyingmay only encodereasoningtheprocess.token cue 'wait',\n     Key takeaway\n                    Steering a cue feature can elicit more “reflective” outputs, but the feature may only capture a token-level cue such as\n                        “wait.” This is useful for control, but insufficient for interpreting the underlying reasoning.\n\nFigure 5. Illustration of cue-driven separability without semantic reasoning representation. Top: Reasoning traces often contain stable\ncue tokens such as wait, while non-reasoning text does not. A contrastively selected SAE feature that activates on the cue can separate\nreasoning from non-reasoning despite encoding only a low-dimensional lexical pattern. Bottom: Steering such a feature can increase the\nprobability that the LLM emits the cue token, which may correlate with more reflective or backtracking-like outputs. This behavioral\nchange reflects dynamics already present in the base LLM, and does not imply that the SAE feature represents the underlying reasoning\nprocess.\n\n                                                13\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nOur framing is not that linguistic patterns and high-level behaviors are separate or opposing. Reasoning traces\ninevitably involve language, and token-level structure can be a genuine part of how reasoning is expressed. The issue is\ncoupling. When a recurring cue is strongly correlated with a broader behavioral state, sparsity creates an asymmetry in\nwhat is easiest to represent: low-dimensional correlates are retained by activating a small number of coordinates, while\nhigh-dimensional variability across semantically equivalent realizations is penalized because it requires distributing mass\nacross many coordinates. This is conceptually different from feature absorption (Chanin et al., 2025). Feature absorption\nstudies how, under sparsity, a feature that is a subset of another can dominate because it achieves lower sparsity cost (for\nexample, a “short” feature outcompeting a broader “starts with s” feature). Our theoretical analysis instead highlights a\ndimensionality effect: sparsity penalizes representing an isotropic or otherwise high-dimensional component more heavily\nthan a stable low-dimensional correlate, even when both are part of the same behavioral phenomenon and even under an\nidealized dictionary.\nRelated concerns and opportunities appear in SAE analyses of other high-level behaviors such as refusal, hallucination,\nand instruction following. For refusals, SAE features can predict and influence refusal behavior, while also correlating\nwith specific refusal phrases (Yeo et al., 2025). For hallucination and knowledge awareness, latent directions associated\nwith entity familiarity can causally affect whether a model abstains or hallucinates attributes (Ferrando et al., 2025).\nFor instruction-following settings, SAEs can be used to steer performance on structured tasks (He et al., 2025). These\nworks demonstrate the practical utility of SAE features as control levers and as diagnostic signals. Our results suggest\na complementary methodological caution: when an SAE feature correlates with a high-level behavior, that correlation\ncan arise because the feature captures a low-dimensional linguistic correlate of the behavior, rather than a monosemantic\nrepresentation of the underlying computation. This does not reduce the value of the features for intervention or analysis, but\nit affects what kinds of semantic claims are warranted without falsification.\nOur falsification results have important limitations. First, they primarily address monosemantic interpretations of individual\ncontrastive SAE features. They do not rule out the existence of non-monosemantic features that jointly respond to both a\ntoken-level cue and aspects of reasoning behavior, nor do they exclude the possibility that reasoning-relevant information is\nspread across many features in a way that resists single-feature attribution. Second, while our theoretical analysis explains\nwhy sparse objectives can suppress high-dimensional within-reasoning variation, it is not a complete characterization of\nSAE training dynamics or of how distributed computations manifest across layers and time steps. As a result, our evidence\nshould be read as guidance about what current contrastive pipelines reliably establish, not as a claim that SAEs cannot\nrepresent any reasoning-relevant structure. In practice, we advocate treating contrastive correlations as hypotheses and\nusing causal and adversarial tests, including paraphrase-based falsification of top-activating samples, to assess whether an\ninterpretation is robust.\nOverall, our findings suggest a constructive direction for the literature that interprets SAE features for high-level behaviors.\nThe goal is not to dismiss SAE-based interpretability, but to strengthen it. SAEs remain a powerful tool for surfacing\nconsistent internal directions and for enabling targeted interventions (Galichin et al., 2025; Venhoff et al., 2025; Chen et al.,\n2025; Li et al., 2025b; Wang et al., 2025; Fang et al., 2026; Zhang et al., 2025; Dong et al., 2026; He et al., 2026; Li et al.,\n2026; Yeo et al., 2025; Ferrando et al., 2025; He et al., 2025). Our contribution is to clarify a sparsity-driven failure mode\nthat is especially relevant when high-level behaviors co-occur with low-dimensional linguistic correlates, and to provide\nfalsification-oriented evaluations that can help practitioners distinguish robust behavioral representations from cue-like\ncorrelates.\n\n\n\n\n\n                                                14\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nB. Theory: Sparsity suppresses high-dimensional within-reasoning variation\n\nB.1. Setting and notation\nFix integers k ≥2 and d ≥k. Let {v1, . . . , vk} ⊂Rd be an orthonormal set and define the dictionary matrix W :=\n[v1, . . . , vk] ∈Rd×k so that W⊤W = Ik. We consider a stylized “reasoning subspace” in which reasoning-related\nactivations lie in span{v1, . . . , vk}, with v1 capturing a stable low-dimensional correlate and the remaining directionscapturing within-reasoning variability.\nLet a ≥0 and b > 0 be scalars. We define a random activation vector\n                                h := av1 + bg,                                                    (3)\n\nwhere g ∈span{v2, . . . , vk} is distributed as\n                                                   1\n                                    g ∼N  0, k −1Ik−1                                                 (4)\nin the coordinate system of the basis {v2, . . . , vk}. Explicitly, let ξ ∈Rk−1 have i.i.d. N(0, k−1)1   coordinates and set\ng := Pki=2 ξi−1vi. Then h has coordinates\n             W⊤h = x ∈Rk,    x1 = a,     xi = bξi−1 for i ∈{2, . . . , k}.                         (5)\nIn particular, for i ∈{2, . . . , k},                                                                        b2\n                                         xi ∼N  0, σ2  ,    σ2 := k −1,\nand the x2, . . . , xk are independent.\nWe analyze two activation rules used in sparse autoencoders.\n\n(i) ℓ1-regularized decoding.  Given λ > 0, define the ℓ1-regularized code\n\n                                                                      2 + λ∥z∥1.                                       (6)                                z⋆(h) ∈argz∈Rkmin ∥h −Wz∥2\n\n(ii) Top-K decoding.  Given an integer K ∈{0, 1, . . . , k}, define the Top-K approximation by keeping the K largest-\nmagnitude coordinates of x = W⊤h and zeroing the rest. Formally, let SK(x) ⊆{1, . . . , k} be any size-K index set\nachieving the K largest values of |xi|. Define z(K) ∈Rk by\n                                         z(K)i   := xi · 1[i ∈SK(x)].                                              (7)\nThen Wz(K) is the orthogonal projection of h onto the span of the selected basis directions.\n\nB.2. Main theorems\n\nWe first record how the cue coordinate behaves under the same sparse decoding rules we analyze for the residual. This\nmakes the setting in Equations (3) and (4) easier to interpret: the cue component av1 is a single stable direction, while the\nbehavioral component bg is isotropic within a (k −1)-dimensional subspace. We then state and prove the ℓ1 suppressionresult used in the main text, followed by an analogous bound for Top-K.\nLemma B.1 (ℓ1 recovers the cue by soft-thresholding). Fix k ≥2 and let W ∈Rd×k have orthonormal columns with\nW = [v1, . . . , vk]. Let h follow Equations (3) and (4) with parameters a ≥0 and b > 0, and let z⋆(h) be any minimizer ofEquation (6). Then\n                                  z⋆1(h) = ST(a, λ/2) = max (a −λ/2, 0) .                                      (8)\nIn particular, if a ≥λ/2 then the cue reconstruction error along v1 equals (a −z⋆1(h))2 = (λ/2)2.\nLemma B.2 (Top-K selects the cue when it exceeds the residual order statistic). Fix k ≥2 and let W ∈Rd×k have\northonormal columns with W = [v1, . . . , vk]. Let h follow Equations (3) and (4) with parameters a ≥0 and b > 0, and let\n\n                                                15\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n\n\n                                                                                                                        (1)                                                                                                                (k−1)z(K) be the Top-K code defined in Equation (7) with K ≥1. Let xi := ⟨vi, h⟩for i ≥2, and let X2                                                              ≥· · · ≥X2\ndenote the order statistics of {x22, . . . , x2k}. Then\n                                                                         (K).                                        (9)                                    z(K)1  (h) = a  whenever  a2 ≥X2\nMoreover, with σ2 := k−1,b2\n                         P  z(K)1  (h) ̸= a ≤2(k −1) exp −a22σ2    .                                 (10)\n\nLemmas B.1 and B.2 formalize a basic asymmetry in our setting. The cue component is a single coordinate in the\northonormal dictionary and is therefore inexpensive to represent: under ℓ1, it is recovered up to the usual soft-threshold\nbias, and under Top-K, it is selected whenever its magnitude is not dominated by the K-th largest residual coordinate. In\ncontrast, the residual component is spread isotropically across k −1 coordinates. The theorems below quantify how sparsitysuppresses the recovered energy from this high-dimensional residual, even though the cue is still recovered.\nTheorem B.3 (ℓ1 suppresses high-dimensional residual). Fix k ≥2 and let W have orthonormal columns. Let h followEquations (3) and (4) with parameters\n                                                b2                               a ≥0 and b > 0, λand letλ√k−1z⋆(h) be any minimizer of Equation (6). Define\n                                 k−1 and define u := 2σ =    2b    . Thenz⋆2:k := (z⋆2, . . . , z⋆k) ∈Rk−1. Let σ2 =\n                                             2 = (k −1)E ST(X, λ/2)2 ≤b2Ψ(u),                     E ∥z⋆2:k∥2\nwhere X ∼N(0, σ2), ST(x, t) := sign(x) max{|x| −t, 0}, and\n                                                   2ϕ(u)\n                                        Ψ(u) :=           .                                               (11)\n                                             u\nIn particular,\n                        r 2 1                         E                                    ∥z⋆2:k∥22 ≤b2  π u exp −u22     ,                                    (12)\nwhich decays exponentially in (k −1)λ2/b2 for fixed λ/b.\nTheorem B.4 (Top-K captures at most a K log k/k fraction of isotropic residual). Fix k ≥2 and let W ∈Rd×k have\northonormal columns. Let h follow Equations (3) and (4) with parameters a ≥0 and b > 0, and let z(K) be the Top-Kcode defined in Equation (7). Define the residual energy captured outside the cue coordinate as\n\n                                                                          2\n                          RK :=   z(K)2    , . . . , z(K)k          .\n                                                                          2\n\nLet σ2 := k−1b2  and let X1, . . . , Xk−1 be i.i.d.      σ2). Then for any K       1, . . . , k                                   N(0,                ∈{0,       −1},\n                              E[RK] ≤σ2K (2 log (2(k −1)) + 2) .                                    (13)\nEquivalently,\n                              E[RK]   K\n                                                    (2 log (2(k    + 2) .                                   (14)                                          b2  ≤ k            −1))                             −1\nTheorem B.4 implies that if K is held fixed while k grows, the expected recovered fraction from the isotropic residual\nvanishes. More generally, the recovered fraction is at most on the order of K log k/k, so capturing a constant fraction of a\nhigh-dimensional isotropic component requires K to scale nearly linearly in k up to logarithmic factors. This formalizes the\nintuition that representing isotropic high-dimensional variation requires activating many coordinates, which sparse Top-K\ncodes cannot do when K ≪k.\n\nB.3. Proofs\nProof of Lemma B.1.  Let x := W⊤h ∈Rk. Since W has orthonormal columns,\n                                                                                    2\n                                                                                                                           .                                                                                    2                         ∥h −Wz∥2                                                2 = ∥x −z∥2                                                             2 +   I −WW⊤ h\n\n                                                16\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nThe second term does not depend on z, so minimizing Equation (6) is equivalent to minimizing ∥x −z∥2                                                                                                           2 + λ∥z∥1 over\nz ∈Rk. This objective is separable across coordinates. Because g ∈span{v2, . . . , vk}, we have x1 = ⟨v1, h⟩= a.Therefore z⋆1 is any minimizer of the scalar problem\n                                     minz∈R(z −a)2 + λ|z|.\nThe unique minimizer is the soft-threshold operator z = ST(a, λ/2). Since a ≥0, this equals max(a −λ/2, 0), whichproves Equation (8). The stated cue reconstruction error follows immediately.\n\nProof of Lemma B.2.  Let x := W⊤h = (x1, . . . , xk). As in the proof of Theorem B.4, Top-K decoding in an\northonormal basis selects a support of size at most K that maximizes Pi∈S x2i , and then sets z(K)i  = xi on that support. If\na2 = x21 is at least the K-th largest value among {x22, . . . , x2k}, then index 1 belongs to the set of K largest values among\n                                                      1  = x1 = a, proving Equation (9). For the probability bound, the{x21, . . . , x2k}, and Top-K must select index 1. Thus z(K)\n                1failure event {z(K)                     ̸= a} implies max2≤i≤k x2                                                                  i > a2, hence max2≤i≤k |xi| > a. By Equation (5), for i ≥2 the random\nvariables xi are i.i.d. N(0, σ2) with σ2 = b2/(k −1). A union bound and the Gaussian tail inequality yield\n                                      k\n          P  max   > a X P   > a) = (k      > a)          exp                ,                2≤i≤k |xi|    ≤       (|xi|        −1)P (|X|    ≤2(k −1)    −a22σ2\n                                    i=2\nwhich is Equation (10).\n\nProof of Theorem B.3.  We proceed in steps.\n\nStep 1: reduce the optimization to coordinates.  Since W has orthonormal columns, for any z ∈Rk,\n                                                                                             2 + C0,                                                                                2 = ∥x −z∥2                                                           2 + ∥h −WW⊤h∥2                                 2 = ∥W⊤h −W⊤Wz∥2               ∥h −Wz∥2\n                                               2 does not depend on z. Therefore, minimizing Equation (6) is equivalent towhere x := W⊤h and C0 := ∥h −WW⊤h∥2\n                                   min         2 +                                                  (15)                                         z∈Rk ∥x −z∥2   λ∥z∥1.\n\nStep 2: separability and the soft-thresholding solution.  The objective in Equation (15) is separable across coordinates:\n\n                                                         k\n                                              2 + λ∥z∥1 = X  (xi −zi)2 + λ|zi|  .                         ∥x −z∥2\n                                                       i=1\nThus a minimizer z⋆can be obtained by minimizing each coordinate independently:\n                                        z⋆i ∈argz∈Rmin(xi −z)2 + λ|z|.\nWe claim that the unique minimizer is z⋆i = ST(xi, λ/2). To verify, fix x ∈R and consider f(z) := (x −z)2 + λ|z|.\nIf z > 0, then f(z) = (x −z)2 + λz and f ′(z) = 2(z −x) + λ. Setting f ′(z) = 0 yields z = x −λ/2. This solution liesin the region z > 0 iff x > λ/2.\nIf z < 0, then f(z) = (x −z)2 −λz and f ′(z) = 2(z −x) −λ. Setting f ′(z) = 0 yields z = x + λ/2. This solution lies\nin the region z < 0 iff x < −λ/2.\nIf |x| ≤λ/2, then the stationary points above fall outside their regions. In this case, the minimizer occurs at the non-\ndifferentiable point z = 0. To confirm, note that for z > 0 with |x| ≤λ/2,\n                               f ′(z) = 2(z −x) + λ ≥2(0 −|x|) + λ ≥0,\nso f is non-decreasing on (0, ∞) and minimized at z = 0. Similarly for z < 0,\n                               f ′(z) = 2(z −x) −λ ≤2(0 + |x|) −λ ≤0,\nso f is non-increasing on (−∞, 0) and minimized at z = 0. Therefore,\n                      z⋆= ST(x, λ/2) = sign(x) max (|x| −λ/2, 0) .\nApplying this to each coordinate yields z⋆i = ST(xi, λ/2).\n\n                                                17\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nStep 3: compute              b2   E[∥z⋆2:k∥22] in terms of a one-dimensional expectation.  By Equation (5), x2, . . . , xk are i.i.d. N(0, σ2)\nwith σ2 = k−1. By Step 2,\n                                   z⋆i = ST(xi, λ/2)   for   i ∈{2, . . . , k}.\nThus\n                                             k\n                   E ∥z⋆2:k∥2                                          2 = X E (z⋆i )2 = (k −1)E ST(X, λ/2)2  ,                           (16)\n                                            i=2\nwhere X ∼N(0, σ2).\nStep 4: compute E[ST(X, t)2] in closed form.  Let t > 0 and set u := t/σ. Write X = σZ with Z ∼N(0, 1). Then\n             ST(X, t) = sign(Z)σ max (|Z| −u, 0) ,    ST(X, t)2 = σ2 (|Z| −u)2 1[|Z| > u].\nBy symmetry,\n                                            Z ∞\n                       E ST(X, t)2 = 2σ2                                                              (z −u)2ϕ(z) dz.                                  (17)                                                     u\nExpand (z −u)2 = z2 −2uz + u2 and integrate term by term:\n               Z ∞              Z ∞            Z ∞           Z ∞\n\n                   u                        (z −u)2ϕ(z) dz =  u  z2ϕ(z) dz −2u  u  zϕ(z) dz + u2  u  ϕ(z) dz.                 (18)\nWe now evaluate each integral. First,\n                                    Z ∞\n                                              zϕ(z) dz = ϕ(u),                                            (19)\n                                           u\nsince dz(−ϕ(z))d     = zϕ(z). Second,       ∞                                  Z\n                                             ϕ(z) dz = 1 −Φ(u).                                          (20)                                          u\nThird, using ϕ′(z) = −zϕ(z),\n           Z ∞          Z ∞                       Z ∞\n                 z2ϕ(z) dz =                                                        u +                                                                 ϕ(z) dz = uϕ(u) + 1 −Φ(u).           (21)              u                              u  z(−ϕ′(z)) dz = −[zϕ(z)]∞                                                             u\nSubstituting Equations (19) to (21) into Equation (18) gives\n     Z ∞\n           (z −u)2ϕ(z) dz = uϕ(u) + 1 −Φ(u) −2uϕ(u) + u2 1 −Φ(u) = (1 + u2) 1 −Φ(u) −uϕ(u).       u\nCombining with Equation (17) yields\n                    E ST(X, t)2 = 2σ2  (1 + u2)(1 −Φ(u)) −uϕ(u)  .                            (22)\n\nStep 5: upper bound using Mill’s ratio and define Ψ.  We use the standard inequality for u > 0,\n                                         1 −Φ(u) ≤ϕ(u)u   .                                              (23)\nSubstitute Equation (23) into Equation (22):\n\n                                                           ϕ(u)                       ϕ(u)       E ST(X, t)2          (1 + u2)ϕ(u)      = 2σ2    + uϕ(u)      = 2σ2        .       (24)                 ≤2σ2         u  −uϕ(u)         u        −uϕ(u)        u\n                         λ   λ√k−1\nWe now set t = λ/2, so u = 2σ =    2b    . Plugging Equation (24) into Equation (16) gives\n\n                                                  ϕ(u)        ϕ(u)                   E                           ∥z⋆2:k∥22 ≤(k −1)  2σ2 u  = 2b2 u = b2Ψ(u),\n\n                                             √1                                                              expwhere we define Ψ(u) := 2ϕ(u)u   as in Equation (11). Finally, since ϕ(u) =                                                                                        2    , we obtain Equation (12). This                                                                      2π                                                            −u2\nconcludes the proof.\n\n                                                18\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nProof of Theorem B.4.  We prove Equation (13) by reducing Top-K decoding in an orthonormal basis to a bound on the\nmaximum of Gaussian coordinates and then integrating a tail inequality.\n\nStep 1: Top-K decoding in an orthonormal basis.  Let x := W⊤h ∈Rk. Since W has orthonormal columns, for any\nz ∈Rk,                                                       2                      2\n                                                                                                                               .                                                               2                                                                                       2                       ∥h −Wz∥2                                             2 = W⊤h −z                                 +   I −WW⊤ h\nThe second term is independent of z, hence z(K) minimizes ∥x −z∥2                                                                         2 subject to ∥z∥0 ≤K. For any fixed support\n                                                                                                                                             i/∈S x2i .S ⊆{1, . . . , k} with |S| ≤K, the minimizer is zi = xi for i ∈S and zi = 0 otherwise, with objective value P\nTherefore, an optimal support maximizes Pi∈S x2i , so Top-K selects indices of the K largest values of x2i .\n\nStep 2: reduction to residual coordinates and a monotone upper bound.  Let xi :=                                                                                                       b2⟨vi, h⟩so that x = (x1, . . . , xk).\nBy Equation (5), the residual coordinates (x2, . . . , xk) are i.i.d. N(0, σ2) with σ2 = k−1. Since RK keeps at most Kcoordinates from (x2, . . . , xk), it is upper bounded by the sum of the K largest squared residual coordinates:\n\n\n                                    K\n                              RK ≤ X X2(j),                                               (25)\n                                                    j=1\n\nwhere X2(1) ≥· · · ≥X2                      (k−1) are the order statistics of X21, . . . , X2k−1 for i.i.d. Xi ∼N(0, σ2).\nStep 3: upper bound by K times the maximum.  Let\n\n                     M :=  max X2i .\n                                                1≤i≤k−1\n\nSince X2(j) ≤M for all j, we have\n                                K\n              X X2(j) ≤KM.                                              (26)\n                                             j=1\nCombining Equations (25) and (26) and taking expectation yields\n                                     E[RK] ≤KE[M].                                              (27)\nStep 4: a tail bound for the maximum.  Let Y := max1≤i≤k−1 |Xi|, so M = Y 2. For any t ≥0, by a union bound andsymmetry,\n                                       k−1\n                      P (Y ≥t) ≤ X P (|Xi| ≥t) = (k −1)P (|X| ≥t) ,\n                                            i=1\nwhere X ∼N(0, σ2). Write X = σZ with Z ∼N(0, 1). Using P(|Z| ≥u) ≤2 exp −u2/2  for u ≥0, we obtain\n                        P (|X| ≥t) = P (|Z| ≥t/σ) ≤2 exp −t22σ2    ,\n\nand therefore\n                           P (Y ≥t) ≤2(k −1) exp −t22σ2    .                                    (28)\n\nStep 5: bounding E[M] by tail integration.  Since Y ≥0, the tail integral identity gives\n                                   ∞                       ∞\n                               Z                                                Z\n                                               P Y                          E[Y 2] =                                                                         du.                                      ≥√u                               P Y 2 ≥u du =                                                                    0                                            0\n\nUsing Equation (28),\n                                Z ∞\n                            E[Y 2] ≤  0  min  1, 2(k −1) exp −u2σ2    du.\n\n                                                19\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nLet u0 := 2σ2 log (2(k −1)) so that 2(k −1) exp −u0/(2σ2) = 1. Splitting the integral at u0 yields\n                               Z u0      Z ∞\n                           E[Y 2] ≤  0  1 du +  u0 2(k −1) exp −u2σ2  du\n                     = u0 + 4σ2(k −1) exp −u02σ2\n                     = 2σ2 log (2(k −1)) + 2σ2.                                              (29)\nBecause M = Y 2, Equation (29) implies\n                              E[M] ≤2σ2 log (2(k −1)) + 2σ2.                                      (30)\n\nStep 6: conclude the bound on E[RK].  Substituting Equation (30) into Equation (27) gives\n                  E[RK] ≤K 2σ2 log (2(k −1)) + 2σ2 = σ2K (2 log (2(k −1)) + 2) ,\nwhich is Equation (13). Dividing by b2 = (k −1)σ2 yields Equation (14). This completes the proof.\n\n\n\n\n\n                                                20\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nC. Experiment results on additional models\n\nTo assess the generality of our findings beyond the Gemma-3 family, we apply the same experimental protocol described in\nSections 4 and 5 to three additional models: Llama-3.1-8B (Grattafiori et al., 2024) and two models from the Gemma-2\nfamily (Gemma-2-9B and Gemma-2-2B) (Gemma Team et al., 2024). These models span different architectural families\nand scales, providing a comprehensive test of robustness across contemporary open-weight language models.\n\nC.1. Llama-3.1-8B\n\nWe analyze Llama-3.1-8B, an 8B parameter model with 32 transformer layers from Meta AI. We focus on layer 16 (50%\ndepth), selected based on minimal token concentration following the same criterion used in Section 5.1. We use sparse\nautoencoders from the Llama Scope release (He et al., 2024) with 32,768 features trained on residual stream activations.\nTable 6 summarizes feature detection and token injection results for both reasoning datasets. As in the main experiments, we\nidentify the top 100 features by Cohen’s d and classify them using the token injection framework from Section 4.3.\n\nTable 6. Feature detection and token injection results for Llama-3.1-8B. TD denotes token-driven, PTD partially token-driven, WTD\nweakly token-driven, and CD context-dependent.\n\n           Dataset            Mean d    TD     PTD    WTD    CD     Avg. Inject. d\n         s1K                   0.851   37 (37%)  18 (18%)  28 (28%)  17 (17%)      0.909\n           General Inquiry CoT    1.015   26 (26%)  17 (17%)  24 (24%)  33 (33%)      0.613\n\nLlama-3.1-8B exhibits moderate token injection effects intermediate between Gemma-3 and Gemma-2 models. For s1K,\n83% of features show some degree of token-driven behavior (combining all three categories), with an average injection\nCohen’s d of 0.909. For General Inquiry CoT, 67% show token-driven behavior with average d of 0.613. The higher\nproportion of context-dependent features on General Inquiry CoT (33%) compared to s1K (17%) mirrors patterns observed\nin other models, suggesting dataset-specific differences in feature activation patterns.\nTo investigate the context-dependent features, we apply the LLM-guided falsification protocol from Section 4.4 to a random\nsample from each dataset (17 features from s1K, 20 from General Inquiry CoT). Across all 37 analyzed features, none\nsatisfy the criteria for genuine reasoning behavior. The LLM classifies all features as confounds, with high confidence for 30\nof them (81%). The dominant confounds include conversational discourse markers, formal writing style, meta-cognitive\nplanning phrases, and technical vocabulary that appears in both reasoning and non-reasoning contexts.\n\nC.2. Gemma-2-9B\n\nWe analyze Gemma-2-9B, a 9B parameter model with 42 transformer layers, focusing on a representative middle layer\nselected based on minimal token concentration in a preliminary analysis, following the same criterion used in Section 5.1.\nWe use sparse autoencoders from the GemmaScope release (Lieberum et al., 2024) with 16,384 features trained on residual\nstream activations.\nTable 7 summarizes feature detection and token injection results for both reasoning datasets. As in the main experiments, we\nidentify the top 100 features by Cohen’s d and classify them using the token injection framework from Section 4.3.\n\nTable 7. Feature detection and token injection results for Gemma-2-9B. TD denotes token-driven, PTD partially token-driven, WTD\nweakly token-driven, and CD context-dependent.\n\n             Dataset            Mean d   TD    PTD   WTD    CD     Avg. Inject. d\n           s1K                   0.709   6 (8%)  7 (9%)  23 (29%)  42 (54%)      0.285\n             General Inquiry CoT    0.764   6 (6%)  4 (4%)  33 (33%)  57 (57%)      0.294\n\nCompared to Gemma-3 models, Gemma-2-9B exhibits a substantially larger fraction of context-dependent features and\nmarkedly smaller injection effect sizes. Although statistically significant activation differences between reasoning and\nnon-reasoning text are still observed at the detection stage, the average Cohen’s d induced by token injection is below 0.3\nfor both datasets. This indicates weaker reliance on shallow token-level cues, but does not by itself imply the presence of\ngenuine reasoning features.\n\n                                                21\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nTo further investigate these context-dependent features, we apply the LLM-guided falsification protocol from Section 4.4 to\n20 randomly sampled features per dataset. Across all 40 analyzed features, none satisfy the criteria for genuine reasoning\nbehavior. The LLM classifies all features as confounds, with high confidence for 34 of them. The dominant confounds\ninclude formal academic writing style, meta-cognitive discourse markers, and technical vocabulary that appears in both\nreasoning and non-reasoning contexts.\n\nC.3. Gemma-2-2B\n\nWe next analyze Gemma-2-2B, a 2B parameter model with 26 layers, using the same methodology. We again select a middle\nlayer based on token concentration analysis and apply an SAE with 16,384 features.\nTable 8 reports the corresponding feature detection and token injection results.\n\n                             Table 8. Feature detection and token injection results for Gemma-2-2B.\n\n            Dataset            Mean d   TD     PTD    WTD    CD     Avg. Inject. d\n          s1K                   0.636   2 (2%)  18 (18%)  36 (36%)  44 (44%)      0.281\n            General Inquiry CoT    0.602   1 (1%)   7 (7%)   35 (35%)  57 (57%)      0.207\n\nGemma-2-2B shows the weakest token injection effects among all models studied. Only a small fraction of features are\nclassified as strongly token-driven, while between 44% and 57% are context-dependent. Average injection effect sizes are\nalso the lowest observed. Despite this reduced token sensitivity, LLM-guided analysis of 40 context-dependent features\nagain identifies no genuine reasoning features. Thirty-six of these features are classified as confounds with high confidence.\nThe identified confounds include procedural discourse markers, formal sentence structure, and domain-specific vocabulary\npatterns.\n\n\n\n\n\n                                                22\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nD. Experiment results on alternative ranking metrics\n\nIn the main text, we use Cohen’s d as the primary criterion for ranking and selecting candidate reasoning features (Section 4.2).\nTo evaluate the robustness of our conclusions to this choice, we repeat the full experimental pipeline using two alternative\nranking metrics: ROC-AUC and frequency ratio. For every configuration, we rank all SAE features by the corresponding\nmetric and select the top 100 features that satisfy the following criteria: minimum Cohen’s d effect size d ≥0.3, Bonferroni-\ncorrected p-value ≤0.01 under the Mann-Whitney U test, and ROC-AUC ≥0.6 when using the feature activation as aunivariate classifier. All experiments in this section are conducted on Gemma-3-4B-Instruct at layer 22 using the s1K dataset,\nwith all other parameters held fixed, including datasets, sample sizes, statistical thresholds, token injection strategies, and\nLLM-guided falsification.\n\nD.1. ROC-AUC based selection\n\nROC-AUC measures a feature’s ability to discriminate between reasoning and non-reasoning samples across all possible\nthresholds. For a feature i, it is defined as\n\n                                                                 nR  nNR\n                                                  1\n                    AUCi = P aRi,j > aNRi,k =  X X 1 aRi,j > aNRi,k  .\n                                            nRnNR j=1 k=1\n\nThis metric is distribution-free, invariant to monotonic transformations, and robust to class imbalance. We rank all SAE\nfeatures by ROC-AUC and select the top 100 features satisfying AUC ≥0.6, Bonferroni-corrected p ≤0.01, and Cohen’s\nd ≥0.3.\nTable 9 summarizes the resulting feature statistics and injection outcomes. Features selected by ROC-AUC exhibit token\ninjection behavior that closely mirrors the results obtained using Cohen’s d ranking. In particular, 95% of features fall\ninto one of the token-driven categories, while only a small fraction remain context-dependent. The mean Cohen’s d of the\nselected features is comparable to that of the Cohen’s d ranked set, indicating strong agreement between the two metrics.\n\n      Table 9. Results for the top 100 features ranked by ROC-AUC on Gemma-3-4B-Instruct at layer 22 using the s1K dataset.\n\n                                     Metric                      Value\n                             Mean Cohen’s d              0.830\n                             Mean ROC-AUC             0.667\n                                     Token-driven              59 (59%)\n                                            Partially token-driven       18 (18%)\n                                Weakly token-driven        18 (18%)\n                                     Context-dependent          5 (5%)\n                                       Features analyzed (LLM)       5\n                                  Genuine reasoning features      0\n\nAll five context-dependent features identified under ROC-AUC ranking are classified as confounds by the LLM-guided\nfalsification procedure described in Section 4.4, with high confidence in each case.\n\nD.2. Frequency ratio based selection\n\nWe next consider the frequency ratio metric, which measures how much more often a feature activates on reasoning samples\nthan on non-reasoning samples. For feature i, we define\n                                                           freqRi + ϵ\n                                         FreqRatioi =                 ,\n                                                         freqNRi + ϵ\nwhere freqRi and freqNRi  denote the proportion of samples whose maximum activation exceeds a fixed threshold, and ϵ = 0.01\nis a smoothing constant. The activation threshold is set to max(0.5 · σbaseline, 0.01), following the same procedure used inthe auxiliary analyses described in Section 4.2.\nRanking features by frequency ratio and selecting the top 100 yields results that are nearly identical to those obtained with\nROC-AUC. As shown in Table 10, 96% of selected features exhibit statistically significant token-driven behavior, with\n\n                                                23\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nonly four features classified as context-dependent. These features also show comparable effect sizes and discriminative\nperformance.\n\n    Table 10. Results for the top 100 features ranked by frequency ratio on Gemma-3-4B-Instruct at layer 22 using the s1K dataset.\n\n                                     Metric                      Value\n                             Mean Cohen’s d              0.830\n                             Mean ROC-AUC             0.667\n                                     Token-driven              65 (65%)\n                                            Partially token-driven       14 (14%)\n                                Weakly token-driven        17 (17%)\n                                     Context-dependent          4 (4%)\n                                       Features analyzed (LLM)       4\n                                  Genuine reasoning features      0\n\nLLM-guided analysis of all four context-dependent features again identifies no genuine reasoning features, with each\nclassified as a confound.\n\nD.3. Comparison across ranking metrics\n\nTo quantify overlap between feature sets selected by different ranking metrics, we compute Jaccard similarities between\nthe top 100 features selected by Cohen’s d, ROC-AUC, and frequency ratio. Figure 6 shows that the overlap is substantial\nacross all pairs, indicating that the three metrics largely prioritize the same subset of features.\n\n\n                                   1.0\n                                                              Three-way overlap: 80 features\n                                               0.82\n                                   0.8                                                                       0.74                    0.75\n\n\n                                   0.6                                                                                        Similarity\n\n                                   0.4\n                                                              Jaccard\n\n                                   0.2\n\n\n                                   0.0\n                                               Cohen’s d                 Cohen’s d            AUC vs\n                                                   vs AUC                    vs Freq                     Freq\n\nFigure 6. Jaccard similarity between top-100 feature sets selected by different ranking metrics on Gemma-3-4B-Instruct at layer 22 using\nthe s1K dataset.\n\nTaken together, these results demonstrate that our main conclusions do not depend on the specific choice of ranking metric.\nWhether features are selected by Cohen’s d, ROC-AUC, or frequency ratio, the vast majority are explained by token-level or\nshort-range contextual confounds, and no genuine reasoning features are identified under any selection criterion.\n\n\n\n\n\n                                                24\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nE. Additional experimental statistics\n\nThis section reports supplementary statistics from the main experiments that provide additional quantitative context for\ninterpreting the results presented in Section 5.\n\nE.1. Token dependency statistics across configurations\n\nBeyond the categorical classification induced by token injection, we analyze the degree to which feature activations are\nconcentrated on a small subset of tokens. For each feature, we compute a token concentration score defined as the fraction\nof total activation mass attributable to the top 30 tokens ranked by mean activation. We additionally report normalized\nactivation entropy as a complementary measure of dispersion. High concentration and low entropy indicate strong reliance\non a limited set of lexical triggers.\nTable 11 summarizes token dependency statistics for all main configurations. Across models, layers, and datasets, between\n30% and 78% of features exhibit high token dependency, defined as concentration greater than 0.5. Notably, s1K con-\nfigurations generally show lower token concentration than General Inquiry CoT configurations for the same model and\nlayer. Gemma-3-4B-Instruct layer 17 on s1K shows the lowest token concentration (mean: 0.402, median: 0.265), while\nGemma-3-12B-Instruct layer 27 on General Inquiry CoT shows the highest (mean: 0.714, median: 0.735), suggesting both\narchitectural and dataset-specific influences on token dependency.\n\n\nTable 11. Token concentration statistics for top-ranked features across all main configurations. High dependency denotes features with\nconcentration greater than 0.5.\n\n                 Model                  Layer   Dataset   Mean  Median  High dep.\n                  Gemma-3-12B-Instruct    17     s1K       0.529    0.478   41 (41%)\n                  Gemma-3-12B-Instruct    17     Gen. Inq.   0.641    0.685   73 (73%)\n                  Gemma-3-12B-Instruct    22     s1K       0.461    0.457   30 (30%)\n                  Gemma-3-12B-Instruct    22     Gen. Inq.   0.622    0.681   73 (73%)\n                  Gemma-3-12B-Instruct    27     s1K       0.521    0.480   41 (41%)\n                  Gemma-3-12B-Instruct    27     Gen. Inq.   0.714    0.735   78 (78%)\n                  Gemma-3-4B-Instruct     17     s1K       0.402    0.265   32 (32%)\n                  Gemma-3-4B-Instruct     17     Gen. Inq.   0.639    0.699   63 (63%)\n                  Gemma-3-4B-Instruct     22     s1K       0.539    0.449   47 (47%)\n                  Gemma-3-4B-Instruct     22     Gen. Inq.   0.690    0.836   69 (69%)\n                  Gemma-3-4B-Instruct     27     s1K       0.528    0.473   48 (48%)\n                  Gemma-3-4B-Instruct     27     Gen. Inq.   0.674    0.760   71 (71%)\n                   DS-R1-Distill-Llama-8B  19     s1K       0.569    0.528   52 (52%)\n                   DS-R1-Distill-Llama-8B  19     Gen. Inq.   0.687    0.826   69 (69%)\n\n\nFor s1K configurations, median concentration values are often lower than means, indicating left-skewed distributions where\nmost features have moderate-to-low concentration with a minority showing very high concentration. Conversely, General\nInquiry CoT configurations show median values close to or higher than means, suggesting more uniform high concentration.\nFigure 7 visualizes the distribution of token concentration across layers for representative models.\n\nE.2. Injection strategy performance\n\nWe further analyze which injection strategies are most effective at eliciting feature activation.  For a representative\nconfiguration, Gemma-3-12B-Instruct at layer 22 on s1K, we identify the injection strategy that yields the largest Cohen’s\nd for each feature. The prepend strategy dominates, accounting for 69.7% of best-performing cases, followed by bigram\ninjection, replacement, and trigram injection. Context-preserving strategies collectively account for a small fraction of cases.\nThis distribution indicates that simple token presence is typically sufficient to drive feature activation, and that preserving\nlocal co-occurrence or syntactic context does not substantially attenuate injection effects. Figure 8 compares Cohen’s d\ndistributions across strategies.\n\n                                                25\n\n                          Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n\n\n\n\n                 1.0         High dependency threshold\n\n\n\n                 0.8\n\n\n\n                 0.6                                                 Concentration\n                 0.4\n                   Token\n\n                 0.2\n\n\n\n                 0.0\n\n                              G3-12B          G3-12B          G3-12B          G3-4B           G3-4B           G3-4B\n                               L17             L22             L27             L17             L22             L27\n\nFigure 7. Token concentration distributions across layers for Gemma-3-12B-Instruct and Gemma-3-4B-Instruct on the s1K dataset.\n\n\n\n\n\n               6\n                                                                                                                                 Large effect\n                                                                                                          Medium effect\n               5                                                                                                          Small effect\n                          Effect) 4\n\n\n               3                                     (Injection\n    d 2\n\n\n               1                          Cohen’s\n\n               0\n\n                     Prepend        Intersperse      Bigram        Trigram      Bigram+Ctx    Trigram+Ctx\n                                                     Injection Strategy\n\n        Figure 8. Cohen’s d distributions across token injection strategies for Gemma-3-12B-Instruct at layer 22 on s1K.\n\n\n\n\n\n                                              26\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nE.3. Average injection effect sizes across configurations\n\nThis section reports the magnitude of activation changes induced by token injection across all experimental configurations.\nFor each model, layer, and reasoning dataset, we compute the average Cohen’s d achieved by the best-performing injection\nstrategy for each of the 100 candidate features, as defined in Section 4.3. The reported values therefore summarize the\nstrength of the strongest token-level intervention per feature, averaged across features within each configuration.\nTable 12 presents the resulting average effect sizes. Across all 14 configurations, the mean Cohen’s d ranges from 0.521\nto 1.471, with an overall mean of 0.974 and median of 0.982. All configurations exceed d = 0.5, which corresponds to a\nmedium effect size under standard conventions (Cohen, 2013), and 6 of the 14 configurations exceed d = 1.0, indicating\nvery large effects.\n\n\nTable 12. Average Cohen’s d for token injection across configurations. Values are computed by averaging, for each configuration, the best\ninjection effect size per feature across the top 100 candidate features.\n\n                  Model                        Layer   s1K   General Inquiry CoT\n                     Gemma-3-12B-Instruct           17    1.266         0.982\n                     Gemma-3-12B-Instruct           22    0.539         0.660\n                     Gemma-3-12B-Instruct           27    1.044         0.698\n                     Gemma-3-4B-Instruct            17    1.404         1.078\n                     Gemma-3-4B-Instruct            22    1.409         0.913\n                     Gemma-3-4B-Instruct            27    1.471         0.756\n                     DeepSeek-R1-Distill-Llama-8B    19    0.899         0.521\n\n\nThese effect sizes indicate that injecting a small number of feature-associated tokens into non-reasoning text is sufficient\nto induce substantial activation shifts. In particular, injecting three tokens into 64-token sequences, which corresponds\nto approximately 4.7% of the input tokens, produces activation increases that are comparable to or exceed conventional\nmedium and large effect size thresholds. The consistency of these effects across models, layers, and datasets provides strong\nevidence that token-level patterns play a dominant role in driving the activation of features identified by contrastive methods.\nWe observe systematic variation across configurations. Gemma-3 models generally exhibit larger average injection effects\nthan DeepSeek-R1-Distill-Llama-8B. Gemma-3-4B-Instruct shows the highest injection effects (1.404–1.471 on s1K), while\nGemma-3-12B-Instruct layer 22 shows the lowest among Gemma-3 models (0.539–0.660). Nevertheless, even the smallest\nobserved average effect size represents a medium effect, underscoring that token injection reliably induces strong feature\nactivation across all tested conditions.\n\nE.4. Activation magnitude analysis\n\nTo contextualize effect sizes, we analyze absolute activation magnitudes across conditions. For each feature, we compute\nthe mean activation across samples within each condition and then average these values across features.\nTable 13 reports activation statistics for Gemma-3-12B-Instruct at layer 22 on s1K. Token injection increases mean activation\nby a factor of approximately 1.32 relative to the non-reasoning baseline and reaches parity with activations observed on\ngenuine reasoning text. The overlap in upper-tail statistics further indicates that token injection is sufficient to reproduce the\nactivation regimes associated with reasoning inputs.\n\n\nTable 13. Activation magnitude statistics for Gemma-3-12B-Instruct at layer 22 on s1K. Injected refers to the best-performing token\ninjection strategy per feature.\n\n                         Condition             Mean     Std.    Median   90th pct.\n                        Non-reasoning (baseline)   416.5   1102.8    26.2     1366.8\n                        Non-reasoning (injected)   549.8   1123.1    68.5     1971.5\n                        Reasoning text            558.3   1139.5    144.2    2010.3\n\n\n\n                                                27\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nE.5. LLM-guided falsification convergence\n\nWe analyze the convergence behavior of the LLM-guided falsification protocol described in Section 4.4. Table 14 reports\nthe number of iterations required to reach the stopping criteria across all 153 context-dependent features from the main\nexperiments.\n\n              Table 14. Iteration statistics for LLM-guided falsification across all analyzed context-dependent features.\n\n                                       Statistic                         Value\n                           Mean iterations to convergence        2.4\n                              Median iterations to convergence      2.0\n                                Converged in 1 iteration          47 (31%)\n                                Converged in 2 iterations         68 (44%)\n                                Converged in 3 or more iterations  38 (25%)\n                               Reached max iterations (10)        3 (2%)\n\nMost features converge rapidly, with 75% resolving within two iterations. Features requiring more iterations typically\ninvolve overlapping stylistic or discourse-level patterns.\n\n\n                        60                                                                                       Mean: 3.4\n                                                                                              Median: 2\n                        50\n\n                        40                                                      Features\n              of 30\n\n                        20                                         Number\n\n                        10\n\n                         0\n                                1     2     3     4     5     6     7     8     9    10\n                                                 Iterations to Convergence\n\n                       Figure 9. Distribution of iterations required for LLM-guided falsification to converge.\n\n\nE.6. Feature overlap across reasoning datasets\n\nFinally, we examine whether the same features are selected when ranking on different reasoning datasets. For each model\nand layer, we compute the Jaccard similarity between the top 100 features identified using s1K and General Inquiry CoT.\nTable 15 shows that overlap is generally low, with Jaccard similarities ranging from 0.058 to 0.190. Larger models exhibit\nmoderately higher overlap, while deeper layers tend to show reduced overlap. These results indicate that different reasoning\ndatasets activate largely distinct feature subsets.\nFigure 10 provides a visual summary of feature overlap across datasets. LLM-guided analysis of shared context-dependent\nfeatures again identifies only confounds, including mathematical notation detectors, formal discourse markers, and meta-\ncognitive phrases that appear across reasoning and non-reasoning text.\n\n\n\n\n\n                                                28\n\n                           Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n\n\n\n\n                   Table 15. Overlap between top-ranked features selected using s1K and General Inquiry CoT.\n\n                        Model                 Layer   Intersection   Jaccard\n                          Gemma-3-12B-Instruct    17       27        0.156\n                          Gemma-3-12B-Instruct    22       32        0.190\n                          Gemma-3-12B-Instruct    27       12        0.064\n                          Gemma-3-4B-Instruct     17       11        0.058\n                          Gemma-3-4B-Instruct     22       16        0.087\n                          Gemma-3-4B-Instruct     27       13        0.070\n\n\n\n\n\n                                                                               1.0\n                 s1K only\n    175          Shared\n                   Gen. Inq. only                                                   0.8\n    150\n\n    125Features                                                                           0.6of 100                                                                                                                                                                                                Similarity\n\n     75                                                                                                                                                      Jaccard 0.4Number     50                                                                                                           0.19                                                                               0.2      0.16\n     25                                                                                                             0.06       0.06       0.09       0.07\n      0                                                                       0.0\n          L17     L22     L27     L17     L22     L27                L17     L22     L27     L17     L22     L27\n        G3-12B     G3-12B     G3-12B     G3-4B     G3-4B     G3-4B                  G3-12B     G3-12B     G3-12B     G3-4B     G3-4B     G3-4B\n\n                   Figure 10. Feature overlap between s1K and General Inquiry CoT across models and layers.\n\n\n\n\n\n                                               29\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nF. Hyperparameter settings\n\nThis section specifies all hyperparameters used throughout the experimental pipeline described in Sections 4 and 5. Unless\notherwise stated, these settings are shared across all models, layers, and datasets.\n\nF.1. Feature detection\n\nCandidate reasoning features were identified using 1,000 samples from each corpus, reasoning and non-reasoning, with each\nsample truncated to a maximum of 64 tokens. Feature activations were aggregated using the maximum activation across\ntokens. In the main experiments, features were ranked by Cohen’s d, while appendix experiments used alternative ranking\nmetrics as described in Appendix D.\nWe imposed three simultaneous selection thresholds: minimum Cohen’s d of 0.3, maximum Bonferroni-corrected p-value\nof 0.01 using the Mann-Whitney U test (Mann & Whitney, 1947), and minimum ROC-AUC of 0.6. From the features\nsatisfying all criteria, we selected the top 100 ranked by the primary metric.\nFor token dependency analysis, we extracted the top 30 tokens per feature based on mean activation, requiring a minimum\nof five occurrences. We additionally extracted the top 20 bigrams with at least three occurrences and the top 10 trigrams\nwith at least two occurrences. Activation collection used a batch size of 16 for all models.\n\nF.2. Token injection\n\nToken injection experiments were conducted on the top 100 features selected in the detection stage. For each feature, we\nused 500 non-reasoning samples for the baseline condition and 500 non-reasoning samples for the injected condition, with\nall samples chunked to 64 tokens. All processing used a batch size of 16.\nWe evaluated eight injection strategies: prepend, intersperse, replace, inject bigram, inject trigram,\nbigram before, trigram, and comma list.  For simple token strategies, namely prepend, intersperse,\nreplace, and comma list, we injected three tokens selected from the top 10 tokens for the feature. For bigram-based\nstrategies, we injected two bigrams selected from the top 20 bigrams. For trigram-based strategies, we injected one trigram\nselected from the top 10 trigrams.\nFeature classification followed Cohen’s effect size conventions. Token-driven features required d ≥0.8 with p < 0.01.\nPartially token-driven features required 0.5 ≤d < 0.8 with p < 0.01. Weakly token-driven features required 0.2 ≤d < 0.5\nwith p < 0.05. Features with d < 0.2 or p ≥0.05 were classified as context-dependent. For each feature, the injectionstrategy yielding the largest Cohen’s d was used for final classification.\n\nF.3. LLM-guided falsification\n\nFor features classified as context-dependent in the injection stage, we randomly sampled up to 20 features per configuration\nfor LLM-guided falsification as described in Section 4.4. The protocol was run for a maximum of 10 iterations per feature,\nwith early stopping once three valid false positives and three valid false negatives were identified.\nThe activation threshold for validation was set to 0.5 times the maximum activation observed on reasoning samples for the\nfeature. A false positive was considered valid if its maximum activation exceeded this threshold, while a false negative was\nconsidered valid if its maximum activation was below 0.1 times the threshold. In each iteration, the LLM generated five\ncandidate false positives and five candidate false negatives.\nTemperature settings varied by phase. Hypothesis generation and final interpretation used temperature 0.3 to promote\nconsistency, while counterexample generation used temperature 0.8 to encourage diversity.\n\nF.4. Steering experiments\n\nSteering experiments were conducted exclusively on Gemma-3-12B-Instruct at layer 22, using the top three features ranked\nby Cohen’s d on the s1K dataset. We evaluated two steering strengths, γ = 0.0 for the baseline condition and γ = 2.0 for\npositive amplification. The steering intervention was scaled by the maximum feature activation observed in the reasoning\ncorpus.\nText generation used a maximum of 16,384 new tokens, sampling temperature 0.6, and nucleus sampling with top-p set\n\n\n                                                30\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nto 0.95. All prompts followed the model’s chat template. Evaluation used one-shot chain-of-thought prompting. For\nAIME 2024, performance was measured by exact numerical answer matching, while for GPQA Diamond, performance was\nmeasured by multiple-choice accuracy.\n\nF.5. Model and SAE configuration\n\nAll Gemma-3 models used the GemmaScope-2 sparse autoencoder release with 16,384 features per layer and small ℓ0\nregularization. DeepSeek-R1-Distill-Llama-8B used an SAE with 65,536 features trained on reasoning-focused datasets.\nAll models were run in bfloat16 precision on a single NVIDIA A100 80GB GPU.\nFor additional models reported in Appendix C, we used analogous configurations. Llama-3.1-8B used SAEs from the Llama\nScope release with 32K features per layer. Gemma-2-9B and Gemma-2-2B both used SAEs with 16,384 features per layer\nfrom the corresponding GemmaScope release. Experiments using alternative ranking metrics in Appendix D employed\nidentical model and SAE configurations, differing only in the feature ranking criterion.\n\n\n\n\n\n                                                31\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nG. LLM-guided feature interpretation results\n\nThis section provides complete documentation of all LLM-generated feature interpretations, including high-activation\nexamples with token-level visualization, refined interpretations, and generated counterexamples, for one representative\nconfiguration (Gemma-3-4B-Instruct, layer 22, General Inquiry CoT). For each feature, we show three high-activation\nexamples from the reasoning corpus with tokens colored by activation strength (darker blue indicates higher activation),\nfollowed by the LLM’s interpretation and classification, and examples of false positives (non-reasoning text that activates\nthe feature) and false negatives (paraphrases of high-activating reasoning text that does not activate the feature).\n\n\nFeature 163\n\nHigh-Activation Examples:\n\nExample 1: Then, I needed to describe how attention mechanisms address this by allowing the decoder to selectively\nattend to different parts of the image during caption generation. Initially, I need to examine the steps involved in the\nExample 2: AI excels at pattern recognition and data processing but struggles with common-sense reasoning and abstract\nthinking. I realized this limitation would directly impact its ability to grasp the nuances of jokes.Next, I thought\nExample 3: of these areas, I should provide a concise explanation of how NLP is used and its benefits. For example, for\nchatbots, I can explain how NLP enables them to understand and respond to human language.\nInterpretation: This feature detects a specific syntactic construction used to express procedural necessity and goal-oriented\nsequencing, characterized by an initial infinitive of purpose (‘To [verb]...’) followed by sequence markers (‘first’, ‘then’) and\nmodals of obligation (‘must’, ‘need’, ‘should’). It does not distinguish between internal cognitive planning (reasoning) and\nexternal physical instructions (navigation/policy), activating on both provided the grammatical structure is present.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To reach the ancient temple ruins, tourists first need to traverse the dense jungle path. Then, you will cross the river using\n   the old bridge. To navigate the terrain safely, you must wear appropriate...\n2. To cross the dangerous mountain pass safely, hikers first need to navigate the steep ridge clearly marked on the trail map.\n   Then, you must traverse the glacier efficiently to avoid the risk of falling...\n3. To enforce the privacy policy efficiently, the corporation first must identify the data sources clearly defined in the user\n   agreement. The legal department should then review the consent forms thoroug...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Addressing improvements in image captioning via attention mechanisms starts by grasping the limits of older models\n   lacking such features. Traditional systems compress images into fixed vectors, causin...\n2. Initial thoughts focused on why AI finds humor difficult. Humor relies on complex human traits missing in current\n   software. Thinking about key elements like surprise and context came before everything...\n3. Grasping the request for practical Natural Language Processing examples is the starting point. Effective handling involves\n   looking at NLP in business and daily tech. Analysis of application areas like...\n\n\n\nFeature 13118\n\nHigh-Activation Examples:\n\nExample 1: effectively, I'll first identify the core challenges. These generally revolve around latency, throughput, data\nfreshness, resource management, and scalability/availability. Then, for each challenge, I'll outline\nExample 2: multiplying 63 by 400, I can first multiply 63 by 4, and then multiply the result by 100. This strategy\nsimplifies the calculation because multiplying by\n\n                                                32\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nExample 3: PM). This involves finding the difference between the minutes and the hours. There are 30 minutes from 0:30\nAM to 11:00 AM, and then\nInterpretation: This feature detects procedural segmentation and distinctness, specifically triggering on vocabulary that\nemphasizes handling components individually (e.g., “separately”, “individually”) within a step-by-step structure. It is not\nspecific to cognitive reasoning but rather identifies the linguistic pattern of breaking a task—whether mental or physical—into\ndiscrete, sequential actions.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To pack the fragile china securely, I need to wrap the plates separately. First, I’ll cushion the cups individually with paper.\n  The box itself is reinforced. The move entails a loading phase. Then, I’...\n2. To style the hair perfectly, I need to curl the sections separately. First, I’ll spray the strands individually for hold. The\n   heat itself is moderate. The look entails a setting phase. Then, I’ll brus...\n3. To iron the dress shirts correctly, I need to press the collars separately. First, I’ll spray the cuffs individually with starch.\n  The fabric itself is cotton. I must use a high heat setting for the be...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Real-time query systems face hurdles like latency or throughput so we should look at those core issues plus data freshness.\n   Spotting these challenges helps us find targeted solutions for keeping syste...\n2. Calculating the time from ten-thirty to noon means counting the minutes up to eleven plus the full hour that follows. This\n   strategy gives us the total duration by combining the two parts.\n3. Large number multiplication gets simpler with patterns like powers of ten. We can also use shortcuts for numbers like\n   eleven or five to speed things up. These tricks make the calculation much faster.\n\n\nFeature 1123\n\nHigh-Activation Examples:\n\nExample 1: First, I should consider the importance of consistency. A consistent UI helps users learn the system quickly\nand reduces cognitive load. This leads me to the next point: clear feedback. Users need to know\nExample 2: Initially, I need to examine the provided numbers. Jane has 7 stickers, and she gives 4 away. So, the operation\nI need to perform is subtraction. That must mean I subtract\nExample 3: answer this question effectively, I first needed to consider the current state of AI research and development. I\nthought about the areas where I've been seeing the most buzz and advancements lately. I immediately thought\nInterpretation: This feature detects a specific first-person syntactic template characterized by the dense usage of process-\noriented adverbs (specifically “effectively,” “comprehensively,” “thoroughly,” “accurately”) combined with sequence markers\n(“first,” “next”) and the pronoun “I”. It activates on this lexical cluster regardless of whether the subject matter is cognitive\nplanning or physical action (e.g., cleaning a microphone or stocking a break room).\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To serve the colony effectively, I first comprehensively filtered the water supply. Next, I thoroughly inspected the storage\n   tanks. I accurately measured the levels today. Therefore, I approach the ma...\n2. To assist the developers effectively, I first comprehensively organized the server racks. Next, I thoroughly labeled the\n   cables. I accurately connected the power supply. My approach indicates that the...\n3. To support the developers effectively, I first comprehensively stocked the break room with fresh coffee beans. Next, I\n   thoroughly organized the tangled power cables beneath the shared workstations. I ...\n\n                                                33\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Solving the sticker problem requires basic arithmetic. Jane starts with 7 and gives away 4. Subtracting the given amount\n   from the total yields the final count of stickers remaining.\n2. Current trends in technology highlight Generative AI as a rapidly advancing field. Recent developments have seen\n   models producing high-quality images and text, marking a significant shift in the capab...\n3. Healthcare benefits significantly from machine learning integration. Key applications include improving diagnostics,\n   tailoring medicine to individuals, and accelerating drug discovery. These technolog...\n\n\nFeature 282\n\nHigh-Activation Examples:\n\nExample 1: I need to break down what factors might affect that performance. I can start with the most obvious one: the\ndata the model is trained on. If the data is flawed, the model will learn\nExample 2: My approach begins with identifying these stages, which typically include idea generation, drafting, editing,\ncharacter development, and world-building (especially for genres like fantasy and science fiction). Initially, I need\nExample 3: solving the numerical problem provided. Next, I need to address the specific problem: -8 +5 - (-3) -2. To\ntackle this effectively, I will apply the rules\nInterpretation: This feature detects the specific syntactic template of first-person procedural planning, characterized by the\ncombination of self-referential pronouns (“I”, “My”) with sequencing markers (“First”, “Then”) and strategic nouns/verbs\n(“approach”, “need to”, “identify”). It functions as a style detector for the ‘Chain of Thought’ format rather than a semantic\ndetector of reasoning, as it activates on any content using this ‘First, I need to...’ structure (including simple descriptions)\nbut fails to detect identical reasoning processes when written in the passive voice or third person.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To describe this software feature, I need to clarify the structure. First, I need to define the user inputs. Then, I will provide\n   an explanation of the background calculation. Next, I need to list the...\n2. My approach to reviewing this novel involves a literary explanation. First, I need to identify the author’s objectives.\n   Then, I must consider the narrative inputs and themes. Next, I will analyze the ...\n3. To critique this novel effectively, I need to formulate a structured approach.  First, I need to consider the narrative\n   explanation. Then, I must identify the thematic inputs provided by the author. Ne...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Defining ‘accuracy’ in the context of AI serves as the starting point. It essentially measures how well a model performs\n   tasks like classification. Following the definition, an analysis of performance...\n2. An analysis of the inquiry highlights the role of AI in creative writing. To provide a comprehensive answer, one must\n   examine the various phases of the writing process. Identifying stages such as idea...\n3. Answering the question comprehensively requires outlining key strategies for database optimization. Indexing is a critical\n   tool for faster data retrieval. Describing the purpose of indexes and showing...\n\n\nFeature 14872\n\nHigh-Activation Examples:\n\nExample 1: First, I should consider the division itself. 17 divided by 2 is 8.5. However, since I can't give half a candy, I\nneed to consider the whole\n\n                                                34\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nExample 2: last, I need to figure out how many times1 eraser can be taken out of the total of 4 erasers. This sounds like a\ndivision problem. First, I needed to understand the\nExample 3: friends. This is a division problem. I should divide the total number of bananas (4) by the number of friends\n(2). So, I'll calculate 4 ÷ 2.\nInterpretation: This feature detects the syntactic pattern of first-person procedural planning and self-narration, specifically\ntriggering on the combination of first-person pronouns (‘I’, ‘me’) with modals of necessity or intent (‘need’, ‘should’, ‘will’).\nIt identifies the linguistic style of an agent explicitly articulating their next steps, regardless of whether the content is abstract\nmathematical reasoning or concrete physical instructions.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To assemble this bookshelf, I first need to determine which board is the bottom piece. I should look for the pre-drilled\n   holes near the edge. I will align the side panel with the base. I need to figur...\n2. First, I need to determine if the car tires are properly inflated. I should look for the recommended pressure on the door\n    label. I need to figure out which tire looks low. I will simply attach the air...\n3. First, I need to determine the correct time to set this alarm clock. I should check the time on my phone. I need to figure\n   out which button changes the hour digit. I will simply hold down the ’set’ bu...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Analyzing the task involves splitting 17 candies between 2 kids without breaking any. The situation calls for integer\n   division. 17 over 2 makes 8, leaving 1 behind. This calculation shows that 8 is th...\n2. Review the provided data points. Mike holds 4 erasers total. Usage is 1 per day. Determining the duration involves\n   dividing the total quantity by the daily consumption rate. The math is clear: 4 divid...\n3. The problem asks for an equal share of bananas. With 4 bananas and 2 buddies, division is the necessary operation. Splits\n   happen evenly here. Dividing 4 by 2 results in 2. Each friend receives exactly...\n\n\nFeature 491\n\nHigh-Activation Examples:\n\nExample 1: the ethical concerns of AI, I need to consider the various aspects of AI development and deployment where\nethical issues can arise. First, I should consider the data used to train AI models. If the training\nExample 2: , I need to consider various aspects of data handling and AI implementation. Initially, I need to examine the\nstages where data privacy is most at risk, from data collection to model training and deployment. First\nExample 3: problems. My approach begins with recognizing that multilingual support involves more than just translating\ntext. It encompasses a comprehensive adaptation of the software to different languages, cultures, and regional\nrequirements.Initially, I need\nInterpretation: This feature detects the syntactic template and punctuation of explicit procedural planning preambles,\nspecifically the ‘To [goal], I need to [action]’ structure often found in Chain-of-Thought responses. It tracks the structural\nmarkers (periods, commas, ‘First’, ‘effectively’) of this specific self-reflective planning style, activating equally strongly on\ncomplex topics and trivial/synthetic examples provided they utilize this specific rhetorical template.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To address the topic of invisible ink effectively, I need to consider the transparency of the liquid. First, I need to recall the\n   secret message. My approach begins with analyzing the blank paper comp...\n2. To address the topic of arranging the bookshelf effectively, I need to consider the visual appeal of the covers. First, I\n   should outline a color-coding system. My approach begins with sorting the book...\n\n                                                35\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n3. To answer the question of how to brew tea comprehensively, I need to consider the water temperature. First, I need to\n   identify the type of tea leaves. My approach begins with boiling the water to the ...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Mere translation fails to achieve true multilingual support; the software’s core architecture needs modification. The code\n    itself must change to accommodate the structural differences between language...\n2. Ethical risks in AI development are most prominent in the data collection phase, where biases in training sets can be\n   learned and amplified by the system if not carefully managed.\n3. Surrounding information allows AI systems to interpret user intent correctly by providing the necessary background for\n   ambiguous queries.\n\n\nFeature 4510\n\nHigh-Activation Examples:\n\nExample 1: for implicit constraints and requirements. The mention of “limited resources and time” suggests that I need to\nfocus on efficiency and cost-effectiveness. This eliminates approaches that are resource-intensive upfront, such as\nExample 2: easier to track. Next, I need to consider other methods people use, like aligning numbers by place value and\nadding column by column, carrying over when necessary. I should also think about ways to simplify\nExample 3: resulting in P = 2 * length + 2 * width, which can also be written as P = 2 * (length + width).Next, I needed to\naddress the units of\nInterpretation: This feature detects the infinitive marker “to” specifically when used in syntactic structures indicating purpose\n(e.g., “To [verb]...”) or necessity (e.g., “need to...”). It is a grammatical feature that identifies goal-oriented procedural\nlanguage, activating on step-by-step plans regardless of whether the content is complex reasoning, a recipe, or a simple\nnarrative action.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To bake the perfect chocolate cake, I need to preheat the oven to 350 degrees. First, I need to sift the dry ingredients into\n   a large bowl. To ensure the batter is smooth, I need to beat the eggs one ...\n2. First, I need to hide before the guards come back. To stay alive, I need to reach the ventilation shaft in the ceiling. I need\n   to move quietly. To open the grate, I need to use the small knife in my p...\n3. To assemble this bookshelf, I need to identify the screws listed in the manual. First, I need to lay out all the wooden\n   panels on the floor. To connect the sides, I need to use the allen wrench provid...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Understanding the central question regarding knowledge base expansion under tight resources is vital. Prioritizing\n   strategies that maximize impact while minimizing effort is key. Initially, examining ...\n2. Answering effectively requires considering various approaches for adding large sums. Breaking figures into hundreds,\n    tens, and ones seems optimal, facilitating tracking and mirroring standard learning...\n3. Calculating a rectangle’s perimeter starts by recalling the definition: total distance around a shape. Adding lengths of all\n   four sides achieves this. Logic dictates summing two lengths and two widths...\n\n\nFeature 3810\n\nHigh-Activation Examples:\n\n                                                36\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nExample 1: the positive direction. I also need to provide a clear algebraic representation of this principle, such as`a - (-b)\n= a + b`, and then give concrete examples to demonstrate the rule\nExample 2: ?” and “What are the different types of AI?” Next, I should think about the practical applications and real-\nworld impacts of AI, which prompts questions like “What are the current applications of AI\nExample 3: , I need to understand the question which is asking for practical examples of Natural Language Processing\n(NLP). To tackle this effectively, I should consider various aspects of NLP usage in both everyday technology and\nbusiness.\nInterpretation: This feature detects a specific lexical and syntactic template used for procedural planning, characterized by\nthe pattern ‘First, I need to [verb]’ or ‘To tackle this... effectively’. It responds strictly to the combination of first-person\nmodal necessity (‘I need to’) followed by analytical verbs (‘identify’, ‘define’, ‘outline’), regardless of whether the subject\nmatter is cognitive reasoning, sports strategy, or creative writing.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To tackle this dream effectively, I need to identify the shifting shadows. First, I should define the nature of the fog\n   surrounding me. I need to outline the path through the void and establish a conn...\n2. To tackle this awkward dinner effectively, I need to identify a safe topic of conversation. First, I should define the mood\n   of the room to avoid tension. I need to outline my anecdotes and establish a...\n3. To tackle this sculpture effectively, I need to identify the natural grain of the wood. First, I should define the posture of\n   the central figure. I need to outline the rough cuts and establish the cor...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. The assignment is to demonstrate how to subtract negative integers. Step one is grasping the essence of subtraction and\n  how it ties to addition. Subtraction acts like adding the inverse, so removing a...\n2. The query seeks real-world samples of Natural Language Processing. A solid response involves exploring NLP’s role in\n   daily tech and business. I will start by breaking down the specific areas using thi...\n3. First, we have to retrieve the main formula for a rectangle’s area. The total space is the product of length and width. So,\n   the rule is ‘area = length * width’. To add depth, I should also talk about ...\n\n\nFeature 1148\n\nHigh-Activation Examples:\n\nExample 1: an AI model better, I need to break down the training process into key components. First, I need to consider\nthe data itself – its quality, preparation, and how it's fed into the\nExample 2: multilingual software application support, I first need to break down the overall problem into smaller sub-\nproblems. My approach begins with recognizing that multilingual support involves more than just translating text. It\nencompasses a comprehensive adaptation\nExample 3: To tackle this effectively, I should break down the answer into two main parts: the considerations and the\ntypes of services. For the considerations, I need to think about what someone would look for when\nInterpretation: This feature detects a specific lexical cluster of formal vocabulary related to structural decomposition,\norganization, and thoroughness (e.g., “break down,” “categorize,” “thoroughly,” “structured”). It activates on the presence of\nthese specific terms whether they are used in a meta-cognitive planning context or in static descriptions of systems, manuals,\nand software updates. It fails to detect the semantic concept of problem decomposition when expressed in simpler or more\ncasual language.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n                                                37\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n1. Version 2.0 has been implemented to thoroughly address user feedback. We have categorized the settings menu to break\n  down complex options into distinct panels. This update introduces a structured work...\n2. The corporate safety manual is structured to thoroughly address workplace hazards. It categorizes the potential risks to\n   break down the emergency protocols into distinct action plans, focusing on empl...\n3. The corporate audit framework is employed to thoroughly address the question of financial transparency and compliance.\n    It carefully categorizes the transaction logs to break down the complex revenue s...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Regarding the question on supporting software in multiple languages, I will split the big task into smaller bits. It starts\n   with realizing that this involves more than just translating words. It requi...\n2. Regarding the question on supporting software in multiple languages, I will split the big task into smaller bits. It starts\n   with realizing that this is more than just translating text. It involves ful...\n3. The user asks how to apply AI to personal tasks with few resources. Because that subject is huge, I will select particular\n   spots where it works. I’ll start with writing and art tools.\n\n\nFeature 6048\n\nHigh-Activation Examples:\n\nExample 1: question comprehensively, I need to outline several key strategies for optimizing database query performance.\nFirst, I should consider indexing. Indexes are crucial for speeding up data retrieval, so I need to explain their purpose,\nExample 2: question effectively, I need to explain what estimation is in the context of addition and then describe some\ncommon strategies used for estimation. First, I need to define estimation as a method for approximating numbers to\nsimplify\nExample 3: question effectively, I need to explain how subtraction can be understood in terms of adding negative\nnumbers. First, I need to define the concept of an additive inverse (or negative) of a number. This\nInterpretation: This feature specifically detects the first-person pronoun “I” when used in the context of meta-cognitive\nplanning, self-narration, or outlining a response strategy (e.g., “I need to”, “I should”). It is strictly tied to the first-person\nperspective and the syntactic structure of an agent explicitly stating their intentions, rather than the semantic content of\nreasoning itself.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To answer this question about the course structure, I need to outline the core topics effectively. First, I should consider\n   the introductory module. I need to identify the required textbooks and expla...\n2. To answer this question about the perfect sourdough, I need to identify the core biological processes of fermentation.\n    First, I should consider the activity of the wild yeast. I need to explain how te...\n3. To answer this question effectively, I need to outline the core principles of interior design for small spaces. First, I should\n   consider the layout and flow of the room. I need to identify how lightin...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. To provide a comprehensive answer regarding database query performance, an outline of key strategies is essential.\n   Indexing functions as a primary consideration. Because indexes speed up data retrieva...\n2. Tackling this inquiry effectively involves defining estimation within the context of addition, followed by a description of\n  common strategies. The definition should characterize estimation as a method...\n3. Understanding subtraction through the lens of adding negative numbers requires a clear explanation. A crucial initial step\n   involves defining the additive inverse. This foundation establishes that subt...\n\n                                                38\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nFeature 791\n\nHigh-Activation Examples:\n\nExample 1: First, I should consider the data itself. If AI systems are dealing with sensitive data, robust security measures\nmust be in place, like encryption and anonymization. I need to highlight the risk\nExample 2: additional marbles she finds, which is2. To determine the total number of marbles Olivia has, I must combine\nthese two quantities. This means I should add the number of initial marbles to the number\nExample 3: To find the total number of seashells, I should add these two quantities together. So, I need to calculate 5 + 2.\nPerforming the addition, 5 + 2 equals 7\nInterpretation: This feature detects the specific syntactic sequence of a comma following an introductory transition (like\n“First” or “To answer...”) immediately preceding the phrase “I need to” or “I must.” It identifies a specific structural template\noften used in Chain-of-Thought prompting but activates on this syntax regardless of whether the semantic content is logical,\nnonsense, or creative.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To answer this question comprehensively, I need to consider the existential dread of a melted snowman. First, I need to\n    identify where the carrot nose went, as this is the most pressing mystery of the...\n2. First, I need to identify the melody within the noise. To compose this symphony, I need to consider the rhythm of the city\n    streets and how the traffic sounds blend into a chaotic harmony.\n3. To answer this question comprehensively, I first need to consider the possibility that we are all just butterflies dreaming. I\n   should identify the color of my wings and determine if I can fly towards ...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Determining the suitability of AI for sensitive tasks requires analyzing the specific aspects that define sensitivity. Usually\n    this implies handling regulated or confidential data. Consequently the re...\n2. The calculation starts with the 7 marbles Olivia owns originally. Next comes accounting for the 2 additional marbles she\n   discovered later. Finding the total demands combining these two separate quanti...\n3. Recalling the standard formula for a rectangle’s area is the prerequisite step. Multiplying length by width yields the area.\n   The core concept is ‘area = length * width’. Making the answer complete als...\n\n\n\nFeature 444\n\nHigh-Activation Examples:\n\nExample 1: to break down the process into manageable steps: converting to improper fractions, finding a common\ndenominator, subtracting the fractions, converting back to a mixed number, and then addressing the borrowing scenario.\nFirst,\nExample 2: perform the calculation carefully. My approach begins with setting up the subtraction: 100 - 27 — Initially, I\nneed to examine the ones column. I can\nExample 3: down the answer into key strategies. Let me start by analyzing what makes a conversation seamless and\nengaging. This leads me to consider defining clear goals, mapping user journeys, and structuring the flow hierarchically.\nInterpretation: This feature functions as a semantic detector for specific abstract, categorical, or procedural nouns (e.g.,\n“process,” “problem,” “sentence,” “recipe,” “topic”) that label systems, tasks, or structural elements. While these words\nfrequently appear during planning (hence the initial hypothesis), the feature activates reliably on these tokens in non-\nreasoning contexts such as technical manuals, formal narratives, and descriptive writing, indicating it is tied to the vocabulary\nrather than the cognitive process.\n\n                                                39\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. The editor circled the **sentence** in red. She noted that the **structure** was awkward and the **topic** was unclear.\n  The entire **paragraph** lacked coherence. She recommended rewriting the **text*...\n2. The manual outlines the installation **process**. It describes the **functionality** of each **element**. The **system**\n   handles the data **retrieval** automatically. Users can configure the **setting...\n3. The moderator posed the **question** to the panel. The **topic** of discussion was renewable energy. The expert\n   provided a detailed **answer**. She analyzed the **issue** from a scientific **perspecti...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. I need to determine what makes a bot chat effective. I’ll look at clarity and engagement. I’ll discuss the requirements,\n   starting with creating a smooth exchange for the user.\n2. I have to subtract 27 from 100. Because of the zeros, I need to borrow. I will place 100 on top of 27. The ones place is\n   zero, so I must borrow from the neighboring columns before subtracting.\n3.  I have to take 27 away from 100. Because of the zeros, I need to borrow. I will place 100 on top of 27. The ones place is\n   zero, so I must borrow from the left.\n\n\nFeature 34\n\nHigh-Activation Examples:\n\nExample 1: Expressions (CTEs) often helps. Using `EXPLAIN` to analyze the execution plan is crucial because it shows\nhow the database intends to run the query and highlights inefficiencies like full table scans. Rew\nExample 2: list.sort()` modifies the list in-place. Then, I must explain the crucial role of the `key` parameter, which\nallows specifying a function to extract the sorting key from each object.\nExample 3: that could be the information surrounding a user's query. Initially, I need to examine what kinds of\ninformation might constitute context for an AI. I must then connect this to how the AI processes this\nInterpretation: This feature detects determiners (primarily “the”, “its”, “their”) when they appear within specific procedural\nor instructional sentence templates, typically characterized by introductory markers like “First,” “To,” or “//” followed by\nintent phrases like “I need to identify” or “address the.” It identifies the syntactic structure of outlining a primary step or\ndefinition, regardless of whether the content is cognitive reasoning, code documentation, or physical description.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1.  // First, to initialize the module, identify the core dependency. // The entire script relies on this file. // To handle the input,\n   the function parses the string. // The core logic is defined in the ...\n2. First, I need to identify the bird on the branch. To see the colors, I use my binoculars. The entire flock takes flight. I need\n   to capture the image. To focus the lens, I turn the dial. The core marki...\n3.  // First, to execute the script, identify the core function. // The entire process runs in the background. // To handle the\n   output, the system writes to the log. // Its configuration is loaded from th...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Start by grasping what constitutes complex database queries. Typically, such requests involve multiple tables, intricate\n    filtering, plus massive datasets. Handling these efficiently demands attention ...\n2. Addressing how one sorts lists of Python objects using attributes requires providing a full guide on various techniques.\n    First, introducing `sorted()` functions and `list.sort()` methods is best, noti...\n\n                                                40\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n3. Answering how context affects AI outputs requires considering what ‘context’ means for AI and usage patterns. My\n   approach starts by thinking about general definitions of context—circumstances forming ...\n\n\nFeature 13167\n\nHigh-Activation Examples:\n\nExample 1: , I need to identify the core capabilities of AI. These generally include machine learning, natural language\nprocessing, computer vision, robotics, and expert systems. I need to define each of these capabilities clearly,\nExample 2: , I need to determine the core issue the question is addressing, which is how to improve the precision of\nsearch queries. To tackle this effectively, I need to break down the concept of search query precision\nExample 3: , I need to consider the core aspects of LLMs and their functionalities to identify potential limitations. To\ntackle this effectively, I'll start by thinking about what LLMs are good at, which is\nInterpretation: This feature functions as a precise n-gram detector for the sequence “First, I need to”, specifically activating\non the token “I” within this structure. It captures the syntactic initiation of a first-person sequential action or plan, but it is\nagnostic to the semantic content, activating equally on abstract cognitive planning and mundane physical chores.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. First, I need to remove the core of the apple. It is hard and inedible, so I use a small paring knife to carefully cut it out.\n  Once that is done, I can slice the rest of the fruit into even rings for ...\n2. First, I need to identify my suitcase on the crowded luggage carousel. There are so many black bags that look exactly\n    alike, circling around and around. I squint my eyes under the fluorescent lights, ...\n3. First, I need to catch my breath. I ran all the way from the subway station to the office building because I overslept and\n  was running late. My heart is pounding in my chest, and I have to lean agains...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. To initiate the process, one must outline the fundamental functions of artificial intelligence. These elements typically\n   comprise machine learning, natural language processing, and robotics. Defining ...\n2. The starting point is determining the main issue: improving search query precision. To handle this, breaking down the\n   concept of accuracy is required, along with finding methods that influence it. The...\n3. Let us begin by evaluating the primary aspects of Large Language Models to find their constraints. An effective analysis\n    starts by looking at their strengths, which are mainly text processing based on...\n\n\nFeature 928\n\nHigh-Activation Examples:\n\nExample 1: should prioritize strategies that maximize impact while minimizing time and effort.Initially, I should\nexamine the question for implicit constraints and requirements. The mention of “limited resources and time” suggests\nthat I need to\nExample 2: tackle this effectively, I should use an example to illustrate this principle. Initially, I need to examine a simple\narithmetic expression that involves subtracting a negative number. Let's choose `5 - (-3\nExample 3: to identify that the core problem is the unlike denominators. To tackle this, I need to explain the concept of a\ncommon denominator, specifically the least common multiple (LCM). I should illustrate how to find\nInterpretation: This feature detects specific syntactic constructions related to first-person agency, intent, and necessity,\ncharacterized by the combination of first-person pronouns (‘I’, ‘me’, ‘we’) with modals (‘should’, ‘can’, ‘will’) and infinitives\n(‘to’). It is not a reasoning detector; rather, it identifies the grammatical structure of a speaker stating what they are doing,\n\n                                                41\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nneed to do, or will do, regardless of whether the context is solving a complex logic puzzle, making casual social plans, or\ndescribing physical actions.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1.  I’ll come over to your place directly after work. You simply need to let me know the time. I can bring the drinks, and I\n   should probably pick up ice too. This allows me to help out. We typically eat l...\n2. To open the box, I need to pull the tab. This allows me to lift the lid. You can see the contents inside. I should handle it\n    carefully. I’ll place it on the table directly. I’ve checked the seal. It s...\n3. I should have told you sooner. It leads me to feel guilty. I’ll make it up to you, I promise. You can trust me on that. I\n   simply forgot the date. I’ve been so busy lately. I need to apologize properly...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Understanding the core question regarding knowledge base growth under tight resources is key. This requires prioritizing\n   high-impact strategies with minimal time or effort. Checking for implicit const...\n2. Answering this requires explaining subtraction of negative numbers and the link with addition. Defining the core principle\n   comes first: subtracting a negative equals adding a positive. Using an exampl...\n3. Adding fractions with different denominators demands outlining the process. Identifying the unlike denominators is the\n   main issue. Explaining the common denominator concept, specifically the least com...\n\n\n\nFeature 934\n\nHigh-Activation Examples:\n\nExample 1: for me is to recall the multiplication table. I remember that 7 times 8 is a standard multiplication fact. If I\ndidn't remember it directly, I could break it down. For example\nExample 2: So, (2/5) *150 gives me the number of apples sold.After calculating the apples sold, I need to subtract that\nnumber from the original150\nExample 3: ` by itself on one side of the equation. To do this, I need to undo the addition of 5. The opposite operation is\nsubtraction, so I should subtract 5 from *both*\nInterpretation: This feature detects procedural discourse markers and sequential transitions used to organize step-by-step\nprocesses. It activates strongly on temporal connectors (e.g., “Then”, “Next”, “Initially”, “So”) and syntactic structures\nthat introduce a sequence of actions (e.g., “To [action], I first...”), appearing in both logical reasoning chains and mundane\nphysical instructions (like painting or cleaning). It tracks the linguistic structure of a sequence rather than the semantic\ncontent of reasoning.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. To paint the room effectively, I first needed to prime the walls. Initially, the color looked too dark. Then, it dried to a\n    lighter shade. Next, I applied the second coat. So, the finish was smooth. I...\n2. To clean the garage effectively, I first needed to move the boxes. Initially, the dust made me sneeze. Then, I swept the\n    floor. Next, I organized the tools. So, the space became usable again. Now, the...\n3. To assemble the table effectively, I first needed to sort the screws. Initially, the parts looked similar. Then, I read the\n   diagram. Next, I tightened the bolts. This led to a sturdy frame. So, the ta...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n                                                42\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n1. Multiplication is essentially repeated addition. Seven times eight translates to adding the number seven eight separate\n   times. Memorizing the multiplication table offers a faster route. 7 multiplied b...\n2. Figuring out the remaining apples involves calculating the sold amount. The market sales accounted for two-fifths of the\n  150 total apples. Multiplying 150 by 0.4 results in 60 apples sold. Deducting t...\n3. Isolating `x` in the equation `3x + 5 = 14` is the primary objective. The addition of 5 necessitates subtraction as the\n   inverse operation. Removing 5 from both sides preserves equality and simplifies ...\n\n\n\nFeature 4010\n\nHigh-Activation Examples:\n\nExample 1: , I need to consider the number of marbles Olivia initially possesses, which is 7. Then, I need to account for\nthe additional marbles she finds, which is2. To determine the total\nExample 2: , I need to identify the core mathematical operation required to solve the problem. The question asks how\nmany cookies each friend receives when 9 cookies are shared among 3 friends. This indicates a division problem\nExample 3: , I need to figure out the total number of stamps Lily started with, which is 6. Then, I need to subtract the\nnumber of stamps she lost, which is 1. So,\nInterpretation: This feature functions as a precise n-gram or phrase detector for the sequence “First, I need to”, specifically\nactivating on the pronoun “I” within this rigid structure. It is semantically blind, activating with identical strength (∼677) onboth complex cognitive planning and mundane physical descriptions (e.g., wiping tables), provided the specific introductory\nphrase is used.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. First, I need to unlock the front door. The key is right here in my pocket. I truly struggle with this old lock sometimes.\n  We are finally home after a long trip. I just want to get inside and sit down...\n2. First, I need to wipe the table. It is covered in crumbs from dinner. I sure hope we have enough paper towels left. I truly\n   dislike a messy kitchen. We just finished eating. I need to clean this up qu...\n3. First, I need to put on my heavy coat. It is freezing outside today. I truly hate the winter cold. I just want to stay warm\n   while we walk. We are going to the shops down the street. I need to find my ...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Start by noting the 7 marbles Olivia has originally. Add the 2 extra marbles she found to that amount for the total. The\n  sum of 7 and 2 is 9. This means she has 9 marbles in total.\n2. To calculate the share for each friend divide the 9 cookies by 3 people. This division problem of 9 over 3 results in 3.\n   Each friend receives 3 cookies.\n3. Lily established a collection of 6 stamps initially. She lost 1 stamp so subtraction is the right step. Calculating 6 minus 1\n   leaves 5. The final number of stamps is 5.\n\n\n\nFeature 1430\n\nHigh-Activation Examples:\n\nExample 1: dive into the technical details. So I should provide options for both online courses and books. For online\ncourses, I should consider platforms like Coursera, edX, fast.ai, and Udacity\nExample 2: subtract 5 from *both* sides of the equation. This maintains the balance of the equation. When I subtract 5\nfrom both sides, I get `3x + 5 - 5\n\n                                                43\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nExample 3: extraction, and content recommendation. For each of these areas, I should provide a concise explanation of\nhow NLP is used and its benefits. For example, for chatbots, I can explain how NLP enables them\nInterpretation: This feature detects a specific cluster of technical, geometric, and categorical vocabulary (e.g., “cube”,\n“rectangle”, “category”, “samples”) alongside adverbs of precision (e.g., “accurately”, “effectively”, “thoroughly”). While\nthese words frequently appear during the decomposition phase of formal problem-solving, the feature is lexical rather than\nfunctional, activating equally strongly on static descriptions of physical objects, data layouts, or artwork that utilize this\nspecific vocabulary.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. The sculpture consists of a large **cube** resting on a wide **rectangle**. To view the **samples** **accurately**,\n   observers should stand to the **left**. This angle reveals the **biased** perspectiv...\n2. The textbook page illustrates the concept of numbers by showing a grid of **integers** and **fractions** inside a yellow\n   **rectangle**. The accompanying text answers the student’s **question** **compr...\n3. The laboratory rack holds the test **samples** sorted by **category**. To record the **data** **accurately**, the\n   technician scans the barcode on the **left**. The protocol manual outlines the storage...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. We need a dozen even wedges from one pie. The simplest path is splitting the circle in half, then into quarters. One cut\n   makes two bits, and a cross cut yields four.\n2. The request seeks practical uses for language processing tech. A good response covers its role in both daily gadgets and\n   corporate tools. We can begin by spotting main fields like automated chat agent...\n3. The core task is adding speech control to a Python app. The work divides into steps: grabbing audio, changing sound to\n    text, parsing commands, running actions, and signaling the person that it is fini...\n\n\nFeature 1171\n\nHigh-Activation Examples:\n\nExample 1: a number line. First, I need to consider what subtraction means visually on a number line — it means moving\nto the left. The first number in the subtraction problem is where I should start on the\nExample 2: 2, dividing by 2 and then dividing by 2 again will give the same result as dividing by 4. For example, if I want\nto divide 20 by 4, I\nExample 3: missing addend. First, I need to identify the basic components of an addition equation: the addends and the\nsum is the total you get when you add the addends together.\nInterpretation: This feature detects a specific lexical cluster involving modals of necessity, ability, and intent (e.g.,\n“need”, “can”, “wants”) combined with conditional or resultative connectors (e.g., “if”, “gives”, “until”, “where”). Rather\nthan detecting the semantic process of reasoning, it identifies sentences that describe requirements and their subsequent\noutcomes or conditions, which appears frequently in ‘step-by-step’ planning but equally in recipes, sports commentary, and\ntroubleshooting guides.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. This is a classic recipe where patience gives the best flavor. The dough needs to rest in a warm bowl until it doubles in\n    size. If you can wait, the high heat gives it a perfect golden crust. The bake...\n2. Here is the answer to the connection issue everyone is asking about. The system wants to update automatically. If you\n   can click the prompt, it gives you immediate access. We need to address the server...\n\n                                                44\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\n3. He wants the victory more than anything. If he gives his best effort on the field, he can succeed. The fans are asking for a\n    final goal. He needs to run hard until the whistle blows. This match gives ...\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. Division works by subtracting the divisor repeatedly. Remove the specific amount from the starting total over and over.\n   The cycle ends at zero. Counting the removals reveals the final answer.\n2. Like terms are defined by sharing the same variable and power. In the expression 3x + 4y - 2x + 5y, certain elements\n    align. Note that 3x and -2x both use x to the first power. Thus, they belong togeth...\n3. Division functions fundamentally as repeated subtraction. One subtracts the divisor from the main number repeatedly.\n   The process concludes once the value hits zero. The total count of these subtractio...\n\n\nFeature 14138\n\nHigh-Activation Examples:\n\nExample 1: natural language. First, I need to think about the initial stage, which is obtaining the text data itself. So, the\nfirst step would naturally be **Text Acquisition**. After acquiring the raw text,\nExample 2: he's sharing them with3 siblings. It's crucial to understand that Alex is sharing with *his* siblings, and not\nincluding himself in the distribution. To figure out how many toys\nExample 3: define “borrowing” in the context of subtraction, highlighting that it's more accurately described as\nregrouping. My approach begins with identifying the core issue – when a digit in the subtrahend\nInterpretation: This feature detects a specific lexical cluster of words commonly found in educational word problems,\ntechnical descriptions, and illustrative examples.  It activates on a fixed set of nouns (e.g., “birds”, “eggs”, “interface”,\n“tax”, “students”) and verbs (e.g., “sharing”, “handle”, “indicates”, “constitutes”) regardless of the surrounding context.\nWhile these words frequently appear in the setup phase of reasoning tasks (e.g., a math problem about sharing), the feature\nresponds to the vocabulary itself rather than the syntactic structure or reasoning process.\nClassification: Confound (Confidence: HIGH)\nFalse Positives (Non-reasoning content that strongly activates the feature):\n\n1. The main ingredient in the recipe is organic **eggs**. **She** is **sharing** the chocolate **cakes** **with** the\n   family. The process involves **handling** the batter carefully. The taste **is** **tr...\n2. The garden is full of wild **birds** and **flies**. The stone path is described **as** **geometric**. The broken shell\n   **indicates** the presence of **eggs**. The environment **constitutes** a safe ha...\n3. The new computer features a **robust** **interface**. The software is **optimizing** the processing speed. The guide\n    is **about** how to **handle** errors. The screen **indicates** the system status.\n\nFalse Negatives (Semantic paraphrases of high-activation samples that fail to activate):\n\n1. To solve this efficiently, I must review the standard NLP workflow. My process starts by gathering raw data. We label\n    this step Text Acquisition. Once I have the material, I usually find it disorganiz...\n2.  I need to extract the key figures from the problem statement. Alex possesses 9 toys. He allocates these items to 3 siblings.\n  We must note that Alex gives them away rather than keeping any. To find the...\n3. To solve this, I will review the standard NLP sequence. Collecting data happens first. We label this phase Text Acquisition.\n  Raw inputs often contain noise and need cleaning.\n\n\n\n\n\n                                                45\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nH. Dataset details\n\nThis section provides detailed descriptions of the datasets used to construct reasoning and non-reasoning corpora in our\nexperiments (Section 5). We use two reasoning datasets with explicit chain-of-thought traces and one general-text dataset as\na non-reasoning baseline.\n\nH.1. s1K-1.1\n\nThe s1K-1.1 dataset is a curated collection of 1,000 challenging mathematics problems, derived from the original s1K dataset\nintroduced by Muennighoff et al. (2025). The questions span a range of mathematical domains, including algebra, geometry,\nnumber theory, and combinatorics, and are designed to require multi-step reasoning. In contrast to the original s1K dataset,\nwhich contains reasoning traces generated by Gemini Thinking, s1K-1.1 augments the same set of 1,000 questions with\nadditional chain-of-thought traces generated by DeepSeek-R1, resulting in a mixture of Gemini- and DeepSeek-generated\nsolutions. We use both types of traces in our experiments.\nEach example consists of a problem statement and an associated reasoning trace that decomposes the solution into explicit\nintermediate steps. The traces are written in natural language and include algebraic manipulations, case analyses, and\nexplanatory commentary. We treat the reasoning trace as the reasoning text and exclude the final answer when constructing\ninputs for feature analysis, in order to focus on intermediate reasoning behavior rather than answer tokens. For all\nexperiments, inputs are truncated to a maximum of 64 tokens.\n\nH.2. General Inquiry Thinking Chain-of-Thought\n\nTo evaluate reasoning features beyond mathematics, we use the General Inquiry Thinking Chain-of-Thought dataset (Wensey,\n2025). This dataset contains approximately 6,000 question-answer pairs with explicit chain-of-thought annotations. Unlike\nmathematics-focused datasets, General Inquiry spans a broad range of domains, including scientific reasoning, logical\npuzzles, everyday decision making, and philosophical or conceptual questions.\nEach example includes a user question and a step-by-step reasoning trace that justifies the final answer. The diversity of\ntopics and styles reduces the risk that results are driven by domain-specific vocabulary or formatting conventions. As with\ns1K-1.1, we use only the chain-of-thought portion of each example and truncate inputs to 64 tokens. For each experimental\nconfiguration, we randomly sample 1,000 examples from the dataset to form the reasoning corpus.\n\nH.3. Pile Uncopyrighted\n\nAs a source of non-reasoning text, we use the uncopyrighted subset of the Pile (Gao et al., 2020). The Pile is a large-scale\nEnglish text corpus constructed from 22 heterogeneous sources, including academic writing, books, reference material, and\nweb text. The uncopyrighted version removes all copyrighted components to support responsible use.\nWe randomly sample 1,000 text passages from this corpus and truncate each passage to 64 tokens. These samples are\ntreated as non-reasoning text and are used as the baseline distribution in contrastive feature detection (Section 4.2) and token\ninjection experiments (Section 4.3). While some passages may contain implicit reasoning, the dataset does not include\nexplicit chain-of-thought traces or structured problem-solving discourse, making it a suitable non-reasoning comparison\ncorpus.\n\n\n\n\n\n                                                46\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nI. Benchmark details\n\nThis section describes the external benchmarks used to evaluate the behavioral effects of feature steering (Section 5.5).\nThese benchmarks are used only as supplementary evaluations and do not form the basis of our primary conclusions.\n\nI.1. AIME 2024\n\nWe evaluate mathematical reasoning performance using problems from the American Invitational Mathematics Examination\n(AIME) 2024 (Zhang & Math-AI Team, 2024). AIME is a well-established mathematics competition at the advanced high\nschool level, consisting of problems that require multi-step symbolic reasoning and careful algebraic manipulation. The\n2024 edition includes 30 problems drawn from the AIME I and AIME II contests.\nEach problem has a single integer answer, and detailed official solutions are available. In our experiments, we use the\nproblem statements as prompts and evaluate model outputs based on exact match with the ground-truth numerical answers.\nWe use one-shot chain-of-thought prompting and allow long generation lengths to avoid truncating reasoning traces.\n\nI.2. GPQA Diamond\n\nWe also evaluate scientific reasoning using the Diamond split of the Graduate-Level Google-Proof Question Answering\nbenchmark (GPQA) (Rein et al., 2024). GPQA is a multiple-choice question answering dataset constructed by domain\nexperts in biology, physics, and chemistry. The questions are intentionally designed to be difficult for both non-experts and\nstate-of-the-art language models, even with access to external resources.\nThe Diamond split consists of the most challenging subset of questions and is commonly used as a stress test for advanced\nreasoning capabilities. Expert annotators achieve substantially higher accuracy within their own domains than non-expert\nvalidators, highlighting the depth of domain knowledge required. Due to the sensitivity of the dataset and the risk of leakage,\nwe do not reproduce or paraphrase individual questions in this paper.\nIn our steering experiments, we evaluate accuracy on the multiple-choice answers using one-shot chain-of-thought prompting.\nAs with AIME 2024, these results are reported as supplementary evidence and are interpreted cautiously, since performance\nchanges alone do not imply that a steered feature encodes a genuine reasoning mechanism.\n\n\n\n\n\n                                                47\n\n                            Falsifying Sparse Autoencoder Reasoning Features in Language Models\n\nJ. Licenses and responsible use\n\nWe carefully adhere to the licenses and usage terms of all datasets, models, and benchmarks used in this study. For\nnon-reasoning text, we use the uncopyrighted subset of the Pile dataset. The s1K-1.1 dataset and the General Inquiry\nThinking Chain-of-Thought dataset are released under the MIT license.\nWe evaluate open-weight language models released under permissive or research-friendly terms. The Gemma 2 and Gemma\n3 models are used in accordance with the Gemma Terms of Use. The Llama 3.1 models are used under the Llama 3.1\nCommunity License Agreement. The DeepSeek distilled models are released under the MIT license. Sparse autoencoders\nfrom the Gemma Scope and Gemma Scope 2 releases are licensed under the Creative Commons Attribution 4.0 License,\nand the Llama Scope release is licensed under the Apache License 2.0.\nFor evaluation benchmarks, AIME 2024 is used under the Apache License 2.0, and GPQA is released under the Creative\nCommons Attribution 4.0 License.\nFigure 1 incorporates icons created by karyative and Bartama Graphic from the Noun Project, licensed under the Creative\nCommons Attribution 3.0 License (CC BY 3.0). The icons have been resized and stylistically adapted for consistency with\nthe figure design. Use of these icons complies with the license requirements, including attribution to the original creators\nand indication of modifications.\nAll experiments are conducted for research purposes only. We do not release any new model weights or datasets, and we do\nnot modify or redistribute licensed resources beyond what is permitted by their respective terms. We encourage future work\nbuilding on this study to similarly respect licensing constraints and responsible research practices.\n\n\n\n\n\n                                                48\n\n## Claim to Classify\n\"many contrastively selected candidates are highly sensitive to token-level interventions with 45-90% activating after injecting only a few associated tokens\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Causal token injection (activation patching variant)",
    "method_rung": 2,
    "claim_rung": 2,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The claim is from the abstract: 'many contrastively selected candidates are highly sensitive to token-level interventions with 45-90% activating after injecting only a few associated tokens'. The method used is causal token injection, which involves inserting tokens into non-reasoning text and measuring activation changes. This is an intervention on the model (replacing/adding tokens) and measures causal effect on feature activation, fitting Rung 2 (Interventional). The claim describes a causal effect: injecting tokens changes activation. It uses language like 'sensitive to token-level interventions' and 'activating after injecting', which are causal markers (intervening on X changes Y). There is no uniqueness or mechanistic language; it's about sufficiency of tokens to elicit activation. No hedge words present. Confidence is high because the method and claim are clearly described and align with Rung 2 definitions."
  },
  "metadata": {
    "model": "deepseek/deepseek-v3.2",
    "usage": {
      "prompt_tokens": 48645,
      "completion_tokens": 237,
      "total_tokens": 48882
    },
    "finish_reason": "stop"
  }
}