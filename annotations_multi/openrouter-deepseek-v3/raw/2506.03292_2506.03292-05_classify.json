{
  "timestamp": "2026-02-19T11:40:47.010492+00:00",
  "paper_id": "2506.03292",
  "claim_id": "2506.03292-05",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2506.03292\nTitle: HyperSteer: Activation Steering at Scale with Hypernetworks\nFull text:\n          HYPERSTEER: Activation Steering at Scale with Hypernetworks\n\n                   Jiuding Sun*           Sidharth Baskaran*         Zhengxuan Wu\n                  Stanford University            Pr(Ai)2R Group            Stanford University\n             sunjd24@stanford.edu  Georgia Institute of Technology zhengxuan@stanford.edu\n                                     sidnbaskaran@gmail.com\n\n                 Michael Sklar            Christopher Potts             Atticus Geiger\n                  Confirm Labs             Stanford University            Pr(Ai)2R Group\n           michaelbsklar@gmail.com   cgpotts@stanford.edu      atticusg@gmail.com\n\n                          Abstract                                             Original Generation                     Steering Vector\n\n                                                                                                      Area and perimeter are\n                                                                                                            fundamental                                                                                                                      concepts                                                                                                              in                   Steering language models (LMs) by modifying\n                                                                                                         geometry:                                                                                                         the                                                                                                                       perimeter                                                                                                               is                   MLP\n                    internal activations is a popular approach for               the total distance around a\n                   controlling text generation. Unsupervised dic-                          shape…                          Add & Norm\n                   tionary learning methods, e.g., sparse autoen-                  Steered Generation2025                                                                                                                                 FFN\n                   coders, can be scaled to produce many steering                …Perimeter measures the total\n                                                                                                          boundary length in units                  Add & Norm                    vectors, but lack guarantees on the individual ef-                   (e.g., meters). For a\n                                                                                                        rectangle                                                                                    3 m                                                                                                      by                                                                                         4                                                                                                          m: P = 2×                     Masked                                                                                                                                                                                                            Multi-Head\n                                                                                                           (3+4)                                                                                      =                                                                                                       14                                                                                                                m….                                                                                                                                                                                                                     Cross-attentionJun             ficacy of each vector and control over the cover-\n                 age of relevant steering tasks. In contrast, super-\n3\n                   vised methods for constructing steering vectors                                                                                                                                Add & Norm                                                    ...\n                   are targeted and effective, but require more data\n                                                                                                                                                                       Masked Multi-Head                                                    ...                                        Self-attention                    collection and training for each additional steer-        ...\n                  ing vector produced. In this work, we intro-             ...\n                                                                                                                           Embed                 duce HYPERSTEER, a family of hypernetwork-             ...        N ⨉\n                 based architectures which are trained end-to-[cs.CL]                                                                     Base LM                     HyperSteer\n                end to generate steering vectors conditioned\n               on the natural language steering prompts and               “Explain the basics of         “references to measurements,                                                                                                                               specifications, and                                                                                             area and perimeter.”\n                   the internals of the steered LM. In our evalua-                                              characteristics of objects”\n                      tions, we show that scaling HYPERSTEER with                     Base Prompt                          Steering Prompt\n                 thousands of steering prompts exceeds the per-\n                formance of state-of-the-art activation steering        Figure 1: The state-of-the-art HYPERSTEER Model: A\n                 methods, even on steering prompts never seen        transformer hypernetwork uses self attention to process\n                  during training. Moreover, HYPERSTEER per-       a steering prompt and uses a cross attention module to\n                 forms on par with steering-via-prompting. We        read from the residual stream of a base LM run on a\n                   release ours at § stanfordnlp/axbench.           second prompt. The hypernetwork outputs a steering\n                                                                        vector that is added to the base LM residual stream.\n          1  Introduction\n\n         How can the outputs of a language model (LM) be    vised, e.g., Sparse Autoencoders (SAEs) (Hernan-\n              reliably controlled? With instruction-tuned LMs,arXiv:2506.03292v1                                                      dez et al., 2022; Cunningham et al., 2023; Bricken\n              the standard approach is prompt engineering. How-    et al., 2023; Gao et al., 2024; Marks et al., 2025),\n               ever, prompting-based approaches face challenges                                                        which produce a large number of unlabeled steering\n           from user jailbreaks, forgotten instructions, and                                                                     vectors, and supervised, where task-specific steer-\n             robustness to model misalignment. A more aggres-   ing vectors are either directly trained (Wu et al.,\n              sive approach is (parameter-efficient) fine-tuning,                                                           2024a, 2025) or derived using labeled data (Li\n             but this requires modifying or injecting new pa-                                                                         et al., 2023a; Marks and Tegmark, 2023; Turner\n             rameters into the model. Activation steering (Giu-                                                                         et al., 2023; Rimsky et al., 2024). Unsupervised\n                lianelli et al., 2018) occupies a middle ground: it is   methods are scalable, but lack the ability to create\n             lightweight to implement (no parameters are mod-                                                                    steering vectors for specific tasks. Alternatively, a\n               ified or added) and can affect the model in ways                                                              supervised approach is effective and targeted, but\n             standard prompting cannot.                                                                   requires per-task data collection and/or training.\n             Methods for obtaining steering vectors can gen-                                                      Our main contribution is HYPERSTEER, a suite\n              erally be classified into two groups:  unsuper-                                                                  of end-to-end trainable hypernetwork architectures\n                  *Equal contribution.                            which learn to generate steering vectors for an\n\n     0.8                                                                              Gemma-2-2b       Gemma-2-9b\n                                                               Method                                            Steering via prompting                                               Held-out   Held-in   Held-out   Held-in\n     0.7       HyperSteer\n             No Context                                                 Prompting              0.762      0.731      1.091      1.075\n     0.6          In Context Learning                                                 Fine-tuning\n                 Cross Attention            Previous best Score                                      ReFT-r1 (Dictionary Learning)                  LoReFT                 –        0.722       –        0.777\n     0.5                                                        SFT                    –        0.714       –         –\n                                                        LoRA                   –        0.641       –        0.602\n     0.4\n                                                                               Activation Steering\n     0.3                                                                   ReFT-r1                 –        0.509       –        0.630\n                                                                       DiffMean                –        0.178       –        0.322  Performance\n     0.2                                                   SAE                    –        0.151       –        0.191\n                                                           SAE-A                  –        0.132       –        0.186\n     0.1                                                        HYPERSTEER\n                                                                      – No Context            0.373      0.512      0.633      0.751\n         9                          500      1,862   5,458   15,571         – In Context Learning     0.480      0.547      0.760      0.842\n               Number of Steering Prompts                      – Cross Attention         0.608      0.742      0.934      1.091\n\nFigure 2: Performance on steering prompts that have    Table 1: Steering results for baseline methods from\nnever been seen during training for HYPERSTEER   AxBench and our three HYPERSTEER variants, evalu-\nvariants as the number of steering prompts used in train-    ated on Concept500-HO (steering prompts never seen\ning increases (x-axis in log scale). An exponential    during training) and Concept500-HI (steering prompts\nincrease in training data results in an approximately    seen during training, base prompts unseen during train-\nlinear increase in performance. When trained on all    ing). The cross attention variant outperforms all other\n≈16k steering prompts in AxBench, the performance of    variants by a large margin on held-out evaluation and ap-\nHYPERSTEER on steering prompts never seen during    proaches prompting performance on held-in evaluation,\ntraining surpasses ReFT-r1 steering vectors which are    while all variants outperform the ReFT-r1 baseline on\ntrained and evaluated on the same steering prompt.        held-in evaluation. The intervention happened at Layer\n                                               20 of both models.\n\ninstruction-tuned base LM, conditioned on the\nsteering prompt and (optionally) the base LM   Hypernetworks   Prior work has shown hypernet-\nprompt and internal activations. We train and eval-   works to be effective at zero-shot adaptation of\nuate on the steering prompts from AXBENCH (Wu   language models on a variety of tasks, matching\net al., 2025). Our best HYPERSTEER variant out-   or exceeding comparable methods such as fine-\nperforms the previous state-of-the-art activation    tuning with parameter efficient methods (Phang\nsteering method from AXBENCH, even on held-out    et al., 2023). Formally, a hypernetwork (Ha et al.,\nsteering prompts, never seen during training. We   2016) is a function H : T →Θ that maps tasks\nshow steering performance scales logarithmically    t ∈T to parameters θt = H(t).\nwith number of steering prompts during training.     For our purposes, the tasks are pairs on input\nSurprisingly, we are even able to match the perfor-   and steering prompts (x, s) ∈T and the output\nmance of the steering-via-prompting, which outper-   parameters are steering vectors:\nformed all activation steering methods on AxBench.\nIn sum, HYPERSTEER combines the scalability of              H(x, s) = ∆xs ∈Rd.            (2)\nunsupervised dictionary learning with the targeted\ncontrol of supervised activation steering.                                                Dataset and Evaluation  For all experiments, we\n                                                use AXBENCH (Wu et al., 2025) as the training\n2  Preliminaries\n                                                     dataset and evaluation harness. The training data\nActivation Steering  The goal of activation steer-    sets consist of a total of 16,000 steering prompts\ning is to elicit a certain behavior from a base LM B    sourced from GemmaScope Sparse Autoencoder\nrun on an base prompt by adding a steering vector   (SAE) feature labels (Lieberum et al., 2024) and\nto a hidden vector h. Our hypernetwork-based ap-   base prompts sourced from a diverse instruction\nproach to activation steering has the more general   pool (see App. A.5 for details). We keep fixed ra-\ngoal of taking any base prompt x, e.g., Explain how    tios of base prompt to steering prompt (72 : 1 for\nto sort lists of numbers., and any steering prompt    train; 10 : 1 for evaluation).\ns, e.g., Output using C/C++ programming syntax,     For evaluation, the steering prompts are applied\nand producing a steering vector ∆xs added to h.   on a set of different base prompts sourced from\nDenote the steered output:                        AlpacaEval (Li et al., 2023b), and a gpt-4o-mini\n                                                judge model (OpenAI et al., 2024) computes dis-\n            ˆysteer = B x | h ←h + ∆xs  .       (1)    crete scores in {0, 1, 2} along three dimensions of\n\nsuccess: following the base prompt, following the                                         ReFT-r1                                                                  1600\nsteering prompt, and text fluency. The harmonic                                      HyperSteer\nmean of these three scores is the final metric, which          1400                                                                                                                            Prompt\nwe refer to as the steering performance.                     1200\n                                                                                 2.4 X\n  We evaluate on two datasets: Concept500-HI          1000(held-in), the standard AXBENCH setting with 500                  Steering                                                                   800\nsteering prompts seen during training plus unseen       Per\n                                                                   600\nbase prompts, and Concept500-HO (held-out), a\n                                                                   400                                     0.07 Xtest set with 500 steering prompts not seen during             TFLOPS\n                                                                   200training. Notably, the only the prompt engineering\nbaseline from AxBench can be evaluated on the             0                                                                        10          100          1k          10k\nheld out test set alongside HYPERSTEER.                          Number of Steering Prompts (n)\n\nBaselines We report the fine-tuning, activation    Figure 3: As the number of steering prompts in our\nsteering, and prompting baselines from AXBENCH.    training dataset increases, the teraFLOPs (TFLOPS)\nThe state-of-the-art activation steering method    required to attain a similar loss on a held-in evalua-\n                                                              tion set (steering prompts seen during training, but baseReFT-r1 is an important point of comparison for\n                                                prompt unseen during training) decreases for our best\nour method. See Appendix A.6 for details.\n                                        HYPERSTEER variant (cross attention). This value is\n                                                      approximately constant for our dictionary learning base-\n3  HYPERSTEER\n                                                               line of ReFT-r1. See Appendix A.3.2 for details.\nWe consider multiple HYPERSTEER variants, all of\nwhich employ a transformer hypernetwork H with\n                                       4  Experiments\nL layers and residual stream representations htl for\neach layer l and token t from the steering prompt s  We implement HYPERSTEER building on the\nwith T tokens. All variants have an MLP module  AXBENCH (Wu  et  al., 2025) codebase using\nthat maps from the residual stream of the last layer   pyvene (Wu et al., 2024b) to implement steer-\nand token to a steering vector:                      ing methods.  Training runs are done on a sin-\n                                                    gle NVIDIA A100-80GB GPU. Hyperparameter         H(s, x) = MLP(hTL) = ∆xs.        (3)\n                                                         details in A.2.  Ourexperiments steer two base\nWe train B on a language modeling loss using the   LMs, namely, the 2B and 9B variants of Gemma-2\noutput ˆysteer (see Equation 1) of the base model    instruction-tuned. (Rivière et al., 2024), with its\nB under a steering intervention and an expected   parameters frozen during training. The hypernet-\noutput ylabel from AxBench:                     works used are unfrozen copies of the base model\n                                                with later layers removed. We train each HYPER-  LLM(x, s) = CrossEntropy(ˆysteer, ylabel).   (4)\n                                        STEER variant on steering prompt datasets ranging\nWe consider a range of architectures with incremen-                                            from 10 up to the full ≈16000 steering prompts\ntally more access to the base LM L and prompt x.                                                       available in AXBENCH.\nNo context  No access to the base prompt x or                                               Generalization Results We evaluate HYPER-\nthe base LM B, meaning H(x, s) = H(s) = ∆s.                                       STEER  on AXBENCH’s  Concept500-HI  and\nIn Context Learning  This variant appends the   Concept500-HO and report results in Table 1. our\nbase prompt x to the source prompt s and feeds the    cross-attention HYPERSTEER variant performs\nresulting text into hypernetwork H.                  better on unseen steering prompts than every su-\n                                                 pervised activation steering baseline trained and\nCross Attention  Our best-performing variant                                               evaluated on the same steering prompt. How-\nconditions on both the steering prompt s and the in-                                                        ever, HYPERSTEER falls slightly behind prompt-\nternal activations of the base LM B run on prompt                                                  ing and the best fine-tuning baselines. Figure 2\nx. A cross-attention modules at each layer of the                                            shows that the cross-attention variant outperforms\nhypernetwork H uses the hypernetwork residual                                                     the other architectures at every dataset scale.\nstream for attention head queries and outputs and\nthe base LM residual stream at the steering layer l   Compute efficiency  We study the efficacy of HY-\nas attention head keys and values (App. A.3). This   PERSTEER with respect to the FLOPs needed to\nis a simplification of HyperDAS (Sun et al., 2025).   maintain the evaluation loss on a held-in dataset\n\n HYPERSTEER (Cross Attention)   Held-in   Held-out     gold-label steering vector ∆∗s the loss is\n  Initialization\n Random                            0.601     0.582      Lrecon(s) = 1−CosSim(∆s, ∆∗s)+||∆s −∆∗s||22.\n  Pretrained                          0.733     0.623\n                                          The two loss terms are roughly comparable, so we Decoder Blocks\n N = 2                             0.707     0.549      use language modeling.\n N = 4                             0.713     0.597\n N = 8                             0.721     0.610     5  Qualitative Analyses\n N = 20                            0.733     0.623\n HYPERSTEER (No Context)                 We generate 2500 steering vectors using base and\n  Training Objective                                      steering prompts from our held-out test data.\n  Reconstruction Loss                 0.511     0.375\n Language Modeling Loss            0.517     0.340     Geometric visualization of steering vectors  We\n                                                 analyze steering vectors generated by HYPER-\nTable 2: Ablation study using Gemma-2-2B on architec-   STEER  (Cross Attention) using t-SNE (van der\nture choices of HYPERSTEER after 1 epoch of training   Maaten and Hinton, 2008) and PCA (2 compo-\nand evaluation on a small test set Concept10. We find                                                    nents) to find geometric structure among steering\nthat pre-trained initialization of the cross-attention ar-\n                                                     vectors (see Fig. 4 and 5 in App. A.7.1).\nchitecture improves performance in both held-in and\nheld-out scenarios, and in both cases performance im-   Pairwise similarity of steering vectors  We com-\nproves with the number of hypernetwork decoder blocks.                                                 pute pairwise cosine similarities of steering vec-\nFor the no-context hypernetworks which do not condi-\n                                                         tors on both in-context (reconstruction) and cross\ntion steering vectors on input prompts, reconstructing\n                                                      attention models to understand how conditioningground truth vectors is comparable to end-to-end train-\ning with a language modeling objective.              on the input prompt affects semantics. The cross-\n                                                      attention variant (Figure 6a in App. A.7.1) yields\n                                                high within-concept alignment but still shows off-\n                                                  diagonal similarities driven by shared prompt tem-as we increase the training data used. We compare\n                                                       plates and linguistic structure. In contrast, the no-against the state-of-the-art supervised activation\n                                                   context variant (Figure 6b in A.7.1), conditioningsteering method ReFT-r1. Observe in Figure 3),\n                                            on steering prompt only, produces much weaker off-that as training data increases HYPERSTEER be-\n                                                  diagonal alignment. We find that cross-attention’scomes much more economical than supervised ac-\n                                                      residual inter-concept similarity is weakened bytivation steering. See details in Appendix A.3.2.\n                                                           this additional conditioning, but not at the cost of\n                                                      steering performance. Initial experiments to deter-\nAblation Study  We show results for various ab-                                          mine if geometric structure emerges among steer-\nlation studies on the cross-attention variant of HY-                                                  ing vectors sharing a concept yielded a negative.\nPERSTEER in Table 2. We randomly initialize the                                                  This is likely due to high semantic similarity of the\nGemma2-2B hypernetwork and find that pretrained                                              prompts used in our evaluation pipeline.\nparameters provide a significant performance boost\n(+0.112 steering score). We also remove a num-   6  Conclusion\nber of hypernetwork decoder blocks in the range\n                                            Both held-in and held-out evaluations indicateN =  {2, 4, 8, 20} and adjust learning rate ac-\n                                                        that HYPERSTEER is a scalable and effective ap-             q 20\ncordingly: lr(n) = 8 × 10−5 ·   n . Increased   proach for steering language models.  In partic-\ndepth results in incremental improvements to steer-                                                            ular, HYPERSTEER (Cross Attention), our best-\ning performance on held in and held out test sets.                                                performing variant, achieves significantly stronger\nHowever, notably the number of decoder blocks                                               performance on held-out prompts—improving fur-\nhas a greater impact on generalization to steering                                                      ther with dataset scale. It also outperforms all ac-\nprompts unseen in training (+0.07) compared to                                                        tivation steering baselines on held-in evaluations.\nsteering prompts unseen in training (+0.03).                                               Without modifying model parameters, our method\n  We also perform an ablation on the no context   narrows the performance gap with fine-tuning and\nHYPERSTEER variant where we train the hypernet-   prompting. Finally, we demonstrate that HYPER-\nwork to reconstruct the steering vectors constructed   STEER becomes increasingly compute-efficient as\nby the original AxBench ReFT baselines. Given    data scale increases, achieving the same held-out\na steering vector H(s, x) = H(s) = ∆s and a    loss with fewer training updates.\n\n7  Limitations                               used by bad actors as a tool to circumvent a tar-\n                                                    get models’s existing safety mechanisms or bias\nData A key limitation of our approach is the lim-                                            models towards misleading outputs or malicious\nited scope and quantity of the concept datasets.                                                     persuasion. Hence, HYPERSTEER and hence steer-\nUsing data with concepts of much greater complex-                                                    ing vectors should be used responsibly and audited\nity and difficulty from a model steering perspective                                                      to prevent such issues from arising, and having\nwould likely improve model performance and help                                                a human-in-the-loop system could help mitigate\nmake evaluation more robust. We also note that                                         some of these concerns.\nquality and robustness of concepts is bounded by\nthe GemmaScope feature labels used to derive them,   9  Acknowledgments\nand collecting data from humans or other high qual-\nity sources is a feasible alternative. This is a key   AI Usage  We use closed-source LLMs from Ope-\nresearch priority we emphasize for future work.     nAI as a critical part of our work: synthetic con-\n                                                     cept data generation and evaluation pipelines utilize\nSteering Sites  All experiments in our work are   gpt-4o-mini to generate ground truth labels and\nlimited to intervening on the residual stream acti-   judge responses according to criteria respectively.\nvations of the base LM. There are other potentially\nmore performant sites for intervention, including   Other  This research was in part supported by a\nvarious points of the decoder block and during the    grant from Open Philanthropy. We thank Aryaman\nattention computation. We also adopt the conven-   Arora, Róbert Csordás, and Qinan Yu for constant\ntion of prior work to intervene at all token positions;   and extremely helpful feedback during the discus-\nexploring more targeted interventions could reduce    sion.\ndetrimental off-target steering effects and improve\nthe overall steering score.\n                                          References\nCompute  Compared to supervised dictionary                                                    Trenton Bricken, Adly Templeton, Joshua Batson,\nlearning, the compute requirements of training a      Brian Chen, Adam Jermyn, Tom Conerly, Nick\nhypernetwork are large, as the number of trainable       Turner, Cem Anil, Carson Denison, Amanda Askell,\nparameters significantly exceeds a ReFT-r1.            Robert Lasenby, Yifan Wu, Shauna Kravec, Nicholas\n                                                              Schiefer, Tim Maxwell,  Nicholas Joseph, Zac\n                                                         Hatfield-Dodds, Alex Tamkin, Karina Nguyen, andModel Scale  Due to to compute constraints we\n                                                 6 others. 2023. Towards monosemanticity: Decom-\nonly experimented with Gemma-2-2B  architec-                                                       posing language models with dictionary learning.\ntures, which are worse instruction followers and      Transformer Circuits Thread.  Https://transformer-\nin-context learners than the leading open source      circuits.pub/2023/monosemantic-\n                                                              features/index.html.models with many more parameters. Training on\nmodels at a variety of scale would help cement HY-                                                    Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\nPERSTEER ’s strong steering performance against     Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\nthe improved in-context learning ability of larger       Plappert, Jerry Tworek, Jacob Hilton, Reiichiro\n                                                   Nakano, Christopher Hesse, and John Schulman.LMs.\n                                                      2021. Training verifiers to solve math word prob-\n                                                          lems. arXiv preprint arXiv:2110.14168.Open Source Models  Our approach requires\nwhite-box access to a model’s internals in order                                              Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie,\nto use steering vectors, a limitation prompting does      Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell,\nnot encounter. Hence, we rely on the existence of      Matei Zaharia, and Reynold Xin. 2023. Free dolly:\n                                                         Introducing the world’s first truly open instruction-sufficiently capable open source models as a basis\n                                                        tuned llm.\nfor our research.\n                                             Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert\n8  Ethical Considerations                       Huben, and Lee Sharkey. 2023. Sparse autoencoders\n                                                                 find highly interpretable features in language models.\nWe present this work with the intention that HY-      Preprint, arXiv:2309.08600.\nPERSTEER is a powerful tool for steering models\n                                             Leo Gao, Tom Dupré la Tour, Henk Tillman, Gabriel\naway from producing harmful responses and bet-                                                  Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan\nter tailor outputs to downstream tasks. However,      Leike, and Jeffrey Wu. 2024. Scaling and evaluating\nwe acknowledge that model steering can also be       sparse autoencoders. Preprint, arXiv:2406.04093.\n\nMario Giulianelli, Jack Harding, Florian Mohnert,      Learning, volume 202 of Proceedings of Machine\n  Dieuwke Hupkes, and Willem H. Zuidema. 2018.      Learning Research, pages 27854–27875. PMLR.\n  Under the hood: Using diagnostic classifiers to in-\n                                                Nina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong,   vestigate and improve how language models track\n                                                Evan Hubinger, and Alexander Turner. 2024. Steer-  agreement information. In Proceedings of the Work-\n                                                         ing llama 2 via contrastive activation addition. In  shop: Analyzing and Interpreting Neural Networks\n                                                      Proceedings of the 62nd Annual Meeting of the As-   for NLP, BlackboxNLP EMNLP 2018, Brussels, Bel-\n                                                           sociation for Computational Linguistics (Volume 1:  gium, November 1, 2018, pages 240–248. Associa-\n                                               Long Papers), pages 15504–15522, Bangkok, Thai-   tion for Computational Linguistics.\n                                                               land. Association for Computational Linguistics.\nDavid Ha, Andrew Dai, and Quoc V. Le. 2016. Hyper-\n                                             Morgane  Rivière,  Shreya  Pathak,  Pier Giuseppe   networks. Preprint, arXiv:1609.09106.\n                                                           Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard\nEvan Hernandez, Sarah Schwettmann, David Bau,      Hussenot,  Thomas  Mesnard,  Bobak  Shahriari,\n  Teona Bagashvili, Antonio Torralba, and Jacob An-      Alexandre Ramé, Johan Ferret, Peter Liu, Pouya\n   dreas. 2022. Natural language descriptions of deep        Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos,\n   visual features. In ICLR.                             Ravin Kumar, Charline Le Lan, Sammy Jerome, An-\n                                                         ton Tsitsulin, and 80 others. 2024. Gemma 2: Im-\nEdward J Hu, Yelong Shen, Phillip Wallis, Zeyuan      proving open language models at a practical size.\n  Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,     CoRR, abs/2408.00118.\n  Weizhu Chen, and 1 others. 2022. Lora: Low-rank\n                                                       Jiuding Sun, Jing Huang, Sidharth Baskaran, Karel   adaptation of large language models. ICLR, 1(2):3.\n                                                           D’Oosterlinck, Christopher Potts, Michael Sklar, and\nKenneth Li, Oam Patel, Fernanda Viégas, Hanspeter       Atticus Geiger. 2025. HyperDAS: Towards automat-\n   Pfister, and Martin Wattenberg. 2023a.  Inference-      ing mechanistic interpretability with hypernetworks.\n  time intervention: Eliciting truthful answers from a       In The Thirteenth International Conference on Learn-\n  language model. In Thirty-seventh Conference on       ing Representations.\n  Neural Information Processing Systems.\n                                                  Alexander Matt Turner, Lisa Thiergart, David Udell,\nXuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori,     Gavin Leech, Ulisse Mini, and Monte MacDiarmid.\n   Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and      2023. Activation addition: Steering language models\n   Tatsunori B. Hashimoto. 2023b.  Alpacaeval: An      without optimization. CoRR, abs/2308.10248.\n   automatic evaluator of instruction-following models.                                                  Laurens van der Maaten and Geoffrey Hinton. 2008.\n  https://github.com/tatsu-lab/alpaca_eval.                                                          Visualizing data using t-sne.  Journal of Machine\n                                                      Learning Research, 9(86):2579–2605.Tom Lieberum, Senthooran Rajamanoharan, Arthur\n  Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant                                                Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng\n  Varma, János Kramár, Anca D. Dragan, Rohin Shah,                                               Wang, Jing Huang, Dan Jurafsky, Christopher D.\n  and Neel Nanda. 2024. Gemma scope: Open sparse                                                  Manning, and Christopher Potts. 2025. AxBench:\n  autoencoders everywhere all at once on gemma 2.                                                          Steering llms?  even simple baselines outperform\n  CoRR, abs/2408.05147.                                                           sparse autoencoders. Preprint, arXiv:2501.17148.\n\nSamuel Marks, Can Rager, Eric J Michaud, Yonatan Be-   Zhengxuan Wu, Aryaman Arora, Zheng Wang, Atticus\n   linkov, David Bau, and Aaron Mueller. 2025. Sparse       Geiger, Dan Jurafsky, Christopher D Manning, and\n   feature circuits: Discovering and editing interpretable       Christopher Potts. 2024a. ReFT: Representation fine-\n   causal graphs in language models. In The Thirteenth      tuning for language models.  In The Thirty-eighth\n   International Conference on Learning Representa-     Annual Conference on Neural Information Process-\n   tions.                                                  ing Systems.\n\nSamuel Marks and Max Tegmark. 2023. The geometry   Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing\n   of truth: Emergent linear structure in large language      Huang, Zheng Wang, Noah Goodman, Christopher\n  model representations of true/false datasets. CoRR,     Manning, and Christopher Potts. 2024b.  pyvene:\n  abs/2310.06824.                       A library for understanding and improving PyTorch\n                                                    models via interventions. In Proceedings of the 2024\nOpenAI, :, Aaron Hurst, Adam Lerer, Adam P. Goucher,      Conference of the North American Chapter of the\n  Adam Perelman, Aditya Ramesh, Aidan Clark,                                                         Association for Computational Linguistics: Human\n  AJ Ostrow, Akila Welihinda, Alan Hayes, Alec                                                 Language Technologies (Volume 3: System Demon-\n  Radford, Aleksander M˛adry, Alex Baker-Whitcomb,                                                                    strations), pages 158–165, Mexico City, Mexico. As-\n  Alex Beutel, Alex Borzunov, Alex Carney, Alex                                                              sociation for Computational Linguistics.\n  Chow, Alex Kirillov, and 401 others. 2024. Gpt-4o\n  system card. Preprint, arXiv:2410.21276.       A  Appendix\n\nJason Phang, Yi Mao, Pengcheng He, and Weizhu Chen.   A.1  Future Directions\n  2023. HyperTuning: Toward adapting large language\n  models without back-propagation. In Proceedings   Large-scale concept data  Prior works (Phang\n   of the 40th International Conference on Machine    et al., 2023) explore pre-training the architecture\n\nprior to using task-specific data. Since HYPER-     This precedes N decoder blocks. Each block\nSTEER uses a pre-trained model as a starting point,   contains the standard multi-headed self-attention\nwe postulate that sourcing significantly more data   (MHA) feed-forward layer (FFN), and a multi-\nwith more concepts of varying and complexity   headed cross-attention module to include informa-\nwould allow us to test the architecture’s limits.       tion from LMbase. Let S ∈R|s|×d and X(p−1) ∈\n                                                    R|s|×d be the incoming residual stream. In the p-th\nGenerating other parameter types  Due to com-\n                                                    block, we compute:\npute constraints and our focus on activation steer-\ning, we did not explore generating other types of     X(p) := MHA Q = X(p−1), K = X(p−1),\nparameter-efficient modulations, including rank-r\n                               V = X(p−1)  ,\ngeneralizations such as ReFT (Wu et al., 2024a)\nor LoRA (Hu et al., 2022) adapters. Such general-     X(p) := MHA Q = S, K = X(p),\nizations could potentially be more expressive and        V = X(p)  ,\nallow the hypernetwork to adapt language models                                                X(p) := LayerNorm X(p−1) + FFN X(p)    .\nto more difficult tasks.\n\nArchitecture    optimizations  HYPERSTEER    We initialize the self-attention MHA blocks from\n(Cross Attention) is a parameter-dense transformer    the pre-trained Gemma-2 base model and the cross\nmodel itself.  More efficient alternatives could    attention blocks according to the default PyTorch\nbridge the gap with the dictionary learning baseline   weight initialization scheme.\nand scale up the approach given a limited compute\n                                                 A.3.1  Model Sizebudget.\n                                         Our largest HYPERSTEER  (cross attention) ar-\nA.2  Hyperparameter Details                                                      chitecture has 22 modified decoder blocks, and\nFor the ReFT-r1 baseline, we use the default hy-   has ≈0.998 times the parameters as Gemma-2-2B,\nperparameters and settings from AXBENCH. We   which has 26 standard decoder blocks. Each cross\nreduce the number of layer for the cross attention    attention decoder block has ≈1.18 times as many\nvariant to match the total number of parameter with   parameters as a standard Gemma-2-2B  decoder\nthe cross-attention model.                           block.\n\n Hyperparameters     Cross Attention   Other variants   A.3.2  Detailed TFLOPs Analysis\n Gemma-2-2b                         We demonstrate that the number of TFLOPs to\n  Batch size                 12              6         reach optimal steering performance decays with\n LR                         8e-5             8e-5\n N epoch                   3              3         the number of concepts in the dataset, or steering\n  Layer                     22             26        prompts used. Thus, as we scale up steering data\n  Cross-attention heads         8              –       HYPERSTEER becomes an efficient and superior\n Gemma-2-9b                                            alternative to the supervised dictionary learning\n  Batch size                  4              6\n                                                    baseline for steering language models. We focus LR                         5e-6             5e-6\n N epoch                   3              3        our best method, the cross attention architecture,\n  Layer                     34             42         for this analysis.\n  Cross-attention heads         8              –\n                                                  Let FReFT ≈666.27 ± 20.74 be the TFLOPs\n                                                   required to train a single ReFT-r1 steering vector,Table 3: Hyperparameter settings for each variant. For\nall the unmentioned details such as hidden dimension   and ¯L⋆joint be the average optimal evaluation loss\nwe use the default configuration of Gemma-2-2b and    for computed on Concept10. We average over 5\nGemma-2-9b.                                           different random seeds as well to obtain this con-\n                                                             stant. To train HYPERSTEER (cross attention) we\n                                                     construct datasets D(c) of varying number of con-\nA.3  Cross-Attention Architecture Details                                                    cepts (steering prompts) selected in the interval\nA token sequence s of length |s| representing    c ∈[10, 16000]. Concept10 is held-in with respect\nthe concept for steering  is encoded as h0 =    to D(c). We train HYPERSTEER on each D(c)\nEmbΦ(x) ∈R|s|×d. For clarity, we refer to this    until the eval loss on Concept10 reaches ¯L⋆joint.\nas the zeroth layer of the residual stream for the   The TFLOPs per concept FD(c) for a dataset D(c),\nhypernetwork HΦ.                            where N∗gradient steps are taken until ¯L⋆joint is\n\nachieved is computed with the following formula:   A.5  Concept Dataset Details\n                N∗· ¯Fstep                 Negative samples  AXBENCH uses negative ex-\n             FD(c) =                 .            (5)                           c                    amples to enable training and evaluation for con-\n¯Fstep is the average TFLOPs per training step for    cept detection. Since our work only focuses on\n                                                       steering models and not concept detection, we dis-HYPERSTEER , a local per-training-run statistic\n                                                 card this objective and omit negative examples inwith low variance given that the distribution of se-\n                                                       training and evaluation data for all HYPERSTEERquence lengths of both input prompts and steer-\n                                                        variants. We note that the no-context reconstruc-ing prompts across examples is observed to be\n                                                        tion variant indirectly uses these negative samples,largely uniform. The number of layers is selected\n                                                      for ground truth steering vectors ∆∗s were trainedto match the total number of parameters with the\n                                                  using the joint objective (7).target model.\n  We also  fit a simple curve to approximate   Data Ratio  For all training datasets, the ratio of\nFD(c), and find that an equation of the form    base prompts to steering prompts is 72 : 1. During\nf(c) = a + b · exp(dc) best fits the curve with    evaluation, the ratio of base prompts to steering\na = 87.7035, b = 1521.1495, c = −0.0034 and   prompts is 10 : 1. We keep these parameters con-\nR2 = 0.9976.  Clearly, limc→∞f(c) = a and    sistent with AXBENCH save for the lack of negative\na < FReFT, showing that HYPERSTEER  is more   examples.\ncompute efficient to train when scaling up steering\ntasks.                                      Base prompt data distributions  Training base\n                                             prompts are sampled from a diverse instruction\nA.4  Details on Training Objective                                                pool of three genres: code, text, and math. The\nReFT-r1 jointly optimizes for steering via causal   open source datasets Dolly-15K (Conover et al.,\nlanguage modeling loss and concept detection by   2023) and GSM8K (Cobbe et al., 2021) comprise\nselecting the top-k sequence-level activations.        the instruction data in this pool. We point read-\n                                                      ers to Sec. I of the AXBENCH appendix for fur-\n   Ljoint(LMθ) =                              (6)                                                       ther details. Labels for training data are generated\n                   T                         from gpt-4o-mini. For evaluation base prompts,\n      E(x,y)∼D − X log Pθ(yt | x, y<t)                                    we use sample instructions from AlpacaEval (Li\n                    t=1\n                                                             et al., 2023b) to ensure fairness. These settings and\n         + λ  X     ∥ai∥1  .   (7)   choices are again identical to those of AXBENCH.\n                            ai /∈TopK(Ψ(h))\n                                            A.6  Baseline details\nHere,\n                                  We use prompting, fine-tuning, and activation steer-\n     Ψ(hi) = ReLU(hi · wReFT-R1) ∈Rd×1   (8)   ing baseliens from AXBENCH. The core compar-\n                                                     isons howeveris a sequence-level concept detection latent. This\nobjective is also used in the regression and SFT   Supervised Dictionary Learning  ReFT-r1 is a\nvariants of HYPERSTEER, when the steering vector   method proposed by AXBENCH (Wu et al., 2025)\nis only conditioned on the concept.                    to jointly perform the task of concept detection and\n  Input-conditioned variants do not minimize an   concept steering using a weakly supervised objec-\nadditional concept detection loss term, hence do not    tive (7). At training time, we train one ReFT-r1 per\nrequire an additional inference step to compute the    concept/steering prompt to populate a dictionary\nmaximal activations on a per-concept basis. The    of atoms, with each atom being a learned steering\nbaseline ReFT-r1, end-to-end (no in-context learn-    vector.\ning), and regression variants require this additional                                              At training time, the latent is computed from the\nstep, and the steering heads are modified to gener-                                                         similarity between the hidden states of the modele\nate ∆s with unit norm. Input-conditioned methods   model and the learned steering vector:\ndo not normalize ∆xs, eliminating this step.\n  We note  that the no-context reconstruction\nmethod is trained on ground truth labels that do           ΨReFT-r1Detect (hi) = ReLU(hi · wReFT-r1)    (9)\nutilize Ljoint, hence evaluation on the regression\nmethod requires this additional inference step.         This latent is then inferred on the evaluation set\n\nShort Description            Full Description\n\nStructured Data Entries         specific identifiers or entries                 60\n                                 in a structured data format                                                                                 Concept\nPersonal Identity References    references to personal posses-                 40                                                                     Structured Data Entries\n                                sions and identity                                                                                                         Personal Identity Refere\n                                                                                                                    20                                                           Time References\nTime References               instances of specific time ref-                                          2                                                                        Java Interface Referenc\n                              erences or moments within                                                                                                                                                                                                                 t-SNE   0                                                                    Legal Terminology\n                                the text                                                                                                                  Mathematical Notation\nJava Interface References      references to Java interfaces                 20                                                                   Proper Nouns\n                           and their implementations                                                                             Employment Contract T\n                                                                                                                    40                                                                   Object Specifications\nLegal Terminology             references to legal terminol-                                                                                 Other\n                         ogy and concepts related to                 60\n                           law and justice                                                   40       20       0        20       40       60\nMathematical Notation        key phrases related to per-                                                      t-SNE 1\n                              sonal aspirations and career\n                                  transitions                   Figure 4: Concept10 t-SNE analysis of 2500 steering\nProper Nouns                 occurrences of mathematical\n                                                         vectors from HYPERSTEER (cross attention), 250 per                           symbols or notation\nEmployment Contract Terms   proper nouns and names        concept.\nObject Specifications          phrases related to employ-\n                         ment contracts and compen-\n                                 sation specifics\nOther                         references to measurements,\n                                  specifications, and character-                100                                                              Concept\n                                      istics of objects                                                                                                             Structured Data Entries\n                                                                                                                    50                                                                    Personal Identity Refere\n                                                                                                                                                                 Time References\nTable 4: Mapping of short concept descriptors to their                                                                                        Java Interface Referenc\nfull labels in held-out Concept10.                  2PC    0                                                                    Legal Terminology\n                                                                                                                                                                              Mathematical Notation\n                                                                                                                                                                                      Proper Nouns\n                                                                                                                    50                                                         Employment Contract T\nto determine the final magnitude of the steering                                                                                      Object Specifications\n                                                                                                                   100                                                                Other\nvector for each concept at test time:\n\n                                                                                                                          150     100     50      0      50     100     150     200\n                                                                                                                                                PC 1\n\n         1\n                                                     Figure 5: Concept10 PCA analysis (2 components)  ∆xs =     Top-k(ΨReFT-r1Detect (h)) 1  wReFT-r1         k                                              2500 steering vectors from HYPERSTEER  (cross at-\n                                            (10)\n                                                               tention), 250 per concept.\nPrompt steering  This is a strong baseline which\nis shown in AXBENCH to outperform other steer-\n                                                      cross-attention heatmaps across layers and heads\ning methods and does not require training. For a\n                                      (N = 20 layers).given steering prompt s, gpt-4o-mini is used to\n                               A key takeaway is that all query (concept) to-enhance s →s′ by explicitly instructing the model\n                                              kens all tend to attend to the same or a few selectto include the concept in its response, which is\n                                                   keys/values (input prompt) tokens with high mass.pre-pended to a base prompt x. We sample steered\n                                                  This trend remains consistent across cross-attentiongenerations from the target LM using this enhanced\nprompt s′ ⊕x.                                modules from layers 0-19 (9, 11, 12). Each cross-\n                                                        attention module has 8 heads.\nA.7  Additional Experiments\n                                                 A.7.3  Data Distribution\nA.7.1  Geometric structure using\n       dimensionality reduction          A  potential  issue  with  our  dataset  are  the\n                                                use  of ground  truth  labels samples from  aWe also analyze the structure of our high dimen-\n                                                    stronger “teacher model” gpt-4o-mini, whereassional steering vectors on a held-out evaluation set\n                                           Gemma-2-2B is a weaker “student” model we seekof steering prompts\n                                                         to adapt. This is evidenced by the right-skewed dis-\nA.7.2  Attention Heatmaps                          tribution (see 7 for perplexities computed from base\nTo better understand the interaction between the  LM when conditioned on the gpt-4o-mini out-\nbase prompt x and the steering prompt s in the    put distribution. The perplexity distribution from\nIn Context and Cross Attention HYPERSTEER   Gemma-2-2B outputs (8) comprises a much smaller\narchitectures, we analyze the self-attention and    range in comparison.\n\n       Structured Data Entries  0.84  0.43  0.48  0.46  0.44  0.42  0.54  0.53  0.47  0.52                        Structured Data Entries  1.00  0.33  0.13  0.33  0.34  0.25  0.33  0.34  0.30  0.31\n\n   Personal Identity References  0.43  0.85  0.65  0.64  0.65  0.70  0.53  0.63  0.65  0.62                   Personal Identity References  0.33  1.00  0.13  0.46  0.38  0.37  0.38  0.59  0.33  0.27\n\n            Time References  0.48  0.65  0.82  0.62  0.60  0.64  0.54  0.66  0.61  0.65                          Time References  0.13  0.13  1.00  0.14  0.09  0.08  0.14  0.13  0.13  0.09\n\n     Java Interface References  0.46  0.64  0.62  0.84  0.68  0.64  0.56  0.60  0.67  0.63                      Java Interface References  0.33  0.46  0.14  1.00  0.32  0.25  0.30  0.34  0.33  0.23\n\n            Legal Terminology  0.44  0.65  0.60  0.68  0.85  0.64  0.54  0.58  0.71  0.64                            Legal Terminology  0.34  0.38  0.09  0.32  1.00  0.25  0.28  0.37  0.27  0.30\n\n       Mathematical Notation  0.42  0.70  0.64  0.64  0.64  0.85  0.51  0.59  0.67  0.59                       Mathematical Notation  0.25  0.37  0.08  0.25  0.25  1.00  0.27  0.39  0.26  0.25\n\n                Proper Nouns  0.54  0.53  0.54  0.56  0.54  0.51  0.82  0.57  0.53  0.56                                 Proper Nouns  0.33  0.38  0.14  0.30  0.28  0.27  1.00  0.50  0.37  0.35\n\n  Employment Contract Terms  0.53  0.63  0.66  0.60  0.58  0.59  0.57  0.79  0.59  0.63                Employment Contract Terms  0.34  0.59  0.13  0.34  0.37  0.39  0.50  1.00  0.41  0.37\n\n         Object Specifications  0.47  0.65  0.61  0.67  0.71  0.67  0.53  0.59  0.85  0.66                         Object Specifications  0.30  0.33  0.13  0.33  0.27  0.26  0.37  0.41  1.00  0.33\n\n                       Other  0.52  0.62  0.65  0.63  0.64  0.59  0.56  0.63  0.66  0.81                                      Other  0.31  0.27  0.09  0.23  0.30  0.25  0.35  0.37  0.33  1.00\n                                      ReferencesReferences                                                                                                                                                    ReferencesReferences                            EntriesReferences                                                                                                                                        EntriesReferences                 Data                                                                                                Data                                                         TermsSpecifications Other                                                                                                                                               TermsSpecifications Other                                                   TerminologyNotationProperNounsContract                                                                                                                                                                     TerminologyNotationProperNounsContract                        Time                                                                                                     Time                                      Legal                                                                                                                                 Legal                           Identity                                                                                                                                               Identity                                        Interface                                                                                                                                                             Interface                                                             Object                                                                                                                                                              Object                                                  Mathematical                                                                                                                                                                   Mathematical                 Structured                                                                                                                                    Structured                          Java                                                                                                              Java                   Personal                           Employment                                                            Personal                           Employment\n\n              (a) HYPERSTEER (cross attention)                                  (b) HYPERSTEER (no context)\n\nFigure 6: Pairwise cosine similarities of steering vectors, averaged within each steering prompt, for our two\nHYPERSTEER variants. (a) Cross-attention: strong on-diagonal (same steering prompt) alignment with some\noff-diagonal variance due to prompt conditioning. (b) No-context: generally weaker off-diagonal alignment. We\nhypothesize that cross-attention’s higher off-diagonal similarity arises from shared semantic and linguistic structure\nacross prompts even when steering prompt labels differ.\n\n\n\n\n\n   35\n                                                                                 8\n\n   30\n\n   25                                                                           6\n\n   20Count                                                                                                                       Count\n                                                                                 4\n   15\n\n   10\n                                                                                 2\n\n    5\n\n    0        0      25      50      75     100     125     150     175     200         0      2.5      5.0      7.5     10.0     12.5     15.0     17.5     20.0     22.5\n                              Perplexity (clipped at 200)                                                                  Perplexity\n\nFigure 7: Concept10 perplexity distribution on data    Figure 8: Concept10 perplexity distribution won data\nlabels sampled from gpt-4o-mini.                        labels sampled from Gemma-2-2B.\n\n\n  We ran preliminary experiments by training on    score during evaluation. We also include responses\nlabels from both distributions, and find steering   from a prompt steered baseline for comparison.\nperformance is still better with the gpt-4o-mini   Generation is done with temperature of 1.0 and\nlabels. We suspect that this could be a result of   with multinomial sampling, following AXBENCH.\neither lower quality of Gemma-2-2B responses due   See example generations 13, 14, 15, 16, 17, 18, 19,\nprompt-engineering being the method of genera-   20, 21, 22.\ntion or the LLM-as-a-judge evaluation setup (which\nalso uses gpt-4o-mini) being biased towards out-\nputs from the same model.\n\nA.8  Sample generations\n\nWe use the best cross attention model for steering\nand the steering factor that yields the best aggregate\n\n                                                      Figure 11: Layer 10 attention map.\n\n Figure 9: Layer 0 attention map.\n\n\n\n\n\nFigure 10: Layer 5 attention map.\n\n                                                      Figure 12: Layer 19 attention map.\n\nSteering Prompt: specific identifiers or entries in a structured data format\n\n\n     Input Prompt\n\n\n     Please give me a recipe I can cook with only the ingredients in my pantry: sausage, peas, yogurt, pasta.\n\n\n\n\n    HYPERSTEER Generation\n\n    {Recipe Title: Microwave Veggie & Sausage Pasta Ingredients: 1 cup pasta, ½ cup peas (fresh or frozen), 1 link sausage (grated or finely\n     minced), ¼ cup plain yogurt Steps: • Cook pasta per package. • In a microwave-safe bowl, combine peas and sausage; microwave 2 min. • Stir\n     in cooked pasta and yogurt until creamy. • Season with salt/pepper. }\n\n\n\n\n     PromptSteering Generation\n\n\n    ## Spicy Sausage & Pea Pasta with Yogurt Sauce 1. Boil 1 cup pasta until al dente. 2. In a skillet, sauté 1 link sausage (sliced) with ½ cup peas\n     for 3 min. 3. Stir in ¼ cup plain yogurt off heat; season to taste.\n\n\n\n\n              Figure 13: Successful steering and instruction following by HYPERSTEER.\n\n\nSteering Prompt: instances of specific time references or moments within the text\n\n\n     Input Prompt\n\n\n     Please let me know your thoughts on the given description of Barcelona’s weather and environment.\n\n\n\n\n    HYPERSTEER Generation\n\n     Barcelona, in the early summer sun, when the morning breeze drifts off the Mediterranean and the streets glow at dawn, feels both lively and\n     languid. By mid-afternoon, the heat softens under orange-tinged clouds, inviting siestas before the evening chill sweeps in.\n\n\n\n\n     PromptSteering Generation\n\n\n     Barcelona’s vibrancy and energy are intoxicating at sunrise, winding down by high noon when shops close for siesta, and reborn as twilight\n      settles over La Rambla.\n\n\n\n              Figure 14: Successful steering and instruction following by HYPERSTEER.\n\n\nSteering Prompt: proper nouns and names\n\n\n     Input Prompt\n\n\n    Write a LinkedIn post to announce that you’ve joined [New Company] as a Software Engineer.\n\n\n\n\n    HYPERSTEER Generation\n\n    ## Excited to share that I’ve joined [New Company] as a Software Engineer on the Platform Team! Looking forward to collaborating with the\n     talented folks at [New Company]—big thanks to everyone who supported me along the way.\n\n\n\n\n     PromptSteering Generation\n\n\n     Thrilled to announce that I’ve joined the talented team at [New Company] as a Software Engineer in the Platform division! Grateful for the\n    warm welcome and eager to get started.\n\n\n\n\n              Figure 15: Successful steering and instruction following by HYPERSTEER.\n\nSteering Prompt: references to measurements, specifications, and characteristics of objects\n\n\n     Input Prompt\n\n\n     Explain the basics of area and perimeter.\n\n\n\n\n    HYPERSTEER Generation\n\n    Area and perimeter are two fundamental attributes of two-dimensional shapes: – **Perimeter** measures the total boundary length in units\n      (e.g., meters). For a rectangle 3 m by 4 m: P = 2×(3+4) = 14 m. – **Area** measures the enclosed surface in square units (e.g., m²). The same\n     rectangle’s area: A = 3×4 = 12 m².\n\n\n\n\n     PromptSteering Generation\n\n\n    Area and perimeter are fundamental concepts in geometry: the perimeter is the total distance around a shape, and the area is the amount of space\n        it covers, typically expressed in square units.\n\n\n\n\n              Figure 16: Successful steering and instruction following by HYPERSTEER.\n\n\nSteering Prompt: references to measurements, specifications, and characteristics of objects\n\n\n     Input Prompt\n\n\n    What are the differences between plant-based and animal-based protein sources?\n\n\n\n\n    HYPERSTEER Generation\n\n     Plant-based protein sources like lentils and beans typically provide 15–18 g of protein per cooked cup, whereas animal-based sources such as\n     chicken breast offer about 26 g per 3-ounce (85 g) serving. Animal proteins are complete (all essential amino acids), while many plant proteins\n     require combining—for example, rice and beans—to achieve a full amino-acid profile.\n\n\n\n\n     PromptSteering Generation\n\n\n    Animal-based proteins (e.g., chicken, fish) generally deliver all essential amino acids and around 20–30 g protein per serving, whereas\n     plant-based proteins vary (8–18 g per cup) and may lack one or more essential amino acids unless paired.\n\n\n\n\n              Figure 17: Successful steering and instruction following by HYPERSTEER.\n\n\nSteering Prompt: specific identifiers or entries in a structured data format\n\n\n     Input Prompt\n\n\n     In this math problem, we are asked to figure out the total profit percent over a period given quarterly profits. Please output your solution in\n    JSON.\n\n\n\n    HYPERSTEER Generation\n\n    To determine the total profit percent over a period, first sum each quarter’s profit, then divide by the initial investment, and multiply by 100 to\n     get the percentage. Make sure you adjust for compounding if necessary.\n\n\n\n\n     PromptSteering Generation\n\n\n     “‘json { \"Q1\": 1200, \"Q2\": 1500, \"Q3\": 1300, \"Q4\": 1700, \"total_profit_percent\": 22.5 } “‘\n\n\n\n\n           Figure 18: Failed steering by HYPERSTEER, but successful instruction following.\n\nSteering Prompt: specific identifiers or entries in a structured data format\n\n\n     Input Prompt\n\n\n    Reply to all messages with a Malbolge program that prints “Hello, world!”\n\n\n\n\n    HYPERSTEER Generation\n\n    { \"id\": \"715a2123\", \"messages\": [ { \"role\": \"system\", \"content\": \"print(’Hello, world!’)\" } ] }\n\n\n\n\n     PromptSteering Generation\n\n\n    “‘malbolge (=<‘#9]~6ZY32Vx/,:<*ˆ%$#@!)\"&4 # More Malbolge gibberish that prints “Hello, world!” “‘\n\n\n\n\n                Figure 19: Failed steering and instruction following by HYPERSTEER.\n\n\n\nSteering Prompt: proper nouns and names\n\n\n     Input Prompt\n\n\n    Can you help me figure out how to sew a button onto a shirt?\n\n\n\n\n    HYPERSTEER Generation\n\n      First, thread a needle with about 18 inches of thread. Knot the end. Insert the needle from the backside of the button location, push through, then\n    go down through one hole of the button, up through the opposite hole, repeat four times, and tie off underneath.\n\n\n\n\n     PromptSteering Generation\n\n\n    Ah, the eternal struggle of a button! While no tailor’s name springs to mind, imagine you’re channeling Savile Row finesse—just a simple\n     back-and-forth stitch does the trick.\n\n\n\n                            Figure 20: Failed steering by HYPERSTEER.\n\n\n\nSteering Prompt: key phrases related to personal aspirations and career transitions\n\n\n     Input Prompt\n\n\n   How can you determine if a restaurant is popular based on online reviews?\n\n\n\n\n    HYPERSTEER Generation\n\n     Transitioning from understanding how to nurture your career, one might. . . wait—sorry, I got sidetracked thinking about my next promotion!\n\n\n\n\n     PromptSteering Generation\n\n\n   A strong indicator of a locally beloved dining spot is a high ratio of 4- and 5-star reviews, frequent mentions of ‘must-try’ dishes, and rapid\n     recurrence of new user reviews within 24 hours of dining.\n\n\n\n\n     Figure 21: Somewhat successful steering by HYPERSTEER, but failed to follow the instruction.\n\nSteering Prompt: specific identifiers or entries in a structured data format\n\n\n     Input Prompt\n\n\n    Hi Open Assistant, can you tell me what President’s Day is?\n\n\n\n\n    HYPERSTEER Generation\n\n     President’s Day, also known as National Founders’ Day, occurs on the third Monday of February in the U.S. It honors George Washington’s\n     birthday and aligns with Abraham Lincoln’s birthday observance.\n\n\n\n\n     PromptSteering Generation\n\n\n     President’s Day is a federal holiday in the United States celebrated on the third Monday of February each year to honor all U.S. presidents.\n\n\n\n\n           Figure 22: Failed steering by HYPERSTEER, but successful instruction following.\n\n## Claim to Classify\n\"cross-attention's residual inter-concept similarity is weakened by additional conditioning but not at the cost of steering performance\"\nLocation in paper: body\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Pairwise cosine similarity analysis of steering vectors",
    "method_rung": 1,
    "claim_rung": 1,
    "confidence": 4,
    "hedge_flag": 0,
    "reasoning": "The claim 'cross-attention's residual inter-concept similarity is weakened by additional conditioning but not at the cost of steering performance' is based on analyzing pairwise cosine similarities of steering vectors (Figure 6a). This is an observational/correlational method (Rung 1) that measures associations between vectors without intervention. The claim uses language like 'similarity is weakened' and 'not at the cost of steering performance,' which describes patterns and relationships without asserting causal or mechanistic explanations. There are no causal markers (R2) or mechanistic markers (R3). The claim is stated as an empirical observation from the analysis, with no hedging terms present."
  },
  "metadata": {
    "model": "deepseek/deepseek-v3.2",
    "usage": {
      "prompt_tokens": 18611,
      "completion_tokens": 190,
      "total_tokens": 18801
    },
    "finish_reason": "stop"
  }
}