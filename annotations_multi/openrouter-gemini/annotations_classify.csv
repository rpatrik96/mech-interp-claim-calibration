paper_id,claim_id,claim_text,claim_location,claim_prominence,method_used,method_rung,claim_rung,gap_score,confidence,hedge_flag,reasoning
2211.00593,2211.00593-01,presenting an explanation for how GPT-2 small performs a natural language task called indirect object identification (IOI),abstract,3,Path patching (causal intervention) and circuit analysis,2,3,1,5,0,"The method used is path patching, which is a form of activation patching (Rung 2). The claim uses the functional verb 'performs' and frames the work as an 'explanation' of the model's internal behavior. According to the codebook, functional verbs like 'performs' and the mechanistic narrative of 'how' a model works are markers of Rung 3 (Mechanistic/Counterfactual) claims. This creates a +1 gap between the interventional evidence and the mechanistic claim."
2211.00593,2211.00593-02,Our explanation encompasses 26 attention heads grouped into 7 main classes,abstract,3,Path patching and activation patching (causal interventions),2,3,1,5,0,"The method used is path patching, which is a form of activation patching (Rung 2). The claim uses the term 'explanation' and groups components into functional 'classes' to describe how the model performs a task, which constitutes a mechanistic narrative (Rung 3). According to the codebook, describing a functional mechanism or 'how' a model performs a task is a Rung 3 claim, creating a +1 gap."
2211.00593,2211.00593-03,this investigation is the largest end-to-end attempt at reverse-engineering a natural behavior,abstract,3,path patching and causal interventions,2,3,1,5,0,"The claim uses the term 'reverse-engineering', which is explicitly listed in the codebook as a Rung 3 linguistic marker because it implies a complete mechanistic narrative. The methods used (path patching, activation patching, and knockouts) are interventional and establish causal sufficiency, which corresponds to Rung 2. This creates a +1 gap between the method used and the claim made."
2211.00593,2211.00593-04,Name Mover Heads... move the name from the subject to the end position,body,1,Path patching (activation patching variant),2,3,1,5,0,"The method used is path patching, which is a causal intervention (Rung 2) that measures the effect of specific activation paths on the output. The claim uses the functional verb 'move', which implies a mechanistic narrative of how the model performs the task (Rung 3). This matches the 'R2 to R3' overclaiming pattern identified in the calibration anchor for this paper."
2211.00593,2211.00593-05,S-Inhibition Heads... inhibit attention from the Name Mover Heads to the S token,body,1,Path patching (causal intervention on the query vector of Name Mover Heads),2,3,1,5,0,"The method used is path patching, which is a Rung 2 interventional method that measures causal mediation. The claim uses the functional/mechanistic verb 'inhibit' to describe the specific action of one component on another's internal mechanism (attention). According to the codebook, functional verbs and mechanistic narratives that describe how a model 'performs' or 'uses' components to achieve a specific internal state are classified as Rung 3. This creates a +1 gap between the interventional evidence and the mechanistic claim."
2211.00593,2211.00593-06,the circuit is faithful complete and minimal,abstract,2,"Causal interventions (path patching, knockouts) and quantitative evaluation metrics (faithfulness, completeness, minimality)",2,3,1,5,0,"The claim uses the definite article 'the circuit' and asserts 'completeness' and 'faithfulness' to the model's internal mechanism, which are Rung 3 mechanistic/uniqueness markers. The methods used (path patching and knockouts) are interventional (Rung 2) as they establish causal sufficiency but do not satisfy the counterfactual uniqueness or absolute necessity required for Rung 3. The paper itself acknowledges that the circuit fails the most challenging completeness tests, yet the abstract claim is stated as a fact."
2202.05262,2202.05262-01,factual associations correspond to localized directly-editable computations,abstract,3,Causal mediation analysis (causal tracing) and Rank-One Model Editing (ROME),2,3,1,5,0,"The method used is interventional (R2), involving activation patching (causal tracing) and weight modification (ROME) to establish causal sufficiency. However, the claim uses Rung 3 linguistic markers: it asserts that factual associations 'correspond to' (an identity/mechanistic claim) 'localized computations' (functional attribution). This implies a specific mechanistic structure rather than just causal mediation, creating a +1 gap between the interventional evidence and the mechanistic claim."
2202.05262,2202.05262-02,a distinct set of steps in middle-layer feed-forward modules that mediate factual predictions,abstract,3,Causal mediation analysis (causal tracing) via activation patching,2,2,0,5,0,"The method used is causal tracing, which is a form of activation patching (Rung 2). The claim uses the linguistic marker 'mediate', which is explicitly listed in the codebook as a Rung 2 causal marker. The claim and method are perfectly aligned at Rung 2."
2202.05262,2202.05262-03,mid-layer feed-forward modules... storing factual associations,abstract,3,Causal mediation analysis (causal tracing) and Rank-One Model Editing (ROME),2,3,1,5,0,"The method used is interventional (R2), involving activation patching and weight editing to observe causal effects on model output. However, the claim uses the term 'storing', which according to the codebook's decision tree for polysemous terms, is a Rung 3 (Mechanistic) claim because it implies a specific storage mechanism rather than just causal mediation. The gap between the interventional evidence (R2) and the storage/mechanistic claim (R3) constitutes a +1 overclaim."
2202.05262,2202.05262-04,ROME is effective on a standard zero-shot relation extraction model-editing task,abstract,3,Rank-One Model Editing (ROME) evaluated on zsRE benchmark,2,2,0,5,0,"The method (ROME) is an interventional weight-editing technique (Rung 2). The claim uses the term 'effective' to describe the performance of this intervention on a specific task (zsRE). According to the codebook, claims about the result of an intervention or its effectiveness are Rung 2. There is no overclaim here as the claim rung matches the method rung."
2301.05217,2301.05217-01,We fully reverse engineer the algorithm learned by these networks,abstract,3,"Ablation in Fourier space, weight analysis, and activation analysis",2,3,1,5,0,"The claim uses the phrase 'fully reverse engineer' and 'the algorithm', which are explicit Rung 3 linguistic markers indicating a complete mechanistic and unique functional attribution. The methods used (Fourier ablation) are interventional (Rung 2) but do not establish counterfactual uniqueness or necessity to the level required for a Rung 3 claim, creating a +1 gap."
2301.05217,2301.05217-02,uses discrete Fourier transforms and trigonometric identities to convert addition to rotation,abstract,3,Ablation in Fourier space and weight/activation analysis,2,3,1,5,0,"The claim uses functional/mechanistic verbs ('uses', 'convert') to describe a specific algorithm. While the paper provides interventional evidence (Rung 2) via Fourier ablations to show these components are necessary, the claim is framed as a complete mechanistic narrative of how the model performs the task (Rung 3). This matches the 'Grokking' calibration case in the codebook."
2301.05217,2301.05217-03,grokking arises from the gradual amplification of structured mechanisms encoded in the weights,abstract,3,Ablation in Fourier space and weight/activation analysis,2,3,1,5,0,The method is classified as Rung 2 because the authors use Fourier-space ablations to establish causal necessity of specific frequencies. The claim is classified as Rung 3 because it uses the term 'encoded' in a mechanistic sense (referring to the underlying structure of the algorithm) and describes the 'mechanism' as the source of the behavior. This matches the R2 to R3 overclaiming pattern identified in the calibration rationales for this specific paper.
2409.04478,2409.04478-01,SAEs struggle to reach the neuron baseline,abstract,3,Interchange intervention on SAE features and neurons,2,2,0,5,0,"The method used is interchange intervention (a form of activation patching), which is a Rung 2 interventional method. The claim 'struggle to reach the neuron baseline' refers to the comparative performance of these features in mediating the model's behavior during those interventions. This is a causal sufficiency claim (Rung 2) rather than a mechanistic or uniqueness claim (Rung 3)."
2409.04478,2409.04478-02,sets of SAE features that separately mediate knowledge of which country a city is in,abstract,3,Interchange intervention on SAE features using Differential Binary Masking (DBM),2,2,0,5,0,"The method uses interchange interventions (patching) to measure the effect of specific feature sets on model output, which is a Rung 2 interventional method. The claim uses the term 'mediate', which is the specific linguistic marker for Rung 2 causal claims according to the codebook. Therefore, the claim is perfectly calibrated to the method."
2601.11516,2601.11516-01,activation probes may be a promising misuse mitigation technique,abstract,3,Linear probing,1,1,0,5,1,The claim is associational/observational (R1) as it describes probes as a 'promising technique' for a task (mitigation) without asserting a specific internal mechanism or causal necessity. The method used in the prior work cited for this specific abstract claim is linear probing (R1). The claim is explicitly hedged with the word 'may'.
2601.11516,2601.11516-02,probes fail to generalize under important production distribution shifts,abstract,3,"Linear probing and novel probe architectures (MultiMax, Rolling Attention) evaluated on distribution shifts (long-context, multi-turn).",1,1,0,5,0,"The method used is observational (Rung 1) because it involves training and evaluating probes on frozen activations without intervening on the model's internal state to change behavior. The claim is associational (Rung 1) because 'fail to generalize' refers to the predictive performance/accuracy of the probes on new distributions, which is a statement about the limits of the associational evidence extracted by the probes."
2304.14997,2304.14997-01,reverse-engineered nontrivial behaviors of transformer models,abstract,3,activation patching,2,3,1,5,0,"The claim uses the term 'reverse-engineered', which is a Rung 3 linguistic marker indicating a complete mechanistic understanding of an algorithm. The method used to support this (and the paper's focus) is activation patching, which is an interventional method (Rung 2) that establishes causal sufficiency but not the unique mechanistic necessity required for Rung 3."
2304.14997,2304.14997-02,ACDC algorithm rediscovered 5/5 of the component types in a circuit,abstract,3,Automatic Circuit DisCovery (ACDC) / Activation Patching,2,1,0,5,0,"The method used (ACDC) is based on activation patching, which is a Rung 2 interventional method. The claim itself is purely associational/observational (Rung 1) because it simply states that the algorithm 'rediscovered' or identified the same components as previous work, without making a functional or causal claim about the components' roles in this specific sentence."
2304.14997,2304.14997-03,researchers can understand the functionality of each component,abstract,3,activation patching,2,3,1,5,0,"The claim uses the functional/mechanistic term 'understand the functionality', which corresponds to Rung 3 (Mechanistic/Counterfactual). The method described in the abstract context is activation patching, which is a Rung 2 (Interventional) method. This represents a +1 gap (overclaim) typical of mechanistic interpretability papers that use causal interventions to support functional narratives."
2304.14997,2304.14997-04,finding the connections between abstract neural network units that form a circuit,abstract,3,Activation patching (ACDC algorithm),2,3,1,5,0,"The method (ACDC) is based on activation patching, which is a Rung 2 interventional method. The claim uses the term 'circuit', which according to the codebook's decision tree for polysemous terms, is classified as Rung 3 (mechanistic/uniqueness claim) because it implies a functional subgraph responsible for a behavior."
2407.14008,2407.14008-01,partially reverse-engineer the circuit responsible for the Indirect Object Identification task,abstract,3,"Resample ablation, Edge Attribution Patching (EAP), and Automated Circuit Discovery (ACDC)",2,3,1,5,1,"The claim uses the term 'reverse-engineer' and 'the circuit responsible for', which are Rung 3 linguistic markers implying a functional/mechanistic narrative and a unique causal structure. The methods used (ablation and patching) are interventional (Rung 2) as they establish causal sufficiency but do not prove uniqueness or a complete counterfactual mechanism. The author includes the hedge 'partially', but per the codebook, the underlying claim remains Rung 3."
2407.14008,2407.14008-02,Layer 39 is a key bottleneck,abstract,3,"Zero and Resample ablation, Layer Removal, and minimal cross-talk subset computation",2,3,1,5,0,"The authors use interventional methods (Rung 2) such as resample ablation and layer removal to show that Layer 39 is necessary for the task. However, the claim that it is a 'key bottleneck' is a mechanistic/functional attribution (Rung 3) that implies a specific structural role in the model's internal algorithm. According to the codebook, functional descriptions of a component's role ('bottleneck', 'responsible for') are Rung 3, creating a +1 gap."
2407.14008,2407.14008-03,Convolutions in layer 39 shift names one position forward,abstract,3,Resample ablation on individual convolution slices,2,3,1,5,0,"The method used is resample ablation (interchange intervention) on specific convolution slices to test the effect on logit difference, which is a Rung 2 interventional method. The claim uses the functional verb 'shift', which describes a specific mechanistic operation/algorithm performed by the component, making it a Rung 3 claim. This follows the 'performs/computes' functional attribution rule in the codebook."
2407.14008,2407.14008-04,The name entities are stored linearly in Layer 39's SSM,abstract,3,Activation modification (Replace/Subtract and Add) and Cosine Similarity,2,3,1,5,0,"The claim uses the term 'stored' to describe how entities are represented in the SSM, which is a Rung 3 mechanistic/storage claim according to the codebook. The evidence provided in Section 4.3 involves 'Replace' and 'Subtract and Add' methods (interchange interventions/activation patching) which establish causal sufficiency (Rung 2), but do not prove the unique storage mechanism or counterfactual necessity required for Rung 3. This follows the 'ROME' calibration pattern where interventional evidence is used to support a 'storage' claim."
2501.17148,2501.17148-01,prompting outperforms all existing methods followed by finetuning,abstract,3,LLM-as-a-judge evaluation of steered outputs,2,2,0,5,0,"The method used is model steering (intervention-based) evaluated by an LLM judge on three axes (concept, instruct, fluency). This is a Rung 2 method because it measures the causal effect of interventions on model behavior. The claim 'outperforms' refers to the empirical performance on these Rung 2 metrics (causal efficacy) rather than a mechanistic or counterfactual claim about internal structure, making it a Rung 2 claim."
2501.17148,2501.17148-02,SAEs are not competitive,abstract,3,SAE feature attribution and steering evaluation,2,1,0,5,0,"The claim 'SAEs are not competitive' is an associational/observational claim (Rung 1) about the performance of a method relative to baselines on a benchmark. While the evidence used to support this includes interventional steering (Rung 2), the claim itself is a comparative performance statement rather than a causal or mechanistic one. It describes the empirical result of the benchmark (Rung 1) without making a claim about the model's internal causal structure or unique mechanisms."
2501.17148,2501.17148-03,representation-based methods such as difference-in-means perform the best,abstract,3,"Difference-in-means (DiffMean) and other representation-based methods (Probe, ReFT-r1)",1,1,0,5,0,"The claim refers specifically to 'concept detection' performance (AUROC) as measured in the benchmark. In the context of this paper, concept detection is an associational task where a classifier (like DiffMean or a Probe) is used to predict labels from frozen activations. This is a Rung 1 method supporting a Rung 1 claim about predictive performance."
2404.03646,2404.03646-01,specific components within middle layers show strong causal effects at the last token of the subject,abstract,3,Causal tracing (activation patching),2,2,0,5,0,"The method used is activation patching (causal tracing), which is a Rung 2 interventional method. The claim uses the linguistic marker 'causal effects', which is the standard Rung 2 marker for interventional results. There is no overclaim as the claim rung matches the method rung."
2404.03646,2404.03646-02,rank-one model editing methods can successfully insert facts at specific locations,abstract,3,ROME (Rank-One Model Editing),2,2,0,5,0,"The method used is ROME, which is an interventional weight-modification technique (Rung 2). The claim uses the verb 'insert', which in the context of model editing refers to the successful causal outcome of the intervention (causal sufficiency) rather than a claim about the model's unique internal mechanism or counterfactual necessity. This aligns with Rung 2."
2404.03646,2404.03646-03,linearity of Mamba's representations of factual relations,body,1,Linearity of Relation Embedding (LRE) / Jacobian-based first-order Taylor approximation,1,3,2,5,0,"The method (LRE) is a correlational/associational technique that uses linear approximations (Jacobians) to see if information is decodable or present in a linear subspace (Rung 1). The claim uses the term 'representations', which, according to the polysemous terms decision tree, defaults to Rung 3 (mechanistic) unless the context explicitly limits it to 'decodability'. Here, the paper frames it as an investigation into the 'internal mechanisms' and 'how LMs extract this information', moving it into the mechanistic narrative category."
2505.14685,2505.14685-01,LM binds each character-object-state triple together by co-locating their reference information,abstract,3,Causal Abstraction with Interchange Interventions and Desiderata-based Component Masking (DCM),2,3,1,5,0,"The claim uses the functional/mechanistic verb 'binds' and describes a specific internal structural operation ('co-locating reference information') to explain how the model represents data. According to the codebook, functional attribution and mechanistic narratives are Rung 3. The evidence provided is based on activation patching (interchange interventions) and subspace masking (DCM), which are Rung 2 interventional methods that establish causal sufficiency but not the unique mechanistic necessity required for Rung 3."
2505.14685,2505.14685-02,lookback mechanism which enables the LM to recall important information,abstract,3,Causal Mediation Analysis (Interchange Interventions / Activation Patching),2,3,1,5,0,"The method used is activation patching (interchange interventions), which is a Rung 2 interventional method. The claim uses the functional/mechanistic verb 'enables the LM to recall', which implies a specific internal algorithm or mechanism (Rung 3). According to the codebook, functional verbs like 'recalls' or 'performs' are Rung 3 linguistic markers, creating a +1 gap between the interventional evidence and the mechanistic claim."
2505.14685,2505.14685-03,the binding lookback retrieves the correct state OI,abstract,3,Causal Abstraction / Interchange Interventions (Activation Patching),2,3,1,5,0,"The method used is activation patching (interchange interventions) on specific subspaces, which is a Rung 2 interventional method. The claim uses the functional verb 'retrieves' and describes a specific mechanistic step ('the binding lookback retrieves...') as part of a larger 'reverse-engineering' narrative. According to the codebook, functional verbs and mechanistic narratives are markers of Rung 3 claims."
2510.06182,2510.06182-01,LMs implement such retrieval via a positional mechanism,abstract,3,Interchange interventions (activation patching),2,3,1,5,0,"The claim uses the functional verb 'implement' to describe how the model performs a task, which is a Rung 3 mechanistic/functional attribution. The paper identifies this as the 'prevailing view' based on prior work using activation patching (Rung 2). The paper's own evidence also relies on interchange interventions (Rung 2) to test this mechanism, creating a +1 gap between the interventional evidence and the mechanistic claim."
2510.06182,2510.06182-02,LMs supplement the positional mechanism with a lexical mechanism and a reflexive mechanism,abstract,3,Interchange interventions (activation patching) and causal abstraction modeling,2,3,1,5,0,"The method used is interchange intervention (Rung 2), which establishes causal sufficiency. However, the claim uses the term 'mechanism' and describes how the model 'supplements' one with others to 'drive model behavior,' which constitutes a functional/mechanistic narrative (Rung 3). According to the codebook, describing 'the mechanism' or 'how it works' beyond the result of the intervention is a Rung 3 claim."
2510.06182,2510.06182-03,causal model combining all three mechanisms that estimates next token distributions with 95% agreement,body,1,Causal abstraction/Interchange intervention,2,3,1,5,0,"The method used is interchange intervention (Rung 2), which establishes causal sufficiency. The claim uses the term 'causal model' and 'mechanisms' to describe how the model 'estimates' distributions, which falls under Rung 3 (mechanistic narrative/functional attribution). The codebook specifically identifies 'causal model' and 'mechanism' as R3 markers when uniqueness or complete functional explanation is implied, as seen in the calibration cases for Grokking and IOI."
2510.06182,2510.06182-04,how LMs bind and retrieve entities in-context,abstract,3,Interchange interventions (activation patching) and causal abstraction modeling,2,3,1,5,0,"The claim uses the functional/mechanistic verb 'bind' and 'retrieve' to describe the model's internal operations. According to the codebook, 'how' a model performs a task and functional verbs like 'retrieve' or 'bind' (similar to 'encodes' or 'computes') constitute Rung 3 mechanistic claims. The evidence provided is based on interchange interventions (activation patching), which are Rung 2 methods. This creates a +1 gap (R2 to R3 overclaim), similar to the IOI calibration anchor."
2411.16105,2411.16105-01,circuits within LLMs may be more flexible and general than previously recognized,abstract,3,Path patching and circuit discovery on prompt variants,2,3,1,5,1,The authors use path patching (Rung 2) to identify circuit components. The claim that circuits are 'flexible and general' is a mechanistic/functional attribution (Rung 3) about the nature of the underlying algorithm. The use of 'may be' is an explicit hedge.
2411.16105,2411.16105-02,the circuit generalizes surprisingly well reusing all of its components and mechanisms,abstract,3,Path patching and circuit discovery (re-extracting circuits on prompt variants),2,3,1,5,0,"The claim uses mechanistic language ('reusing all of its components and mechanisms') and refers to 'the circuit' as a functional entity. According to the codebook, functional attribution and mechanistic narratives are Rung 3. The method used is path patching (a variant of activation patching), which is an interventional method classified as Rung 2. This creates a +1 gap (R2 to R3), similar to the IOI calibration anchor."
2411.16105,2411.16105-03,we discover a mechanism that explains this which we term S2 Hacking,abstract,3,Path patching and attention analysis on circuit components,2,3,1,5,0,"The authors use path patching (R2) to identify why the circuit behaves differently from the model. However, the claim uses the term 'mechanism' and 'explains' to provide a functional narrative of how the circuit operates, which falls under Rung 3 (Mechanistic/Counterfactual) according to the codebook's linguistic markers and decision trees for mechanistic narratives."
2411.16105,2411.16105-04,implement algorithms responsible for performing specific tasks,abstract,3,Activation patching (path patching),2,3,1,5,0,"The claim uses the functional/mechanistic verbs 'implement' and 'performing' to describe the relationship between circuits and tasks. According to the codebook, functional attribution and mechanistic narratives are Rung 3. The method used throughout the paper to identify these circuits is path patching (a variant of activation patching), which is an interventional method classified as Rung 2. This creates a +1 gap (R2 to R3)."
2402.17700,2402.17700-01,MDAS achieves state-of-the-art results on RAVEL demonstrating the importance of going beyond neuron-level analyses to identify features distributed across activations,abstract,3,Multi-task Distributed Alignment Search (MDAS),2,3,1,5,0,"The method (MDAS) is an interventional technique based on interchange interventions (activation patching), which establishes causal sufficiency (Rung 2). The claim uses the term 'identify features', which, according to the codebook's decision tree for polysemous terms like 'represents/encodes/identifies', is treated as a Rung 3 mechanistic claim by default unless the context limits it to linear decodability. Furthermore, the claim asserts that these features are 'distributed across activations', making a functional attribution about the model's internal representational structure (Rung 3)."
2402.17700,2402.17700-02,If this leads the LM to output Asia instead of Europe then we have evidence that the feature F encodes the attribute continent,introduction,2,Interchange Intervention (Activation Patching),2,3,1,5,0,"The method used is interchange intervention, which is a form of activation patching (Rung 2). The claim uses the term 'encodes', which according to the codebook decision tree for polysemous terms, defaults to Rung 3 (mechanistic) unless the context specifies a decodability/probing sense. Here, the context is a mechanistic narrative about how the model represents and uses attributes, and the paper elsewhere claims to 'localize' and 'reverse-engineer' these features, confirming a Rung 3 interpretation."
2402.17700,2402.17700-03,Methods with counterfactual supervision achieve strong results while methods with unsupervised featurizers struggle,results,1,"Multi-task Distributed Alignment Search (MDAS), Distributed Alignment Search (DAS), Differential Binary Masking (DBM), Sparse Autoencoder (SAE), and Principal Component Analysis (PCA)",2,2,0,5,0,"The claim compares the performance of different methods on the RAVEL benchmark. The benchmark's primary metric is the 'Disentangle score', which is derived from interchange interventions (activation patching). According to the codebook, activation patching is a Rung 2 method. The claim itself is an empirical observation about the relative effectiveness ('achieve strong results') of these methods in producing causal effects on model behavior, which aligns with Rung 2 (causal sufficiency/influence)."
2402.17700,2402.17700-04,The representations of different attributes gradually disentangle as we move towards later layers,results,1,Multi-task Distributed Alignment Search (MDAS),2,3,1,5,0,"The method (MDAS) is an interventional technique based on interchange interventions (activation patching), which establishes causal sufficiency (Rung 2). The claim uses the term 'representations' and describes a mechanistic narrative of how attributes 'disentangle' across layers, which constitutes a functional/mechanistic claim (Rung 3) about the model's internal organization. This creates a +1 gap (R2 to R3)."
2402.17700,2402.17700-05,Some groups of attributes are more difficult to disentangle than others... Changing one of these entangled attributes has seemingly unavoidable ripple effects,results,1,Multi-task Distributed Alignment Search (MDAS) / Interchange Intervention,2,3,1,5,1,"The method used is MDAS, which is a form of interchange intervention (activation patching) used to find causal subspaces. This is a Rung 2 method. The claim uses the phrase 'unavoidable ripple effects' and 'difficult to disentangle' to describe the underlying structure of the model's representations. According to the codebook, claims about how the model 'is' structured or the nature of its internal 'mechanism' (even when describing entanglement) are Rung 3. The word 'seemingly' acts as a hedge."
2404.03592,2404.03592-01,much prior interpretability work has shown that representations encode rich semantic information,abstract,3,Linear probing / Activation logging (referenced prior work),1,3,2,5,0,"The claim uses the polysemous term 'encode' to describe the relationship between representations and semantic information. According to the decision tree for 'encode', since the context refers to 'prior interpretability work' (typically probing or activation analysis in this context) and the authors use this as a motivation for a 'mechanistic' hypothesis about editing, it functions as a Rung 3 claim. The codebook specifically lists 'representations encode X' as a Rung 3 linguistic marker (functional/mechanistic attribution)."
2404.03592,2404.03592-02,interventions on linear subspaces of representations have provided increasing evidence that human-interpretable concepts are encoded linearly,introduction,2,Interventional interpretability (Distributed Interchange Intervention/DAS),2,3,1,5,0,"The method described (interventions on linear subspaces) corresponds to Rung 2 (Interventional). However, the claim uses the term 'encoded', which according to the polysemous terms decision tree in the codebook, defaults to Rung 3 (mechanistic) unless the context specifies a decodability/probing sense. Here, the context links the intervention to the internal representation mechanism, making it a Rung 3 claim."
2404.03592,2404.03592-03,DAS is highly expressive and can effectively localize concepts within model representations,body,1,Distributed Alignment Search (DAS),2,3,1,5,0,"The method (DAS) is an interventional technique that finds subspaces to maximize counterfactual output probability, placing it at Rung 2. The claim uses the term 'localize', which according to the codebook's decision tree for polysemous terms like 'encodes/represents/stores', implies a mechanistic/functional attribution (Rung 3) when it describes the model's internal structure ('within model representations') rather than just the result of the intervention."
2404.03592,2404.03592-04,a linear subspace distributed across a set of neurons can achieve generalised control over a vast number of tasks,discussion,2,Low-rank Linear Subspace ReFT (LoReFT),2,3,1,5,0,"The method (LoReFT) is interventional, involving the learning of low-rank projections to manipulate representations and observe changes in model behavior (Rung 2). The claim uses the functional/mechanistic verb 'achieve generalised control' and implies a specific structural mechanism ('a linear subspace distributed across a set of neurons') that underlies the model's ability to perform tasks, which aligns with Rung 3 (Mechanistic/Counterfactual). This creates a +1 gap between the interventional evidence and the mechanistic claim."
2404.03592,2404.03592-05,LoReFT shows that training a set of low-rank interventions on selected residual streams can induce a base LM to follow instructions,discussion,2,Low-rank Linear Subspace ReFT (LoReFT),2,2,0,5,0,"The method (LoReFT) is interventional, as it involves learning and applying interventions to hidden representations to change model behavior. The claim uses the phrase 'can induce', which is a causal sufficiency claim (Rung 2) rather than a claim about the unique underlying mechanism or internal representation (Rung 3). The claim accurately reflects that the intervention is sufficient to produce the instruction-following behavior."
2104.08164,2104.08164-01,The factual knowledge acquired during pre-training and stored in the parameters of Language Models,abstract,3,Hyper-network weight editing (KnowledgeEditor),2,3,1,5,0,"The claim uses the term 'stored', which according to the codebook decision tree for polysemous terms, is a Rung 3 mechanistic marker implying a storage/memory mechanism. The method used in the paper (KnowledgeEditor) is an interventional method that modifies weights to change outputs, which establishes causal sufficiency (Rung 2) but does not provide the counterfactual necessity or uniqueness evidence required for a Rung 3 claim about the underlying storage mechanism."
2104.08164,2104.08164-02,our hyper-network can be regarded as a probe revealing which components need to be changed to manipulate factual knowledge,abstract,3,Hyper-network weight update analysis,2,3,1,5,1,"The method involves a hyper-network predicting weight updates (interventions) to change model behavior, which is Rung 2. The claim uses the term 'probe' and 'revealing which components... manipulate factual knowledge,' which implies a functional/mechanistic attribution of where knowledge is stored or controlled, making it a Rung 3 claim. The phrase 'can be regarded as' acts as an explicit hedge."
2104.08164,2104.08164-03,our analysis shows that the updates tend to be concentrated on a small subset of components,abstract,3,Activation logging/Weight update analysis,1,1,0,5,0,"The method used is an observational analysis of weight updates generated by the hyper-network (Figure 4). The claim is purely associational/observational, stating where updates 'tend to be concentrated' based on logging these changes. It does not make a causal or mechanistic claim about the necessity of these specific components for the behavior, but rather reports the distribution of the method's output."
2104.08164,2104.08164-04,our hyper-network can be regarded as a probe revealing the causal mediation mechanisms,body,1,Hyper-network weight update analysis,1,3,2,5,1,"The authors describe their hyper-network as a 'probe' that reveals 'causal mediation mechanisms'. While the hyper-network itself performs interventions (R2), the analysis of which weights it chooses to update is an observational/correlational analysis of the hyper-network's internal logic (R1). The claim uses the term 'mechanisms', which is a Rung 3 linguistic marker. The phrase 'can be regarded as' acts as an explicit hedge."
2104.08164,2104.08164-05,the knowledge manipulation seems to be achieved by primarily modifying parameters affecting the shape of the attention distribution,body,1,Weight update analysis (visualizing average normalized magnitude of updates predicted by the hyper-network),1,3,2,5,1,"The method is observational (Rung 1) because it analyzes the output of a trained hyper-network (the 'probe') rather than performing an intervention on the model's weights to verify if those specific parameters are necessary or sufficient for the behavior. The claim is mechanistic (Rung 3) because it uses functional language ('achieved by', 'affecting') to describe how the model's internal mechanism (the attention distribution shape) is responsible for the knowledge manipulation. The author hedges with 'seems to be'."
2511.22662,2511.22662-01,The core difficulty we identify is that distinguishing strategic deception from simpler behaviours requires making claims about a model's internal beliefs and goals,introduction,2,Conceptual arguments and analysis of existing empirical works,1,3,2,5,0,"The method used is purely observational and conceptual (Rung 1), involving the analysis of existing datasets and theoretical frameworks. The claim itself is a mechanistic/functional attribution (Rung 3) because it asserts that the distinction between types of deception depends on the model's internal 'beliefs and goals'. According to the codebook, attributing internal states like beliefs or goals to a model is a Rung 3 claim, as it moves beyond causal mediation (R2) to a functional/mechanistic narrative of how the model operates."
2511.22662,2511.22662-02,What must be true about the internal state of the language model when it is lying or deceiving for a classifier such as an activation probe to provide good classification performance,body,1,Linear probing (activation probe),1,3,2,5,0,"The claim uses the term 'internal state' and 'lying or deceiving' to describe what a probe is capturing. According to the codebook, describing a model's internal representation as 'lying' or 'deceiving' (functional/mechanistic verbs) rather than just 'decodable information' constitutes a Rung 3 claim. The method used is linear probing, which is explicitly Rung 1."
2511.22662,2511.22662-03,Model beliefs are not stable and are far more context dependent than animal or human beliefs,body,1,"Conceptual arguments and analysis of novel illustrative case studies (e.g., MASK and 'convincing game' prompts)",1,3,2,5,0,"The method used is observational/associational (Rung 1), involving the analysis of model outputs across different prompts and contexts without causal intervention on the model's internal components. The claim uses the term 'beliefs,' which according to the codebook's decision tree for polysemous terms, defaults to a Rung 3 mechanistic reading unless context specifies a decodability sense. Here, the context refers to the model's internal state and intentionality, making it a Rung 3 claim. This creates a +2 gap (R1 method to R3 claim)."
2511.22662,2511.22662-04,We find very low agreement between a full-transcript autorater and the MASK labels,results,1,Comparison of MASK dataset labels against a language model autorater's evaluation of full transcripts.,1,1,0,5,0,"The method is purely observational/associational, involving a statistical comparison of two labeling outputs (MASK vs. Autorater) without any intervention on the model's internal activations or weights. The claim is a straightforward empirical observation of 'low agreement' (a correlation/association metric) between these two data sources, which matches Rung 1."
2511.22662,2511.22662-05,It is mostly true today that models behaving strategically deceptively have a consistent mechanism when they deceive,body,1,Conceptual arguments and analysis of existing empirical works,1,3,2,5,1,"The claim asserts the existence of a 'consistent mechanism' underlying strategic deception, which is a Rung 3 mechanistic claim (functional attribution/internal structure). The method used to support this specific claim in the paper is conceptual reasoning and literature review (Rung 1), as the authors are discussing theoretical possibilities and the current state of the field rather than performing new interventions or counterfactual tests to prove this mechanism's existence."
2503.10894,2503.10894-01,HyperDAS achieves state-of-the-art performance on the RAVEL benchmark for disentangling concepts in hidden states,abstract,3,Interchange intervention (Distributed Alignment Search) optimized via a hypernetwork,2,2,0,5,0,"The claim is about performance on the RAVEL benchmark, which specifically measures 'disentangling' via causal interventions (interchange interventions). According to the codebook, interchange interventions are Rung 2 methods. The claim uses the term 'disentangling', which in the context of this benchmark refers to causal sufficiency and isolation (Iso/Cause scores) rather than a unique mechanistic proof (R3). Therefore, both the method and the claim are classified as Rung 2."
2503.10894,2503.10894-02,features that mediate concepts and enable predictable manipulation,abstract,3,Distributed Alignment Search (DAS) / Interchange Intervention,2,3,1,5,0,"The claim uses the term 'mediate', which is a Rung 2 causal marker, but combines it with 'features that... enable predictable manipulation', which implies a functional/mechanistic role (Rung 3). Furthermore, the abstract frames these features as the internal entities that 'realize' concepts. According to the codebook, identifying 'features' as the functional units of a model's internal workings is a Rung 3 mechanistic claim. The method used (DAS/Interchange Intervention) establishes causal sufficiency (Rung 2) but does not prove the features are the unique or complete mechanism (Rung 3)."
2503.10894,2503.10894-03,HyperDAS automatically locates the token-positions of the residual stream that a concept is realized in,abstract,3,HyperDAS (Transformer-based hypernetwork for automated interchange intervention),2,3,1,5,0,"The method used is an automated form of interchange intervention (Distributed Alignment Search), which is a Rung 2 interventional method. The claim uses the phrase 'is realized in', which is a mechanistic/functional attribution marker (Rung 3) implying that the model's internal representation of the concept is physically located at those specific token positions. According to the codebook, claiming a component 'realizes' or 'represents' a concept based on interventional evidence is a Rung 2 to Rung 3 overclaim (+1 gap)."
2503.10894,2503.10894-04,Interchange interventions identify neural representations that are causal mediators of high-level concepts,body,1,Interchange intervention (Distributed Alignment Search),2,2,0,5,0,"The claim uses the term 'causal mediators', which is the standard linguistic marker for Rung 2. The method described (interchange intervention) is a form of activation patching that establishes causal sufficiency, matching the Rung 2 classification."
2503.10894,2503.10894-05,at deeper layers the hypernetwork learns to intervene on unintuitive positions... which were previously unknown to store attributes,results,1,HyperDAS (Hypernetwork-based Interchange Intervention),2,3,1,5,0,"The method used is an interventional search (Rung 2) based on interchange interventions (patching). The claim uses the term 'store', which according to the polysemous terms decision tree in the codebook, defaults to a Rung 3 mechanistic claim unless the context explicitly limits it to 'linearly decodable'. Here, the context is about identifying the specific internal location responsible for the information, which is a mechanistic narrative. This creates a +1 gap (R2 method supporting an R3 claim)."
2506.18167,2506.18167-01,We demonstrate that these behaviors are mediated by linear directions in the model's activation space and can be controlled using steering vectors,abstract,3,Attribution patching and steering vector intervention,2,2,0,5,0,"The method used is steering vector intervention (adding/subtracting directions and measuring behavioral change), which is a Rung 2 interventional method. The claim uses the term 'mediated' and 'controlled', which are standard Rung 2 linguistic markers for causal sufficiency and influence. The claim does not assert that these are the unique or only mechanisms (R3), but rather that they are causal mediators."
2506.18167,2506.18167-02,Positive steering increases behaviors such as backtracking and uncertainty estimation while negative steering suppresses them confirming the causal influence,results,1,Steering vectors (Difference of Means) and Attribution Patching,2,2,0,5,0,"The method used is steering (intervention) and attribution patching (linearized intervention), which are Rung 2 methods. The claim uses the term 'causal influence' and describes the result of the intervention (increasing/suppressing behavior), which aligns with Rung 2 linguistic markers ('causally affects', 'intervening on X changes Y'). It does not claim to be the unique mechanism or 'the' circuit (R3)."
2506.18167,2506.18167-03,These effects are consistent across both DeepSeek-R1-Distill models reinforcing the hypothesis that Thinking LLMs encode these reasoning mechanisms as linear directions,results,1,Steering vectors (Difference of Means) and Attribution Patching,2,3,1,5,0,"The method used is interventional (steering vectors and attribution patching), which establishes causal sufficiency for behavioral change (Rung 2). However, the claim uses the term 'encode' and 'mechanisms' to describe the internal representation, which according to the codebook decision tree for polysemous terms, defaults to a Rung 3 mechanistic reading unless decodability is explicitly specified. The claim also generalizes the finding to the nature of 'Thinking LLMs' as a class, moving beyond the specific causal result to a mechanistic narrative."
2506.18167,2506.18167-04,Several reasoning behaviors in thinking models can be isolated to specific directions in the model's activation space enabling precise control through steering vectors,conclusion,2,Attribution patching and Difference of Means steering,2,3,1,5,0,"The method used is interventional (Rung 2), involving Difference of Means to extract vectors and attribution patching to measure causal effects. However, the claim uses Rung 3 linguistic markers: 'isolated to specific directions' (implying a unique/mechanistic mapping) and 'enabling precise control' (functional attribution). This follows the 'Steering -> controls' overclaim pattern identified in the codebook."
2506.18167,2506.18167-05,Our findings indicate that the DeepSeek-R1-Distill models have distinct mechanisms to achieve their reasoning process,results,1,Attribution patching and steering vectors,2,3,1,5,0,"The method used is interventional (steering vectors and attribution patching), which establishes causal sufficiency (Rung 2). However, the claim uses the term 'mechanisms' and 'to achieve their reasoning process', which implies a functional/mechanistic narrative (Rung 3) rather than just causal mediation. This follows the R2 to R3 overclaiming pattern identified in the codebook for circuit/mechanism discovery."
2506.03292,2506.03292-01,scaling HYPERSTEER with thousands of steering prompts exceeds the performance of state-of-the-art activation steering methods,abstract,3,Activation steering evaluation using LLM-as-a-judge (AxBench framework),2,2,0,5,0,"The method involves active intervention (activation steering) and measures the resulting change in model output behavior using a judge model. This is a classic Rung 2 interventional setup. The claim is a performance comparison ('exceeds the performance') regarding the efficacy of these interventions, which is a Rung 2 claim. There is no claim of a unique mechanism or 'the' underlying circuit (R3)."
2506.03292,2506.03292-02,HYPERSTEER performs on par with steering-via-prompting,abstract,3,Activation steering with hypernetworks (HyperSteer) compared against prompt engineering baselines using LLM-as-a-judge evaluation.,2,2,0,5,0,"The method is interventional (Rung 2) as it involves modifying internal activations via steering vectors and measuring the resulting change in model output. The claim 'performs on par' is a statement of causal efficacy/sufficiency for a specific task, which aligns with Rung 2. It does not claim to be the unique mechanism (R3) or merely a correlation (R1)."
2506.03292,2506.03292-03,our cross-attention HYPERSTEER variant performs better on unseen steering prompts than every supervised activation steering baseline,results,2,Activation steering evaluation on held-out prompts,2,2,0,5,0,"The method involves activation steering (intervening on the model's residual stream) and measuring the resulting change in output behavior (steering performance). This is a classic Rung 2 interventional setup. The claim is a performance comparison ('performs better') regarding the efficacy of these interventions, which is a Rung 2 claim. It does not make mechanistic or uniqueness claims (R3) nor is it purely observational (R1)."
2506.03292,2506.03292-04,as training data increases HYPERSTEER becomes much more economical than supervised activation steering,results,1,Comparative compute efficiency analysis (TFLOPS vs. evaluation loss) between HyperSteer and ReFT-r1 baseline.,2,2,0,5,0,"The method involves measuring the causal efficacy (steering performance/loss) of interventions relative to the compute cost (TFLOPS) across different data scales. This is an interventional evaluation (Rung 2). The claim is a comparative statement about the efficiency of achieving a causal effect, which falls under Rung 2 (causal sufficiency/utility) rather than a Rung 3 mechanistic or uniqueness claim."
2506.03292,2506.03292-05,cross-attention's residual inter-concept similarity is weakened by additional conditioning but not at the cost of steering performance,body,1,Activation steering with cross-attention hypernetworks and pairwise cosine similarity analysis,2,2,0,5,0,"The method involves activation steering (Rung 2 intervention) and measuring the resulting performance and vector similarity. The claim is causal/interventional: it states that the 'additional conditioning' (the intervention method) 'weakened' similarity (a result of the intervention) without a 'cost' to performance (the outcome of the intervention). This describes the effect of an intervention on model behavior and internal state alignment, which fits Rung 2."
2510.01070,2510.01070-02,secret knowledge can be successfully extracted from the model's internal states even when it is not verbalized explicitly,results,1,Logit lens and Sparse Autoencoders (SAE) feature attribution,1,3,2,5,0,"The method used is primarily observational (Rung 1), involving the inspection of internal activations via logit lens and SAE feature activation logging without causal intervention on the model's weights or activations. The claim uses the term 'extracted' and 'secret knowledge' to describe a mechanistic discovery of internal representations, which, according to the codebook's decision tree for 'encodes/represents/stores', defaults to Rung 3 (mechanistic) when not explicitly supported by interventional evidence."
2510.01070,2510.01070-03,Model internals reveal secrets that its output conceals... white-box methods reveal strong signals corresponding to the female gender during this refusal,body,1,Logit lens and Sparse Autoencoders (SAE) feature attribution,1,3,2,5,0,"The method used is purely observational (Rung 1), involving activation logging and feature attribution without intervention on the model's computation. The claim uses the mechanistic/functional verb 'reveal' and 'reveal strong signals corresponding to' to describe internal representations that 'underlie' the model's state during a refusal. According to the codebook, claims about what the model 'internally represents' or 'reveals' about its knowledge/secrets are coded as Rung 3 (Mechanistic) unless explicitly qualified as mere decodability. The paper frames this as 'reverse-engineering' the model's hidden knowledge, a typical R3 narrative."
2510.01070,2510.01070-04,Fine-tuned model organisms successfully internalize secret knowledge... MOs have successfully internalized their secret knowledge and are aware of it,results,2,Downstream task performance evaluation (comparing fine-tuned MOs to base models and in-context baselines),1,3,2,5,0,"The method used is observational/associational (Rung 1) because it measures the model's output accuracy on specific tasks without intervening on internal activations or weights to establish a causal link. The claim uses the term 'internalized' and asserts the model is 'aware of' the knowledge, which are Rung 3 mechanistic/functional attribution markers. According to the codebook, claims about 'internalizing' or 'representing' knowledge without interventional evidence are classified as Rung 3."
2510.01070,2510.01070-05,Since models must internally represent secret knowledge to use it we should be able to extract it through mechanistic interpretability techniques,body,1,Logit lens and Sparse Autoencoders (SAEs),1,3,2,5,1,"The method used (logit lens and SAE feature attribution) is classified as Rung 1 because it is observational/associational, identifying what information is present in activations without causal intervention. The claim is classified as Rung 3 because it uses the mechanistic linguistic markers 'represent' and 'internally represent', and frames the extraction as a functional necessity for the model to 'use' the knowledge. The presence of 'should be able to' acts as a hedge, but the underlying claim remains mechanistic (R3)."
2410.08417,2410.08417-01,Eigendecomposition of bilinear MLP weights reveals interpretable low-rank structure across toy tasks image classification and language modeling,abstract,3,Eigendecomposition of bilinear MLP weights,1,3,2,5,0,"The method is purely observational/associational (Rung 1) as it involves decomposing frozen weights without any intervention on the model's activations or weights to observe behavioral changes. The claim uses the term 'reveals interpretable low-rank structure', which in the context of the paper's mechanistic narrative (identifying 'circuits' and 'how weights construct features'), constitutes a Rung 3 claim about the model's internal representation and functional organization."
2410.08417,2410.08417-02,For MNIST top eigenvectors represent curve segments specific to each digit class; for Fashion-MNIST top eigenvectors function as localized edge detectors,body,1,Eigendecomposition of interaction matrices (weight-based analysis),1,3,2,5,0,"The method is purely observational/associational (Rung 1) as it involves decomposing the weights of the model without any causal intervention or counterfactual testing. The claim uses functional/mechanistic language ('represent', 'function as') to describe the internal role of these components, which constitutes a Rung 3 claim. This is a classic R1 to R3 overclaim pattern identified in the codebook."
2410.08417,2410.08417-03,Adversarial masks constructed from eigenvectors cause misclassification demonstrating causal importance of extracted features,body,1,Adversarial mask construction and evaluation,2,2,0,5,0,"The method involves an intervention (adding a mask to the input) and measuring the change in model output (misclassification rate), which is a Rung 2 interventional method. The claim uses the term 'causal importance', which is a standard Rung 2 linguistic marker for causal effects established via intervention."
2410.08417,2410.08417-04,A sentiment negation circuit in layer 4 computes not-good and not-bad features via AND-gate-like interactions,body,1,Eigendecomposition of interaction matrices derived from SAE features and bilinear weights,2,3,1,5,0,"The method is interventional (R2) because it uses interaction matrices to show how specific input features causally combine to produce an output feature, effectively a form of weight-based attribution. The claim is Rung 3 because it uses functional/mechanistic language ('computes', 'circuit') and describes the specific logic ('AND-gate-like') of the internal mechanism."
2410.08417,2410.08417-05,Many SAE output features are well-correlated with low-rank eigenvector approximations particularly at large activation values,body,1,Low-rank eigenvector approximation of SAE feature activations,1,1,0,5,0,"The method is observational/associational (Rung 1) because it involves decomposing the weights into eigenvectors and measuring the correlation between those eigenvector activations and the actual SAE activations without intervening on the model's computation. The claim is also Rung 1 as it uses the linguistic marker 'well-correlated with', which is a standard associational claim."
2406.11779,2406.11779-01,The model outputs the largest logit on the true max token by attending more to larger tokens via the QK circuit and copying the tokens it attends to via the OV circuit,body,1,"Singular Value Decomposition (SVD) and qualitative inspection of circuit components (EQKE, EVOU)",1,3,2,5,0,"The method used is observational (Rung 1): the authors perform SVD on the weight matrices and visualize heatmaps to identify patterns (e.g., monotonicity in EQKE, diagonal structure in EVOU). The claim is mechanistic (Rung 3): it uses functional verbs ('outputs', 'attending', 'copying') and a mechanistic narrative ('via the QK circuit... via the OV circuit') to describe how the model performs the task. This follows the 'Attention viz -> performs' overclaim pattern (+2 gap)."
2406.11779,2406.11779-02,EQKE contains a single large rank-one component with singular value ~7800 around 620x larger than the second component,body,1,Singular Value Decomposition (SVD) of the EQKE matrix,1,1,0,5,0,"The method used is SVD, which is an observational/associational method (Rung 1) used to identify statistical structure in frozen weights. The claim is purely descriptive of the mathematical properties of the matrix (singular values and their ratios), which falls under Rung 1 linguistic markers ('contains', 'is associated with' in a correlational sense). There is no causal or mechanistic narrative attached to this specific claim; it is a statement of empirical observation about the model's internal parameters."
2406.11779,2406.11779-03,Zero ablating EQKP changes model accuracy from 0.9992 to 0.9993 confirming EQKP is unimportant to model functioning,body,1,Zero ablation,2,3,1,5,0,"The method used is zero ablation, which is a standard interventional method (Rung 2). The claim uses the term 'unimportant to model functioning', which is a mechanistic/functional attribution claim (Rung 3) according to the codebook's decision tree for 'responsible for/controls/performs'. The paper uses the result of a causal intervention to make a definitive statement about the internal mechanism's necessity/importance."
2406.11779,2406.11779-04,Shorter proofs seem to require and provide more mechanistic understanding; more faithful mechanistic understanding leads to tighter performance bounds,abstract,3,Quantitative metrics (unexplained dimensionality) and qualitative examination of proof strategies (SVD singular value ratios) across 151 model seeds.,2,3,1,5,1,"The claim uses mechanistic/functional language ('require', 'provide', 'leads to') to describe the relationship between internal model structure (faithfulness of understanding) and external performance (proof tightness). While the authors use interventional-style metrics (measuring how bounds change when the 'understanding' is simplified/ablated), the claim is framed as a mechanistic narrative about how the model's internal implementation 'underlies' the proof's success. The use of 'seem' and 'leads to' in the abstract indicates a high-level mechanistic conclusion derived from their interventional experiments."
2406.11779,2406.11779-05,Compounding structureless errors are a key challenge when making rank-1 approximations of constituent matrices,body,1,"Rank-1 approximation of constituent matrices (E, Q, K) and error term analysis",2,3,1,5,0,The method is interventional (R2) because it involves modifying the model's internal components (rank-1 approximations/pessimal ablations) to observe the effect on performance bounds. The claim is R3 because it makes a mechanistic/functional attribution about the 'key challenge' (compounding structureless errors) underlying the model's behavior and the failure of the interpretation to maintain non-vacuous bounds. It describes the 'how' of the failure in a mechanistic narrative.
2508.21258,2508.21258-01,RelP more accurately approximates activation patching than standard attribution patching particularly when analyzing residual stream and MLP outputs,abstract,3,Pearson correlation between RelP/AtP and Activation Patching (R2 ground truth),2,2,0,5,0,"The method used is a comparative evaluation against activation patching (a Rung 2 method). The claim is about the accuracy of an approximation to a causal effect ('approximates activation patching'), which is a Rung 2 claim. The paper does not claim RelP discovers the unique mechanism (R3), but rather that it is a more faithful interventional proxy than the baseline (AtP)."
2508.21258,2508.21258-02,For MLP outputs in GPT-2 Large attribution patching achieves a Pearson correlation of 0.006 whereas RelP reaches 0.956,abstract,3,Pearson correlation between RelP/AtP and Activation Patching,1,1,0,5,0,"The claim is purely associational, reporting a statistical correlation (Pearson r) between two methods. It makes no causal or mechanistic assertion about the model's internal workings, only about the alignment of the attribution methods themselves."
2508.21258,2508.21258-03,RelP achieves comparable faithfulness to Integrated Gradients in identifying sparse feature circuits without the extra computational cost,abstract,3,Integrated Gradients and Relevance Patching (RelP) evaluated via faithfulness/completeness metrics,2,2,0,5,0,The method used is interventional (R2) because faithfulness and completeness metrics are calculated by ablating components (mean-ablation) and measuring the change in model output. The claim is also R2 because it uses the term 'faithfulness' in a comparative sense to describe causal sufficiency (how much performance is captured/maintained under intervention) rather than claiming a unique or complete mechanistic proof (R3).
2508.21258,2508.21258-04,small feature circuits explain most of the model's behavior: in Pythia-70M about 100 features account for the majority of performance,body,1,Relevance Patching (RelP) and Integrated Gradients (IG) on SAE features,2,3,1,5,0,"The method used is RelP (a gradient-based approximation of activation patching) and IG, both of which are interventional (Rung 2) as they measure causal sufficiency/mediation. The claim uses mechanistic language ('explain most of the model's behavior', 'account for') and refers to 'circuits', which according to the codebook (Rung 3) implies a functional/mechanistic narrative of how the model performs a task."
2508.21258,2508.21258-05,RelP enables more faithful localization of influential components in large models,abstract,3,Relevance Patching (RelP) / Layer-wise Relevance Propagation (LRP),1,2,1,5,0,"The method (RelP) is a gradient-based attribution technique derived from LRP. According to the codebook, attribution methods that do not involve actual model intervention (like activation patching) are Rung 1 (Observational/Associational). The claim uses the term 'influential components' and 'localization', which implies causal mediation or sufficiency. Per the decision tree for 'controls/responsible for', claiming a component is 'influential' or 'responsible for' a behavior is a Rung 2 (Causal) claim. Therefore, this is a Rung 1 method making a Rung 2 claim."
2512.05865,2512.05865-01,Attention connectivity can be reduced to approximately 0.3% of edges while retaining the original pretraining loss on models up to 1B parameters,abstract,3,Sparsity-regularized post-training (SPARTAN framework) with GECO constrained optimization,2,2,0,5,0,"The method is interventional (Rung 2) because it involves active modification of the model's internal connectivity (zeroing out edges) and measuring the resulting effect on performance (pretraining loss). The claim is a causal sufficiency claim (Rung 2), stating that a specific intervention (reducing connectivity to 0.3%) is sufficient to maintain a specific outcome (original loss). It does not claim to be the unique mechanism (Rung 3) or merely observe a correlation (Rung 1)."
2512.05865,2512.05865-02,Sparse attention requires roughly three times fewer heads to recover 90% of the clean-model effect compared to the standard model on IOI and Greater-Than tasks,body,1,Activation patching (logit attribution),2,2,0,5,0,"The method used is activation patching (specifically logit attribution), which is a Rung 2 interventional method. The claim is a Rung 2 causal sufficiency claim, stating that a specific subset of components is sufficient to 'recover' or 'explain' a certain percentage of the model's behavior. It avoids Rung 3 mechanistic language like 'the circuit' or 'performs the task' in this specific sentence, focusing instead on the quantitative result of the intervention."
2512.05865,2512.05865-03,Sparse-attention models require 50-100x fewer edges to reach 90% of the cumulative single-instance effect on circuit discovery tasks,body,1,Activation patching (logit attribution) on sparsified models,2,3,1,5,0,"The method used is activation patching (Rung 2), which measures the causal effect of specific components on the model's output. The claim, however, uses the term 'circuit' and 'require' to describe the minimal set of components responsible for the behavior. According to the codebook, 'the circuit' and functional/mechanistic narratives (implying a specific, necessary structure) are classified as Rung 3. This represents a +1 gap (R2 to R3) typical of circuit discovery papers."
2512.05865,2512.05865-04,Local sparsity cascades into global circuit simplification: task-specific circuits involve far fewer components with up to 100x fewer edges,abstract,3,Activation patching and logit attribution,2,3,1,5,0,"The method used is activation patching (Rung 2), which establishes causal sufficiency for specific components. However, the claim uses the term 'circuits' and 'circuit simplification' to describe the model's internal functional architecture. According to the codebook, 'the circuit' or mechanistic narratives describing how the model performs a task (e.g., 'cascades into global circuit simplification') are classified as Rung 3. This represents a +1 gap (R2 to R3) typical of circuit discovery papers."
2512.05865,2512.05865-05,The internal information flow of dense models is diffused across many attention edges whereas sparse post-training consolidates information flow into a small number of edges,body,1,Activation patching and logit attribution,2,3,1,5,0,"The method used is activation patching (Rung 2), which measures causal sufficiency of components. The claim uses the term 'information flow' and 'consolidates', which are mechanistic narrative terms (Rung 3) describing how the model's internal algorithm is structured. This follows the R2 to R3 overclaiming pattern identified in the codebook for circuit discovery papers."
2512.05794,2512.05794-01,TopK SAEs can reveal biologically meaningful latent features but high feature-concept correlation does not guarantee causal control over generation,abstract,3,TopK SAE feature attribution (R1) and steering interventions (R2),2,2,0,5,0,"The claim distinguishes between correlational evidence (R1) and causal control (R2). The authors use both SAE feature identification (R1) and steering (R2) to demonstrate that the former does not imply the latter. The claim itself is a causal sufficiency claim ('guarantee causal control'), which is appropriate for the interventional methods used."
2512.05794,2512.05794-02,Ordered SAEs impose an hierarchical structure that reliably identifies steerable features,abstract,3,Ordered SAE steering (activation intervention),2,3,1,5,0,"The method used is steering (adding a vector to activations and measuring the change in output), which is a Rung 2 interventional method. The claim uses the functional/mechanistic verb 'identifies' and asserts that the method 'reliably' finds 'steerable features', implying a functional property of the internal components (Rung 3). According to the codebook, claiming a component 'is' a feature or 'performs' a role based on steering is a Rung 2 to Rung 3 overclaim (+1 gap)."
2512.05794,2512.05794-03,SAE latents collectively represent antibody information following sparsification,body,2,Linear probing (logistic regression) on SAE latents to predict CDR and gene identities.,1,3,2,5,0,"The method used is linear probing (Rung 1), which establishes correlation between activations and labels. The claim uses the term 'represent', which according to the codebook decision tree for polysemous terms, defaults to Rung 3 (mechanistic) unless the context explicitly limits it to 'linearly decodable'. While the paper shows high decodability, the phrasing 'collectively represent' in the results section frames it as a property of the model's internal state/mechanism rather than just a statistical association, creating a +2 gap."
2512.05794,2512.05794-04,top latents encoded contextual information of the preceding residues,body,2,Activation-threshold analysis and sequence alignment inspection,1,3,2,5,0,"The method used is purely observational (Rung 1): the authors correlate SAE latent activations with specific amino acid positions and residues (IMGT numbering) to see where they fire. However, the claim uses the term 'encoded' (Rung 3) to describe the relationship. According to the polysemous terms decision tree, 'encoded' is coded as R3 by default unless the context explicitly limits it to 'linearly decodable from'. Here, the context is a mechanistic narrative about how the model represents contextual information, making it a Rung 3 claim supported only by Rung 1 evidence."
2512.05794,2512.05794-05,Positively steering on latent 12 increased IGHJ4 proportion in model generation (Pearson R=0.939),body,2,Steering with Ordered SAEs,2,2,0,5,0,"The method used is steering (adding a decoder vector to activations), which is a classic Rung 2 intervention. The claim is strictly about the result of that intervention (increased proportion in generation) and uses causal language ('increased') without claiming to be the unique mechanism or using Rung 3 functional verbs like 'computes' or 'is the circuit'."
2601.03047,2601.03047-01,We successfully reproduce basic feature extraction and steering capabilities,abstract,3,Replication of SAE feature extraction (R1) and feature steering (R2),2,2,0,5,0,"The claim refers to the successful replication of both feature extraction (R1) and steering (R2). Following the codebook rule for multiple methods, the highest-rung method (steering/intervention) determines the method rung. The claim uses the term 'capabilities', which in this context refers to the causal effect of steering on model output, matching Rung 2."
2601.03047,2601.03047-02,feature steering exhibits substantial fragility with sensitivity to layer selection steering magnitude and context,abstract,3,Feature steering (activation clamping) and activation logging across multiple layers and contexts.,2,2,0,5,0,"The claim describes the behavior of the intervention itself (steering) rather than proposing a unique internal mechanism or counterfactual necessity. It characterizes the causal relationship between the intervention (steering magnitude/layer) and the output as 'fragile' and 'sensitive'. Since it describes the results of Rung 2 interventions (steering) without making a Rung 3 uniqueness or functional attribution claim, it is classified as Rung 2."
2601.03047,2601.03047-03,We observe non-standard activation behavior and demonstrate the difficulty to distinguish thematically similar features from one another,abstract,3,SAE feature attribution and activation analysis,1,1,0,5,0,"The claim describes observational findings regarding activation patterns and the lack of distinctness between features. The method used is activation logging/analysis (Rung 1), and the claim uses associational/observational language ('observe', 'demonstrate the difficulty to distinguish') which corresponds to Rung 1."
2601.03047,2601.03047-04,current methods often fall short of the systematic reliability required for safety-critical applications,abstract,3,SAE feature extraction and steering,2,2,0,5,0,"The paper uses interventional methods (feature steering/clamping) to test the reliability of SAE features. The claim is a causal sufficiency/reliability claim (Rung 2) stating that these interventions do not consistently produce the intended effects (falling short of systematic reliability). It does not make a uniqueness or counterfactual claim (Rung 3), but rather evaluates the robustness of the causal influence established by the methods."
2507.08802,2507.08802-01,any neural network can be mapped to any algorithm rendering this unrestricted notion of causal abstraction trivial and uninformative,abstract,3,Mathematical proof (Theorem 1) and empirical demonstration using non-linear alignment maps (RevNets) on randomly initialized models.,3,3,0,5,0,"The claim is a mechanistic/counterfactual assertion (R3) stating that any model can be 'mapped' to any algorithm (functional/mechanistic equivalence). The paper supports this with a Rung 3 method: a mathematical proof of existence (Theorem 1) and counterfactual interventions (DAS with non-linear maps) that achieve 100% interchange-intervention accuracy on random models, demonstrating that the 'mechanism' can be trivially constructed by the alignment map rather than the model."
2507.08802,2507.08802-02,it is possible to perfectly map models to algorithms even when these models are incapable of solving the actual task,abstract,3,Interchange intervention accuracy (IIA) using non-linear alignment maps (RevNets) on randomly initialized models.,2,3,1,5,0,"The method used is a form of activation patching/interchange intervention (Rung 2) applied to non-linear subspaces. The claim uses the phrase 'map models to algorithms', which according to the codebook's decision tree for 'algorithm' and 'mechanism' (Rung 3), constitutes a mechanistic/functional attribution claim. The paper specifically demonstrates that Rung 2 methods can be used to 'find' Rung 3 structures (algorithms) even where they don't exist, which is the core of their 'vacuousness' argument."
2507.08802,2507.08802-03,randomly initialised language models our alignment maps reach 100% interchange-intervention accuracy on the indirect object identification task,abstract,3,Interchange intervention (DAS) with non-linear alignment maps,2,2,0,5,0,"The claim describes the empirical result of an intervention (interchange-intervention accuracy) on a model. According to the codebook, methods like DAS and interchange interventions are Rung 2. The claim itself is a statement of the result of that intervention ('reach 100% accuracy') rather than a claim about the model's underlying mechanism or uniqueness (R3), thus it is classified as Rung 2."
2507.08802,2507.08802-04,causal abstraction is not enough for mechanistic interpretability as it becomes vacuous without assumptions about how models encode information,abstract,3,Theoretical proof (Theorem 1) and empirical demonstration using non-linear alignment maps (RevNets) on randomly initialized models.,2,3,1,5,0,"The method is interventional (Rung 2) because it utilizes Distributed Alignment Search (DAS) and interchange-intervention accuracy (IIA) to test causal sufficiency. The claim is classified as Rung 3 (Mechanistic) because it uses the term 'vacuous,' implying that the method fails to identify 'THE' unique or true mechanism/algorithm of the model. By asserting that the method is 'not enough' for mechanistic interpretability, the authors are making a meta-claim about the inability of Rung 2 methods to reach Rung 3 (functional/mechanistic attribution) without additional constraints."
2311.17030,2311.17030-01,even if a subspace intervention makes the model's output behave as if the value of a feature was changed this effect may be achieved by activating a dormant parallel pathway,abstract,3,Subspace activation patching (DAS) and causal tracing,2,3,1,5,1,"The method used is interventional (Rung 2), specifically subspace activation patching and DAS, which establish causal sufficiency. The claim uses mechanistic language ('activating a dormant parallel pathway') to describe the internal process of the model, which falls under Rung 3 (functional/mechanistic attribution). The author hedges the claim with 'may be', but the underlying claim remains a Rung 3 mechanistic narrative."
2311.17030,2311.17030-02,patching of subspaces can lead to an illusory sense of interpretability,abstract,3,Subspace activation patching (DAS) and causal tracing,2,3,1,5,1,"The claim uses the term 'interpretability' and 'illusory' to argue that a method (patching) can fail to identify the true underlying mechanism. According to the codebook, claims about the 'sense of interpretability' or the validity of a mechanistic narrative (the 'illusion' of finding a circuit) are Rung 3. The method used is activation patching, which is a Rung 2 interventional method. The paper specifically argues that R2 evidence is insufficient to support R3 mechanistic conclusions in certain cases."
2311.17030,2311.17030-03,we demonstrate this phenomenon in a distilled mathematical example in two real-world domains,body,1,Activation patching (DAS) and causal tracing,2,2,0,5,0,"The claim asserts the existence of a phenomenon (the 'interpretability illusion') across different domains. The phenomenon itself is defined by the divergence between causal effect and faithful representation. Since the paper uses interventional methods (Rung 2) to demonstrate that these interventions can produce misleading causal effects, and the claim is about the behavior of these interventions, it is a causal claim (R2) supported by interventional evidence (R2). The authors are claiming that the causal effect observed in these domains is 'illusory' because it doesn't match the underlying mechanism, but the demonstration of the effect itself is Rung 2."
2311.17030,2311.17030-04,there is an inconsistency between fact editing performance and fact localization,abstract,3,Causal tracing (activation patching) and ROME (rank-1 weight editing),2,3,1,5,0,"The claim asserts an 'inconsistency' between where a fact is 'localized' (a mechanistic/storage claim, R3) and where editing is 'effective' (a causal claim, R2). By adopting the terminology of 'localization' to describe the underlying phenomenon of where facts are stored/represented, the authors are making a Rung 3 claim about the model's internal organization. The methods used (ROME and Causal Tracing) are interventional (Rung 2), as they establish causal sufficiency for an output change but do not inherently prove unique storage or the complete mechanism."
2404.15255,2404.15255-01,activation patching is a popular mechanistic interpretability technique but has many subtleties,abstract,3,Literature review and methodological analysis,1,1,0,5,0,"The claim is a high-level descriptive statement about the status and complexity of a technique (activation patching) rather than an empirical finding about model internals. Within the codebook framework, it is associational/observational (R1) as it describes the usage and properties of a method in the field, and the claim itself makes no causal or mechanistic assertion about a specific model's behavior."
2404.15255,2404.15255-02,varying these hyperparameters could lead to disparate interpretability results,abstract,3,activation patching,2,2,0,5,1,"The claim discusses how varying hyperparameters (methodological choices in activation patching) leads to different results. Since activation patching is an interventional method (Rung 2) and the claim is about the causal sensitivity of the results to these interventions, it is classified as Rung 2. The word 'could' acts as an explicit hedge."
2309.16042,2309.16042-01,systematically examine the impact of methodological details in activation patching,abstract,3,Activation patching (causal tracing/interchange intervention),2,1,0,5,0,"The method used is activation patching, which is a Rung 2 interventional method. The specific claim quoted is a meta-claim about the paper's objective: to 'systematically examine the impact' of methodological choices. This is an associational/observational claim (Rung 1) about the relationship between hyperparameters and results, rather than a causal or mechanistic claim about the model's internal structure itself."
2309.16042,2309.16042-02,varying these hyperparameters could lead to disparate interpretability results,abstract,3,Activation patching (causal tracing/interchange intervention),2,1,0,5,1,"The method used is activation patching, which is a Rung 2 interventional method. The claim is associational (Rung 1) because it describes a relationship between hyperparameters and results ('could lead to disparate... results') without making a mechanistic or causal claim about the model's internal structure itself. The claim is about the sensitivity of the interpretability method, not a claim about how the model computes a function."
2512.06681,2512.06681-01,early layers (0-3) act as lexical sentiment detectors encoding stable position specific polarity signals,abstract,3,Activation patching,2,3,1,5,0,"The method used is activation patching (Rung 2), which is an interventional technique. The claim uses the functional/mechanistic verb 'act as' and 'encoding', and describes a specific role ('lexical sentiment detectors') for the components. According to the codebook, functional verbs and 'encoding' (when not explicitly defined as decodability) are classified as Rung 3 mechanistic claims. This creates a +1 gap (R2 method supporting R3 claim)."
2512.06681,2512.06681-02,contextual phenomena such as negation sarcasm domain shifts are integrated primarily in late layers (8-11),abstract,3,Activation patching,2,3,1,5,0,"The method used is activation patching, which is a Rung 2 interventional method. The claim uses the functional/mechanistic verb 'integrated' and specifies a localized functional attribution ('primarily in late layers'), which according to the codebook (functional attribution/mechanistic narrative) constitutes a Rung 3 claim. This creates a +1 gap (R2 to R3)."
2512.06681,2512.06681-03,GPT-2's sentiment computation differs from the predicted hierarchical pattern,abstract,3,Activation patching,2,3,1,5,0,"The method used is activation patching, which is a Rung 2 interventional method. The claim 'GPT-2's sentiment computation differs from...' is a Rung 3 claim because it uses the functional/mechanistic term 'computation' to describe the model's internal process and makes a statement about the underlying architecture of that process (the 'pattern'). This follows the codebook rule that functional verbs and mechanistic narratives (how the model computes) are Rung 3."
2511.05923,2511.05923-01,MHSAs of the last token in middle layers play a critical role in aggregating cross-modal information,abstract,3,Fine-grained Cross-modal Causal Tracing (FCCT),2,3,1,5,0,"The method used is a variant of activation patching (causal tracing), which is a Rung 2 interventional method. The claim uses the functional/mechanistic verb 'aggregating' and assigns a specific 'critical role' to a component, which constitutes a Rung 3 mechanistic narrative. This follows the R2 to R3 overclaiming pattern identified in the codebook for circuit-style discovery papers."
2511.05923,2511.05923-02,FFNs exhibit a three-stage hierarchical progression for the storage and transfer of visual object representations,abstract,3,Fine-grained Cross-modal Causal Tracing (FCCT),2,3,1,5,0,"The method used is a variant of activation patching (causal tracing) which establishes causal sufficiency (Rung 2). However, the claim uses mechanistic and functional language ('storage and transfer', 'hierarchical progression') to describe how the model represents information internally. According to the codebook decision tree for 'storage/encoding', this constitutes a Rung 3 claim because it describes the underlying mechanism rather than just the result of the intervention."
2511.05923,2511.05923-03,we propose Intermediate Representation Injection (IRI) that reinforces visual object information flow,abstract,3,Intermediate Representation Injection (IRI) / Activation Patching,2,3,1,5,0,"The method (IRI) is an interventional technique where internal activations are modified (injected) during inference to observe changes in model performance (hallucination mitigation), which is a Rung 2 method. The claim uses the functional/mechanistic verb 'reinforces' and describes the 'information flow', which implies a mechanistic understanding of how the model is processing data (Rung 3). This follows the overclaim pattern where interventional evidence is used to make a functional/mechanistic claim about the model's internal operations."
2601.05679,2601.05679-01,many contrastively selected candidates are highly sensitive to token-level interventions with 45-90% activating after injecting only a few associated tokens,abstract,3,Causal token injection (inserting feature-associated tokens into non-reasoning text and measuring activation),2,2,0,5,0,"The method is interventional (Rung 2) because it involves modifying the input (token injection) to observe the effect on internal activations. The claim is also Rung 2 because it describes the result of this intervention ('highly sensitive to... interventions', 'activating after injecting') without making a higher-level mechanistic claim about uniqueness or the 'true' underlying algorithm (Rung 3) in this specific sentence."
2601.05679,2601.05679-02,LLM-guided falsification produces targeted non-reasoning inputs that trigger activation,abstract,3,LLM-guided falsification (adversarial counterexample generation),2,2,0,5,0,"The method involves an intervention (constructing targeted inputs to observe model activation changes), which is Rung 2. The claim is a causal sufficiency claim ('inputs that trigger activation'), which matches Rung 2 linguistic markers ('can produce', 'intervening on X changes Y')."
2601.05679,2601.05679-03,sparse decompositions can favor low-dimensional correlates that co-occur with reasoning,abstract,3,Stylized theoretical analysis of SAE decoding (L1 and Top-K) and causal token injection experiments.,2,1,0,5,1,"The claim is associational (R1), stating that SAE features 'favor' (select for) 'correlates' (associations) that 'co-occur' (correlate) with reasoning. The method used to support this includes a theoretical proof of sparsity bias (Rung 2/3 logic) and causal token injection (Rung 2 intervention). Since the method rung (2) is higher than the claim rung (1), this is a well-supported, conservative claim."
2509.06608,2509.06608-01,the last-layer steering vector acts like a token-substitution bias concentrated on the first generated token,body,1,Logit-lens projection and causal prefixing (token-level intervention),2,3,1,5,0,"The method used is interventional (Rung 2): the authors use logit-lens (R1) to identify a direction, but then validate it by prefixing the token to the prompt and measuring the change in model performance (a causal intervention). However, the claim uses the functional/mechanistic verb 'acts like' and 'concentrated on', which describes the internal role or mechanism of the vector rather than just its causal effect. According to the codebook, functional attribution and mechanistic narratives ('acts like X') are classified as Rung 3."
2509.06608,2509.06608-02,the penultimate-layer vector operates through the MLP and unembedding preferentially up-weighting process words,body,1,"Ablation and component-level steering (Skip-Attn, Skip-Layer, Steer-Q/K/V-Proj)",2,3,1,5,0,"The method used is interventional (Rung 2), specifically patching and skipping submodules (MLP vs Attention) to measure causal sufficiency for the performance gain. However, the claim uses Rung 3 linguistic markers ('operates through', 'preferentially up-weighting') to describe a functional mechanism. According to the codebook decision tree for 'controls/is responsible for', since the paper does not prove this is the unique mechanism but describes it as a functional narrative of how the model 'operates', it is classified as Rung 3."
2509.06608,2509.06608-03,steering vectors transfer to other models,body,1,Cross-model steering vector transfer (activation engineering),2,2,0,5,0,"The method involves taking a steering vector (an intervention) trained on one model and applying it to another to observe the causal effect on performance. The claim 'transfer' describes the successful causal influence of the intervention across different models. According to the codebook, steering and interventions that observe output changes are Rung 2. The claim does not assert a unique mechanism or functional 'how' (R3), but rather the persistence of the causal effect (R2)."
2505.22637,2505.22637-01,all seven prompt types produce a net positive steering effect but exhibit high variance across samples,abstract,3,Contrastive Activation Addition (CAA) steering,2,2,0,5,0,"The method used is activation steering (CAA), which is an interventional method (Rung 2). The claim describes the result of this intervention ('produce a net positive steering effect') and its variance across samples. According to the codebook, claims about the results of an intervention (what changed) are classified as Rung 2."
2505.22637,2505.22637-02,higher cosine similarity between training set activation differences predicts more effective steering,abstract,3,Contrastive Activation Addition (CAA) and correlation analysis,2,1,0,5,0,"The method involves activation steering (R2 intervention) and statistical correlation between activation geometry and steering outcomes. The claim itself is purely associational ('predicts'), using Rung 1 linguistic markers to describe the relationship between a metric and an intervention's success. Since the claim rung (1) is lower than the method rung (2), this is a well-supported, conservative claim."
2505.22637,2505.22637-03,vector steering is unreliable when the target behavior is not represented by a coherent direction,abstract,3,Contrastive Activation Addition (CAA) steering and directional agreement analysis (cosine similarity/discriminability index).,2,3,1,5,0,"The method used is activation steering (Rung 2), which involves intervening on the model's activations to observe changes in output. The claim, however, is a mechanistic/functional attribution (Rung 3). It asserts that the 'target behavior' is (or is not) 'represented' by a 'coherent direction' (a mechanistic narrative about how the model internalizes concepts). According to the codebook, claims about how a model 'represents' a concept or the existence of a specific internal structure (like a coherent direction) are Rung 3, especially when the supporting evidence is interventional (R2) rather than a uniqueness proof (R3)."
2301.04709,2301.04709-01,Causal abstraction provides a theoretical foundation for mechanistic interpretability,abstract,3,"Theoretical unification and formalization of existing methods (activation patching, causal scrubbing, DAS, etc.)",2,3,1,5,0,"The paper is a theoretical work that unifies various Rung 2 (interventional) and Rung 3 (counterfactual/mechanistic) methods under a single formal framework. The claim that it provides a 'theoretical foundation' for 'mechanistic interpretability' is a Rung 3 claim because it asserts a functional/mechanistic identity between the theory and the field's goals. While the paper formalizes Rung 3 methods like causal scrubbing, the act of theoretical unification itself is classified as Rung 2 in this context because it demonstrates causal sufficiency of the framework to explain existing methods without proving it is the unique or only possible foundation."
2301.04709,2301.04709-02,generalizing the theory of causal abstraction from mechanism replacement to arbitrary mechanism transformation,abstract,3,Theoretical generalization of causal abstraction framework,3,3,0,5,0,"The claim is a theoretical contribution describing the generalization of a counterfactual framework (causal abstraction). As a theoretical paper providing a 'foundation' for Rung 3 mechanistic claims, the method itself (formal logic and causal modeling) operates at the highest rung of the ladder of causation by defining the conditions for counterfactual necessity and uniqueness."
2301.04709,2301.04709-03,unifying a variety of mechanistic interpretability methods in the common language of causal abstraction,abstract,3,"Theoretical unification and formalization of existing methods (activation/path patching, causal scrubbing, DAS, etc.)",2,3,1,4,0,"The paper is a theoretical framework paper. While it unifies methods from Rungs 1, 2, and 3, the core contribution is providing a 'theoretical foundation' for 'reverse engineering' (R3 language) and 'faithful simplifications' of mechanisms. The claim that these diverse methods can be unified into a single 'language' of causal abstraction is a Rung 3 claim because it asserts a functional/mechanistic equivalence across these tools to describe 'THE mechanism'. The evidence provided is theoretical mapping rather than counterfactual proof, leading to a gap."
2403.07809,2403.07809-01,pyvene supports customizable interventions on a range of different PyTorch modules,abstract,3,Software library implementation (pyvene),2,2,0,5,0,"The claim is about the functional capability of a software library to perform interventions. In the context of the codebook, interventions are Rung 2 methods. The claim 'supports customizable interventions' is a statement of causal capability (R2) rather than a mechanistic discovery (R3) or a purely observational correlation (R1). Since the paper introduces the tool that enables these R2 methods, the method and claim rungs are aligned."
2403.07809,2403.07809-02,pyvene provides a unified and extensible framework for performing interventions on neural models,abstract,3,Software library development (pyvene),2,2,0,5,0,The claim is about the utility and scope of a software framework designed for interventions. The method rung is 2 because the library's core functionality is activation patching and causal tracing (interventional). The claim rung is 2 because it describes the framework's capacity for 'performing interventions' (causal actions) without making a specific mechanistic claim about a model's internal algorithm (R3).
2403.07809,2403.07809-03,we illustrate the power of the library via interpretability analyses using causal abstraction and knowledge localization,abstract,3,Causal tracing (reproduction of ROME) and Distributed Alignment Search (DAS),2,3,1,5,0,"The method used is interventional (Rung 2), specifically causal tracing and DAS, which establish causal mediation. However, the claim uses the term 'knowledge localization' and 'causal abstraction' to describe the analysis. According to the codebook, localization/storage language ('localization') and mechanistic narratives ('causal abstraction') are classified as Rung 3 claims because they imply a specific underlying mechanism or functional mapping beyond simple causal sufficiency."
2601.03595,2601.03595-01,SAEs decompose strategy-entangled hidden states into a disentangled feature space,abstract,3,SAE feature attribution and steering,2,3,1,5,0,"The claim uses the mechanistic term 'decompose' and 'disentangled feature space' to describe the model's internal representation structure (R3). While the paper uses steering (R2) to validate these features, the claim itself is a mechanistic narrative about how the model represents information. The method rung is 2 because the paper uses interventional steering to identify and rank features, but does not perform the full counterfactual/uniqueness tests required for Rung 3."
2601.03595,2601.03595-02,SAE-Steering identifies strategy-specific features from the vast pool of SAE features,abstract,3,SAE-Steering (logit-based recall and interventional ranking),2,3,1,5,0,"The method used is interventional (Rung 2) because the final identification of features relies on 'control effectiveness' measured by steering the model and observing output changes. The claim uses the term 'identifies strategy-specific features', which according to the codebook's decision tree for 'encodes/represents/identifies', constitutes a Rung 3 mechanistic claim (functional attribution) because it asserts the discovery of the specific internal components responsible for a behavior without proving uniqueness or counterfactual necessity."
2601.03595,2601.03595-03,SAE-Steering outperforms existing methods by over 15% in control effectiveness,abstract,3,"Activation-based steering using SAE features compared against baselines (Logit Boosting, Think Intervention, Vector Steering) on AIME and GPQA datasets.",2,2,0,5,0,"The method used is activation-based steering, which is a Rung 2 interventional method. The claim is an empirical performance comparison regarding 'control effectiveness' (the ability to change model output via intervention), which is a Rung 2 claim. The claim does not use Rung 3 language like 'the unique mechanism' or 'represents', but rather focuses on the efficacy of the intervention itself."
2601.03595,2601.03595-04,controlling reasoning strategies can redirect LRMs from erroneous paths to correct ones,abstract,3,SAE-Steering (Intervention on SAE features) and Strategy Router evaluation,2,2,0,5,0,"The method used is activation-based steering (Rung 2), where the authors intervene on specific SAE features to modify model behavior. The claim uses the verb 'redirect', which is a causal/interventional term (Rung 2) describing the effect of the intervention on the model's output accuracy. It does not claim to be the unique or necessary mechanism (Rung 3), but rather demonstrates causal sufficiency for error correction."
2512.05534,2512.05534-01,neural networks represent meaningful concepts as directions in their representation spaces,abstract,3,Linear probing and activation logging (referenced as the basis for the Linear Representation Hypothesis),1,3,2,5,0,"The claim uses the functional/mechanistic verb 'represent' to describe how the model internally structures information. According to the polysemous terms decision tree for 'represent', since the paper is discussing the underlying mechanism (how it works) rather than just an interventional result, it is coded as R3. The methods cited as the basis for this (Park et al., 2024; Elhage et al., 2022) primarily rely on R1 observational evidence like linear probing and activation logging to establish the Linear Representation Hypothesis."
2512.05534,2512.05534-02,we develop the first unified theoretical framework considering SDL as one optimization problem,abstract,3,Theoretical framework development and optimization landscape analysis,3,3,0,5,0,"The claim is a high-level theoretical assertion about the nature of the model's internal optimization (Rung 3). The method used is a formal mathematical proof and theoretical framework that establishes global solutions and uniqueness/non-identifiability conditions, which corresponds to Rung 3 (Counterfactual/Mechanistic) as it aims to define the 'unified' underlying mechanism of SDL variants."
2512.05534,2512.05534-03,we provide novel theoretical explanations for empirically observed phenomena including feature absorption and dead neurons,abstract,3,Theoretical analysis of the SDL optimization landscape (piecewise biconvexity and spurious minima characterization),3,3,0,5,0,"The claim uses the term 'explanations' for internal model phenomena (feature absorption and dead neurons). According to the codebook, claims about 'how it works' or providing a 'mechanistic narrative' are Rung 3. The method used is a theoretical proof of the optimization landscape and uniqueness/existence of solutions (Theorems 3.7 and 3.10), which establishes the underlying mechanism of why these features form, placing the method at Rung 3."
2512.13568,2512.13568-01,neural networks achieve remarkable performance through superposition encoding multiple features as overlapping directions,abstract,3,Literature review / Theoretical framing,1,3,2,5,0,"The claim uses the functional/mechanistic verb 'encoding' and 'achieve performance through', which attributes the model's success to a specific internal mechanism (superposition). While the paper later uses SAEs (R1) and interventions (R2), this specific abstract claim is a high-level mechanistic assertion (R3) presented as an established fact in the field to motivate the study."
2512.13568,2512.13568-02,we present an information-theoretic framework measuring a neural representation's effective degrees of freedom,abstract,3,Shannon entropy applied to sparse autoencoder (SAE) activations,1,3,2,5,0,"The method is purely observational (Rung 1), as it calculates entropy based on activation logs from a frozen model without intervention. However, the claim uses Rung 3 linguistic markers ('measuring... effective degrees of freedom', 'represents') to describe the underlying mechanism of how the model organizes information. According to the codebook, describing what a representation 'is' or its 'effective' functional capacity without interventional evidence constitutes a Rung 3 claim."
2512.13568,2512.13568-03,our metric strongly correlates with ground truth in toy models,abstract,3,Correlation analysis between SAE-derived effective features and ground truth toy model interference patterns,1,1,0,5,0,"The method is purely associational (R1), comparing the metric's output to known ground truth in a toy model. The claim uses the linguistic marker 'correlates with', which is the canonical marker for a Rung 1 (Associational) claim."
2512.13568,2512.13568-04,adversarial training can increase effective features while improving robustness contradicting the hypothesis that superposition causes vulnerability,abstract,3,Shannon entropy applied to Sparse Autoencoder (SAE) activations across models trained with PGD adversarial training.,2,3,1,5,0,"The method is interventional (Rung 2) because it compares models trained under different causal conditions (adversarial training vs. clean training) and measures the resulting internal changes. The claim is Rung 3 because it uses the functional/mechanistic term 'effective features' to describe the model's internal organization and directly challenges a mechanistic hypothesis ('superposition causes vulnerability'). According to the codebook, claims about what a model 'represents' or its 'effective features' are R3, creating a +1 gap."
2511.09432,2511.09432-01,incorporating group symmetries into the SAEs yields features more useful in downstream tasks,abstract,3,Interchange intervention (probing over SAE reconstructions),2,2,0,5,0,"The claim states that the features are 'more useful in downstream tasks'. The paper supports this by training probes (XGBoost, etc.) on the SAE reconstructions and measuring performance (F1 score) on binary classification tasks. According to the codebook, claims about 'usefulness' or 'performance' in downstream tasks supported by interventions (like replacing activations with SAE reconstructions to see if task information is preserved) are Rung 2. The claim is causal in the sense that the method (incorporating symmetries) produces a result (better features for tasks), which is a claim of causal sufficiency for task performance."
2511.09432,2511.09432-02,a single matrix can explain how their activations transform as the images are rotated,abstract,3,Activation logging and linear regression (optimizing matrix M to fit activation transformations),1,3,2,5,0,"The method is Rung 1 (observational) because it involves recording activations and finding a linear correlation (matrix M) that explains the variance between transformed inputs, without intervening on the model's computation to test the effect. The claim is Rung 3 because it uses the functional/mechanistic verb 'explain' to describe how the model's internal representations transform, implying a structural understanding of the model's internal logic."
2511.09432,2511.09432-03,adaptive SAEs discover features that lead to superior probing performance compared to regular SAEs,abstract,3,Linear probing on SAE latents and reconstructions,1,1,0,5,0,"The claim is about 'probing performance', which is a standard Rung 1 (associational) metric. The method used is training classifiers (XGBoost, logistic regression) on frozen SAE features to predict external labels, which is the definition of linear/non-linear probing (Rung 1). The claim does not assert causal necessity or a specific internal mechanism beyond the ability to decode information."
2505.24859,2505.24859-01,steering effectively controls the targeted summary properties,abstract,3,Contrastive Activation Addition (CAA) steering vectors,2,3,1,5,0,"The method used is activation steering (CAA), which is a Rung 2 interventional method (adding a vector to activations to observe output changes). The claim uses the functional verb 'controls' to describe the relationship between the internal component (the vector) and the model's behavior. According to the polysemous terms decision tree in the codebook, 'controls' is classified as Rung 3 (Mechanistic) unless the paper explicitly qualifies it as non-unique causal sufficiency. Since the abstract states 'steering effectively controls' as a general functional property of the model's internals, it is coded as Rung 3, creating a +1 gap."
2505.24859,2505.24859-02,high steering strengths consistently degrade both intrinsic and extrinsic text quality,abstract,3,Contrastive Activation Addition (CAA) steering with varying strengths (),2,2,0,5,0,"The method used is activation steering (CAA), which is a Rung 2 interventional method involving the addition of a bias vector to activations to observe changes in output. The claim is that high steering strengths 'degrade' text quality. According to the codebook, claims about how interventions change or influence output (e.g., 'ablating X degrades Y') are Rung 2 causal claims. The claim is well-calibrated to the method used."
2505.24859,2505.24859-03,combining steering and prompting yields the strongest control over text properties,abstract,3,Contrastive Activation Addition (CAA) combined with prompt engineering,2,2,0,5,0,"The method used is interventional (Rung 2), as it involves adding steering vectors to activations and modifying input prompts to observe changes in model output. The claim uses the term 'control', which in this context refers to causal sufficiency (the ability to produce a desired change in behavior) rather than a claim about the model's unique internal mechanism or counterfactual necessity. Therefore, the claim rung matches the method rung."
2508.11214,2508.11214-01,the language of causality and specifically the theory of causal abstraction provides a fruitful lens on computational implementation,abstract,3,Theoretical framework (Causal Abstraction),3,3,0,5,0,"The claim is a high-level theoretical assertion about the nature of computational implementation. The paper uses the 'Causal Abstraction' framework, which is defined in the codebook as a Rung 3 method (Counterfactual/Mechanistic) because it aims to establish the unique/necessary structure of a mechanism. The claim itself uses mechanistic language ('underpins', 'implementation') to describe how one system realizes the algorithm of another, which aligns with Rung 3's focus on functional attribution and mechanistic narratives."
2508.11214,2508.11214-02,we offer an account of computational implementation grounded in causal abstraction,abstract,3,Causal abstraction (theoretical framework),2,3,1,5,0,"The paper is a theoretical work proposing that 'computational implementation' (a Rung 3 mechanistic concept) is grounded in 'causal abstraction' (a Rung 2 interventional framework). While the method describedcausal abstractionrelies on interventional evidence (Rung 2), the claim is about the fundamental nature of how a system 'implements' or 'computes' (Rung 3). This follows the pattern of using interventional logic to make a mechanistic/functional identity claim."
2411.08745,2411.08745-01,the output language is encoded in the latent at an earlier layer than the concept to be translated,abstract,3,Activation patching (exploratory analysis across layers),2,3,1,5,0,"The method used is activation patching, which is a Rung 2 interventional method. The claim uses the term 'encoded', which according to the codebook decision tree for polysemous terms, defaults to Rung 3 (mechanistic) unless the context specifies a decodability/probing sense. Here, the authors use the intervention to build a mechanistic narrative about the sequential processing order of the model's internal computations ('first resolving output language, then the concept'), which is a Rung 3 claim."
2411.08745,2411.08745-02,we can change the concept without changing the language and vice versa through activation patching alone,abstract,3,Activation patching,2,3,1,5,0,"The method used is activation patching, which is a Rung 2 interventional method. The claim states that they can 'change the concept without changing the language', which is a functional/mechanistic claim (Rung 3) about the independent control and representation of these features. According to the codebook decision tree for 'controls' or 'is responsible for' (and by extension, 'change X without Y'), claiming that components can be manipulated independently to perform specific functions without establishing uniqueness or counterfactual necessity is an overclaim of +1."
2411.08745,2411.08745-03,patching with the mean representation of a concept across different languages improves translation,abstract,3,Activation patching with mean representations across multiple source languages,2,2,0,5,0,"The method uses activation patching, which is a Rung 2 interventional method. The claim states that this intervention 'improves' performance, which is a causal sufficiency claim (Rung 2) rather than a claim about a unique mechanism or functional attribution (Rung 3). The claim and method are well-aligned."
2411.08745,2411.08745-04,results provide evidence for the existence of language-agnostic concept representations,abstract,3,Activation patching (specifically patching mean representations across languages),2,3,1,5,0,"The method uses activation patching (Rung 2) to show that intervening on internal states affects the output. The claim uses the term 'existence of language-agnostic concept representations', which is a Rung 3 mechanistic claim. According to the codebook decision tree for 'represents/representations', if the evidence is interventional but the claim describes the underlying mechanism (how the model stores/organizes information) rather than just the result of the intervention, it is coded as R3. The paper specifically frames this as a 'reverse-engineering' of the internal conceptual space."
2507.20936,2507.20936-01,early MLP layers attend not only to the syntactic structure but also process its semantic content,abstract,3,Activation patching (de-noising variant) and direct effect measurement,2,3,1,5,0,"The method used is activation patching (Rung 2), which establishes causal mediation. However, the claim uses the functional/mechanistic verb 'process' and makes a definitive statement about what the layers 'do' (functional attribution), which corresponds to Rung 3. The paper specifically argues against the 'syntactic only' view by asserting a semantic processing role, which is a mechanistic narrative."
2507.20936,2507.20936-02,these layers transform persona tokens into richer representations which are then used by middle MHA layers,abstract,3,Activation patching (Resample Ablation),2,3,1,5,0,"The method used is activation patching (Rung 2), which establishes causal mediation. However, the claim uses mechanistic/functional language ('transform', 'used by') to describe a specific internal process and narrative of how information flows between components. According to the codebook, functional verbs and mechanistic narratives describing how the model performs a task constitute Rung 3 claims. This follows the 'Patching -> THE circuit/mechanism' overclaim pattern identified in the calibration anchors (e.g., IOI paper)."
2507.20936,2507.20936-03,we identify specific attention heads that disproportionately attend to racial and color-based identities,abstract,3,Attention visualization (value-weighted attention patterns),1,1,0,5,0,"The claim describes attention heads that 'attend to' specific tokens. According to the codebook, attention visualization is a Rung 1 method (observational). The linguistic marker 'attend to' is equivalent to 'concentrates on' or 'activates on', which are Rung 1 markers for associational/observational evidence. There is no causal or mechanistic overclaiming in this specific sentence."
2504.02976,2504.02976-01,patching the first feedforward layer recovered 56% of correct preference demonstrating that associative knowledge is distributed,abstract,3,Activation patching,2,3,1,5,0,"The method used is activation patching, which is a Rung 2 interventional method. The claim uses the patching results to conclude that 'associative knowledge is distributed'. According to the codebook, claims about how knowledge is 'distributed' or 'represented' (mechanistic narrative) are classified as Rung 3. This follows the R2 -> R3 overclaim pattern where causal sufficiency from patching is used to make a definitive claim about the underlying architectural representation of knowledge."
2504.02976,2504.02976-02,patching the final output layer completely restored accuracy indicating that definitional knowledge is localised,abstract,3,Activation patching,2,3,1,5,0,"The method used is activation patching (specifically patching the final output layer), which is a Rung 2 interventional method. The claim uses the term 'localised' to describe how 'definitional knowledge' is stored/represented based on that intervention. According to the codebook decision tree for 'localised' and 'knowledge representation', claims that move from causal sufficiency (restoring accuracy) to a statement about the underlying mechanism or storage of knowledge are classified as Rung 3. This follows the ROME calibration example where localization claims are treated as Rung 3 mechanistic interpretations of Rung 2 causal evidence."
2504.02976,2504.02976-03,factual knowledge is more localized and associative knowledge depends on distributed representations,abstract,3,Activation patching (CLAP),2,3,1,5,0,"The method used is activation patching (CLAP), which is a Rung 2 interventional method that establishes causal sufficiency for specific layers. The claim, however, uses mechanistic language ('knowledge... is localized', 'depends on distributed representations') to describe how the model stores or organizes information. According to the codebook, claims about where knowledge is 'stored' or 'localized' are Rung 3 mechanistic claims. This represents a +1 overclaim (R2 to R3), similar to the ROME calibration case."
2502.03714,2502.03714-01,USAEs jointly learn a universal concept space that can reconstruct and interpret the internal activations of multiple models,abstract,3,Universal Sparse Autoencoder (USAE) training and reconstruction analysis,1,3,2,5,0,"The method used is a variant of Sparse Autoencoders (SAEs) applied to frozen activations across multiple models. According to the codebook, SAE feature attribution and activation logging are Rung 1 (Observational/Associational) because they identify what features activate without intervening on the model's computation. The claim uses the term 'interpret' and 'universal concept space' to describe the internal activations, which falls under Rung 3 (Mechanistic) as it provides a functional/mechanistic narrative of how the model represents information. The gap between the observational evidence (reconstruction) and the mechanistic claim (interpreting the space) represents a +2 overclaim."
2502.03714,2502.03714-02,the learned dictionary captures common factors of variation concepts across different tasks architectures and datasets,abstract,3,Universal Sparse Autoencoder (USAE) training and activation reconstruction analysis,1,3,2,5,0,"The method used is a variant of Sparse Autoencoders (SAE) applied to frozen activations across models. While the paper uses reconstruction error (R2) to validate the dictionary, this remains an associational/observational method (Rung 1) as it identifies features that can reconstruct activations without intervening on the model's computation to prove causal necessity. The claim uses the term 'captures common factors of variationconcepts', which according to the codebook's decision tree for 'concepts' and 'factors of variation' in a mechanistic context, implies a Rung 3 functional/mechanistic claim about what the model internals represent."
2502.03714,2502.03714-03,USAEs discover semantically coherent and important universal concepts across vision models,abstract,3,Universal Sparse Autoencoders (SAE feature attribution and activation logging),1,3,2,5,0,"The method used is a variant of Sparse Autoencoders (USAEs) which, according to the codebook, is a Rung 1 (Observational) method because it identifies which features activate without intervening on the model's internal computations to change behavior. The claim uses the verb 'discover' and 'universal concepts', which falls under the Rung 3 category of functional/mechanistic attribution (representing/encoding). Specifically, the codebook identifies 'SAE -> represents' or 'SAE -> concepts' as a +2 overclaim (R1 to R3)."
2509.18127,2509.18127-01,SAEs facilitate interpretability research to clarify model behavior by explaining single-meaning atomic features,abstract,3,Sparse Autoencoders (SAE) with TopKReLU and automated explanation generation,1,3,2,5,0,"The method used is SAE feature attribution and automated explanation (Rung 1), which identifies features that activate on specific inputs but does not involve causal interventions or counterfactual proofs. The claim uses Rung 3 linguistic markers ('explaining', 'atomic features', 'clarify model behavior'), which implies a functional and mechanistic understanding of the model's internal components (functional attribution)."
2509.18127,2509.18127-02,Safe-SAIL systematically identifies SAE with best concept-specific interpretability,abstract,3,"Concept Contrastive Query Pairs (L0,t and ICDF metrics)",1,3,2,5,0,"The method used to identify the 'best' SAE is based on observational metrics (L0,t and ICDF) that measure the frequency of feature activation on specific concept-related queries compared to de-concept queries. This is a correlational/associational method (Rung 1). The claim uses the functional/mechanistic term 'interpretability' and the definitive 'identifies... best', which in the context of the paper's narrative about 'uncovering underlying mechanisms' and 'reverse-engineering' (as noted in the calibration anchors for Rung 3), constitutes a mechanistic claim about the model's internal representation quality."
2509.18127,2509.18127-03,we extract a rich and diverse set of safety-relevant features that effectively capture high-risk behaviors,abstract,3,SAE feature attribution and automated interpretation,1,3,2,5,0,"The method used is Sparse Autoencoder (SAE) feature extraction and automated labeling (Rung 1), which identifies features that activate on specific safety-related inputs. The claim uses the functional verb 'capture' and asserts that these features 'effectively capture high-risk behaviors,' which implies a mechanistic representation or functional role (Rung 3) rather than simple correlation. This creates a +2 gap between the observational evidence and the mechanistic claim."
2601.02989,2601.02989-01,latent counts are computed and stored in the final item representations of each part,abstract,3,CountScope (causal probing) and zero ablation of final item/comma tokens,2,3,1,5,0,"The claim uses the terms 'computed' and 'stored', which are explicit Rung 3 mechanistic markers according to the codebook. The evidence provided for this specific claim comes from CountScope (a causal probing method) and zero ablation (interventional). While these methods establish causal mediation (Rung 2), the claim that information is 'stored' in a specific representation is a mechanistic narrative that exceeds the interventional evidence."
2601.02989,2601.02989-02,counts are transferred to intermediate steps via dedicated attention heads,abstract,3,Attention knockout and attention visualization,2,3,1,5,0,"The claim uses functional/mechanistic language ('transferred via') and identifies 'dedicated' components, which implies a specific mechanistic role (Rung 3). The evidence provided in the paper for this specific claim comes from attention knockout (Rung 2 interventional) and attention visualization (Rung 1 observational). Since the method involves interventions (knockout) but the claim describes the underlying functional mechanism of the model, it is a Rung 2 to Rung 3 overclaim."
2601.02989,2601.02989-03,this strategy enables LLMs to surpass architectural limitations and achieve high accuracy on large-scale counting,abstract,3,"Observational and causal mediation analysis (attention analysis, activation patching, zero ablation)",2,2,0,5,0,"The claim states that the strategy 'enables' the model to achieve a specific performance outcome. According to the codebook, 'enables' is a Rung 2 linguistic marker indicating causal sufficiency. The methods used to support this include activation patching and zero ablation, which are standard Rung 2 interventional methods that establish causal effects. Therefore, the claim rung matches the method rung."
2512.18092,2512.18092-01,neuron identification can be viewed as the inverse process of machine learning,abstract,3,Theoretical analogy and statistical learning theory (generalization bounds),1,3,2,5,0,"The claim is a high-level mechanistic/functional assertion that defines the nature of the process ('is the inverse process'). According to the codebook, functional attribution and 'is' statements regarding the underlying mechanism are Rung 3. The method used to support this specific claim is a theoretical analogy and the derivation of generalization bounds based on observational data (probing datasets), which does not involve causal interventions on the model, placing the method at Rung 1."
2512.18092,2512.18092-02,we derive generalization bounds for widely used similarity metrics to guarantee faithfulness,abstract,3,Statistical learning theory (generalization bounds),1,3,2,5,0,"The method used is purely theoretical/observational (Rung 1) as it derives bounds based on statistical associations between neurons and concepts without model intervention. However, the claim uses the term 'faithfulness' and 'guarantee' to describe the neuron's underlying function. According to the codebook, claims about a neuron's 'underlying function' or what it 'represents' are Rung 3 mechanistic claims. This creates a +2 gap (R1 to R3)."
2512.18092,2512.18092-03,we propose a bootstrap ensemble procedure that quantifies stability along with guaranteed coverage probability,abstract,3,Bootstrap ensemble procedure (statistical resampling),1,2,1,4,0,"The method used is a bootstrap ensemble which is an observational/statistical resampling technique (Rung 1) as it does not involve active intervention or weight/activation manipulation of the model itself to establish causality. The claim 'quantifies stability' and provides 'guaranteed coverage probability' is a causal/interventional claim (Rung 2) because it asserts that the method can reliably bound or influence the certainty of the explanation's stability, moving beyond simple correlation to a claim of statistical sufficiency/guarantee."
2505.14685,2505.14685-04,reverse-engineering ToM reasoning in LMs,abstract,3,Causal mediation analysis and causal abstraction (interchange interventions on residual vectors and subspaces),2,3,1,5,0,"The paper uses activation patching (interchange interventions) to identify causal mediators, which is a Rung 2 method. The claim 'reverse-engineering' is a Rung 3 linguistic marker as defined in the codebook, as it implies a complete mechanistic understanding of the internal algorithm. This creates a +1 gap (R2 to R3)."
2510.01070,2510.01070-01,Our white-box techniques based on logit lens and sparse autoencoders also consistently increase the success rate of the LLM auditor,abstract,3,Logit lens and Sparse Autoencoders (SAEs),1,2,1,5,0,"The method used (logit lens and SAE feature attribution) is classified as Rung 1 (Observational/Associational) because it involves recording and projecting internal activations without intervening on the model's computation. The claim is classified as Rung 2 (Interventional) because it asserts that these techniques 'increase the success rate' of an auditor. In the context of the paper's 'auditing game,' this is a causal claim about the utility of the information provided to the auditor (i.e., providing X causes an increase in Y). This creates a +1 gap (R1 method supporting an R2 claim)."
