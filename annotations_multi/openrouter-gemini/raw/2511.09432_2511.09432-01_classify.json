{
  "timestamp": "2026-02-19T09:36:19.452522+00:00",
  "paper_id": "2511.09432",
  "claim_id": "2511.09432-01",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2511.09432\nTitle: Group Equivariance Meets MI: Equivariant SAEs\nFull text:\n               Group Equivariance Meets Mechanistic\n               Interpretability: Equivariant Sparse Autoencoders\n\n\n\n\n                                              Ege Erdogan, Ana Lucic\n                                                           University of Amsterdam\n                                           {e.erdogan, a.lucic}@uva.nl\n\n\n                                                 Abstract2025\n\n                               Sparse autoencoders (SAEs) have proven useful in disentangling the opaque activa-\n                                   tions of neural networks, primarily large language models, into sets of interpretableNov                            features. However, adapting them to domains beyond language, such as scientific\n                                data with group symmetries, introduces challenges that can hinder their effective-\n                                 ness. We show that incorporating such group symmetries into the SAEs yields12\n                                  features more useful in downstream tasks. More specifically, we train autoencoders\n                           on synthetic images and find that a single matrix can explain how their activations\n                               transform as the images are rotated. Building on this, we develop adaptively equiv-\n                                 ariant SAEs that can adapt to the base model’s level of equivariance. These adaptive\n                       SAEs discover features that lead to superior probing performance compared to\n                                  regular SAEs, demonstrating the value of incorporating symmetries in mechanistic[cs.LG]                             interpretability tools.\n\n                            https://github.com/ege-erdogan/equivariant-sae\n\n\n                1  Introduction\n\n             ML models are increasingly used for scientific problems, from higher-level data analysis and hypothe-\n                            sis generation [1, 2] to lower-level emulation of physical processes such as protein folding [3]. Being\n                        able to interpret the internals of these models would not only ensure they are scientifically reliable and\n                         controllable, but potentially lead to novel scientific discoveries. Scientific data is often characterized\n                   by underlying symmetries: transformations such as rotations or translations that alter particular\n                          attributes in particular ways, and accounting for those symmetries can lead to more data-efficient\n                    models [4]. While mechanistic interpretability methods, in particular sparse autoencoder (SAEs),\n                     have been applied to scientific ML models in domains such as proteins [5, 6, 7, 8] and cell images\n                           [9, 10], there has been no work on how input symmetries can aid mechanistic interpretability. In this\n                        paper, we present early results suggesting that building SAEs that automatically adapt to symmetriesarXiv:2511.09432v1                  in the data can greatly improve their performance in downstream tasks.\n\n             A set of symmetries such as rotations can be modeled as a group G. Groups act on sets such as\n                     images; e.g. with g ∈G, gx can denote the rotated version of an image x. Transformations of the\n                   same element x form an orbit {gx : g ∈G}. We can then split the features of x into those that are\n                      invariant with respect to G and those that are equivariant. For example, the types of atoms in a\n                     molecule would be features invariant under 3D rotations, but the force vectors acting on each atom\n                    would be equivariant features, rotating along with the molecule. More generally, we define invariant\n                        features as those shared across an orbit: the set of possible options that x can be transformed into,\n                      while equivariant features depend on the particular transformation applied to x. We provide a more\n                         detailed background on SAEs and groups in Appendix B.\n\n                    There are two main challenges when training SAEs on data with group symmetries.  First, the\n                       optimally sparse solution learns one latent per transformation for each equivariant feature, requiring\n\n\n                        39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Mechanistic Inter-\n                             pretability Workshop.\n\nFigure 1:  Left: We train an invariant SAE that maps activations of the transformed inputs to\nthe same latents, and optimize the matrix M to estimate how the activations transform, achieving\nequivariance. Right: Transforming the decoder dictionary D 7→MD allows us to observe which\nfeatures discovered by the SAE are invariant or equivariant with respect to input transformations.\nWe provide a more detailed figure of the mathematical operations involved in Figure 5 in the\nAppendix.\n\n\nO(|G|) latents per semantic feature, which is undesirable for larger groups. Second, we do not know\na priori the degree of equivariance in base model activations, making it difficult to enforce exact\nsymmetries in advance. In this work, we demonstrate that addressing these challenges can lead to\nimproved performance in downstream applications. More specifically:\n\n• We show that a single matrix M acting on the activations explains more than 98% of the\n  variance in the transformed activations for MLP and CNN-based autoencoders trained on a\n  synthetic image dataset transformed under the group of 90◦rotations.\n\n• We design adaptively equivariant SAEs consisting of an invariant autoencoder (avoiding the\n   pitfall of exploding number of latents) which is made equivariant with the addition of M (avoiding\n  the pitfall of unnecessarily-exact equivariance). This allows us adapt to what the model has learned\n  rather than prematurely enforcing exact symmetries.\n\n• We demonstrate our adaptively equivariant SAEs learn more useful features that outper-\n  form regular SAEs in a set of binary probing tasks, despite lagging behind in the reconstruc-\n  tion/sparsity frontier.\n\n\n2  Related work\n\nOur work is one of the first to bridge ideas from the sparse dictionary learning literature and\nthe equivariant representation learning literature with a particular application towards mechanistic\ninterpretability. Learning approximate equivariance via objectives similar to our SAE training\nobjective has been proposed in [11, 12], and our general approach of learning an invariant encoder\nand a separate mapping from the canonical outputs to their original forms follows that of [13]. Our\nmain difference is that we adapt these approaches to the space of neural network activations, where\nthe symmetries are induced by the input transformations and are not well-defined.\n\nAnother line of related work concerns learning symmetries and group representations from data\ndirectly [14, 15]. Most similar to our approach of learning the transformation matrix M, [15] proposes\nthe MatrixNet architecture to learn matrix representation of group elements while staying faithful to\nthe group axioms. Although it solves a similar problem, such an approach is not directly practical\nover neural network activations with dimensions on the order of 103. Processing the resulting matrix\nrepresentation (O(106) parameters) with a neural network would lead to an explosion in the total\nnumber of parameters. That is why we instead opt for optimizing M directly.\n\nTo potentially avoid this explosion of the number of parameters, [14] propose an adversarial training\nmethod to learn potentially nonlinear symmetries by first mapping the observations to a latent space\nusing an autoencoder and learning a linear group action in that latent space. While technically\napplicable to neural network activations, modeling the group action over a latent space further\nremoved from the already difficult-to-interpret neural network activations could make interpretability,\nwhich is our main goal, more challenging.\n\n\n                                       2\n\nGroup-equivariant sparse dictionary learning methods have also been proposed [16, 17] although\nsuch exact symmetries cannot be enforced over neural network activations as we do not know to what\ndegree they are equivariant. Finally, [18] proposes group crosscoders to analyze how the features\nlearned by a neural network change as its inputs are transformed, constructing each dictionary vector\nwith G blocks each the size of the inputs. The size of the dictionary thus scales linearly with |G|\nunlike our approach where the number of parameters is constant with respect to |G|.\n\n3  Method: SAEs with adaptive equivariance\n\nWe consider groups G where all transformations can be obtained as powers of a generator g ∈G, i.e.\nG = {gp}|G|p=1. Our design consists of a group-invariant TopK SAE [19, 20] with a two-layer encoder\nE and linear decoder D, and a matrix M that learns to fit how the base model’s activations transform\nas its inputs are transformed with the action of group G. Thus, with canonical (one representative per\norbit) inputs x ∈X ⊂Rn and model activations ψ(x) ∈Rd, for p = 1, ..., |G|,\n\n        D (E (ψ(gpx))) = ψ(x),  and MpD (E (ψ(gpx))) = ψ(gpx).              (1)\n\nFirst, the SAE reconstructs all activations ψ(gpx) of the transformed inputs as the canonical activation\nψ(x). Then this reconstruction is transformed with M to obtain Mpψ(x) = ψ(gpx).\n\nInvariant SAE. We make our SAE invariant to group transformations of the base model’s inputs by\ntraining it with the following invariance loss:\n                        Linv := Ex∈X,p=1,...,|G| ∥ψ(x) −D (E (ψ(gpx)))∥22                     (2)\n\nAfter observing that a linear encoder may fail to learn to be invariant, we construct our encoder as a\ntwo-layer MLP with a ReLU hidden layer, but keep the decoder to one layer. Therefore, while the\nencoder is expressive enough to learn to be invariant, the canonical activations are still reconstructed\nas sparse linear combinations of the dictionary vectors. This approach is further motivated by previous\nwork showing that more expressive encoders can lead to more interpretable SAEs [21].\n\nActivation transformation matrix M. To map the canonical reconstructions back to their original\nforms, we need to adapt to the symmetries of the model activations and learn how they transform\nas the inputs to the model are transformed. While closed-form solutions might be possible for\ncertain cases, they are not practical for arbitrary neural networks. Since many group actions we care\nabout, including rotations, can be represented as linear transformations, we hypothesize that a linear\ntransformation should be able to explain to the transformation in the model’s activations. Thus, we\noptimize M ∈Rd×d to minimize\n              LM := Ex∈X,p=1,...,|G| ∥ψ(gpx) −Mpψ(x)∥22 .                       (3)\n\nWe initialize M as the identity matrix so that it fits perfectly right away if the model has learned\ninvariant representations, and we optimize it using the Adam optimizer [22].\n\n4  Experiments\n\nDataset and models. We create a synthetic image dataset\nwhere each image contains four shapes. There are 8 possi-\nble shapes, each can be in one of four positions (see Figure\n2). Applying 90◦rotations to the images yields either two\nor four possible orientations for each shape. We train MLP\nand CNN-based autoencoders as base models where the                                                      Figure 2: Sample images from our\ntask is to compress and reconstruct the image (see Ap-                                                         dataset. Each image contains one of\npendix C for training details). Our task is to interpret these\n                                                           eight possible shapes in each of its four\nautoencoders.\n                                                          quadrants.\nProbing Tasks. We define 180 binary probing tasks to\nevaluate the downstream usefulness of the features discov-\nered by SAEs (see Appendix C). The tasks are split into four subsets, based on if a shape is in an\nimage (S), and in a specific position (SP), in a specific orientation (SO), and in both a position and an\norientation (SPO). Note that only the S tasks are invariant to rotations. It is desirable that a small\n\n\n                                       3\n\nnumber of latents encode the concepts used to separate the images in the binary probing task. Thus\nwe first identify a small set of latents that maximally differ between the two classes by filtering the\nSAE latents with the highest absolute difference between the two classes [23]. Then for each task,\nwe train three different probes over the truncated latents as well as the activations, and report results\nfrom the best performing probe averaged across all tasks. The probing methods are kNN, logistic\nregression, and XGBoost, with the XGBoost performing the best overall.\n\nTraining. Training of our equivariant SAE consists of two independent steps that can be done in any\norder or in parallel. In the first step, the encoder and decoder weights are updated to minimize Linv\n(Equation 2), and in the second step, the matrix M is updated to minimize LM (Equation 3). Thus\nthe SAE parameters and M are trained using different objectives, and the training of one does not\naffect the training of the other. They can also be trained over different datasets, although we use the\nsame dataset for both in our experiments.\n\nSAE setup and baselines. We train all SAEs in our experiments over the 256-dimensional middle-\nlayer activations of the base models, and compare our equivariant SAE with two regular TopK SAEs\n(linear encoder and decoder). The equivariant SAE and the first regular SAE both have an expansion\nfactor of 8, resulting in 2,048 latents. The second regular SAE has |G| times the number of latents,\ncorresponding to learning separate latents for each orientation of equivariant features for a total of\n8,192. The regular SAEs are trained by augmenting the dataset with 90◦rotations.\n\n5  Results\n\nRESULT 1: M can be learned effectively, indicating that activation-space transformation can\nbe explained by a linear transformation. Over the middle layer activations of both of our base\nautoencoders, we optimize M for 150 epochs and observe that it can be learned with an average (±\nstd) R2 of 0.987±0.001 between the ground truth and predicted activations across all transformations.\nAs a naive baseline, setting M = I results in average R2 values 0.05 ± 0.08 and 0.49 ± 0.03 for the\nCNN and MLP autoencoders, respectively.\n\nRESULT 2: Equivariant SAEs learn more informative directions in activation space, leading\nto increased performance on group-structured probing tasks.. Figure 3 shows the classification\nperformance on the 180 tasks of the XGBoost probes with the CNN autoencoder for truncation length\n32 and TopK values 8, 16, and 32 (see Appendix D for results with different truncation lengths and\nthe MLP autoencoder). The main outcomes are:\n\n• When probing over the SAE latent activations, the equivariant SAE performs the best, even\n  matching and exceeding the performance of the base model activations in some setups on the S\n  group of tasks. Its performance expectedly drops for the equivariant tasks since its latent activations\n  are learned to be invariant. The regular SAE with the two-layer encoder outperforms the SAEs with\n  one-layer encoders, especially with higher K. This indicates that it can adapt its latent activations\n  to the symmetries of the data, although at lower sparsity levels.\n\n• Across all tasks and setups, the equivariant SAE outperforms regular and wide SAEs when probes\n  are trained over the truncated reconstructions, and is matched by the two-layer encoder SAE only\n  at low sparsity (K = 32).\n\nRESULT 3: Equivariant SAEs lag behind in the reconstruction/sparsity frontier. Figure 4 displays\nsparsity (L1) and the reconstruction (loss when SAE is spliced into the base AE) performance of the\nSAEs in our experiments. While for small K values the equivariant SAE matches the wide SAE’s\nreconstruction performance, regular SAEs generally have sparser latents. The invariance objective\nalso tends to make the models less sensitive to the choice of K, as can be seen from the smaller range\nof sparsity (L1) values the equivariant SAE results in compared to a regular SAE with a two-layer\nencoder. Finally, the improvement in reconstruction from the invariant to the equivariant SAE further\nshows the effect of learning M.\n\n6  Conclusion\n\nWe have presented early results showing that adding domain-specific properties such as group\nequivariance to sparse autoencoders can significantly increase their utility in domains beyond language.\n\n\n                                       4\n\n      SAE       SAE (wide)       SAE (two-layer encoder)           Equivariant SAE       AE Activations              Equivariant       SAE (two-layer encoder)\n                K = 8                 K = 16                K = 32                               Invariant         K = 8      1.0\n                                                                   SAE            K = 16\n      0.8                                                               SAE (wide)       K = 32     Score                                                                                                                                                                                                                                                                                                        Truncated\n      0.6                                                                                        0.8  F1\n      0.4                                                                                                                                                                                                                               Latents       L1\n                                                                                              0.6\n\n      1.0                                                                                                                                                                                                                                        Latents' 0.4      0.8                                                                                                                                                                                                                                                                                              Truncated                                                                                       SAE\n     Score                                                                                          0.2\n      0.6\n  F1\n      0.4                                                                               10 3       10 2       10 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Reconstructions                                                                  AE MSE w/ SAE Spliced\n          S    SO    SP   SPO    S    SO    SP   SPO    S    SO    SP   SPO\n                    Tasks                      Tasks                      Tasks\n                                                        Figure 4:  Sparsity/reconstruction\nFigure 3: Latent and reconstruction probing perfor-  performance of SAEs for varying\nmance, with truncation length 32 and the CNN autoencoder,  TopK values. The x axis corresponds\ncomparing a regular SAE (one-layer encoder), an SAE with   to the base autoencoders’ reconstruc-\n|G| times the latents (wide), and an SAE with a two-layer   tion performance when their intermedi-\nencoder with our equivariant SAE. Performance of probes   ate activations are passed through the\nover the base model activations are duplicated for easier  SAEs, and the y axis denotes the L1\ncomparisons and reflect the upper bound.               norm of the SAE latent activations.\n\n\nOur first result is that a single matrix can explain more than 98% of the variance in how the activations\nof a neural network transform as its inputs are transformed with the action of a discrete cyclic group.\nWe then used this result to design equivariant SAEs that discover features that lead to better probing\nperformance than regular SAEs, indicating that they are more useful in downstream applications.\n\nLimitations and future work. Although our results are promising, they are so far limited to a\nsynthetic task, relatively small models, and a small discrete group, and thus many important questions\nremain to establish the practical usefulness of adaptively equivariant SAEs: Can M be learned as\neffectively in larger models such as frontier foundation models? Can the optimization of M be\nimproved by better utilizing the group structure, e.g. by constraining the optimization to M|G| = I?\nDoes the two-layer encoder qualitatively alter what kind of features are discovered, and how can the\nfeatures best be labeled incorporating the knowledge of how they transform with M? Finally, can the\nreconstruction performance of the equivariant SAE be improved to match that of regular SAEs?\n\nWhile the concept of interpretability is domain-agnostic, progress in mechanistic interpretability has\nlargely been driven by its applications in language, which has led to certain concepts such as group\nequivariance being represented far less prominently than they are in the broader ML literature. Our\nresults highlight the potential benefit of bridging that gap and tailoring mechanistic interpretability\ntools for domains beyond language, despite being early results for a work in progress.\n\nReferences\n\n [1] Yutaro Yamada, Robert Tjarko Lange, Cong Lu, Shengran Hu, Chris Lu, Jakob Foerster, Jeff\n     Clune, and David Ha. The AI Scientist-v2: Workshop-Level Automated Scientific Discovery\n     via Agentic Tree Search. (arXiv:2504.08066), April 2025.\n\n [2] Juraj Gottweis, Wei-Hung Weng, Alexander Daryin, Tao Tu, Anil Palepu, Petar Sirkovic, Artiom\n     Myaskovsky, Felix Weissenberger, Keran Rong, Ryutaro Tanno, Khaled Saab, Dan Popovici,\n     Jacob Blum, Fan Zhang, Katherine Chou, Avinatan Hassidim, Burak Gokturk, Amin Vahdat,\n     Pushmeet Kohli, Yossi Matias, Andrew Carroll, Kavita Kulkarni, Nenad Tomasev, Yuan Guan,\n    Vikram Dhillon, Eeshit Dhaval Vaishnav, Byron Lee, Tiago R. D. Costa, José R. Penadés, Gary\n      Peltz, Yunhan Xu, Annalisa Pawlosky, Alan Karthikesalingam, and Vivek Natarajan. Towards\n     an AI co-scientist. (arXiv:2502.18864), February 2025.\n\n [3] Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel,\n     Olaf Ronneberger, Lindsay Willmore, Andrew J. Ballard, Joshua Bambrick, Sebastian W.\n     Bodenstein, David A. Evans, Chia-Chun Hung, Michael O’Neill, David Reiman, Kathryn\n\n\n                                       5\n\n     Tunyasuvunakool, Zachary Wu, Akvil˙e Žemgulyt˙e, Eirini Arvaniti, Charles Beattie, Ottavia\n      Bertolli, Alex Bridgland, Alexey Cherepanov, Miles Congreve, Alexander I. Cowen-Rivers,\n    Andrew Cowie, Michael Figurnov, Fabian B. Fuchs, Hannah Gladman, Rishub Jain, Yousuf A.\n     Khan, Caroline M. R. Low, Kuba Perlin, Anna Potapenko, Pascal Savy, Sukhdeep Singh, Adrian\n     Stecula, Ashok Thillaisundaram, Catherine Tong, Sergei Yakneen, Ellen D. Zhong, Michal\n      Zielinski, Augustin Žídek, Victor Bapst, Pushmeet Kohli, Max Jaderberg, Demis Hassabis, and\n     John M. Jumper. Accurate structure prediction of biomolecular interactions with AlphaFold 3.\n     Nature, 630(8016):493–500, June 2024.\n\n [4] Johann Brehmer, Sönke Behrends, Pim de Haan, and Taco Cohen. Does equivariance matter at\n     scale? (arXiv:2410.23179), October 2024.\n\n [5] Nithin Parsan, David J. Yang, and John Jingxuan Yang.  Towards Interpretable Structure\n     Prediction With Sparse Autoencoders. In ICLR 2025 Workshop on Machine Learning Multiscale\n     Processes, March 2025.\n\n [6] Elana Simon and James Zou. InterPLM: Discovering Interpretable Features in Protein Language\n    Models via Sparse Autoencoders. page 2024.11.14.623630, January 2025.\n\n [7] Etowah Adams, Liam Bai, Minji Lee, Yiyang Yu, and Mohammed AlQuraishi. From Mecha-\n      nistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse\n     Autoencoders on Protein Language Models. page 2025.02.06.636901, February 2025.\n\n [8] Edith Natalia Villegas Garcia and Alessio Ansuini. Interpreting and Steering Protein Language\n    Models through Sparse Autoencoders. (arXiv:2502.09135), February 2025.\n\n [9] Muhammed Furkan Dasdelen, Hyesu Lim, Michele Buck, Katharina S. Götze, Carsten\n     Marr, and Steffen Schneider.  CytoSAE: Interpretable Cell Embeddings for Hematology.\n     (arXiv:2507.12464), July 2025.\n\n[10] Konstantin Donhauser, Kristina Ulicna, Gemma Elyse Moran, Aditya Ravuri, Kian Kenyon-\n     Dean, Cian Eastwood, and Jason Hartford. Towards scientific discovery with dictionary learning:\n     Extracting biological concepts from microscopy foundation models.  (arXiv:2412.16247),\n     February 2025.\n\n[11] Ahmed A. Elhag, T. Konstantin Rusch, Francesco Di Giovanni, and Michael Bronstein. Relaxed\n     Equivariance via Multitask Learning. (arXiv:2410.17878), October 2024.\n\n[12] Yinzhu Jin, Aman Shrivastava, and P. T. Fletcher. Learning Group Actions on Latent Represen-\n      tations. Advances in Neural Information Processing Systems, 37:127273–127295, December\n     2024.\n\n[13] Robin Winter, Marco Bertolini, Tuan Le, Frank Noe, and Djork-Arné Clevert. Unsupervised\n     Learning of Group Invariant and Equivariant Representations. In Advances in Neural Informa-\n      tion Processing Systems, May 2022.\n\n[14] Jianke Yang, Nima Dehmamy, Robin Walters, and Rose Yu. Latent Space Symmetry Discovery.\n     (arXiv:2310.00105), August 2024.\n\n[15] Lucas Laird, Circe Hsu, Asilata Bapat, and Robin Walters. MatrixNet: Learning over symmetry\n     groups using learned group representations. Advances in Neural Information Processing Systems,\n     37:32512–32535, December 2024.\n\n[16] Christian Shewmake, Nina Miolane, and Bruno Olshausen. Group Equivariant Sparse Coding.\n     In Frank Nielsen and Frédéric Barbaresco, editors, Geometric Science of Information, volume\n     14071, pages 91–101. Springer Nature Switzerland, Cham, 2023.\n\n[17] Christian Shewmake, Domas Buracas, Hansen Lillemark, Jinho Shin, Erik Bekkers, Nina\n     Miolane, and Bruno Olshausen. Visual Scene Representation with Hierarchical Equivariant\n     Sparse Coding. December 2023.\n\n[18] Liv Gorton. Group Crosscoders for Mechanistic Analysis of Symmetry. (arXiv:2410.24184),\n    November 2024.\n\n\n                                       6\n\n[19] Leo Gao, Tom Dupré la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford,\n     Ilya Sutskever, Jan Leike, and Jeffrey Wu.  Scaling and evaluating sparse autoencoders.\n     (arXiv:2406.04093), June 2024.\n\n[20] Alireza Makhzani and Brendan Frey. K-Sparse Autoencoders. (arXiv:1312.5663), March 2014.\n\n[21] Charles O’Neill, Alim Gumran, and David Klindt. Compute Optimal Inference and Provable\n     Amortisation Gap in Sparse Autoencoders. (arXiv:2411.13117), January 2025.\n\n[22] Diederik P. Kingma and Jimmy Ba.  Adam: A Method for Stochastic Optimization.\n     (arXiv:1412.6980), January 2017.\n\n[23] Subhash Kantamneni, Joshua Engels, Senthooran Rajamanoharan, Max Tegmark, and Neel\n     Nanda. Are Sparse Autoencoders Useful? A Case Study in Sparse Probing. (arXiv:2502.16681),\n     February 2025.\n\n[24] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,\n     Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas\n     Köpf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,\n     Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style,\n     High-Performance Deep Learning Library. (arXiv:1912.01703), December 2019.\n\n[25] Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion,\n     Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vander-\n      plas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and Édouard\n     Duchesnay. Scikit-learn: Machine Learning in Python. J. Mach. Learn. Res., 12(null):2825–\n     2830, November 2011.\n\n[26] Tianqi Chen and Carlos Guestrin. XGBoost: A Scalable Tree Boosting System. In Proceedings\n      of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,\n   KDD ’16, pages 785–794, New York, NY, USA, August 2016. Association for Computing\n     Machinery.\n\n[27] G. Bradski. The OpenCV Library. Dr. Dobb’s Journal of Software Tools, 2000.\n\n[28] Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, and Lee Sharkey. Sparse\n     Autoencoders Find Highly Interpretable Features in Language Models. (arXiv:2309.08600),\n     October 2023.\n\n[29] Trenton Bricken, Adly Templeton, Joshua Batson, Brian Chen, Adam Jermyn, Tom Con-\n      erly, Nick Turner, Cem Anil, Carson Denison, Amanda Askell, Robert Lasenby, Yifan Wu,\n    Shauna Kravec, Nicholas Schiefer, Tim Maxwell, Nicholas Joseph, Zac Hatfield-Dodds, Alex\n    Tamkin, Karina Nguyen, Brayden McLean, Josiah E Burke, Tristan Hume, Shan Carter,\n   Tom Henighan, and Christopher Olah. Towards monosemanticity: Decomposing language\n    models with dictionary learning.  Transformer Circuits Thread, 2023.  https://transformer-\n     circuits.pub/2023/monosemantic-features/index.html.\n\n[30] Bart Bussmann,  Patrick Leask, and Neel Nanda.   BatchTopK Sparse Autoencoders.\n     (arXiv:2412.06410), December 2024.\n\n[31] Adly Templeton, Tom Conerly, Jonathan Marcus, Jack Lindsey, Trenton Bricken, Brian Chen,\n   Adam Pearce, Craig Citro, Emmanuel Ameisen, Andy Jones, Hoagy Cunningham, Nicholas L\n     Turner, Callum McDougall, Monte MacDiarmid, C. Daniel Freeman, Theodore R. Sumers,\n    Edward Rees, Joshua Batson, Adam Jermyn, Shan Carter, Chris Olah, and Tom Henighan.\n     Scaling monosemanticity: Extracting interpretable features from claude 3 sonnet. Transformer\n     Circuits Thread, 2024.\n\n[32] Yuxiao Li, Eric J. Michaud, David D. Baek, Joshua Engels, Xiaoqing Sun, and Max Tegmark.\n    The Geometry of Concepts: Sparse Autoencoder Feature Structure. Entropy, 27(4):344, March\n     2025.\n\n[33] Joshua Engels, Eric J. Michaud, Isaac Liao, Wes Gurnee, and Max Tegmark. Not All Language\n    Model Features Are One-Dimensionally Linear. (arXiv:2405.14860), February 2025.\n\n\n                                       7\n\n[34] Michael M. Bronstein, Joan Bruna, Taco Cohen, and Petar Veliˇckovi´c.  Geometric Deep\n     Learning: Grids, Groups, Graphs, Geodesics, and Gauges. (arXiv:2104.13478), May 2021.\n\n[35] Johannes Gasteiger, Janek Groß, and Stephan Günnemann. Directional Message Passing for\n     Molecular Graphs. (arXiv:2003.03123), April 2022.\n\n[36] Omri Puny, Matan Atzmon, Heli Ben-Hamu, Ishan Misra, Aditya Grover, Edward J. Smith,\n    and Yaron Lipman.  Frame Averaging for Invariant and Equivariant Network Design.\n     (arXiv:2110.03336), March 2022.\n\n[37] Alexandre Duval, Simon V. Mathis, Chaitanya K. Joshi, Victor Schmidt, Santiago Miret,\n     Fragkiskos D. Malliaros, Taco Cohen, Pietro Liò, Yoshua Bengio, and Michael Bronstein. A\n     Hitchhiker’s Guide to Geometric GNNs for 3D Atomic Systems. (arXiv:2312.07511), March\n     2024.\n\n\n\n\n\n                                       8\n\nFigure 5:  Left: A neural network ψ  transforms an orbit Gx into more complex, non-linear\nstructures. The invariant SAE maps all activations in a transformed orbit to the same latent point,\nand reconstructs a canonical activation. The matrix M then transforms the reconstructions back to\ntheir original forms, achieving equivariance by approximating the transformed orbit in activation\nspace. Right: Transforming the learned dictionary D 7→MpD allows us to observe which features\ndiscovered by the SAE are invariant or equivariant with respect to input transformations.\n\n\nA  Reproducibility\n\nWe make our SAE and probing implementations public at https://github.com/ege-erdogan/\nequivariant-sae. We implement our models from scratch using PyTorch [24], and use the scikit-\nlearn [25] and XGBoost [26] packages for the various probing methods. We utilize the OpenCV\npackage [27] to create our dataset.\n\nB  Background\n\nB.1  Sparse autoencoders\n\nNeural networks are known to encode more concepts than they have neurons for, a phenomenon\nknown as superposition [11]. This implies that individual neurons are not the right level abstraction to\nanalyze what concepts are involved in a neural network’s computation. Sparse autoencoders (SAEs)\n[28, 29] have shown potential in overcoming this challenge, by decomposing the activations of neural\nnetworks into more interpretable components that are used by the model.\nAn SAE is trained to reconstruct the internal activations x ∈Rd of a model as sparse linear\ncombinations of interpretable features. A typical SAE consists of linear encoder and decoder layers,\nand an activation σ:\n\n                               z = σ (WEx + bE)                                     (4)\n                                                    ˆx = WDz + bD                                          (5)\nwith weights WE, WD and biases bE, bD. The latent z ∈Rn is higher dimensional than the inputs,\nand thus the dictionary vectors (rows of WD) is said to form an overcomplete basis for the activation\nspace.\n\nTo avoid memorization and obtain more clear explanations, the latent z is pushed to be sparse, with a\nlow L0 norm. Since it is difficult to optimize for a low L0 norm directly, SAEs are often trained with\nL1 regularization to minimize\n                     L := ∥x −ˆx∥22 + λ ∥z∥1 .                                   (6)\nAn alternative approach is to enforce the desired L0 directly with an activation function such as TopK\n[20, 19] which filters only the K highest activations for each input or BatchTopK [30] which filters\nover a batch.\n\nThe features learned by an SAE can then be interpreted by finding the inputs that maximally activate\nspecific latents or observing how modifying the strength of a latent changes the model outputs, such as\nin the famous “Golden Gate Claude” [31]. The geometry of features learned by SAEs have also been\nan object of study [32, 33], demonstrating that concepts such as days of the week can be represented\nin an LLM’s activations in particular geometric structures.\n\n\n                                       9\n\nB.2  Symmetries & group equivariance\n\nData in scientific problems often involve various symmetries, transformations that preserve certain\nproperties of the data while some properties can transform along with the symmetries. For example,\nrotating a molecule, moving it in space, or permuting its identical atoms does not change the\nmolecule’s identity, but rotating it can change the orientation of certain vector quantities such as the\nforces acting on each atom.\n\nThe frame of reference we associate with such data, e.g. the particular 3D coordinates we assign\nto atoms in a molecule, is not an inherent property of the molecule or the world but an artifact of\nour observational bias. Thus to model physical phenomena more faithfully, we would prefer to be\nindependent of particular reference frames, and developing such tools has become an active research\narea [34].\n\nSymmetries share certain properties such as being composable (subsequent rotations can also be\nmodeled as a single rotation) and invertible (any rotation can be inverted). Moreover, the identity\ntransform is a trivial symmetry for any object, and the order of composition of three transformations\ndoes not change the end result. These notions are unified by the definition of a group that characterizes\nsymmetry transformations:\nDefinition 1 (Group). A group (G, ∗) is a set G along with an operation ∗: G × G →G such that\nthe following axioms are satisfied:\n\n        • (Associativity) For all g, h, j ∈G, it holds that (g ∗h) ∗j = g ∗(h ∗j).\n\n        • (Identity element) There exists e ∈G such that e ∗g = g for all g ∈G.\n\n        • (Inverses) Any g ∈G has an inverse g−1 ∈G such that g ∗g−1 = e.\n\nA group is further called abelian if its group operation is commutative, i.e. g ∗h = h ∗g for all\ng, h ∈G.\n\nGroups are often denoted by their set, e.g. as G alone, omitting the operation. Groups can be\ndiscrete, such as permutation groups Sn of n objects and the cyclic groups Cn corresponding to\nrotations of an n-gon, or continuous, such as the group of rotations in n-dimensional space, defined\nas SO(n) := {R ∈Rn×n : RRT = I, det R = 1}.\n\nGroups transform sets of objects such as images or molecules via their actions:\nDefinition 2 (Group action). A (left) action of the group (G, ∗) on set X is a map α : G × X →X,\ndenoted\n                                      (g, x) 7→α(g, x) = g · x,\n\nthat satisfies these axioms for all x ∈X:\n\n        • α(e, x) = x with e the identity element in G.\n\n        • α(g, α(h, x)) = α(g ∗h, x) for all g, h ∈G.\n\nA right group action can similarly be defined, and the set X is said to be a G-set.\nDefinition 3 (Orbit). Let X be a G-set. The orbit of x ∈X is the set of all points in X reachable by\ntransforming x with G, denoted\n\n                      Gx := {α(g, x) : g ∈G}.\n\nFunctions mapping between G-sets can then be invariant or equivariant depending on how they\nbehave in each orbit:\nDefinition 4 (Invariant and equivariant functions). For G-sets X and Y with associated actions\nαX, αY , a function f : X →Y is G-invariant if for all g ∈G, x ∈G,\n\n                               f(αX(g, x)) = f(x),\n\nand G-equivariant if\n                            f(αX(g, x)) = αY (g, f(x)).\n\n\n                                       10\n\nFigure 6: Set of available shapes in our dataset. None of the shapes is rotation-invariant, with the\nhorizontal rectangle and diagonal line having two orientations and the other six shapes having four\norientations.\n\n\nUsing neural networks, approximate invariance or equivariance can be achieved by augmenting the\ndata with symmetric inputs, or explicitly via additional loss terms [11]. Straightforward ways of\nachieving exact invariance include limiting the model’s inputs to invariant properties of the data, such\nas internal bond angles in a molecule that are rotation-invariant scalars [35], or averaging the outputs\nover each orbit [36]. Achieving exact equivariance requires more careful consideration of how the\ninput features are processed in each layer of the neural network, but there exists a wide-ranging\nliterature of equivariant models for various groups and data types [37].\n\nC  Experimental details\n\nC.1  Dataset and probing\n\nFigures 6 displays the base shapes in our dataset. When rotated in increments of 90◦, the rectangle\nand the diagonal shapes have two orientations, and the other six shapes have four. Each image then\ncontains a randomly sampled shape in each of its four quadrants. Precise definitions of our binary\nprobing tasks are then as follows, with a shape’s position denoting which of the four quadrants it is in\nin an image, and its orientation denoting which of the four or two orientations it is in:\n\n        • S(s): Does the image contain shape s in any position or orientation?\n        • SO(s, o): Does the image contain shape s in orientation o and any position?\n        • SP(s, p): Does the image contain shape s in position p and any orientation?\n        • SPO(s, p, o): Does the image contain shape s in position p and orientation o?\n\nThis results in a total of 8 S (one for each shape), 28 SO (2 shapes × 2 orientations + 6 shapes ×\n4 orientations), 32 SP (8 shapes × 4 orientations), and 112 SPO (2 shapes × 2 orientations × 4\npositions + 6 shapes × 4 orientations × 4 positions) tasks, for a total of 180 tasks. Note that we\nreport F1 scores rather than raw accuracies as the tasks are not balanced and contain more negative\nthan positive examples, with the share of negative examples ranging from ∼58% in the S tasks to\n87 −89% in the SP and SO tasks, and 97% in the SPO tasks.\n\nThe probe we ultimately report the results from, XGBoost [26], consists of 100 estimators with a\nmaximum depth of 6, and is trained with the learning rate 0.3 and L2 regularization. For completeness,\nlogistic regression probes are trained with learning rate 1e-3 and L2 regularization strength 1e-4, and\nfor the kNN probe we consider the 16 nearest neighbors with respect to Euclidean distance.\n\nC.2  Base models\n\nWe train our base autoencoders for 100 epochs over 10,000 randomly generated samples from our\ndataset and augmenting with random 90◦rotations with a batch size of 64 using Adam [22] with\nlearning rate 1e-3. Their architectures are detailed in Table 1.\n\nC.3  SAEs\n\nThe regular SAEs used in our comparisons are typical TopK SAEs with linear encoders and decoders.\nThe equivariant SAEs also have linear decoders and use the TopK activation, but their encoders\nconsists of two linear layers with a ReLU activation in between and hidden dimension of 512. We\ntrain our sparse autoencoders for 500 epochs over 10,000 samples from our dataset with batch size\n64 using Adam [22] with a learning rate of 1e-3.\n\n\n                                       11\n\nTable 1: Architectures of the MLP and CNN autoencoders. The first section of each models\ncorresponds to the encoder and the second section to the decoder. We train our SAEs over the\npre-activation encoder outputs.\n    MLP          CNN\n\n        Input: 4096 (64×64)   Input: 1×64×64\n\n       Linear(4096, 256)     Conv2d(1, 16, 3×3, stride=2, pad=1)\n     ReLU            ReLU\n       Linear(256, 256)      Conv2d(16, 32, 3×3, stride=2, pad=1)\n     ReLU            ReLU\n                           Conv2d(32, 256, 16×16)\n                     ReLU\n\n       Linear(256, 256)      ConvTranspose2d(256, 32, 16×16)\n     ReLU            ReLU\n       Linear(256, 4096)     ConvTranspose2d(32, 16, 3×3, stride=2, pad=1, out_pad=1)\n                     ReLU\n                           ConvTranspose2d(16, 1, 3×3, stride=2, pad=1, out_pad=1)\n\n\nD  Further probing results\n\nFigure 7 displays further probing results with TopK values 8 and 32. Results generally agree with those\npresented in Section 4. When probing over the truncated reconstructions, the invariant/equivariant\nSAEs result in the most accurate probes over all tasks while the performance of the latent activation\nprobes drop with the equivariant tasks as expected.\n\n\n\n\n\n                                       12\n\n                       SAE       SAE (wide)       SAE (two-layer encoder)           Equivariant SAE       AE Activations\n                                K = 8                 K = 16                K = 32\n                                1.0\n\n                                0.8\n                                             Score 0.6                                                                                                                                                                                                                                                                                              Truncated\n                  F1\n                                0.4                                                                                                                                                                                                                                                                                                            Latents\n                                0.2\n\n                                1.0\n\n                                0.8                                                                                                                                                                                                                                                                                                                                                                                                  Truncated\n                                             Score 0.6\n                  F1\n                                0.4                                0.2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Reconstructions\n\n                            S    SO    SP   SPO    S    SO    SP   SPO    S    SO    SP   SPO\n                                         Tasks                      Tasks                      Tasks\n\n                                           (a) Truncation length = 8, MLP\n\n                       SAE       SAE (wide)       SAE (two-layer encoder)           Equivariant SAE       AE Activations\n                                K = 8                 K = 16                K = 32\n                                1.0\n\n                                0.8\n\n                                0.6                                             Score                                                                                                                                                                                                                                                                                                        Truncated\n                  F1 0.4                                                                                                                                                                                                                               Latents\n                                0.2\n\n                                1.0\n\n                                0.8                                                                                                                                                                                                                                                                                                                                                                                                  Truncated\n                                0.6                                             Score\n                  F1 0.4\n\n                                0.2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Reconstructions\n\n                            S    SO    SP   SPO    S    SO    SP   SPO    S    SO    SP   SPO\n                                         Tasks                      Tasks                      Tasks\n\n                                        (b) Truncation length = 8, CNN\n\n                       SAE       SAE (wide)       SAE (two-layer encoder)           Equivariant SAE       AE Activations\n                                K = 8                 K = 16                K = 32\n                                1.0\n\n\n                                0.8\n                                             Score                                                                                                                                                                                                                                                                                                        Truncated\n                  F1 0.6                                                                                                                                                                                                                               Latents\n                                0.4\n\n\n                                1.0\n                                0.8                                                                                                                                                                                                                                                                                              Truncated\n                                             Score\n                  F1 0.6\n\n                                0.4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Reconstructions\n\n                            S    SO    SP   SPO    S    SO    SP   SPO    S    SO    SP   SPO\n                                         Tasks                      Tasks                      Tasks\n\n                                          (c) Truncation length = 32, MLP\n\nFigure 7: Further probing results with different TopK values. Although increasing TopK and the\ntruncation length increases the performance of the probes trained over the regular SAEs activations\nand reconstructions, results follow a similar trend with those in Figure 3, with the equivariant SAE\nleading to the best overall probes over its reconstructions.\n\n\n\n                                       13\n\n## Claim to Classify\n\"incorporating group symmetries into the SAEs yields features more useful in downstream tasks\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Interchange intervention (probing over SAE reconstructions)",
    "method_rung": 2,
    "claim_rung": 2,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The claim states that the features are 'more useful in downstream tasks'. The paper supports this by training probes (XGBoost, etc.) on the SAE reconstructions and measuring performance (F1 score) on binary classification tasks. According to the codebook, claims about 'usefulness' or 'performance' in downstream tasks supported by interventions (like replacing activations with SAE reconstructions to see if task information is preserved) are Rung 2. The claim is causal in the sense that the method (incorporating symmetries) produces a result (better features for tasks), which is a claim of causal sufficiency for task performance."
  },
  "metadata": {
    "model": "google/gemini-3-flash-preview",
    "usage": {
      "prompt_tokens": 15651,
      "completion_tokens": 189,
      "total_tokens": 15840
    },
    "finish_reason": "stop"
  }
}