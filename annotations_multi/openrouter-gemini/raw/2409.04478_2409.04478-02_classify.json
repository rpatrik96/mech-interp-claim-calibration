{
  "timestamp": "2026-02-19T09:26:33.557969+00:00",
  "paper_id": "2409.04478",
  "claim_id": "2409.04478-02",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2409.04478\nTitle: Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small\nFull text:\n                      Evaluating Open-Source Sparse Autoencoders\n                 on Disentangling Factual Knowledge in GPT-2 Small\n\n\n                    Maheep Chaudhary                     Atticus Geiger\n                            Pr(Ai)2R Group                       Pr(Ai)2R Group\n              maheepchaudhary.research@gmail.com       atticusg@gmail.com\n\n\n\n\n                          Abstract                     space with sparse linear features that are intended\n                                                                      to be better units of analysis.\n          A popular new method in mechanistic inter-\n                                                          However, researchers have invested more into                    pretability is to train high-dimensional sparse\n                  autoencoders (SAEs) on neuron activations and        scaling SAEs, than evaluating them (Templeton\n                 use SAE features as the atomic units of analy-        et al., 2024). In particular, only a handful of works\n                        sis. However, the body of evidence on whether       engage with whether SAEs are useful for a causal2024\n            SAE feature spaces are useful for causal analy-        interpretability analysis (Marks et al., 2024; En-\n                      sis is underdeveloped. In this work, we use        gels et al., 2024; Makelov et al., 2024).  In this\n                   the RAVEL benchmark to evaluate whetherSep                                                            paper, we add to the body of evidence an exam-\n              SAEs trained on hidden representations of GPT-\n5                                                           ple of when sparse autoencoders fail to provide a               2 small have sets of features that separately\n                                                                         better feature space than neurons for finding model-                 mediate knowledge of which country a city is\n                   in and which continent it is in. We evaluate        internal mediators of concepts (Geiger et al., 2024a;\n                   four open-source SAEs for GPT-2 small against       Mueller et al., 2024).  Specifically, we use the\n                 each other, with neurons serving as a baseline,     RAVEL benchmark (Huang et al., 2024) to evaluate\n                and linear features learned via distributed align-      whether the there are sets of SAE features that sep-[cs.LG]               ment search (DAS) serving as a skyline. For                                                                       arately mediate knowledge of which country a city\n                   each, we learn a binary mask to select features\n                                                                                is in and which continent a city is in. We evaluate\n                    that will be patched to change the country of\n                                                                 four publicly available SAEs for GPT-2 small: the                 a city without changing the continent, or vice\n                   versa. Our results show that SAEs struggle      Open AI SAE (Gao et al., 2024), two Apollo SAEs\n                   to reach the neuron baseline, and none come       (Braun et al., 2024), and the Bloom SAE (Bloom,\n                   close to the DAS skyline. We release code here:       2024). As a feature baseline, we use neurons; as\n                github.com/MaheepChaudhary/SAE-Ravel          a feature skyline, we use linear subspaces trained\n                                                            with distributed alignment search (DAS; Geiger\n          1  Introduction\n                                                                            et al. 2024b) to disentangle the country knowledge\n             Individual neurons in neural networks represent   from the continent knowledge.\n          many concepts, and individual concepts are repre-     For each feature space, we train a differentiable\n             sented by many neurons (Smolensky, 1988; Mc-   binary mask to select features that encode the\n             Clelland et al., 1986a,b; Olah et al., 2020; Cam-   country of a city, but not the continent, and vicearXiv:2409.04478v1\n            marata et al., 2020; Bolukbasi et al., 2021; Gurnee    versa. We evaluate the selected features using\n               et al., 2023). What, if not neurons, are the relevant    interchange interventions, where features are fixed\n            meaning-bearing components of neural networks?    to values they would take if a different input were\n            This is a fundamental question in mechanistic in-   provided.  For example, if we fix the ‘country’\n               terpretability. A recent, and increasingly popu-    features for the prompt Paris is a city in the country\n                  lar, unsupervised method for learning features that   and set them to the value they take for the prompt\n            correspond to intuitive concepts is to train high-   Tokyo is a city in, the output should be Japan\n            dimensional sparse autoencoders (SAEs) on the    not France.  If we instead target the ‘continent’\n            hidden representations of deep learning models    features, the output should be Europe not Asia.\n             across a wide range of possible inputs (Bricken      In Figure 1 we show that all SAEs struggle to\n               et al., 2023; Cunningham et al., 2023; Lieberum   compete with the neuron baseline and degrade the\n               et al., 2024; Gao et al., 2024). The encoder of an   model’s knowledge. However, the DAS skyline\n         SAE unpacks neurons into a higher dimensional    sets a high ceiling and there is room to improve.\n\n\n                                                    1\n\n(a) The disentangle score for ‘continent’ and ‘country’ interventions across the layers of GPT-2 small. The disentangle scores for\nempty intervention baselines are shown as dotted lines. The performance of the DAS skyline goes down after layer 7 because the\nknowledge about the city is being moved away from the <city> token. The Apollo SAEs are only available for layers 1, 5, and 9.\n\n\n\n                                  Country-Intervened Continent-Preserved                   Continent-Intervened Country-Preserved\n                          Neurons  DAS  Open AI  Bloom   Apollo      Apollo     Neuron  DAS  Open AI  Bloom   Apollo      Apollo\n                                 SAE    SAE  SAE e2e  SAE e2e+ds               SAE    SAE  SAE e2e  SAE e2e+ds\n\n     Continent Accuracy       46      93      51      36      24         33         48     94      49      37      24         32\n     Country Accuracy        96      94      95      49      84         86         97     99      97      52      81         82\n      Disentangle Score        71      94      73      43      54         59         72     96      73      45      52         57\n\n       Inactive Features         0       0     0.977     0.98     0.966       0.974        0      0     0.977     0.98     0.966       0.974\n   Non-Intervened Features     0.11    0.24    0.006    0.005     0.01       0.009       0.88    0.79    0.015    0.009    0.023       0.018\n     Intervened Features       0.89    0.76    0.015    0.009    0.023       0.018       0.12    0.21    0.007    0.005    0.011       0.009\n\n     Reconstruction Loss       0       0      152     551     2245       2130        0      0      158     516     2576       2318\n  Reconstructed Knowledge    100     100     95      56      67         1         100    100     95      47      35         0\n\n(b) GPT-2 small at layer 1. The first three rows are interchange intervention accuracies for RAVEL using learned binary masks to\nselect features. The next three rows are sparsity evaluations that show the proportion of inactive features, intervened on features,\nand active non-intervened features. The final two rows are reconstruction evaluations that show the models knowledge of cities\nusing a reconstructed representation (no interventions performed) and the average mean-squared error reconstruction loss. The\nbase prompts for each of the two datasets were used for reconstruction evaluations, with source prompts being ignored.\n\n\n\n                                  Country-Intervened Continent-Preserved                   Continent-Intervened Country-Preserved\n                          Neurons  DAS  Open AI  Bloom     Apollo     Apollo   Neuron  DAS  Open AI  Bloom     Apollo     Apollo\n                                  SAE    SAE   e2e+ds SAE  SAE                SAE    SAE   e2e+ds SAE  SAE\n\n     Continent Accuracy       49      91      53      48        22        22      46     93      48      45        18        18\n     Country Accuracy        97      98      88      79        66        66      98     99      91      79        61        61\n      Disentangle Score        73      94      70      64        44        44      72     96      70      62        40        39\n\n       Inactive Features         0       0      0.951    0.979      0.981       0.98      0      0      0.951    0.979      0.981       0.98\n   Non-Intervened Features    0.119    0.325    0.017    0.006      0.008      0.009    0.877    0.69    0.031    0.013      0.017      0.017\n     Intervened Features       0.88    0.674    0.031    0.013      0.017      0.017    0.122   0.309    0.017    0.006      0.008      0.009\n\n     Reconstruction Loss       0       0      644     937      2383      2353      0      0      652     1044      2576      2318\n  Reconstructed Knowledge    100     100     88      77        84        83      100    100     90      86        76        61\n\n                (c) GPT-2 small at layer 5. See the caption above from Figure 1b for details on the table structure.\n\nFigure 1: Metrics on the RAVEL test set for interchange interventions performed on the residual stream in GPT-2\nsmall after transformer block above the city token <city>. For each space of features, we learn ‘country’ features\nthat encode what country a city is in and ‘continent’ features that encode what continent a city is in. Interventions\ntargeting the ‘country’ features should change the output for the prompt <city> is in the country of, but not <city>\nis in the continent of. Interventions targeting the ‘continent’ features should do the opposite. The disentangle score\nis the average of the country and continent accuracies. Neurons serve as a baseline for how easily these two facts are\ndisentangled, and DAS is a supervised feature learning method that serves as a skyline. The SAEs are the methods\nwe seek to evaluate. In sum, using SAE reconstructions harm the knowledge of GPT-2 and SAE features are not\nbetter mediators than the baseline of neurons.\n\n\n\n\n\n                                         2\n\n2  Related Work                                   to take on the value they would have for city Tokyo\n                                                should make the model think that Toronto is in\nBenchmarking SAEs  There are many aspects of\n                                                Japan. The process of fixing features to take on\nSAEs to benchmark. To what degree do the features\n                                                  values they would have for a different input is an\nrespond precisely and accurately to the natural lan-\n                                                  interchange intervention (Geiger et al., 2020; Vig\nguage labels given to them by auto-interpretability\n                                                           et al., 2020; Finlayson et al., 2021). Suppose we\nmethods (Hernandez et al., 2022; Huang et al.,\n                                                have base input prompt b and a source input prompt\n2023; Schwettmann et al., 2023; Bills et al., 2023;\n                                              s for a model M and we want to target features F.\nShaham et al., 2024)? Can we do circuit discovery\n                                                 Define the interchange intervention as\n(Marks et al., 2024; Makelov et al., 2024), represen-\ntation analysis (Engels et al., 2024), or activation                                                                                f = get(M, s, F)\nsteering (Templeton et al., 2024) in SAE feature\n                                                                                                       ˆy = MF←f(b)space? Our question is whether SAEs provide a\nbetter feature space than neurons for localizing the\n                                           where get(M, s, F) retrieves the value that fea-concepts used by deep learning models.\n                                                       tures F take on when M is run with input s and\nInterpretability of Knowledge Representations   MF←f(b) is the output produced when M is run\nThe RAVEL benchmark belongs to a line of re-   with input b under intervention F ←f.\nsearch concerned with how factual knowledge is\nstored within a language model (Geva et al., 2021;   Counterfactual Labels  The label of an inter-\nMeng et al., 2022; Dai et al., 2022; Meng et al.,   change intervention example is determined by the\n2023; Hernandez et al., 2023; Geva et al., 2023).   concept we think is encoded in the features F and\nIn this paper, we are concerned with how factual    the mechanism that determines the output given\nknowledge is stored and processed in hidden vector    the prompt (Geiger et al., 2021). For our task, the\nrepresentations during model inference. Activa-   mechanism connecting the knowledge of a city and\ntion steering or model editing ask how to control    the expected behavior is simple.  If we are inter-\na model, whereas we ask how a model constructs   vening on the ‘country’ features, then the ‘country’\nand manipulates representations to control itself.    prompt should have the label from the source ys\n                                            and the ‘continent’ prompt should have the label\n3  Methodology                             from the base yb. If we intervene on the ‘continent’\n                                                         feature, we use the opposite labels.\n3.1  The RAVEL Benchmark\nRAVEL (Huang et al., 2024) is an benchmark that    Splits  To evaluate a proposed set of ‘country’\nevaluates interpretability methods on localizing and    features and ‘continent’ features, we perform in-\ndisentangling related factual knowledge. We focus    terchange interventions using the RAVEL dataset\non the data for disentangling the country a city is   prompts for base and source inputs. We filtered\nin from the continent it is in.                      our dataset down to 40 cities, which can be used\n                                                       to generate 1600 interchange interventions target-\nFiltering  Following Huang et al. (2024), we fil-                                                  ing ‘country’ and 1600 interchange interventions\nter out all of the cities that GPT-2 small (Radford                                                        targeting ‘continent’ (3200 in total). We split the in-\net al., 2019) doesn’t know both the country and                                                   terchange intervention data so that 70% is training,\nthe continent. However, GPT-2 small is not a very                                    10% is validation, and 20% is test. Our evaluations\ncapable model, so we give five in context examples                                                     are i.i.d. to give SAEs the best chance at success.\nwhen evaluating the knowledge of the model:\n  “Toronto is a city in the country of Canada. Bei-   3.2  Constructing and Selecting Features\njing is a ... <city> is a city in the country of”\n                                            Sparse Autoencoders for Dictionary Learning\n  See Appendix A for the full 5-shot prompts. We\n                                                Sparse autoencoders (SAEs;Bricken et al. 2023;\nfurther filter out multi-token cities to simplify the\n                                         Cunningham  et  al. 2023) are a unsupervised\ntask and give the SAEs the best chance at success.\n                                          method for unpacking a hidden vector represen-\nThe resulting dataset contains 40 cities in total.\n                                                          tation into a higher dimensional, sparsely activated\nInterchange Interventions in Feature Space   If    feature space. The hope is that dimensions in this\na set of features contains the knowledge that   new feature space will correspond to interpretable\nToronto is in Canada, then fixing those features    concepts. SAEs used for this purpose typically\n\n\n                                         3\n\nhave an encoder with a linear transformation fol-      In particular, DAS learns an orthogonal matrix\nlowed by a ReLU and a linear decoder:       R that rotates a hidden vector h, with the dimen-\n                                                      sions of the rotated space Rh being the new feature\n                   ¯x = x −bx                                                   space, i.e. a set of features F are dimensions of\n           f = ReLU(We¯x + be)            Rh. We start by randomly initializing R, which\n                   ˆx = Wdf + bd                        renders all features equally meaningless. Then, an\n                                                  interchange intervention is performed on features\n  SAEs are optimized jointly to have low recon-  F with a base b and source s input prompt pair.\nstruction error and sparse representations:          Loss is computed from the output of the intervened\n            1                                 model:\n     L =  X ∥x −ˆx∥22 + λ ∥f∥1           |X|\n             x∈X\n                                     L = CE(MF←get(M,s,F)(b), y)Low reconstruction loss ensures that the features\nfaithful to the underlying hidden vector and low\n                                          The expected label y is determined by the concept\nsparsity loss is thought to create interpretable fea-\n                                                        that we are localizing in F and the mechanism\ntures. General purpose SAEs are trained on hidden\n                                          by which the concept determines behavior. See\nvector representations created by the model when\n                                                 Section 3.1 for a description of the interchange\nprocessing a enormous amount of text data, e.g., an\n                                                     intervention data. We provide details on hyperpa-\nSAE might be trained on residual stream represen-\n                                                  rameters in Appendix B.\ntations created by the second layer of a transformer\nprocessing the Pile (Gao et al., 2021).                Differential Binary Masking  In order to deter-\n  The Bloom SAE has this standard architecture   mine which features F to select for a given con-\nand training, but the other SAEs are variants. The    cept (‘country’ and ‘continent’ in our case), we\nOpen AI SAE is a top-k SAE, which (Gao et al.,   use Differential Binary Masking (DBM; De Cao\n2024) show to outperform the standard architecture    et al. 2020; Csordás et al. 2021; De Cao et al. 2022;\non the sparsity-reconstruction frontier. A top-k   Davies et al. 2023) to select features for interven-\nencoder is simply the standard encoder except only    tion.  Each feature f in the feature space F is\nthe top-k firing features are kept:                masked with a vector m which is passed into a\n                                               sigmoid σ after being scaled by a temperature T:\n        f = Topk(ReLU(We¯x + be))\n                                                                    fb = get(M, F, b)\n  The two Apollo SAEs have standard architec-\n                                                                 fs = get(M, F, s)ture, but they are trained with additional loss terms.\nThe Apollo SAE (e2e) is trained with the addi-         f = (1 −σ(m/T)) ⊙fb + σ(m/T) ⊙fs\ntional loss objective of the KL-divergence between\n                                            These masks are trained on an interchange inter-the output logits of the model before and after re-\n                                                  vention loss objective while the temperature is an-construction. The Apollo SAE (e2e + ds) has the\n                                                  nealed to make the masks snap to 0 or 1:logit-based loss in addition to a mean-squared error\nloss between the residual stream representations in\n                                       L = CE(MF←f(b), y)\ndownstream layers before and after reconstruction.\n(Braun et al., 2024) also report a praeto improve-                                   When we DBM with DAS, the features and the\nment on the sparsity-reconstruction trade off for                                           masks are learned simultaneosly.\nend-to-end models.\n                                       4  Experiments\nDistributed Alignment Search  SAEs are unsu-\npervised, so features must be further analyzed to de-   Our goal is to find a hidden vector representation\ntermine their conceptual content. In contrast, DAS    in GPT-2 small where the DAS skyline features are\n(Geiger et al., 2024b) learns linear features with    significantly better than the neuron baseline, and\nspecific conceptual content via supervision from    then evaluate whether SAEs are an improvement\ncounterfactual data that describes how a model   on neurons as a unit of analysis. For this reason, we\nshould act when a concept has been intervened    follow the lead of (Huang et al., 2023) and chose to\nupon. DAS features learned specifically for this    explore the residual stream representations of GPT-\ntask will be a skyline for general-purpose SAEs.     2 small above the <city> token in the early layers\n\n\n                                         4\n\nof the model. We implement our experiments with   have the highest reconstruction loss, the Apollo\nnnsight (Fiotto-Kaufman et al., 2024) and pytorch   SAE(e2e + ds) degrades the city-knowledge of\n(Paszke et al., 2019).                         GPT-2 small an amount that is comparable with\n                                       Open AI SAE and Bloom SAE. This is weak evi-\n4.1  Results                                   dence that the end-to-end objective was helpful for\nIn Figure 1a, we report the interchange intervention    preserving model capabilities.\naccuracy across the layers of GPT-2 small. In Fig-\n                                           There is a signifigant gap between baseline andures 1b and 1c, we present the detailed results for\n                                                   skyline; neurons can be improved upon.  Thelayers 1 and 5 of GPT-2 small, because the Apollo\n                                                    skyline provided by DAS at ≈95% accuracy forSAEs are available for those two layers. We learned\n                                                    the first 7 layers of GPT-2 small shows that there‘country’ features and ‘continent’ features, then we\n                                                      are separate linear subspaces that encode the coun-used interchange interventions on those features\n                                                          try a city is in and the continent a city is in. Thisto evaluate whether they, in fact, store the model’s\n                                               means, an SAE with linear features that span theseknowledge of the country and continent that a city\n                                                  subspaces could achieve performance equivalent tois in, respectively. When targeting ‘country’ fea-\n                                        DAS. The neuron baseline at ≈70% is significantlytures for intervention, the ‘country’ accuracy is\n                                             worse than the DAS skyline, and shows that therehigh when the intervention changes the output and\n                                                      are polysemantic neurons that need to be disentan-the ‘continent’ accuracy is high when the interven-\n                                                  gled by a rotation via an orthogonal matrix.tion does not change the model output. The oppo-\nsite is true for interventions on ‘continent’ features.                                            Current SAEs for GPT-2 small struggle to com-\nThe ‘disentangle score’ is the average of the two                                                pete with the neurons.  The two Apollo SAEs\naccuracies. In the middle three rows of the table are                                             and Bloom SAE below the neuron baseline across\nsparsity evaluations that report how many features                                                                   all layers. The ‘country’ and ‘continent’ knowledge\nwere active and/or intervened upon. In the final two                                                     are even more entangled in the feature spaces pro-\nrows of the table are reconstruction evaluations that                                                 vided by these SAEs. The Open AI SAE at ≈70%\nreport the knowledge degradation of GPT-2 small                                                                is able to match the performance of the neuron\nwhen a reconstructed vector is used and the aver-                                                       baseline, but not exceed it.\nage reconstruction loss on residual stream vectors\nabove the <city> token at a given layer.          The top-k SAE is the most performant.  Our\n                                                    evaluation is limited, however the results do seem\n4.2  Discussion                                                         to track improvements in SAEs. The Open AI SAE\nUsing representations reconstructed by SAEs     is a top k-SAE, which a performant architecture on\ndegrades the model’s knowledge of cities.  The    sparsity and reconstruction evaluations (Gao et al.,\nlast row in Figures 1b and 1c that using a represen-   2024). This is in line with our results that the Open\ntation reconstructed by an SAE always degrades   AI SAE is the only model that competes with the\nthe model’s knowledge of the countries and conti-   neuron baseline across all layers.\nnents that cities belong to. For the first layer, we\ncan see that the Bloom SAE and Apollo SAEe2e   5  Conclusion\nseverely harm the model (≈-50%) and the Apollo\n                                We evaluate open-source SAEs on their ability toSAE e2e+ds destroys the knowledge entirely. In\n                                                 provide a feature space for GPT-2 hidden repre-contrast, the Open AI SAE results in only a small\n                                                       sentations where knowledge about the country anddrop in performance (-5%). For the fifth layer, there\n                                                     continent a city is in can be disentangled. We used is less degradation, the Apollo SAE e2e+ds works,\n                                               neurons as a baseline feature space, and a super-and Open AI SAE is again the best.\n                                                   vised feature learned by DAS as a skyline feature\nThe end-to-end SAEs degrade knowledge less    space. While we were able to see meaningful dif-\nrelative to the reconstruction loss.  In our lim-   ferences in performance between the three SAEs,\nited evaluations, there is no evidence that end-to-   only one of the evaluated SAEs was able to reach\nend training used to create the two Apollo SAEs    the neuron baseline and none could reach the DAS\nwas helpful for providing a feature space where    skyline. We hope this is a useful step in evaluating\nknowledge can be disentangled. However, in the    the usefulness of SAEs for a causal interpretability\nlast two rows of Figure 1c we can see that despite    analysis of deep learning models.\n\n\n                                         5\n\nLimitations                                   Xander  Davies,  Max  Nadeau,  Nikhil  Prakash,\n                                                Tamar Rott Shaham, and David Bau. 2023.  Dis-\nIn future, we would like to scale the experiments      covering variable binding circuitry with desiderata.\nto models with available SAEs including gemma,       Preprint, arXiv:2307.03637.\nMistral, Llama, and Pythia. Furthermore, we hope\n                                                      Nicola De Cao, Michael Sejr Schlichtkrull, Wilker Aziz,\nto use more attributes from the RAVEL dataset,                                                  and Ivan Titov. 2020. How do decisions emerge\nsuch as language, gender, etc. for larger models       across layers in neural models? interpretation with\nwith more knowledge.                                      differentiable masking. In Proceedings of the 2020\n                                                     Conference on Empirical Methods in Natural Lan-\n                                                   guage Processing (EMNLP), pages 3243–3255, On-\n                                                                       line. Association for Computational Linguistics.References\n\nSteven   Bills,   Nick  Cammarata,  Dan  Moss-   Nicola De Cao, Leon Schmid, Dieuwke Hupkes, and\n   ing,  Henk  Tillman,  Leo  Gao,  Gabriel  Goh,      Ivan Titov. 2022. Sparse interventions in language\n   Ilya  Sutskever,   Jan  Leike,   Jeff  Wu,  and      models with differentiable masking. In Proceedings\n  William  Saunders.  2023.     Language  mod-       of the Fifth BlackboxNLP Workshop on Analyzing\n   els  can  explain  neurons  in  language  models.     and Interpreting Neural Networks for NLP, pages\n  https://openaipublic.blob.core.windows.         16–27, Abu Dhabi, United Arab Emirates (Hybrid).\n  net/neuron-explainer/paper/index.html.           Association for Computational Linguistics.\n\nJoseph Bloom. 2024. Open source sparse autoencoders    Joshua Engels, Isaac Liao, Eric J. Michaud, Wes Gurnee,\n   for all residual stream layers of gpt2 small.             and Max Tegmark. 2024. Not all language model\n                                                               features are linear. CoRR, abs/2405.14860.\nTolga Bolukbasi, Adam Pearce, Ann Yuan, Andy Co-\n   enen, Emily Reif, Fernanda Viégas, and Martin Wat-   Matthew  Finlayson,  Aaron  Mueller,   Sebastian\n   tenberg. 2021. An interpretability illusion for bert.     Gehrmann, Stuart Shieber, Tal Linzen, and Yonatan\n   Preprint, arXiv:2104.07143.                            Belinkov. 2021.   Causal  analysis of  syntactic\n                                                    agreement mechanisms in neural language models.\nDan Braun, Jordan Taylor, Nicholas Goldowsky-Dill,                                                          In Proceedings of the 59th Annual Meeting of\n  and Lee Sharkey. 2024. Identifying functionally im-                                                            the  Association  for  Computational  Linguistics\n   portant features with end-to-end sparse dictionary                                                 and the 11th International Joint Conference on\n   learning. Preprint, arXiv:2405.12241.                                                       Natural Language Processing (Volume 1:  Long\n                                                          Papers), pages 1828–1843, Online. Association for\nTrenton Bricken, Adly Templeton, Joshua Batson,                                                      Computational Linguistics.\n   Brian Chen, Adam Jermyn, Tom Conerly, Nick\n   Turner, Cem Anil, Carson Denison, Amanda Askell,                                                    Jaden Fiotto-Kaufman, Alexander R Loftus, Eric Todd,\n   Robert Lasenby, Yifan Wu, Shauna Kravec, Nicholas                                                        Jannik Brinkmann, Caden Juang, Koyena Pal, Can\n   Schiefer, Tim Maxwell,  Nicholas Joseph, Zac                                                        Rager, Aaron Mueller, Samuel Marks, Arnab Sen\n   Hatfield-Dodds, Alex Tamkin, Karina Nguyen, Bray-                                                   Sharma, Francesca Lucchetti, Michael Ripa, Adam\n  den McLean, Josiah E Burke, Tristan Hume, Shan                                                                Belfki, Nikhil Prakash, Sumeet Multani, Carla Brod-\n   Carter, Tom Henighan, and Christopher Olah. 2023.                                                                       ley, Arjun Guha, Jonathan Bell, Byron Wallace, and\n  Towards monosemanticity: Decomposing language                                                  David Bau. 2024. Nnsight and ndif: Democratiz-\n  models with dictionary learning. Transformer Cir-                                                         ing access to foundation model internals. Preprint,\n   cuits Thread.                                                        arXiv:2407.14561.\n\nNick Cammarata, Shan Carter, Gabriel Goh, Chris Olah,\n                                             Leo Gao, Stella Biderman, Sid Black, Laurence Gold-  Michael Petrov, Ludwig Schubert, Chelsea Voss, Ben\n                                                                ing, Travis Hoppe, Charles Foster, Jason Phang,  Egan, and Swee Kiat Lim. 2020. Thread: Circuits.\n                                                  Horace He, Anish Thite, Noa Nabeshima, Shawn   Distill. Https://distill.pub/2020/circuits.\n                                                               Presser, and Connor Leahy. 2021.  The pile: An\n                                                  800gb dataset of diverse text for language modeling.Róbert Csordás, Sjoerd van Steenkiste, and Jürgen\n                                               CoRR, abs/2101.00027.  Schmidhuber. 2021. Are neural nets modular? in-\n   specting functional modularity through differentiable\n  weight masks. In International Conference on Learn-   Leo Gao, Tom Dupré la Tour, Henk Tillman, Gabriel\n   ing Representations.                               Goh, Rajan Troll, Alec Radford, Ilya Sutskever, Jan\n                                                            Leike, and Jeffrey Wu. 2024. Scaling and evaluating\nHoagy Cunningham, Aidan Ewart, Logan Riggs, Robert       sparse autoencoders. CoRR, abs/2406.04093.\n  Huben, and Lee Sharkey. 2023. Sparse autoencoders\n   find highly interpretable features in language models.    Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep\n   Preprint, arXiv:2309.08600.                          Chaudhary, Sonakshi Chauhan, Jing Huang, Arya-\n                                            man Arora, Zhengxuan Wu, Noah Goodman, Christo-\nDamai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao      pher Potts, and Thomas Icard. 2024a.  Causal ab-\n  Chang, and Furu Wei. 2022. Knowledge neurons in       straction: A theoretical foundation for mechanistic\n   pretrained transformers. In acl.                              interpretability. Preprint, arXiv:2301.04709.\n\n\n                                         6\n\nAtticus Geiger, Hanson Lu, Thomas Icard, and Christo-     and Neel Nanda. 2024. Gemma scope: Open sparse\n  pher Potts. 2021. Causal abstractions of neural net-      autoencoders everywhere all at once on gemma 2.\n  works. In Advances in Neural Information Process-       Preprint, arXiv:2408.05147.\n   ing Systems 34: Annual Conference on Neural In-\n  formation Processing Systems 2021, NeurIPS 2021,   Aleksandar Makelov, George Lange, and Neel Nanda.\n  December 6-14, 2021, virtual, pages 9574–9586.         2024. Towards principled evaluations of sparse au-\n                                                         toencoders for interpretability and control. Preprint,\nAtticus Geiger, Kyle Richardson, and Christopher Potts.      arXiv:2405.08366.\n  2020.  Neural natural language inference models\n   partially embed theories of lexical entailment and   Samuel Marks, Can Rager, Eric J. Michaud, Yonatan\n   negation. In Proceedings of the Third BlackboxNLP      Belinkov, David Bau, and Aaron Mueller. 2024.\n  Workshop on Analyzing and Interpreting Neural Net-      Sparse feature circuits: Discovering and editing in-\n  works for NLP, pages 163–173, Online. Association       terpretable causal graphs in language models. CoRR,\n   for Computational Linguistics.                          abs/2403.19647.\n\nAtticus Geiger, Zhengxuan Wu, Christopher Potts,   James L. McClelland, David E. Rumelhart, and PDP Re-\n  Thomas Icard, and Noah D. Goodman. 2024b. Find-      search Group. 1986a. Parallel Distributed Process-\n   ing alignments between interpretable causal variables       ing, Volume 2: Explorations in the Microstructure\n  and distributed neural representations.  In Causal       of Cognition: Psychological and Biological Models.\n  Learning and Reasoning, 1-3 April 2024, Los Ange-     The MIT Press.\n   les, California, USA, volume 236 of Proceedings of\n                                                 James L. McClelland, David E. Rumelhart, and PDP Re-\n  Machine Learning Research, pages 160–187. PMLR.\n                                                         search Group. 1986b. Parallel Distributed Process-\n                                                                ing, Volume 2: Explorations in the MicrostructureMor Geva, Jasmijn Bastings, Katja Filippova, and Amir\n                                                               of Cognition: Psychological and Biological Models.  Globerson. 2023. Dissecting recall of factual associ-\n                                                The MIT Press.   ations in auto-regressive language models. Preprint,\n  arXiv:2304.14767.\n                                                 Kevin Meng, David Bau, Alex Andonian, and Yonatan\n                                                          Belinkov. 2022. Locating and editing factual associ-Mor Geva, Roei Schuster, Jonathan Berant, and Omer\n                                                             ations in GPT. In Advances in Neural Information  Levy. 2021.  Transformer feed-forward layers are\n                                                        Processing Systems 35: Annual Conference on Neu-   key-value memories. In emnlp.\n                                                               ral Information Processing Systems 2022, NeurIPS\nWes Gurnee, Neel Nanda, Matthew Pauly, Katherine      2022, New Orleans, LA, USA, November 28 - Decem-\n  Harvey, Dmitrii Troitskii, and Dimitris Bertsimas.      ber 9, 2022.\n  2023. Finding neurons in a haystack: Case studies\n                                                Kevin Meng, Arnab Sen Sharma, Alex J. Andonian,  with sparse probing. Preprint, arXiv:2305.01610.\n                                                    Yonatan Belinkov, and David Bau. 2023.  Mass-\nEvan Hernandez, Belinda Z Li, and Jacob Andreas.      editing memory in a transformer. In The Eleventh\n  2023. Measuring and manipulating knowledge rep-      International Conference on Learning Representa-\n   resentations in language models.  arXiv preprint        tions, ICLR 2023, Kigali, Rwanda, May 1-5, 2023.\n  arXiv:2304.00740.                                   OpenReview.net.\n\nEvan Hernandez, Sarah Schwettmann, David Bau,   Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel\n  Teona Bagashvili, Antonio Torralba, and Jacob An-      Marks, Koyena Pal, Nikhil Prakash, Can Rager,\n   dreas. 2022. Natural language descriptions of deep     Aruna Sankaranarayanan, Arnab Sen Sharma, Jiud-\n   visual features. In The Tenth International Confer-      ing Sun, Eric Todd, David Bau, and Yonatan Be-\n  ence on Learning Representations, ICLR 2022, Vir-       linkov. 2024. The quest for the right mediator: A\n   tual Event, April 25-29, 2022. OpenReview.net.            history, survey, and theoretical grounding of causal\n                                                                    interpretability. Preprint, arXiv:2408.01416.\nJing Huang,  Atticus Geiger, Karel D’Oosterlinck,\n  Zhengxuan Wu, and Christopher Potts. 2023. Rig-    Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel\n   orously assessing natural language explanations of      Goh,  Michael  Petrov,  and Shan  Carter. 2020.\n   neurons.  In Proceedings of the 6th BlackboxNLP     Zoom  in: An introduction to  circuits.    Distill.\n  Workshop: Analyzing and Interpreting Neural Net-       Https://distill.pub/2020/circuits/zoom-in.\n  works for NLP, BlackboxNLP@EMNLP 2023, Singa-\n                                      Adam Paszke, Sam Gross, Francisco Massa, Adam   pore, December 7, 2023, pages 317–331. Association\n                                                             Lerer, James Bradbury, Gregory Chanan, Trevor   for Computational Linguistics.\n                                                             Killeen, Zeming Lin, Natalia Gimelshein, Luca\nJing Huang, Zhengxuan Wu, Christopher Potts, Mor      Antiga, Alban Desmaison, Andreas Kopf, Edward\n  Geva, and Atticus Geiger. 2024. Ravel: Evaluating      Yang, Zachary DeVito, Martin Raison, Alykhan Te-\n   interpretability methods on disentangling language        jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\n  model representations. Preprint, arXiv:2402.17700.       Junjie Bai, and Soumith Chintala. 2019.  Pytorch:\n                                         An imperative style, high-performance deep learning\nTom Lieberum, Senthooran Rajamanoharan, Arthur        library. In Advances in Neural Information Process-\n  Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant       ing Systems 32, pages 8024–8035. Curran Associates,\n  Varma, János Kramár, Anca Dragan, Rohin Shah,       Inc.\n\n\n                                         7\n\nAlec Radford, Jeff Wu, Rewon Child, David Luan,  A  Evaluation Details\n  Dario Amodei, and Ilya Sutskever. 2019. Language\n  models are unsupervised multitask learners.         To enhance, the prediction capability of GPT-2 us-\n                                                  ing in-context learning, we use 5-shot prompt for\nSarah Schwettmann, Tamar Rott Shaham, Joanna\n                                                both the attributes.  Specifically, for country at-  Materzynska, Neil Chowdhury, Shuang Li, Jacob\n  Andreas, David Bau, and Antonio Torralba. 2023.    tribute, we prepare a template as: “Toronto is a city\n  FIND: A function description benchmark for evaluat-    in the country of Canada. Beijing is a city in the\n   ing interpretability methods. In Advances in Neural    country of China. Miami is a city in the country of\n  Information Processing Systems 36: Annual Confer-\n                                                     the United States. Santiago is a city in the country\n  ence on Neural Information Processing Systems 2023,\n  NeurIPS 2023, New Orleans, LA, USA, December 10    of Chile. London is a city in the country of England.\n   - 16, 2023.                                 <city> is a city in the country of”.\n                                                          Similarly, to support the prediction of continent,\nTamar Rott Shaham, Sarah Schwettmann, Franklin\n                                      we also prepare a similar template for the model as:  Wang, Achyuta Rajaram, Evan Hernandez, Jacob\n  Andreas, and Antonio Torralba. 2024.  A mul-  “Toronto is a city in the continent of North America.\n  timodal automated interpretability agent.  CoRR,   Beijing is a city in the continent of Asia. Miami is\n  abs/2404.14394.                             a city in the continent of North America. Santiago\nPaul Smolensky. 1988. On the proper treatment of     is a city in the continent of South America. London\n  connectionism.   Behavioral and Brain Sciences,    is a city in the continent of Europe. <city> is a\n  11(1):1–23.                                            city in the continent of”. The <city> is replaced\n                                               with the city name in the dataset to make severalAdly Templeton, Tom Conerly, Jonathan Marcus, Jack\n   Lindsey, Trenton Bricken, Brian Chen, Adam Pearce,   samples to make the data for both the country and\n   Craig Citro, Emmanuel Ameisen, Andy Jones, Hoagy    continent attributes.\n  Cunningham, Nicholas L Turner, Callum McDougall,                                                       Eventually, we prepare the final dataset consist-\n  Monte MacDiarmid, C. Daniel Freeman, Theodore R.\n                                                  ing of base and source sentences, with their corre-  Sumers, Edward Rees, Joshua Batson, Adam Jermyn,\n  Shan Carter, Chris Olah, and Tom Henighan. 2024.   sponding labels to evaluate different techniques. In\n   Scaling monosemanticity: Extracting interpretable   each example, either the ‘country’ is targeted for\n   features from claude 3 sonnet. Transformer Circuits    intervention or the ‘continent’ is. When a prompt\n  Thread.\n                                                               is for targeted attribute, the intervention should\nJesse Vig, Sebastian Gehrmann, Yonatan Belinkov,   change the output to match the source city. When\n  Sharon Qian, Daniel Nevo, Yaron Singer, and Stu-   the prompt is for the other attribute, the interven-\n   art M. Shieber. 2020. Investigating gender bias in                                                       tion should not change the output.\n  language models using causal mediation analysis.\n   In Advances in Neural Information Processing Sys-\n                              B  Hyperparameters and Compute  tems 33: Annual Conference on Neural Information\n  Processing Systems 2020, NeurIPS 2020, December\n                                We  used  these  parameters  for DBM  and\n   6-12, 2020, virtual.\n                               DBM+DAS training. Batch size of 16. Tempera-\n                                                      ture is annealed linearly from 10 to 0.1. Training\n                                          was for 20 epochs. Learning rate is 0.001.\n                               A masking experiment takes 1 hour approx to\n                                                       run. Three layers had 4 experiments with a run for\n                                                       for each intervention so 4*2 experiments. Layer 1\n                                              had a total of 6 experiments with two interventions\n                                                   each. Total time: 1x3x4x2 + 1x6x2 = 36 hours on\n                                                 a 24GB Nvidia RTX A5000\n\n                           C  Full Reconstruction Evaluation\n\n                                            See Tables 1 and 2 for the reconstruction evalua-\n                                                       tions done across all the layers.\n\n                           D  Training Graphs\n\n                                             See Figures 2a and 3a for the training graphs.\n\n\n\n\n                                         8\n\n   Layers   Bloom SAE  Bloom SAE  OpenAI SAE  OpenAI SAE  Apollo SAE  Apollo SAE    Apollo SAE      Apollo SAE\n              Country     Continent      Country       Continent      Country      Continent   e2e+ds Country  e2e+ds Continent\n  Layer 0     400.87       413.03        102.91         104.2               -                 -                   -                       -\n  Layer 1     551.28        516.5        151.83        158.03       2245.57      2307.15        2129.71          2123.09\n  Layer 2     698.25       681.64        217.13        219.78              -                 -                   -                       -\n  Layer 3     876.36       814.99        330.43        336.34              -                 -                   -                       -\n  Layer 4     890.41       869.71        449.33        458.82              -                 -                   -                       -\n  Layer 5     936.77      1044.33       643.82        651.67       2383.14      2576.08        2353.61          2318.49\n  Layer 6     1178.01      1531.46       839.68        837.81              -                 -                   -                       -\n  Layer 7     4640.78      7757.06      1218.99       1211.81             -                 -                   -                       -\n  Layer 8    19556.78     26810.38      1727.77       1723.93             -                 -                   -                       -\n  Layer 9    27877.84     36537.93      2304.84       2311.26       5276.6       6038.87        2569.59           2665.5\n  Layer 10   532812.74    571233.39     3296.77       3467.73             -                 -                   -                       -\n  Layer 11   846887.04    859555.3      4833.99       4893.55             -                 -                   -                       -\n\nTable 1: The table above denotes the reconstruction loss for country and continent dataset separately for each SAE.\n\n\n\n\n   Layers       Bloom SAE      Bloom SAE     OpenAI SAE     OpenAI SAE       Apollo SAE       Apollo SAE        Apollo SAE          Apollo SAE\n                  Country          Continent         Country          Continent          Country          Continent       e2e+ds Country      e2e+ds Continent\n  Layer 0          0.9375           0.890625   0.9642857142857143    0.9609375                  -                       -                        -                            -\n  Layer 1          0.5625           0.46875    0.9464285714285714    0.9453125   0.6696428571428571   0.3515625   0.008928571428571428          0.0\n  Layer 2   0.5267857142857143    0.5390625   0.9553571428571429    0.9140625                  -                       -                        -                            -\n  Layer 3   0.7142857142857143     0.78125    0.9196428571428571    0.890625                  -                       -                        -                            -\n  Layer 4   0.7946428571428571    0.8984375   0.9196428571428571      0.875                     -                       -                        -                            -\n  Layer 5   0.7678571428571429    0.859375           0.875          0.8984375   0.8392857142857143   0.7578125    0.8303571428571429       0.609375\n  Layer 6   0.7946428571428571     0.78125           0.8125          0.7421875                  -                       -                        -                            -\n  Layer 7           0.875           0.765625   0.7857142857142857    0.703125                  -                       -                        -                            -\n  Layer 8   0.8571428571428571    0.7578125   0.8571428571428571    0.8984375                  -                       -                        -                            -\n  Layer 9   0.6696428571428571    0.5078125   0.9107142857142857    0.9609375   0.9464285714285714   0.9453125            0.875               0.90625\n  Layer 10  0.23214285714285715    0.03125    0.9732142857142857    0.9765625                  -                       -                        -                            -\n  Layer 11            1.0                 1.0                1.0                 1.0                      -                       -                        -                            -\n\n Table 2: The table above denotes the accuracy for country and continent dataset after intervention for each SAE\n\n\n\n\n\n(a) Training graphs for Layer 1 depict the results for both country and continent interventions. The country-intervened data is\nrepresented with dashed lines, while continent-intervened data is shown with bold lines, using the same color scheme as defined\nin the legend above the graph. The plots illustrate the training accuracy and loss for Neuron Masking, SAE Apollo e2e, SAE\nApollo e2e+ds, OpenAI SAE, and Bloom SAE with DAS.\n\n\n\n\n\n(a) Training graphs for Layer 5 depict the results for both country and continent interventions. The country-intervened data is\nrepresented with dashed lines, while continent-intervened data is shown with bold lines, using the same color scheme as defined\nin the legend above the graph. The plots illustrate the training accuracy and loss for Neuron Masking, SAE Apollo e2e, SAE\nApollo e2e+ds, OpenAI SAE, and Bloom SAE with DAS.\n\n\n\n                                         9\n\n## Claim to Classify\n\"sets of SAE features that separately mediate knowledge of which country a city is in\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "Interchange intervention on SAE features using Differential Binary Masking (DBM)",
    "method_rung": 2,
    "claim_rung": 2,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The method uses interchange interventions (patching) to measure the effect of specific feature sets on model output, which is a Rung 2 interventional method. The claim uses the term 'mediate', which is the specific linguistic marker for Rung 2 causal claims according to the codebook. Therefore, the claim is perfectly calibrated to the method."
  },
  "metadata": {
    "model": "google/gemini-3-flash-preview",
    "usage": {
      "prompt_tokens": 17345,
      "completion_tokens": 141,
      "total_tokens": 17486
    },
    "finish_reason": "stop"
  }
}