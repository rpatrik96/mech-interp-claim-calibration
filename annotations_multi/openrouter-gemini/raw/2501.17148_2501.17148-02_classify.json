{
  "timestamp": "2026-02-19T09:27:30.133802+00:00",
  "paper_id": "2501.17148",
  "claim_id": "2501.17148-02",
  "mode": "classify",
  "prompt": {
    "system": "You are an expert annotation assistant for a mechanistic interpretability research study.\nYour task is to annotate empirical claims from ML papers following a structured codebook.\nFollow the codebook instructions exactly. Apply the decision rules for edge cases, including the decision trees for polysemous terms.\nRate your confidence honestly on the 1-5 scale.",
    "user": "## Annotation Codebook\n# H2 Pilot Study Codebook\n## Annotation Guidelines for Testing \"Rung-Appropriate Claims Predict Reproducibility\"\n\n---\n\n## Overview\n\nFor each paper in the sample, extract **all empirical claims** about model internals and annotate:\n1. What method was used (determines method_rung)\n2. What the paper claims (determines claim_rung)\n3. Whether claim_rung > method_rung (overclaiming)\n\n---\n\n## Field Definitions\n\n### paper_id\n- arXiv ID or venue-year-title abbreviation\n- Example: \"2202.05262\" or \"NeurIPS2022-ROME\"\n\n### claim_id\n- Unique identifier within paper: paper_id + sequential number\n- Example: \"2202.05262-01\", \"2202.05262-02\"\n\n### claim_text\n- **Verbatim quote** from the paper\n- Include enough context to understand the claim\n- Use ellipsis [...] for long quotes\n\n### claim_location\n- Where in the paper: abstract, introduction, methods, results, discussion, conclusion\n\n### claim_prominence\n- **3** = Abstract or title claim (highest visibility)\n- **2** = Introduction contribution list or conclusion claim\n- **1** = Body text claim (methods, results, discussion)\n\n---\n\n## Method Rung Classification\n\n### Rung 1: Observational/Associational\nMethods that establish **correlational evidence only**. No intervention on the model.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Linear probing | Train classifier on frozen activations | \"Probe accuracy of 85%\" |\n| Activation logging | Record activations without intervention | \"Feature X activates on...\" |\n| SAE feature attribution | Identify which SAE features activate | \"Feature 4123 fires on...\" |\n| Attention visualization | Inspect attention weights | \"Attention concentrates on...\" |\n| PCA/SVD | Dimensionality reduction analysis | \"First PC correlates with...\" |\n| Correlation analysis | Statistical associations | \"r=0.7 between activation and...\" |\n\n### Rung 2: Interventional\nMethods that establish **causal effects under specific interventions**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Activation patching | Replace activation, measure effect | \"Patching head 9.1 restores 80%...\" |\n| Causal tracing | Systematic patching across positions | \"Layer 15 shows highest causal effect\" |\n| Ablation | Zero/mean out components | \"Ablating heads reduces accuracy by 40%\" |\n| Steering vectors | Add direction, observe output change | \"Adding v shifts sentiment...\" |\n| DAS interchange | Swap aligned subspaces | \"IIA of 0.92 on agreement task\" |\n| ROME/MEMIT edits | Modify weights, observe change | \"After edit, model outputs...\" |\n\n### Rung 3: Counterfactual\nMethods that establish **what would have happened** or **unique mechanisms**.\n\n| Method | Description | Example Evidence |\n|--------|-------------|------------------|\n| Counterfactual patching | Per-instance counterfactual | \"For THIS prompt, had activation been X...\" |\n| Causal scrubbing | Test if mechanism fully explains | \"Scrubbing preserves behavior\" |\n| Necessity tests | Show component is necessary | \"No alternative achieves same behavior\" |\n| Uniqueness proofs | Demonstrate unique structure | \"This is THE circuit\" |\n\n---\n\n## Claim Rung Classification\n\n### Rung 1 Linguistic Markers (Associational Claims)\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"co-occurs with\"\n- \"information is present,\" \"is decodable from\"\n- \"can be extracted,\" \"activates on,\" \"fires when\"\n\n**Examples:**\n- \"Sentiment information is linearly decodable from layer 6\"\n- \"The feature correlates with Python code inputs\"\n- \"Probe accuracy predicts model behavior\"\n\n### Rung 2 Linguistic Markers (Causal Claims)\n- \"causally affects,\" \"has causal effect on\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce,\" \"enables\"\n- \"intervening on X changes Y\"\n- \"ablating X degrades Y\"\n\n**Examples:**\n- \"Head 9.1 causally affects the output\"\n- \"This component is sufficient for the behavior\"\n- \"Ablating these heads degrades performance\"\n\n### Rung 3 Linguistic Markers (Mechanistic/Counterfactual Claims)\n- \"encodes,\" \"represents,\" \"computes,\" \"performs\"\n- \"THE mechanism,\" \"THE circuit,\" \"THE feature\" (uniqueness)\n- \"controls,\" \"is responsible for,\" \"underlies\"\n- \"this head DOES X\" (functional attribution)\n- \"the model uses X to do Y\" (mechanistic narrative)\n\n### Decision Trees for Polysemous Terms\n\n#### \"encodes\" / \"represents\" / \"stores\"\n1. Does the paper provide interventional evidence for this claim?\n   - **NO** → Does context make clear the author means \"is linearly decodable from\"?\n     - YES → Code as **R1**. Note: \"encodes used in decodability sense\"\n     - NO → Code as **R3** (default mechanistic reading)\n   - **YES** → Is the claim about the intervention's *result* (what changed) or the underlying *mechanism* (how it works)?\n     - Result → Code as **R2**\n     - Mechanism → Code as **R3**\n\n#### \"the circuit\" / \"the mechanism\" / \"the algorithm\"\n1. Does the paper test uniqueness (e.g., show no alternative circuit exists)?\n   - **YES** → Code as **R3**\n   - **NO** → Is \"the\" a naming convention (referring to the circuit they found) or a uniqueness claim?\n     - If qualifications exist elsewhere in the paper → Code as **R3**, add note: \"definite article likely naming convention; qualification at [location]\"\n     - If no qualifications → Code as **R3**\n\n#### \"controls\" / \"is responsible for\"\n1. Is the evidence from an intervention (ablation, patching, steering)?\n   - **YES** → Does the paper claim the component is the *unique* controller?\n     - YES → Code as **R3**\n     - NO → Code as **R2** (causal sufficiency, not uniqueness)\n   - **NO** → Code as **R3** (mechanistic claim without interventional support)\n\n**Examples:**\n- \"The model **encodes** subject-verb agreement in this subspace\"\n- \"These heads **perform** the IOI task\"\n- \"**The circuit** moves names from subject to output\"\n- \"This feature **represents** the concept of deception\"\n- \"The model **uses** these components to track entities\"\n\n---\n\n## Overclaim Patterns (Common)\n\n| Pattern | Method Used | Typical Claim | Gap |\n|---------|-------------|---------------|-----|\n| Probing → \"encodes\" | Linear probe (R1) | \"Model encodes X\" (R3) | +2 |\n| Patching → \"THE circuit\" | Activation patching (R2) | \"This is the circuit\" (R3) | +1 |\n| Steering → \"controls\" | Steering vectors (R2) | \"Controls concept X\" (R3) | +1 |\n| SAE → \"represents\" | SAE attribution (R1) | \"Model represents X\" (R3) | +2 |\n| Attention → \"performs\" | Attention viz (R1) | \"Head performs X\" (R3) | +2 |\n| Ablation → \"necessary\" | Ablation (R2) | \"Necessary for behavior\" (R3) | +1 |\n\n---\n\n## Hedge Flag\n\n### hedge_flag\n- **1** = Claim contains an explicit hedge (e.g., \"may,\" \"suggests,\" \"potentially,\" \"we hypothesize\")\n- **0** = No hedge present; claim is stated as established fact\n\nRecord hedging separately from confidence. A claim can be high-confidence R3 *with* a hedge (the annotator is confident the claim is R3, and the author hedged it).\n\n---\n\n## Confidence Scoring\n\nRate your confidence in the rung assignments (1-5):\n- **5** = Very confident, clear case\n- **4** = Confident, minor ambiguity\n- **3** = Moderately confident, some ambiguity\n- **2** = Low confidence, significant ambiguity\n- **1** = Very uncertain, edge case\n\nDocument ambiguous cases in the notes field.\n\n---\n\n## Replication Status\n\n### Coding\n- **0** = Successfully replicated (all main claims hold)\n- **0.5** = Partially replicated (some claims hold, others fail)\n- **1** = Failed replication (main claims do not hold)\n- **NA** = No replication attempt found\n\n### Evidence Sources (in priority order)\n1. Published replication studies\n2. Replication sections in subsequent papers\n3. GitHub issues documenting failures\n4. Author corrections/errata\n5. BlackboxNLP reproducibility track\n\n---\n\n## Annotation Process\n\n1. **Read abstract and introduction** - identify main claims\n2. **Identify methods used** - classify each method's rung\n3. **For each claim:**\n   - Quote verbatim\n   - Identify linguistic markers\n   - Assign claim_rung based on markers\n   - Calculate gap_score\n   - Assign confidence\n4. **Search for replication evidence** - cite sources\n5. **Document edge cases** in notes\n\n---\n\n## Edge Cases and Guidance\n\n### Hedged Claims\n- \"may encode\" → still Rung 3 if followed by mechanistic narrative\n- \"suggests that\" → code based on the underlying claim, not the hedge\n- Note hedging in confidence score\n\n### Multiple Methods\n- If paper uses multiple methods, code each claim-method pair separately\n- Use the method that directly supports each specific claim\n\n### Implicit Claims\n- Code both explicit and implicit claims\n- Implicit claims from narrative framing should be noted\n- Weight implicit claims lower in confidence\n\n### Review/Survey Papers\n- Code as NA for replication (not empirical)\n- Still useful for method classification reference\n\n---\n\n## Calibration Cases\n\n### Ground Truth: IOI Circuit Paper (Wang et al., 2022)\n- **Method:** Activation patching (Rung 2)\n- **Claim:** \"The circuit\" (implies uniqueness, Rung 3)\n- **Overclaim:** +1\n- **Known issue:** Different ablation strategies yield different circuits\n\nUse this as calibration anchor for Rung 2→3 overclaiming pattern.\n\n\n## Calibration Examples\n# Calibration Set Rationales\n\n## Overview\n\nThis document provides detailed rationales for the 5 calibration papers, serving as anchor examples for consistent annotation of the remaining papers.\n\n---\n\n## Paper 1: IOI Circuit (2211.00593) - PRIMARY CALIBRATION ANCHOR\n\n**Wang et al., \"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Path patching (activation patching variant)\n- **Supporting methods:** Attention pattern analysis (R1), ablation (R2)\n- **Rationale:** The paper's core evidence comes from causal interventions that measure effects of patching activations. This establishes causal sufficiency but not counterfactual necessity/uniqueness.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"performs IOI task\" | \"performs\" = functional | +1 (R2→R3) |\n| \"Name Movers move names\" | \"move\" = mechanistic | +1 (R2→R3) |\n| \"S-Inhibition heads inhibit\" | \"inhibit\" = functional | +1 (R2→R3) |\n| \"the circuit\" | definite article = uniqueness | +1 (R2→R3) |\n| \"reverse-engineering\" | implies complete mechanism | +1 (R2→R3) |\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:** Different ablation strategies (mean ablation vs. zero ablation vs. resample ablation) yield different circuits\n- **Evidence:** Zhang et al. (2024), Conmy et al. (2023) ACDC paper notes\n- **Implication:** The \"circuit\" found depends on methodological choices, undermining uniqueness claims\n\n### Calibration Lesson\nThe IOI paper is the canonical example of **Rung 2 → Rung 3 overclaiming** via:\n1. Using definite articles (\"THE circuit\")\n2. Functional verbs (\"moves,\" \"inhibits,\" \"performs\")\n3. Mechanistic narratives (\"reverse-engineering the algorithm\")\n\n**Use this pattern to identify similar overclaims in other circuit-discovery papers.**\n\n---\n\n## Paper 2: ROME (2202.05262)\n\n**Meng et al., \"Locating and Editing Factual Associations in GPT\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Causal tracing (activation patching on corrupted inputs)\n- **Secondary method:** ROME editing (weight modification)\n- **Rationale:** Both methods involve interventions but establish causal effects, not mechanisms.\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"storing factual associations\" | \"storing\" = memory mechanism | +1 (R2→R3) |\n| \"correspond to localized computations\" | \"correspond\" = identity claim | +1 (R2→R3) |\n| \"stored in a localized manner\" | \"stored\" + \"localized\" | +1 (R2→R3) |\n\n### Appropriate Claims (No Overclaim)\n- \"mediate factual predictions\" - \"mediate\" is proper R2 language\n- \"ROME is effective\" - empirical claim matched to method\n\n### Replication Status: PARTIAL (0.5)\n- **Known issues:**\n  - Hase et al. (2023) \"Does Localization Imply Representation?\" questions causal tracing interpretation\n  - ROME edits have side effects on related knowledge\n  - Localization claims sensitive to prompt variations\n- **Implication:** Causal effects real, but \"storage\" interpretation overclaims\n\n### Calibration Lesson\nStorage/memory language (\"stores,\" \"encodes,\" \"contains\") typically implies Rung 3 mechanistic claims. Causal tracing only establishes causal mediation (R2), not storage mechanisms.\n\n---\n\n## Paper 3: Grokking (2301.05217)\n\n**Nanda et al., \"Progress measures for grokking via mechanistic interpretability\"**\n\n### Method Classification: Rung 2 (Interventional)\n- **Primary method:** Ablation in Fourier space\n- **Supporting methods:** Weight analysis (R1), activation analysis (R1)\n- **Rationale:** Ablation establishes causal necessity of Fourier components\n\n### Key Overclaim Patterns Identified\n\n| Claim | Linguistic Marker | Method-Claim Gap |\n|-------|------------------|------------------|\n| \"fully reverse engineer\" | completeness claim | +1 (R2→R3) |\n| \"the algorithm\" | definite article = uniqueness | +1 (R2→R3) |\n| \"uses DFT... to convert\" | functional mechanism | +1 (R2→R3) |\n| \"encoded in the weights\" | from weight analysis alone | +2 (R1→R3) |\n\n### Replication Status: REPLICATED (0)\n- **Strong replication:** Multiple groups have confirmed the Fourier structure\n- **Why different from IOI?**\n  - Simpler, controlled setting (synthetic task)\n  - Algorithm structure mathematically constrained\n  - Predictions verified through multiple methods\n\n### Calibration Lesson\nEven well-replicated papers can have overclaims at the linguistic level. The grokking claims are less problematic because:\n1. Multiple methods converge\n2. Mathematical structure constrains possibilities\n3. Authors make specific testable predictions\n\n**Pattern:** Small overclaim gap + strong replication = less concern\n\n---\n\n## Paper 4: SAE Evaluation (2409.04478)\n\n**Chaudhary & Geiger, \"Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge\"**\n\n### Method Classification: Mixed Rung 1-2\n- **Primary method:** SAE feature attribution (R1)\n- **Evaluation method:** Interchange intervention (R2)\n- **Rationale:** Paper evaluates R1 method using R2 evaluation\n\n### Claim Analysis\nThis paper is methodologically careful and largely avoids overclaiming:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"SAEs struggle to reach baseline\" | R2 | Appropriate for intervention evidence |\n| \"features that mediate knowledge\" | R2 | \"mediate\" matches intervention method |\n| \"useful for causal analysis\" | R2 | Claims about causal utility, not mechanism |\n\n### Replication Status: REPLICATED (0)\n- Paper is itself an evaluation/replication study\n- Findings consistent with other SAE evaluations (Marks et al., Engels et al.)\n\n### Calibration Lesson\n**Evaluation papers** tend to have lower overclaim rates because:\n1. Explicit comparison to baselines/skylines\n2. Focus on method utility, not mechanism claims\n3. Negative results naturally cautious\n\n**Pattern:** Papers that evaluate methods rather than discover mechanisms tend to have better claim-method alignment.\n\n---\n\n## Paper 5: Gemini Probes (2601.11516)\n\n**Kramár et al., \"Building Production-Ready Probes For Gemini\"**\n\n### Method Classification: Rung 1 (Observational)\n- **Primary method:** Linear probing\n- **Rationale:** Probing is purely observational/correlational\n\n### Claim Analysis\nThis paper is well-calibrated to its method:\n\n| Claim | Rung | Notes |\n|-------|------|-------|\n| \"probes may be promising\" | R1 | Hedged, correlational |\n| \"probes fail to generalize\" | R1 | Empirical observation |\n| \"successful deployment\" | R1 | Outcome claim, not mechanism |\n\n### Overclaim Analysis\nNo significant overclaims detected. The paper:\n- Uses appropriate hedging (\"may be\")\n- Focuses on empirical performance, not mechanisms\n- Does not claim probes \"detect\" or \"identify\" internal states (which would be R3)\n\n### Replication Status: NA\n- Production paper, not standard academic replication context\n\n### Calibration Lesson\n**Production/applied papers** focused on probe performance tend to have appropriate claim levels because:\n1. Focus on external validity (does it work?)\n2. Less incentive for mechanistic narratives\n3. Engineering framing vs. science framing\n\n---\n\n## Summary: Overclaim Patterns by Paper Type\n\n| Paper Type | Typical Overclaim | Example |\n|------------|------------------|---------|\n| Circuit discovery | \"THE circuit\" + functional verbs | IOI |\n| Knowledge localization | \"stores,\" \"encodes\" | ROME |\n| Algorithm analysis | \"reverse-engineer,\" \"the algorithm\" | Grokking |\n| Method evaluation | Low overclaim (comparative) | SAE Eval |\n| Production/applied | Low overclaim (empirical focus) | Gemini Probes |\n\n## Key Linguistic Markers Summary\n\n### Rung 3 (Mechanistic) - Watch for:\n- \"encodes,\" \"represents,\" \"stores,\" \"contains\"\n- \"performs,\" \"computes,\" \"executes,\" \"implements\"\n- \"THE circuit/mechanism/algorithm\" (uniqueness)\n- \"uses X to do Y\" (mechanistic narrative)\n- \"is responsible for,\" \"controls,\" \"underlies\"\n\n### Rung 2 (Causal) - Appropriate for interventions:\n- \"causally affects,\" \"has causal effect\"\n- \"mediates,\" \"influences\"\n- \"is sufficient for,\" \"can produce\"\n- \"intervening on X changes Y\"\n\n### Rung 1 (Correlational) - Appropriate for probing/attribution:\n- \"correlates with,\" \"is associated with\"\n- \"predicts,\" \"is decodable from\"\n- \"activates on,\" \"fires when\"\n- \"information is present\"\n---\n\n## Inter-Annotator Calibration Notes\n\nFor the pilot study (single annotator), use these decision rules:\n\n1. **When in doubt about claim_rung:**\n   - Check for functional verbs (performs, computes) → R3\n   - Check for uniqueness language (the, only) → R3\n   - Check for storage/encoding language → R3\n\n2. **When in doubt about method_rung:**\n   - If no intervention on model → R1\n   - If intervention but not per-instance counterfactual → R2\n   - If establishes unique/necessary mechanism → R3\n\n3. **Edge cases:**\n   - Hedged R3 claims (\"may encode\") → still R3, note hedge in confidence\n   - Multi-method papers → use highest-rung method that directly supports claim\n   - Implicit claims from narrative → code but weight lower in confidence\n\n\n## Paper Context\nPaper ID: 2501.17148\nTitle: AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders\nFull text:\n                AXBENCH: Steering LLMs? Even Simple Baselines\n                         Outperform Sparse Autoencoders\n\n\n\n                    Zhengxuan Wu * 1 Aryaman Arora * 1  Atticus Geiger 2 Zheng Wang 1 Jing Huang 1\n                          Dan Jurafsky 1 Christopher D. Manning 1 Christopher Potts 1\n\n\n                         Abstract                                                 1.00                      Prompt\n\n               Fine-grained steering of language model outputs\n                                                                                 LoReFT2025                   is essential for safety and reliability. Prompting                      0.75                                                                                                                      SFT*\n                                                                                                          Type             and finetuning are widely used to achieve these                                       (Overall)\n                                                                        LoRA                                    Prompt                goals, but interpretability researchers have pro-\n                                                                                                                  0.50                         ReFT-r1        SAEMar        posed a variety of representation-based techniques                                                                                                                                                                                                                            steering3         as well, including sparse autoencoders (SAEs),                                                         SDL                                                                                                      DiffMean\n                 linear artificial tomography, supervised steering                      0.25      SAE\n                                                                                    SAE-A                 vectors, linear probes, and representation finetun-                     Model      PCA\n                                                                                                      Probe                 ing. At present, there is no benchmark for mak-                    LAT                                                                                        SSV                                                                                                                  0.00\n               ing direct comparisons between these proposals.\n                                                                                    0.6     0.7     0.8     0.9     1.0                Therefore, we introduce AXBENCH, a large-scale\n                                                                                    Concept detection (AUROC)[cs.CL]        benchmark for steering and concept detection, and\n                report experiments on Gemma-2-2B and 9B. For                                                                   Figure 1: Average results across eight tasks on C concept\n                 steering, we find that prompting outperforms all                                                                          detection (0–2) vs. S model steering (0–2) for all methods\n                existing methods, followed by finetuning. For                                                            on AXBENCH. *Only evaluated on Gemma-2-2B.\n               concept detection, representation-based methods\n              such as difference-in-means, perform the best. On\n              both evaluations, SAEs are not competitive. We                                                                             limitations: circumvention via jailbreaks and continued\n               introduce a novel weakly-supervised representa-                                                                              training, reliance on dataset quality, and uninterpretabil-\n                 tional method (Rank-1 Representation Finetun-                                                                                   ity (Anwar et al., 2024). Interpretability researchers have\n                 ing; ReFT-r1), which is competitive on both tasks                                                                      thus proposed a new class of representation-based inter-\n              while providing the interpretability advantages                                                                     ventions for steering LMs, which hope to address these\n                 that prompting lacks. Along with AXBENCH, we                                                                             issues. These methods include learning steering vectors\n                 train and publicly release SAE-scale feature dic-                                                             from small labelled datasets, self-supervised sparse autoen-\n                 tionaries for ReFT-r1 and DiffMean.                                                                      coders (SAEs), among other techniques. Since steering may\n                                                                      enable lightweight and interpretable control over model out-arXiv:2501.17148v3             https://github.com/stanfordnlp/axbench\n                                                                             puts, it has emerged as a potential alternative to finetuning\n                                                              and prompting (see §2).\n\n          1. Introduction                                          Unfortunately, Pres et al. (2024); Braun et al. (2024) note\n                                                                              that existing benchmarks for steering only evaluate a few\n           In order to be useful, language models (LMs) must fol-   methods at merely toy scales. To assess whether representa-\n         low user instructions and be aligned to human goals and     tion steering is a viable alternative to existing model control\n           values. While prompting and finetuning are now widely    techniques, we need to evaluate it in a more realistic setting,\n          used to instill such behaviour in LMs, both methods have     e.g. over open-vocabulary concepts and on long-form gener-\n                                                                                 ation, and compare it to prompting and finetuning baselines.             *Equal contribution 1Department of Computer Science, Stan-\n            ford University 2Pr(AI)2R Group. Correspondence to: Zhengx-                                                                      In this work, we introduce AXBENCH, a benchmark for\n          uan Wu <wuzhengx@cs.stanford.edu>,  Aryaman  Arora\n                                                                          evaluating LM control methods at scale using synthetic data.          <aryaman@cs.stanford.edu>.\n                                              AXBENCH takes in a list of natural language descriptions\n             Preprint.                                                    of concepts and samples relevant training and evaluation\n\n                                                         1\n\n                                   AXBENCH\n\ndata from an LLM. We evaluate model-control methods,    fixed directions, is one such intervention-based tool for\nincluding prompting and finetuning baselines, along two    model control (Zou et al., 2023; Li et al., 2024; Turner et al.,\nutility axes: concept detection C and model steering S .    2024; Marks and Tegmark, 2024; Liu et al., 2024; van der\nFor the former, we use labelled synthetic data as ground    Weij et al., 2024; Rimsky et al., 2024). Finetuning-based\ntruth; for the latter, we evaluate long-form generations using    approaches such as ReFT (Wu et al., 2024a) enable optimi-\nan LLM judge. The labelled training data enables com-    sation of steering directions on a dataset. Steering vectors\nparison between supervised dictionary-learning methods    need not be computed from labelled data; SAEs enable scal-\n(SDLs) and unsupervised methods like SAEs. The bench-    able discovery of steering vectors from unlabelled data. In\nmark includes tasks generated from SAE concept lists for    the same class of approaches, latent adversarial training\nGemmaScope (Lieberum et al., 2024), covering two layers    (Casper et al., 2024) and circuit breakers (Zou et al., 2024)\neach from instruction-tuned Gemma-2-2B and Gemma-2-9B    are representation-based control methods that increase the\n(Gemma Team et al., 2024). However, AXBENCH is by    adversarial robustness of LLMs.\nnature extensible to arbitrary concept descriptions: we in-\ntend to add new evaluation tasks as better feature-labelling    Sparse autoencoders.  Sparse autoencoders (SAEs) aim\ntechniques and new approaches to steering emerge.            to enable self-supervised and thus scalable decomposition\n                                                             of the representation space into meaningful concepts (Tem-We evaluate a variety of steering methods—including a\n                                                            pleton et al., 2024; Chalnev et al., 2024; Makelov, 2024;novel weakly-supervised method we introduce, ReFT-r1—\n                                                     O’Brien et al., 2024; Gao et al., 2024). SAEs are trainedalong with prompting, full finetuning, and two parameter-\n                                                                to reconstruct LLM hidden representations in a higher-efficient finetuning methods (LoRA and LoReFT). On steer-\n                                                        dimensional latent space with a sparsity penalty, based oning, only ReFT-r1 is competitive with finetuning and prompt-\n                                                              the assumption that concepts must be represented sparselying baselines, while SAEs fall behind both ReFT-r1 and\n                                                                in order to prevent interference. The latents are then la-difference-in-means (Marks and Tegmark, 2024) on both\n                                                             belled with natural-language descriptions using automaticaxes. While representation steering methods largely lag\n                                                                      interpretability pipelines (e.g. Juang et al., 2024), which canbehind incumbent model-control techniques, ReFT-r1 is\n                                                           then be used to identify useful latents to steer the LM.evidence that steering can be pushed further with the avail-\nability of comprehensive evaluation benchmarks. Finally,    Recent work reports mixed results when evaluating SAEs for\nalong with AXBENCH, we train and publicly release SAE-    steering; SAEs (but also several other steering methods) suf-\nscale feature dictionaries for ReFT-r1 and DiffMean.  1;     fer from a tradeoff between model control and capabilities\nwe call this approach supervised dictionary learning (SDL;    preservation (Mayne et al., 2024; Chalnev et al., 2024; Dur-\nFigure 2)                                      mus et al., 2024; Bhalla et al., 2025). However, Karvonen\n                                                                       et al. (2024) report Pareto-optimal performance when using\n2. Related work                               SAEs to prevent models from producing regular expressions\n                                                                  in code. Overall, evaluating SAEs remains an open problem\nRepresentation-based control.  Interventional/causal in-    because there is no ground-truth set of features to compare\nterpretability has emerged as the dominant paradigm for     against.\nunderstanding neural networks in the LLM era, enabling\nthe reverse-engineering of circuits underlying specific be-\n                                                        3. AXBENCH\nhaviours (Giulianelli et al., 2018; Vig et al., 2020; Geiger\net al., 2021; 2022; Meng et al., 2022; Chan et al., 2022;   AXBENCH is a benchmark which takes in a list of natural\nWang et al., 2023; Goldowsky-Dill et al., 2023; Geiger et al.,    language descriptions of concepts and synthetically gener-\n2024; Guerner et al., 2024; Geiger et al., 2024). An impor-    ates the appropriate training and evaluation data for each\ntant assumption in much of this work is the linear represen-    concept using an LLM (Figure 2). The training and eval-\ntation hypothesis, which claims that linear subspaces of rep-    uation data consists of labelled pairs of instructions and\nresentations in neural networks encode concepts (Mikolov    responses, where the responses are either positive examples\net al., 2013b; Pennington et al., 2014; Bolukbasi et al., 2016;    expressing the presence of the concept of interest, or nega-\nElhage et al., 2022; Park et al., 2023; Nanda et al., 2023).     tive examples that represent the unsteered behaviour of the\nIntervening on representations has thus emerged as an alter-   model (see §3.1 for details).\nnative to finetuning and prompting for LM control.\n                                      We evaluate along two axes: concept detection C and\nRepresentation-based steering by adding fixed vectors to   model steering S . For the former, we measure classifica-\nactivations, or clamping activations to a certain value along     tion performance on a held-out set of labelled data.2 For the\n\n   1We open-source all of our datasets and trained dictionaries at      2We focus on binarised concept detection, as a multi-class\nhttps://huggingface.co/pyvene.                                   classification task over n classes can also be formulated into a\n                                                                     binarised one over n features.\n\n                                   AXBENCH\n\n\n\n\n\nFigure 2: Key components of AXBENCH: (a) an example of how we collect data for evaluating concept detection and model\nsteering; (b) the synthetic data generation process for training and evaluation given Golden Gate Bridge as a concept; and (c)\nthe contrasting training pipelines of SAEs and SDLs; both use LLMs, but SAEs use them to label pretrained features while\nwe instead direct them to generate training data.\n\n\nlatter, we use an LLM judge to rate steered outputs on three        randomly select seed instructions from our instruction\nrelevant axes (see §3.3).                                       pool which belong to genre gc; see Appendix I for\n                                                                    dataset details. We then prompt the LLM to generate\nIn this work, we use natural language concept lists for\n                                                               responses to these instructions.5\nGemmaScope SAEs as input, and generate training and eval-\n                                                                      2. Positive examples: For each randomly sampled in-\nuation data for the following representation sites: layers\n                                                                        struction from the instruction pool, we prompt the LLM\n10 and 20 of instruction-tuned Gemma-2-2B, and layers 20\n                                                                      to generate a response that incorporates the concept c.\nand 31 of instruction-tuned Gemma-2-9B. We sample 500\n                                         We use the generated concept-conditioned responses\nconcepts for each task to generate data; we term this dataset\n                                                              concatenated with their instructions (using the LM’s\nCONCEPT500. These eight tasks (4 sites × 2 axes) form the\n                                                                  chat template) as our positive set.\ncore training and evaluation testbeds for AXBENCH. Below,\n                                                                      3. Negative examples: To evaluate the generalisation\nwe describe the data generation process and evaluation setup\n                                                                            ability of each method, we independently sample seed\nfor both axes.\n                                                                     instructions from all genres for negatives.6 These in-\n                                                                     structions are shared across concepts in order to save\n3.1. Synthetic concept dataset generation\n                                                                generation costs (i.e., (x−c , y−)n/20    is independent of\nWe  construct  a  small  training  dataset   Dtrain  =         the concept c). We sample responses from the LM\n{(x+c,i, y+)}n/2i=1 ∪{(x−c,i, y−)}n/2i=1.  with n  examples      we plan to steer (not the LLM) without any additional\nand a concept detection evaluation dataset Dconcept of the          instructions. We use the paired instructions and re-\nsame structure and harder examples, where y+ and y−are         sponses as our negative set.\nbinary labels indicating whether the concept c is present.      4. Hard negative examples (evaluation only): For each\nWe set n = 144 for our main experiments. 3                       concept, we find contrasting concepts that are semanti-\n                                                                        cally related to our concept of interest but which should\nWe query gpt-4o-mini-2024-07-18 to generate the data;                                                                not activate the concept. We find these by (a) generat-\nthe prompts used in this pipeline are presented in Ap-                                                                  ing a list of phrases that are semantically relevant to our\npendix J.2. Generating the data requires the following steps                                                                 concept, (b) filtering for those which are polysemous,\n(note that only the evaluation set includes hard negatives):                                                          and (c) finding alternative senses of those words which\n  1. Genre labelling & seed instructions: We consider         our concept should not activate on. This results in a set\n     three genres:  text, code, and math. We prompt the         of contrast concepts ccontrast, each of which is a specific\n   LLM to pick the genre gc for each concept.4 We then         sense of a polysemous word wcontrast. We then ask the\n   3Using a small training dataset ensures our methods are practi-     errors should contain code instead of descriptions of coding errors.\ncal and cost-effective alternatives to SAEs.                          5Each example costs less than $0.00006.\n   4Genre labelling increases input diversity. For example, inputs      6We sample instructions based on overall genre distribution:\nrelated to concepts such as programming code contains syntactic   70% from text, 15% from code, and 15% from math.\n\n                                   AXBENCH\n\n   LLM to generate responses incorporating wcontrast into     tasks (Zou et al., 2023; Makelov, 2024; Bhalla et al., 2025)\n     the sentence where wcontrast should express the sense    or condition generation on a fixed prefix (Chalnev et al.,\n     related to ccontrast. We use the contrastive responses    2024). To the best of our knowledge, we are the first to\n     paired with their instructions as our hard negative set.     evaluate model steering methods in the open-vocabulary\n                                                                   setting at scale.\nThe negative training set is not applicable to all methods\n(e.g. full finetuning only needs the positive training set for\nmodel steering).                                      Task description.  Given a prompt x, the model’s original\n                                                           generation can be written as ˆy = LM(x). We produce\n3.2. C Concept detection                                   the model’s counterfactual generation conditioned on the\n                                                          concept-based intervention ΦSteer(h):\nA popular LM interpretability method is to train probes\n(Conneau et al., 2018; Hewitt and Manning, 2019; Belinkov                                                                                                         ˆySteer = LM x, h ←ΦSteer(h)            (3)\net al., 2017) that measure to what extent LM representations\nencode properties of interest, e.g. linguistic features. In\n                                                   where h ←ΦSteer(h) is an in-place representation modifi-\nrecent years, the goal of concept detection has broadened                                                                   cation. We use the open-source intervention library pyvene\nto the open-vocabulary setting, with unsupervised methods\n                                                                 to perform such interventions on PyTorch implementations\nbecoming more common (Bills et al., 2023; Huben et al.,\n                                                             of models (Wu et al., 2024b).\n2024; Choi et al., 2024).\n\n                                                      Evaluation dataset.  We evaluate these steering methodsTask description.  Formally, given a Transformer-based\n                                                                in the instruction-following setting, where we sample in-LM with a hidden dimension size of d, we define a concept\n                                                                structions from Alpaca-Eval (Li et al., 2023) and promptclassifier as a parameterized function ΨDetect that maps a\nmodel representation h ∈Rd into a binary label ˆy indicating    the LM to generate a response while intervening on its for-\n                                                   ward pass in-place using one of the steering methods.the relative presence of a concept:\n\n                   ΨDetect(h) = ˆy ∈R1                 (1)    Evaluation metrics.  For the intervened model generation,\n                                           we evaluate ˆySteer based on the harmonic mean of the fol-\nwhere Ψ is any function, e.g. a neural network.\n                                                        lowing scores, each of which the LLM rates using a discrete\n                                                            score of 0, 1, or 2:\nEvaluation dataset.  To evaluate a concept classifier, we\nmeasure how accurately it can predict ground-truth labals       1. Concept score represents how well the concept is in-\non the labelled evaluation set from Dconcept (see §3.1).              corporated into the response.\n                                                                      2. Instruct score represents how well the response is\nEvaluation metrics.  Since our labels are at the sequence-         related to the instruction.\nlevel, we need to aggregate token-label scores from Ψ to       3. Fluency score represents how fluent the response is.\nevaluate it. Given a sequence of token representations hl =                                                          Since we compute the harmonic mean, the overall score also\n[ hl1, hl2, . . . , hln ] with n tokens at layer l ∈[1, m], we max-    ranges from 0 to 2, but heavily penalises poor performance\npool the detection scores to get a sequence-level prediction:                                                  on any of these three subscores.  For each concept, we\n                                                    randomly sample 10 instructions from Alpaca-Eval and\n                      ˆyDetect = max ΨDetect(hl)               (2)\n                                                       sample continuations for each steering factor (see discussion\n                                                  on steering factor in §5.2). To ensure a fair comparison,We then normalize ˆyDetect between [0, 1] by min-max nor-\n                                           we partition our instructions into two equally sized sets,malisation over the evaluation dataset for each concept. The\n                                                               selecting the best factor from one set and evaluating it onpredicted score represents how strongly a concept is present\n                                                              the holdout set. Our judge prompts with further discussionin a sequence, which we can compare to the true label.\n                                                       can be found in Appendix J.3.\n\n3.3. S Model steering\n                                                        4. Methods\nRepresentation-based steering has emerged as a potential\nalternative to existing model-control methods (e.g. finetun-    In this section, we describe the interpretability methods we\ning and prompting) and a practical application of various    evaluate along with our baseline prompting and finetun-\ninterpretability methods (see §2). Unlike concept detection,    ing methods. For each method, we label which axes it is\nmodel steering assesses causal efficacy in controlling model    evaluated on using C and S . All of our interpretability\nbehaviour. Previous evaluation benchmarks for steering are    methods except SAEs are SDLs that learn rank-1 subspaces\nnot general-purpose; they either rely on a limited set of     for targeted concepts.\n\n                                   AXBENCH\n\nNotation.  Given a LM, the hidden representations of di-   component of ∆. We follow the same detection and steering\nmensionality d for a token sequence of length n in layer l of    setup as DiffMean.\nthe LM are represented as hl = [ hl1, hl2, . . . , hln ] ∈Rn×d.\nThe set of representations concatenated from all of the train-  C S Linear probe (Probe).  The linear probe learns to\ning set inputs is denoted as H ∈Rs×d, where s = Ph|h|.    classify tokens as concept-relevant by projecting represen-\nWe denote H+ as the subset of H including only positive     tations hi onto a learned direction wProbe ∈Rd×1 just as in\ntraining inputs and H−for the negative inputs (see §3.1    DiffMean. To convert this into a probability, we apply the\nfor training dataset details). Finally, per-method projection    sigmoid activation, and then minimise binary cross-entropy\nvectors w and representations hi are the same shape: Rd×1.    loss with the true labels:\n\n                                   (                     )                                                           1\nC S Difference-in-means (DiffMean).  DiffMean uses     min  X LBCE(y, Sigmoid(hi · wProbe)))     (5)\nthe difference between averaged representations from two         wProbe   |h| hi∈h\nclasses of inputs as a steering vector (Marks and Tegmark,\n2024). The projection vector wDiffMean is defined as:         where y is the token-level class label indicating whether\n                                                                     this token belongs to a positive or negative example. The\n               1               1                        detection and steering setup is then identical to DiffMean.\n    wDiffMean =  X h+i −  X h−i    (4)            |H+|           |H−|\n                  h+i ∈H+          h−i ∈H−                                   C S Supervised steering vector (SSV).  The supervised\n              | mean of{zpositives }  | mean of{znegatives }           steering vector method directly learns an intervention that\n                                                     maximises the language-modelling probability of the posi-\nWe compute  detection  scores  with  the  dot  product,                                                                    tive responses. For a sequence of token representations h,\ni.e. ΨDiffMeanDetect  (hi) = hi·wDiffMean.7 Our steering operation is   we apply an intervention to each token representation:\nsimple activation addition: ΦDiffMeanSteer   (hi) = hi + αwDiffMean\nwhere α is the steering magnitude, which depends on the                   ΦSSV(hi) = hi + wSSV               (6)\nsteering factor and is optimized as a hyperparameter, as\ndescribed in §5.2.                                    where wSSV ∈Rd×1 is a learned vector. As described\n                                                                in §3.3, we backpropagate gradients by training with the\n                                                       language modeling loss, similar to supervised fine-tuningC S Principle component analysis (PCA).  For PCA,\n                                                         (SFT):we use the first principal component of the positive set of\nhidden representations as the projection vector.8 We first             n                                   (                    )\nsubtract the mean H+ from each h+, gathering the cen-     min X log PLM yt | y<t, x; h ←ΦSSV(h)       (7)\n                                                                    wSSVtered vectors into a matrix H ∈R|H+|×d. We then find             t=1\nthe top principal component wPCA ∈Rd×1 of H, i.e. the\n                                                   where yi is the i-th output token, y<i are the preceding to-unit vector that captures the largest variance along its di-\n                                                              kens, and x is the prompt. For evaluating concept detection\nrection, using sklearn.decomposition.PCA (Pedregosa\n                                                      and model steering SSV follows the same setup as DiffMean.\net al., 2011). We follow the same detection and steering\n                                       We apply ReLU to get the detection scores.\nsetup as DiffMean.\n\n                                   C S Rank-1 representation finetuning (ReFT-r1).  We\nC S Linear artificial tomography (LAT).  LAT searches\n                                                             introduce a novel method based on ReFT (Wu et al., 2024a)\nfor a single latent direction that can separate positive ex-\n                                                   which jointly learns concept detection and steering on su-\namples by learning from their pairwise activation differ-\n                                                             pervised data by combining the training objectives of linear\nences (Zou et al., 2023). Concretely, we create pairwise\n                                                         probing and supervised steering.\nactivation differences δ by randomly partitioning H into\npairs (hi, hj) (with i ̸= j) and computing δ = ∥hi−hj∥,hi−hj    We compute latents for concept detection as:\nwhere the denominator ensures each difference is unit-\n                                                                             ΨReFT-r1Detect (hi) = ReLU(hi · wReFT-r1)         (8)normalized. We gather all these pairwise differences into\n                      |H|\na matrix ∆∈R 2 ×d. We then perform PCA (using    During training we perform a representation-level interven-\nsklearn) on ∆; then wLAT ∈Rd×1 is the top principal     tion on each hi based on the latents of the sequence h:\n   7Following Gao et al. (2024), we normalize wDiffMean to have                      1\nunit norm. We apply the same normalization to the learned weights     ΦReFT-r1(hi) = hi +     TopK(ΨReFT-r1Detect (h)) 1  wReFT-r1                                                                  kof PCA, LAT, Probe, and ReFT-r1.\n                                                                                                                           (9)   8We found no significant difference between using only the\npositive set vs. the entire set of hidden representations for both    where wReFT-r1 ∈Rd×1 is a learned vector.  Finally, the\nPCA and LAT; see Appendix F for ablations.                        training objective combines language modelling loss subject\n\n                                   AXBENCH\n\nto this intervention, along with L1 regularisation on the non-  C S Prompting baseline.  For concept detection, we use\ntop-k latents:                                                  the same LLM judge as described in §3.3 to rate the presence\n                                                              of a concept on a scale of 0 to 2. For model steering, we use       n                  \n  min     X log P LMΦReFT-r1 (yt | y<t, x) + λ X ∥ai∥1      an LLM to engineer a prompt given a concept, which we  wReFT-r1                                                 use to steer our local model by prepending it to the actual    − t=1                            ai /∈TopK(Ψ(h))                                                                    instruction. We provide prompt templates and examples in\n                                                     (10)\n                                                   Appendix J and Appendix N.\nDetection and steering is identical to DiffMean.\n\nC S Sparse autoencoders (SAE).  Sparse autoencoders    S Finetuning baselines. We test full-parameter super-\nare a self-supervised dictionary learning method (see §2).    vised finetuning (SFT) and two parameter-efficient finetun-\nWe use pretrained SAEs from GemmaScope, which are the    ing methods: Low-rank adaptation (LoRA; Hu et al., 2022)\nbest available SAEs for Gemma-family LLMs (Lieberum    and low-rank representation finetuning (LoReFT; Wu et al.,\net al., 2024).9 The SAEs we used are trained to learn two    2024a). In all cases, we finetune to minimise the language-\ndictionary matrices, {Wenc, Wdec} ∈Rd×z where z is    modelling loss on the responses in the positive split of the\nthe number of latents. For our evaluating concept c, we     dataset; the negative training split is discarded. We then use\nuse {wenc, wdec} ∈Rd×1 as the detection and steering    the finetuned models as baselines for steering.\nrepresentations, respectively:                                                      For all of our SDLs except SSV, we constrain any learned\n          ΨSAEDetect(hi) = σ (hi · wenc + benc)               subspace to have a unit norm, following the same setup as\n                                                   SAEs. With a unit-norm constraint, we find that SSV is hard\nwhere σ is an activation function (in our case, JumpReLU)                                                                to use for steering models. For prompting and finetuning\nand benc is a learned bias.10 For steering, we use activation                                                                 baselines, we randomly score one generation on the testing\naddition as DiffMean. Note that Templeton et al. (2024) use                                                                 instruction set (since the factor is not a parameter for those\nactivation clamping; we report ablations in Appendix F.                                                          methods), resulting in the same number of observations for\n                                                            those methods.\nC S SAEs with AUROC selection (SAE-A).  Given that\nother methods have access to a training dataset, to enable                                                                    4.1. Evaluation\nfair comparison we attempt to use our training dataset for\nSAE feature selection. For each feature, we compute its    Datasets. We synthetically generate training and valida-\nmax-pooled activations per Equation (2) over each train-    tion datasets (see §3.1) for 500 concepts, which we release\ning example, compute AUROC over the dataset given true    as CONCEPT500. The concepts are sampled from the Neu-\nlabels, and select the highest-scoring feature by this metric.    ronpedia SAE concept list for GemmaScope as described in\n                                                  Appendix B. For each concept, we include 144 examples\nC Bag-of-Words (BoW).  For the BoW baseline, we first     for training and ≈72 samples for evaluating concept detec-\nconstruct a featurizer that tokenizes text by whitespace and     tion.11 In this paper, we train and evaluate all methods, and\ncounts word frequencies. The vocabulary for this featurizer     report results on CONCEPT500. For SFT, we only train and\nis derived from the training dataset. We then train a logistic    evaluate on the first 20 concepts due to limited resources.\nregression classifier to predict class probabilities, framing\n                                                      For evaluating steering, we use the instructions from the\nthe task as binary classification. To mitigate overfitting,\n                                                   Alpaca-Eval dataset (Li et al., 2023). For each concept,\nwe incorporate a regularization term. This BoW approach\n                                           we sample 10 instructions. We generate up to 128 tokens\nleverages statistical biases inherent in LLM-generated data.\n                                                                for each instruction over 14 steering factors. We split the\n                                                                 instructions into two equal sets – one for selecting the best\nC Gradient-based baselines.  We test two gradient-based\n                                                                 factor and the other for evaluation.\nattribution methods, which are applicable only to concept\ndetection: Input × gradients (I×G) and Integrated gradients   We additionally release training and evaluation datasets\n(IG; Sundararajan et al., 2017). For both, we train a classifi-    for all 16K concepts in GemmaScope as the CONCEPT16K\ncation head on the hidden representations of some layer and    dataset suite. We train and release SAE-scale dictionaries\napply the methods to produce token-level attribution scores    on this dataset only for the best-performing methods found\nΨDetect(hi). Implementation details are in Appendix H.       on CONCEPT500. See Appendix L for dataset statistics and\n                                                   Appendix E for further experiments on CONCEPT16K.\n   9GemmaScope releases a set of SAEs for Gemma-2-27B, but the\nconcept list is not publicly released, which makes the SAEs for\nGemma-2-9B the largest ones available for evaluations.            Models.  Our evaluations rely on access to and control\n   10Note that this parameterisation cannot apply to TopK (Gao    over the LLM’s representations. To reduce training cost, we\net al., 2024) and BatchTopK SAEs, which require loading in the\nentire encoder matrix to compute latents.                               11This varies based on valid hard negatives.\n\n                                   AXBENCH\n\n    Method   Gemma-2-2B   Gemma-2-9B   Avg.                           Balanced?     balanced     imbalanced\n              L10    L20    L20    L31\n                                                                                        Gemma-2-2B: L10               Gemma-2-2B: L20\n                                                                                                                                                                                                                                                                                                       0.947                                                0.942    DiffMean                0.948                        0.946                                0.955                                        0.921                                                                                                                                                                                                                        0.934                                                                                                                                                                                                                                                                                                                0.926                                                                                                                                                                                                                                                                                                                                0.922                                                                                                                                                                                                                                0.918                                                                                                                                                                                                                                                                                                                        0.915                                                                                               1.00                                                                                                                                                                                                                                         0.908                                                                                                                                                                                                                                                                                                                                         0.902                                                                                                                                                                                                                                                 0.899                                                                                                                                                                                                                                                         0.881                                                                                                                                                                                                                                                                                                                                                 0.863                                                                                                                                                                                                                                                                  0.854                                                                                                                                                                                                                                                                                                                                                          0.825                                                                                                                                                                                                                                                                                                                    0.789                                                                                                                                                                                                                                                                                                                                                                  0.776                                                                                                                                                                                                                                                                                                           0.764                                                                                                                                                                                                                                                                                           0.770                                                                                                                                                                                                                                                                          0.778   0.765                                        0.942     Probe                0.940                        0.946                                0.933                                                0.940                                                                                                                                                                                                                            0.739                                                                                                                                                                                                                                                                                                                                                                           0.749                                                                                                                                                                                                                                    0.711                                                                                                                                                                                                                                                                                                                            0.689                                                                                                                                                                                                                                                                                                                                     0.687                                                                                                                                                                                                                                             0.675                                                                                               0.75\n                                                                                                                                                                                                                                                     0.596                0.952                        0.965     ReFT-r1                                0.966   0.869                                                0.938                                                                                                                                                                                                                                                                                                                                             0.557                                                                                                                                                                                                                                                              0.529\n                                                                                                                                                                                                                                                                                                                                                      0.488\n                                                                                                                                                                                                                                                                      0.444                                                                                               0.50    Prompt                0.910                        0.921                                0.940                                        0.943                                                0.929\n                                                                                                                                                                                                                                                                                                                                                              0.342                                                                                                                                                                                                                                                                                                                                                                       0.322\n                                                                                                                                                                                                                                                                                       0.281    SAE-A     0.924   0.911   0.924   0.907   0.917                                                                                               0.25                                                          0.183            0.163                                                                          0.133\n   BoW       0.909   0.931   0.904   0.912   0.914\n    SSV        0.934   0.950   0.910   0.854   0.912                  0.00\n    LAT        0.742   0.809   0.572   0.725   0.712       F1            Gemma-2-9B: L20               Gemma-2-9B: L31\n                                                                                                                                                                                                                        0.939                                                                                                                                                                                                                                0.921                                                                                               1.00                                                                                                                                                                                                                                         0.908                                                                                                                                                                                                                                                                                                                        0.906                                                                                                                                                                                                                                                                                                                0.901                                                                                                                                                                                                                                                                                                       0.885                                                                                                                                                                                                                                                                                                                                         0.882   0.889                                                                                                                                                                                                                                                 0.872   0.880   0.888   SAE                0.735                        0.755                                0.631                                        0.659                                                0.695                                                                                                                                                                                                                                                                                                                                0.825                                                                                                                                                                                                                            0.789                                                                                                                                                                                                                                                                                                                                                          0.784                                                                                                                                                                                                                                    0.750                                                                                                                                                                                                                                                                                                                    0.731                                                                                                                                                                                                                                             0.728                                                                                                                                                                                                                                                                                                                                                                  0.715   0.735                                                                                                                                                                                                                                                                                                                            0.676                                                                                                                                                                                                                                                                          0.700   0.702   0.695                                                                                                                                                                                                                                                                                                           0.639   PCA                0.714                        0.712                                0.559                                        0.622                                                0.652                                                                                               0.75\n    IG         0.440   0.375   0.508   0.383   0.426                                                                                0.529   0.518   0.478                                                                  0.519   0.495                                                                                               0.50\n    IxG        0.243   0.217   0.193   0.330   0.246                                                                                                                  0.239                                         0.221                                                                                               0.25                                                                                                                                          0.270   0.272\n                                                                                                                                                                                                                                                                               0.074            0.038                                                                          0.120\nTable 1: C Mean AUROC for each method on concept           0.00\ndetection.         Bold indicates                         highest                    AUROC in                                                that                                          column;                                                                                   ReFT-r1DiffMeanProbeSSVBoWPromptLATSAEPCAReFT-r1DiffMeanProbeSSVBoWPromptLATSAEPCA                no significant                                  difference                                               vs.                                               the                                                   best per-underline indicates\nformer. Gray indicates non-representation steering methods.                             Method\n\n                                                               Figure 3: C Mean F1 scores vs. dataset balance.\nprefer to use models for which pretrained SAEs are avail-\nable. We thus evaluate our methods on two open models,\nGemma-2-2B-it and Gemma-2-9B-it (henceforth referred     nificantly outperformed by five supervised methods, all of\nto without the -it suffix), from the Gemma-family, with cor-   which are much cheaper to train using a limited amount of\n                                                                synthetic data. The remaining methods (PCA, IG, and IxG)responding SAEs released as GemmaScope. We evaluate\n                                                       perform poorly; PCA’s better-than-random performance isour methods with model representations from the residual\nstreams of layers 10 and 20 for Gemma-2-2B and layers 20    nevertheless impressive given its unsupervised nature. Ad-\nand 31 for Gemma-2-9B. We use SAEs from GemmaScope     ditional results are given in Appendix C.\nthat are trained for these layers.12 To ensure a fair compari-\nson, we perform separate hyperparameter-tuning for each   F1 score under class imbalance.  In real-world text, pos-\nmethod. Details can be found in Appendix K.                    itive instances of concepts are much rarer than negative\n                                                               instances. We thus report F1 on both the balanced setting\n                                              (50% positive instances) and an imbalanced setting with5. Results\n                                                  3600 additional negative examples (≈1% positive). We\n5.1. C Concept detection                               choose classification threshold by maximising F1, binarise\n                                                             the resulting predictions, and report statistics on this dis-\nFor concept detection, CONCEPT500 consists of passages of                                                                   crete classification. Figure 3 shows that the relative ordering\ntext with ground-truth labels for each concept. Each method                                                            of methods does not change substantially between the two\nprovides us with token-level concept scores obtained from                                                                   settings; despite their sparsity, SAEs perform poorly, but\nthe representation of that token at a particular layer. To                                         LAT and PCA also degrade substantially.\ncompute a passage-level score, we take the mean of the\ntoken-level concept scores. See Appendix M for a visualiza-\n                                                                    5.2. S Model steering\ntion of token-level concept scores.\n                                                      For model steering, we take concept labels from CON-\nAUROC.  In Table 1, we report the average area under   CEPT500 and apply the (pre)trained steering methods to\nthe ROC curve (AUROC) for each method over all con-    the base model and sample generations. We score the gen-\ncepts. Overall, we find that DiffMean, Probe, and ReFT-r1    erations using an LM judge as described in §3.3. We addi-\nare the best performers with no statistically significant dif-    tionally benchmark prompting, full-finetuning (SFT), and\nference (p < 0.05) between any of them under a paired    two parameter-efficient finetuning methods (LoReFT and\nt-test. Prompt, SAE-A, and SSV are not far behind and   LoRA) as non-steering baselines.\nsignificantly outperform the remaining methods. LAT also                                                      For steering methods, we note that steering factor is an\nperforms better than random. Vanilla SAEs are thus sig-                                                         important hyperparameter. We select the optimal steering\n                                                                factor for each method independently for every concept   12For Gemma-2-2B, we follow the common practice to use SAEs\nfor the base LM, as SAEs are not available for the instruction-tuned    based on which factor achieves the highest overall steering\nmodel at the time of publication (Lieberum et al., 2024).            score, as given by the LLM judge. Our actual steering\n\n                                   AXBENCH\n\n\n    Method   Gemma-2-2B   Gemma-2-9B   Avg.          Method    Gemma-2-2B    Gemma-2-9B    Avg.\n               L10    L20    L20    L31                            L10    L20    L20    L31\n\n     Prompt     0.698   0.731   1.075   1.072   0.894           Prompt    90.0%   91.5%   97.6%   99.1%   94.5%\n    LoReFT    0.701   0.722   0.777   0.764   0.741          LoReFT    88.9%   88.2%   88.6%   90.3%   89.0%\n    SFT        0.637   0.714  —   —    0.676         SFT       90.0%   87.5%  —   —    88.8%\n    LoRA      0.637   0.641   0.602   0.580   0.615         LoRA     85.0%   83.4%   79.9%   81.5%   82.5%\n     ReFT-r1    0.633   0.509   0.630   0.401   0.543           ReFT-r1    85.2%   82.3%   83.6%   76.0%   81.8%\n     DiffMean   0.297   0.178   0.322   0.158   0.239           DiffMean   63.2%   55.2%   64.3%   52.2%   58.7%\n    SAE       0.177   0.151   0.191   0.140   0.165         SAE       50.0%   50.0%   50.0%   50.0%   50.0%\n    SAE-A     0.166   0.132   0.186   0.143   0.157         SAE-A    49.3%   46.6%   48.5%   50.7%   48.8%\n    LAT        0.117   0.130   0.127   0.134   0.127         LAT       43.5%   48.2%   42.7%   48.6%   45.8%\n   PCA       0.107   0.083   0.128   0.104   0.105        PCA      42.1%   42.9%   42.2%   45.4%   43.1%\n     Probe      0.095   0.091   0.108   0.099   0.098            Probe      40.4%   44.0%   41.9%   45.6%   43.0%\n    SSV        0.072   0.001   0.024   0.008   0.026         SSV       38.8%   32.0%   32.5%   34.0%   34.3%\n\nTable  2:  S Mean  overall  steering scores  for each    Table 3: S Winrate against SAEs for each method, after\nmethod, after steering factor selection. Gray indicates non-    steering factor selection.\nrepresentation steering methods.\n\n                                                                   that SAE-A slightly underperforms the unsupervised SAE;          Gemma-2-2B: L10     Gemma-2-2B: L20   Method\n     1.25                                                            better classification does not directly lead to better steering.\n                                                        ReFT-r1     1.00\n     0.75                                              DiffMean\n     0.50                                                Winrate.  We compute winrates against SAEs by compar-\n     0.25                                      SAE         ing overall scores on each concept under each setting. WeScore     0.00\n                                               SAE-A        treat ties as 0.5 wins and 0.5 losses. We report the results          Gemma-2-9B: L20     Gemma-2-9B: L31\n     1.25                                          LAT          in Table 3. Again, ReFT-r1 (88.0%) and DiffMean (61.6%)\n     1.00                                                          achieve winrates of greater than 50% against SAEs, andConcept 0.75                                   PCA\n     0.50                                                            relative rankings are similar to those for overall score. We\n     0.25                                               Probe        note that DiffMean and ReFT-r1 show higher winrates on\n     0.00                                                SSV           earlier layers in both models.        2.0  1.5  1.0  0.5  0.02.0  1.5  1.0  0.5  0.0\n                    Instruct Score\n                                                        Steering factor. We compare the effect of changing the\nFigure 4: S Mean concept score vs. instruct score as the    steering factor on instruct vs. concept scores in Figure 4.\nsteering factor for each method is varied.              We notice that increasing the factor monotonically reduces\n                                                                     instruct score in all methods, i.e. larger steering vectors harm\n                                                                   capabilities; this agrees with prior findings (Durmus et al.,\nmagnitude (i.e., α, as described in §4) is the product of the    2024; Chalnev et al., 2024). However, the effect varies\nsteering factor and the maximal activations aggregated over    by layer for concept score: concept score increases then\nthe evaluation dataset for concept detection.13                decreases in earlier layers, while it roughly monotonically\n                                                             increases with steering factor in later layers. In all cases,\nOverall scores.  We report the mean overall score for each    ReFT-r1 traces a Pareto-optimal path, achieving the highest\nmethod (i.e. the harmonic mean of three subscores:  flu-    concept score for any chosen instruct score.\nency, instruction-following, and concept presence) in Ta-\nble 2. Prompting, along with slightly worse finetuning base-    6. Discussion\nlines, outperforms all steering methods on average, except\nfor ReFT-r1. ReFT-r1 is competitive with prompting in    Simple yet powerful baselines.  While representation-\nGemma-2-2B but significantly behind on Gemma-2-9B;    level interventions have been shown to be useful in both\nprompting scores improve by a large margin on the larger    enhancing model capabilities and for safety (see §2), they\nmodel. Additionally, DiffMean significantly outperforms     fail to outperform standard prompting and finetuning base-\nSAEs, particularly in earlier layers.                              lines on AXBENCH. This is sobering evidence of the current\n                                                                   limitations of steering techniques. However, our results sug-\nThe remaining supervised steering methods fail to beat                                                                gest that joint learning of concept detection and steering (as\nSAEs, and no steering methods besides ReFT-r1 approach                                                                 in ReFT-r1) may be the key to advancement.\nprompting or finetuning performance. Importantly, we note\n\n   13For SAEs, we query Neuronpedia to obtain the maximal acti-   SDL vs. SAEs. We have shown that SDL methods can\nvation per concept.                                            achieve similar scalability and better performance at a lower\n\n                                   AXBENCH\n\ncost compared to SAEs. Unlike SAEs, SDL methods re-    interp meetings; Jake Mendel for enlightening discussion\nquire concepts to be known a priori; however, SDLs can be    about the direction and framing of the work; Neel Nanda for\neasily augmented with new features without retraining. We     helpful suggestions on SAE feature selection; and Chenglei\nalso note that SDLs depend on high-quality data generators,     Si, Ken Ziyu Liu, Oam Patel, Luke Bailey, Harshit Joshi,\nwhereas SAEs rely on high-quality concept discriminators.   Yanzhe ‘Sanju’ Zhang, Nikil Roashan Selvam, Julie Kallini,\nThese methods are not mutually exclusive and can comple-   Omar Shaikh, Thomas Chen, Tristan Thrush, and Yangjun\nment each other.                                    Ruan for various helpful discussions. We thank Joseph Tey\n                                                     and Nick Jiang for pointing out equation typos in an earlier\n                                                                       draft.SAE concept label quality.  The concept  lists used\nin  this paper were adapted from Neuronpedia’s auto-    This research is supported in part by grants from Open\ninterpretability pipeline, which is often skewed towards    Philanthropy.\ntoken-level concepts and misses high-level abstractions.\nWhile we tried to do post-hoc SAE feature selection to\n                                             References\nmitigate this, the poor performance of SAEs is at least par-\ntially a reflection of the limitations of auto-interpretability.   Usman Anwar, Abulhair Saparov, Javier Rando, Daniel\nIt would be interesting to explore whether the SAE perfor-      Paleka, Miles Turpin, Peter Hase, Ekdeep Singh Lubana,\nmance on AXBENCH improves as better feature labelling       Erik Jenner, Stephen Casper, Oliver Sourbut, Benjamin L.\nmethods are used and labels become less shallow (e.g. Choi      Edelman, Zhaowei Zhang, Mario G¨unther, Anton Ko-\net al., 2024).                                                      rinek, Jose Hernandez-Orallo, Lewis Hammond, Eric\n                                                          Bigelow, Alexander Pan, Lauro Langosco, Tomasz Ko-\n                                                                rbak, Heidi Zhang, Ruiqi Zhong, Se´an ´O h´Eigeartaigh,7. Conclusion\n                                                            Gabriel Recchia, Giulio Corsi, Alan Chan, Markus An-\nWe introduced AXBENCH, a new benchmark for evaluating       derljung, Lilian Edwards, Aleksandar Petrov, Chris-\nLM control methods at scale using synthetic data. To answer        tian Schroeder de Witt, Sumeet Ramesh Motwan, Yoshua\nthe question in the title of this work: our evaluation shows      Bengio, Danqi Chen, Philip H. S. Torr, Samuel Albanie,\nthat even at SAE scale, representation steering is still far      Tegan Maharaj, Jakob Foerster, Florian Tramer, He He,\nbehind simple prompting and finetuning baselines. Simulta-      Atoosa Kasirzadeh, Yejin Choi, and David Krueger. Foun-\nneously, we showed that a novel steering method, ReFT-r1,       dational challenges in assuring alignment and safety of\nis capable of closing the gap to some extent; representation-       large language models. arXiv:2404.09932, 2024. URL\nbased steering has not yet exhausted its potential. No mat-     https://arxiv.org/abs/2404.09932.\nter the outcome, we believe that comprehensive evaluation\nbenchmarks like AXBENCH are necessary for continued    Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan\nprogress on this problem.                                         Sajjad, and James Glass. What do neural machine trans-\n                                                                      lation models learn about morphology? In Regina Barzi-\n                                                               lay and Min-Yen Kan, editors, Proceedings of the 55th\nImpact Statements                                                      Annual Meeting of the Association for Computational\nIn this paper, we explore representation-based methods for       Linguistics (Volume 1: Long Papers), pages 861–872,\nsteering language models and introduce AXBENCH, a large-      Vancouver, Canada, July 2017. Association for Compu-\nscale benchmark for evaluating these techniques. We believe       tational Linguistics. doi: 10.18653/v1/P17-1080. URL\nthat the immediate ethical and societal implications of our      https://aclanthology.org/P17-1080.\nresearch are minimal. However, we recognize that enhanced\n                                                Usha  Bhalla,  Suraj  Srinivas, Asma  Ghandeharioun,\ncontrol over language model outputs could potentially be\n                                                      and Himabindu Lakkaraju.  Towards unifying inter-\nmisused to reinforce biases or manipulate information. To\n                                                                     pretability and control:  Evaluation via intervention.\naddress these concerns, we advocate for the responsible\n                                                          arXiv:2411.04430, 2025. URL https://arxiv.org/\napplication of steering methods and ensure transparency by\n                                                       abs/2411.04430.\npublicly releasing our datasets and feature dictionaries. We\nencourage ongoing collaboration and dialogue within the                                                        Steven  Bills, Nick Cammarata, Dan Mossing, Henk\nresearch community to monitor and mitigate any unintended                                                             Tillman, Leo Gao, Gabriel Goh, Ilya Sutskever, Jan\nconsequences of these technologies.                                                                Leike, Jeff Wu, and William Saunders. Language models\n                                                        can explain neurons in language models, 2023. URL\nAcknowledgements                                 https://openaipublic.blob.core.windows.net/\n                                                     neuron-explainer/paper/index.html.\nWe thank R´obert Csord´as, Qinan Yu, and Jiuding Sun for\nconstant and extremely helpful feedback during our weekly    Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou, Venkatesh\n\n                                   AXBENCH\n\n  Saligrama, and Adam T. Kalai. Man is to computer    Nelson Elhage, Tristan Hume, Catherine Olsson, Nicholas\n  programmer as woman is to homemaker?  Debiasing       Schiefer, Tom Henighan, Shauna Kravec, Zac Hatfield-\n  word embeddings. In D. Lee, M. Sugiyama, U. Luxburg,      Dodds, Robert Lasenby, Dawn Drain, Carol Chen, Roger\n   I. Guyon, and R. Garnett, editors, Advances in Neural      Grosse, Sam McCandlish, Jared Kaplan, Dario Amodei,\n  Information Processing Systems, volume 29. Curran As-      Martin Wattenberg, and Christopher Olah.  Toy mod-\n   sociates,  Inc., 2016.  URL https://proceedings.       els of superposition.   Transformer Circuits Thread,\n  neurips.cc/paper files/paper/2016/file/             2022.  URL https://transformer-circuits.pub/\n  a486cd07e4ac3d270571622f4f316ec5-Paper.pdf.        2022/toy model/index.html.\n\nJoschka Braun,  Dmitrii Krasheninnikov, Usman An-   Leo Gao, Tom Dupr´e la Tour, Henk Tillman, Gabriel Goh,\n  war,  Robert  Kirk,  Daniel  Tan,  and David  Scott      Rajan Troll, Alec Radford, Ilya Sutskever, Jan Leike, and\n  Krueger. A sober look at steering vectors for LLMs.       Jeffrey Wu. Scaling and evaluating sparse autoencoders,\n  In Alignment Forum,  2024.   URL https://www.     2024. URL https://arxiv.org/abs/2406.04093.\n  alignmentforum.org/posts/QQP4nq7TXg89CJGBh/\n                                                              Atticus Geiger, Hanson Lu, Thomas Icard, and Christopher  a-sober-look-at-steering-vectors-for-llms.\n                                                                        Potts. Causal abstractions of neural networks. In M. Ran-\nStephen Casper, Lennart Schulze, Oam Patel, and Dylan       zato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wort-\n  Hadfield-Menell. Defending against unforeseen failure     man Vaughan, editors, Advances in Neural Information\n  modes with latent adversarial training, 2024. URL https:      Processing Systems, volume 34, pages 9574–9586. Cur-\n  //arxiv.org/abs/2403.05030.                             ran Associates, Inc., 2021. URL https://proceedings.\n                                                     neurips.cc/paper files/paper/2021/file/\nSviatoslav Chalnev, Matthew Siu, and Arthur Conmy. Im-     4f5c422f4d49a5a807eda27434231040-Paper.pdf.\n  proving steering vectors by targeting sparse autoencoder\n                                                            Atticus Geiger, Zhengxuan Wu, Hanson Lu, Josh Rozner,   features. arXiv:2411.02193, 2024. URL https://arxiv.\n                                                                Elisa Kreiss, Thomas Icard, Noah D. Goodman, and  org/abs/2411.02193.\n                                                            Christopher Potts. Inducing causal structure for inter-\nLawrence  Chan,   Adri`a  Garriga-Alonso,   Nicholas       pretable neural networks. In Kamalika Chaudhuri, Ste-\n  Goldowsky-Dill, Ryan Greenblatt, Jenny Nitishinskaya,       fanie Jegelka, Le Song, Csaba Szepesv´ari, Gang Niu,\n  Ansh Radhakrishnan, Buck Shlegeris, and Nate Thomas.     and Sivan Sabato, editors, International Conference on\n  Causal scrubbing: A method for rigorously testing      Machine Learning, ICML 2022, volume 162 of Proceed-\n   interpretability hypotheses. In Alignment Forum, 2022.      ings of Machine Learning Research, pages 7324–7338,\n  URL https://shorturl.at/jZoHi.                        Baltimore, Maryland, USA, 2022. PMLR. URL https:\n                                                     //proceedings.mlr.press/v162/geiger22a.html.\nDami Choi, Vincent Huang, Kevin Meng, Daniel D. John-\n  son, Jacob Steinhardt, and Sarah Schwettmann.  Scal-    Atticus Geiger, Duligur Ibeling, Amir Zur, Maheep Chaud-\n  ing automatic neuron description, October 2024. URL       hary, Sonakshi Chauhan, Jing Huang, Aryaman Arora,\n  https://transluce.org/neuron-descriptions.         Zhengxuan Wu, Noah Goodman, Christopher Potts, and\n                                                 Thomas Icard. Causal abstraction: A theoretical founda-\nAlexis Conneau, German Kruszewski, Guillaume Lample,       tion for mechanistic interpretability. arXiv:2301.04709,\n   Lo¨ıc Barrault, and Marco Baroni. What you can cram      2024. URL https://arxiv.org/abs/2301.04709.\n   into a single $&!#* vector: Probing sentence embed-\n  dings for linguistic properties. In Iryna Gurevych and   Gemma  Team,  Morgane  Riviere,  Shreya  Pathak,\n  Yusuke Miyao, editors, Proceedings of the 56th Annual       Pier Giuseppe Sessa,  Cassidy Hardin, Surya Bhu-\n  Meeting of the Association for Computational Linguis-       patiraju, L´eonard Hussenot, Thomas Mesnard, Bobak\n   tics (Volume 1: Long Papers), pages 2126–2136, Mel-       Shahriari, Alexandre Ram´e, Johan Ferret, Peter Liu,\n  bourne, Australia, July 2018. Association for Computa-     Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela\n   tional Linguistics.  doi: 10.18653/v1/P18-1198. URL     Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome,\n  https://aclanthology.org/P18-1198.                 Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan\n                                                               Girgin, Nikola Momchev, Matt Hoffman, Shantanu\nEsin Durmus, Alex Tamkin, Jack Clark, Jerry Wei, Jonathan      Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier\n  Marcus, Joshua Batson, Kunal Handa, Liane Lovitt, Meg     Bachem, Alanna Walton,  Aliaksei Severyn,  Alicia\n  Tong, Miles McCain, Oliver Rausch, Saffron Huang, Sam       Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic,\n  Bowman, Stuart Ritchie, Tom Henighan, and Deep Gan-     Amanda Carl, Amy Shen, Andy Brock, Andy Coenen,\n   guli. Evaluating feature steering: A case study in mitigat-     Anthony  Laforge,  Antonia  Paterson, Ben  Bastian,\n  ing social biases, 2024. URL https://anthropic.com/       Bilal  Piot, Bo Wu, Brandon Royal,  Charlie Chen,\n  research/evaluating-feature-steering.               Chintu Kumar, Chris Perry, Chris Welty, Christopher A.\n\n                                   AXBENCH\n\n  Choquette-Choo, Danila Sinopalnikov, David Wein-       for NLP, pages 240–248, Brussels, Belgium, November\n  berger, Dimple Vijaykumar, Dominika Rogozi´nska,      2018. Association for Computational Linguistics. doi:\n  Dustin Herbison, Elisa Bandy, Emma Wang, Eric Noland,      10.18653/v1/W18-5426. URL https://aclanthology.\n  Erica Moreira, Evan Senter, Evgenii Eltyshev, Francesco      org/W18-5426.\n  Visin, Gabriel Rasskin, Gary Wei, Glenn Cameron, Gus\n                                                          Gabriel Goh. Decoding the thought vector, 2017. URL  Martins, Hadi Hashemi, Hanna Klimczak-Pluci´nska,\n                                                     https://gabgoh.github.io/ThoughtVectors/.  Harleen Batra, Harsh Dhand, Ivan Nardini, Jacinda\n  Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha    Nicholas Goldowsky-Dill, Chris MacLeod, Lucas Sato,\n  Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi,     and Aryaman Arora. Localizing model behavior with\n  Jocelyn Becker, Joe Fernandez, Joost van Amersfoort,      path patching. arXiv:2304.05969, 2023. URL https:\n  Josh Gordon, Josh Lipschultz, Josh Newlan, Ju yeong Ji,     //arxiv.org/abs/2304.05969.\n  Kareem Mohamed, Kartikeya Badola, Kat Black, Katie\n  Millican, Keelin McDonell, Kelvin Nguyen, Kiranbir    Cl´ement Guerner, Anej Svete, Tianyu Liu, Alexander\n  Sodhia, Kish Greene, Lars Lowe Sjoesund, Lauren      Warstadt, and Ryan Cotterell. A geometric notion of\n  Usui, Laurent Sifre, Lena Heuermann, Leticia Lago,      causal probing. arXiv:2307.15054, 2024. URL https:\n   Lilly McNealus, Livio Baldini Soares, Logan Kilpatrick,     //arxiv.org/abs/2307.15054.\n  Lucas Dixon, Luciano Martins, Machel Reid, Manvinder                                                     John Hewitt and Christopher D. Manning. A structural\n  Singh, Mark Iverson, Martin G¨orner, Mat Velloso, Mateo                                                         probe for finding syntax in word representations.  In\n  Wirth, Matt Davidow, Matt Miller, Matthew Rahtz,                                                                                    Jill Burstein, Christy Doran, and Thamar Solorio, edi-\n  Matthew Watson, Meg Risdal, Mehran Kazemi, Michael                                                                          tors, Proceedings of the 2019 Conference of the North\n  Moynihan, Ming Zhang, Minsuk Kahng, Minwoo Park,                                                      American Chapter of the Association for Computational\n  MofiRahman, Mohit Khatwani, Natalie Dao, Nenshad                                                                 Linguistics: Human Language Technologies, Volume 1\n  Bardoliwalla, Nesh Devanathan, Neta Dumai, Nilay                                                      (Long and Short Papers), pages 4129–4138, Minneapo-\n  Chauhan, Oscar Wahltinez,  Pankil Botarda,  Parker                                                                                      lis, Minnesota, June 2019. Association for Computa-\n  Barnes, Paul Barham, Paul Michel, Pengchong Jin, Petko                                                                    tional Linguistics. doi: 10.18653/v1/N19-1419. URL\n  Georgiev, Phil Culliton, Pradeep Kuppala, Ramona                                                     https://aclanthology.org/N19-1419.\n  Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir\n  Rokni, Rishabh Agarwal, Ryan Mullins, Samaneh Saadat,   Edward  J. Hu, Yelong Shen,  Phillip Wallis, Zeyuan\n  Sara Mc Carthy, Sarah Cogan, Sarah Perrin, S´ebastien      Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\n  M. R. Arnold, Sebastian Krause, Shengyang Dai, Shruti     Weizhu Chen.  LoRA: Low-rank adaptation of large\n  Garg, Shruti Sheth, Sue Ronstrom, Susan Chan, Timothy      language models.  In The Tenth International Confer-\n  Jordan, Ting Yu, Tom Eccles, Tom Hennigan, Tomas      ence on Learning Representations, ICLR 2022, Virtual\n  Kocisky, Tulsee Doshi, Vihan Jain, Vikas Yadav, Vilobh      Event, 2022. URL https://openreview.net/forum?\n  Meshram, Vishal Dharmadhikari, Warren Barkley, Wei      id=nZeVKeeFYf9.\n  Wei, Wenming Ye, Woohyun Han, Woosuk Kwon,\n                                                       Robert Huben, Hoagy Cunningham, Logan Riggs, Aidan\n  Xiang Xu, Zhe Shen, Zhitao Gong, Zichuan Wei, Victor\n                                                             Ewart, and Lee Sharkey. Sparse autoencoders find highly\n  Cotruta, Phoebe Kirk, Anand Rao, Minh Giang, Ludovic\n                                                                     interpretable features in language models. In The Twelfth\n  Peran, Tris Warkentin, Eli Collins, Joelle Barral, Zoubin\n                                                               International Conference on Learning Representations,\n  Ghahramani, Raia Hadsell, D. Sculley, Jeanine Banks,\n                                                 ICLR 2024, Vienna, Austria, 2024. OpenReview.net. URL\n  Anca Dragan, Slav Petrov, Oriol Vinyals, Jeff Dean,\n                                                     https://openreview.net/forum?id=F76bwRSLeK.\n  Demis Hassabis, Koray Kavukcuoglu, Clement Farabet,\n  Elena Buchatskaya, Sebastian Borgeaud, Noah Fiedel,   Caden Juang, Gonc¸alo Paulo, Jacob Drori, and Nora Belrose.\n  Armand Joulin, Kathleen Kenealy, Robert Dadashi, and     Open source automated interpretability for sparse autoen-\n  Alek Andreev. Gemma 2: Improving open language      coder features, 2024. URL https://blog.eleuther.\n  models at a practical size. arXiv:2408.00118, 2024. URL      ai/autointerp/.\n  https://arxiv.org/abs/2408.00118.\n                                             Dan Jurafsky and James H. Martin.  Speech and Lan-\n                                                     guage Processing. Online, 2025. URL https://web.\nMario Giulianelli, Jack Harding, Florian Mohnert, Dieuwke                                                     stanford.edu/∼jurafsky/slp3/. 3rd ed. draft.\n  Hupkes, and Willem Zuidema.  Under the hood: Us-\n  ing diagnostic classifiers to investigate and improve how   Adam Karvonen, Dhruv Pai, Mason Wang, and Ben Keig-\n  language models track agreement information.  In Tal      win. Sieve: SAEs beat baselines on a real-world task (a\n  Linzen, Grzegorz Chrupała, and Afra Alishahi, edi-      code generation case study). Tilde Research Blog, 2024.\n   tors, Proceedings of the 2018 EMNLP Workshop Black-    URL https://www.tilderesearch.com/blog/sieve.\n  boxNLP: Analyzing and Interpreting Neural Networks      Blog post.\n\n                                   AXBENCH\n\nMichael Lan, Philip Torr, Austin Meek, Ashkan Khakzar,       sentations of true/false datasets. arXiv:2310.06824, 2024.\n  David Krueger, and Fazl Barez. Sparse autoencoders re-    URL https://arxiv.org/abs/2310.06824.\n  veal universal feature spaces across large language mod-\n   els.  arXiv:2410.06981, 2024. URL https://arxiv.   Harry Mayne, Yushi Yang, and Adam Mahdi. Can sparse\n  org/abs/2410.06981.                                     autoencoders be used to decompose and interpret steering\n                                                                 vectors? arXiv:2411.08790, 2024. URL https://arxiv.\nAnders Boesen Lindbo Larsen, Søren Kaae Sønderby, Hugo      org/abs/2411.08790.\n  Larochelle, and Ole Winther. Autoencoding beyond pix-\n                                                    Kevin Meng, David Bau, Alex Andonian, and Yonatan   els using a learned similarity metric. In Maria-Florina\n                                                             Belinkov. Locating and editing factual associations in  Balcan and Kilian Q. Weinberger, editors, Proceedings of\n                                                GPT. In S. Koyejo, S. Mohamed, A. Agarwal, D. Bel-  the 33nd International Conference on Machine Learning,\n                                                               grave, K. Cho, and A. Oh, editors, Advances in Neu-  ICML 2016, New York City, NY, USA, June 19-24, 2016,\n                                                                   ral Information Processing Systems, volume 35, pages  volume 48 of JMLR Workshop and Conference Proceed-\n                                                      17359–17372. Curran Associates, Inc., 2022.  URL   ings, pages 1558–1566. JMLR.org, 2016. URL http:\n                                                     https://arxiv.org/abs/2202.05262.  //proceedings.mlr.press/v48/larsen16.html.\n\n                                                        Tom´as Mikolov, Ilya Sutskever, Kai Chen, Gregory S.Kenneth Li, Oam Patel, Fernanda Vi´egas, Hanspeter Pfis-\n                                                          Corrado, and Jeffrey Dean. Distributed representations   ter, and Martin Wattenberg. Inference-time intervention:\n                                                              of words and  phrases and  their  compositionality.   Eliciting truthful answers from a language model. Ad-\n                                                              In Christopher  J. C. Burges,  L´eon Bottou, Zoubin  vances in Neural Information Processing Systems, 36,\n                                                       Ghahramani, and Kilian Q. Weinberger, editors, Ad-  2024. URL https://arxiv.org/abs/2306.03341.\n                                                         vances  in Neural  Information  Processing  Systems\nXuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori,      26:  27th Annual Conference on Neural Information\n  Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tat-      Processing Systems 2013. Proceedings  of a meet-\n  sunori B. Hashimoto. AlpacaEval: An automatic evalu-      ing held December 5-8, 2013, Lake Tahoe, Nevada,\n   ator of instruction-following models. https://github.     United States, pages 3111–3119, 2013a. URL https:\n  com/tatsu-lab/alpaca eval, 5 2023.                   //proceedings.neurips.cc/paper/2013/hash/\n                                                    9aa42b31882ec039965f3c4923ce901b-Abstract.\nTom Lieberum, Senthooran Rajamanoharan, Arthur Conmy,      html.\n  Lewis Smith, Nicolas Sonnerat, Vikrant Varma, Janos\n  Kramar, Anca Dragan, Rohin Shah, and Neel Nanda.   Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. Lin-\n  Gemma scope: Open sparse autoencoders everywhere all       guistic regularities in continuous space word represen-\n   at once on gemma 2. In Yonatan Belinkov, Najoung Kim,       tations. In Lucy Vanderwende, Hal Daum´e III, and Ka-\n  Jaap Jumelet, Hosein Mohebbi, Aaron Mueller, and Han-       trin Kirchhoff, editors, Proceedings of the 2013 Con-\n   jie Chen, editors, Proceedings of the 7th BlackboxNLP       ference of the North American Chapter of the Associa-\n  Workshop: Analyzing and Interpreting Neural Networks       tion for Computational Linguistics: Human Language\n   for NLP, pages 278–300, Miami, Florida, US, Novem-      Technologies, pages 746–751, Atlanta, Georgia, June\n  ber 2024. Association for Computational Linguistics.      2013b. Association for Computational Linguistics. URL\n   doi: 10.18653/v1/2024.blackboxnlp-1.19. URL https:     https://aclanthology.org/N13-1090/.\n  //aclanthology.org/2024.blackboxnlp-1.19.\n                                                            Ulisse Mini, Peli Grietzer, Mrinank Sharma, Austin Meek,\nSheng Liu, Haotian Ye, Lei Xing, and James Y. Zou. In-     Monte MacDiarmid, and Alexander Matt Turner. Under-\n  context vectors: Making in context learning more effec-      standing and controlling a maze-solving policy network.\n   tive and controllable through latent space steering. In      arXiv:2310.08043, 2023. URL https://arxiv.org/\n   Forty-first International Conference on Machine Learn-     abs/2310.08043.\n   ing, ICML 2024, Vienna, Austria, July 21-27, 2024. Open-\n                                                     Neel Nanda, Andrew Lee, and Martin Wattenberg. Emer-\n  Review.net, 2024.  URL https://openreview.net/\n                                                            gent linear representations in world models of self-\n  forum?id=dJTChKgv3a.\n                                                            supervised sequence models. In Yonatan Belinkov, So-\nAleksandar Makelov. Sparse autoencoders match supervised      phie Hao, Jaap Jumelet, Najoung Kim, Arya McCarthy,\n   features for model steering on the IOI task. In ICML 2024      and Hosein Mohebbi, editors, Proceedings of the 6th\n  Workshop on Mechanistic Interpretability, 2024. URL     BlackboxNLP Workshop:  Analyzing and Interpreting\n  https://openreview.net/forum?id=JdrVuEQih5.         Neural Networks for NLP, pages 16–30, Singapore, De-\n                                                      cember 2023. Association for Computational Linguistics.\nSamuel Marks and Max Tegmark. The geometry of truth:       doi: 10.18653/v1/2023.blackboxnlp-1.2. URL https:\n  Emergent linear structure in large language model repre-     //aclanthology.org/2023.blackboxnlp-1.2/.\n\n                                   AXBENCH\n\nKyle O’Brien, David Majercak, Xavier Fernandes, Richard    Nishant Subramani, Nivedita Suresh, and Matthew Peters.\n  Edgar, Jingya Chen, Harsha Nori, Dean Carignan,      Extracting latent steering vectors from pretrained lan-\n  Eric Horvitz, and Forough Poursabzi-Sangde.  Steer-     guage models.  In Smaranda Muresan, Preslav Nakov,\n  ing language model refusal with sparse autoencoders.     and Aline Villavicencio, editors, Findings of the As-\n  arXiv:2411.11296, 2024. URL https://arxiv.org/       sociation for Computational Linguistics: ACL 2022,\n  abs/2411.11296.                                       pages 566–581, Dublin, Ireland, May 2022. Associa-\n                                                                  tion for Computational Linguistics.   doi:  10.18653/\nKiho Park, Yo Joong Choe, and Victor Veitch. The linear\n                                                                 v1/2022.findings-acl.48. URL https://aclanthology.\n  representation hypothesis and the geometry of large lan-\n                                                     org/2022.findings-acl.48.\n  guage models. arXiv:2311.03658, 2023. URL https:\n  //arxiv.org/abs/2311.03658.                   Mukund Sundararajan, Ankur Taly, and Qiqi Yan.  Ax-\n                                                             iomatic attribution for deep networks. In Proceedings ofFabian Pedregosa, Ga¨el Varoquaux, Alexandre Gramfort,\n                                                                  the 34th International Conference on Machine Learning -  Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu\n                                                      Volume 70, ICML’17, page 3319–3328. JMLR.org, 2017.  Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg,\n  Jake VanderPlas, Alexandre Passos, David Cournapeau,                                                  Adly Templeton, Tom Conerly, Jonathan Marcus, Jack\n  Matthieu Brucher, Matthieu Perrot, and Edouard Duch-                                                             Lindsey, Trenton Bricken, Brian Chen, Adam Pearce,\n  esnay. Scikit-learn: Machine learning in Python. The                                                          Craig Citro, Emmanuel Ameisen, Andy Jones, Hoagy\n  Journal of Machine Learning Research, 12:2825–2830,                                                    Cunningham, Nicholas L Turner, Callum McDougall,\n  2011.  doi: 10.5555/1953048.2078195. URL https:                                                 Monte MacDiarmid, C. Daniel Freeman, Theodore R.\n  //dl.acm.org/doi/10.5555/1953048.2078195.                                                        Sumers, Edward Rees, Joshua Batson, Adam Jermyn,\nJeffrey Pennington, Richard Socher, and Christopher Man-     Shan Carter, Chris Olah, and Tom Henighan.  Scal-\n  ning.  GloVe:  Global vectors for word representa-      ing monosemanticity: Extracting interpretable features\n   tion.  In Alessandro Moschitti, Bo Pang, and Walter      from Claude 3 Sonnet.  Transformer Circuits Thread,\n  Daelemans, editors, Proceedings of the 2014 Confer-      2024.  URL https://transformer-circuits.pub/\n  ence on Empirical Methods in Natural Language Process-     2024/scaling-monosemanticity/index.html.\n  ing (EMNLP), pages 1532–1543, Doha, Qatar, October\n                                                      Alexander Matt Turner, Peli Grietzer, Ulisse Mini, Monte  2014. Association for Computational Linguistics. doi:\n                                             M, and David Udell. Understanding and controlling a  10.3115/v1/D14-1162. URL https://aclanthology.\n                                                          maze-solving policy network. Alignment Forum, March  org/D14-1162.\n                                                           2023a. URL https://shorturl.at/XGtmh.\nItamar Pres, Laura Ruis, Ekdeep Singh Lubana, and David\n  Krueger. Towards reliable evaluation of behavior steer-   Alexander Matt Turner, Peli Grietzer, and Lisa Thiergart.\n  ing interventions in LLMs, 2024. URL https://arxiv.     Maze-solving agents: Add a top-right vector, make the\n  org/abs/2410.17245.                                      agent go to the top-right. Alignment Forum, March 2023b.\n                                       URL https://shorturl.at/7Qdy9.\nNina Rimsky, Nick Gabrieli, Julian Schulz, Meg Tong,\n  Evan Hubinger, and Alexander Turner. Steering Llama    Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David\n  2 via contrastive activation addition.  In Lun-Wei Ku,      Udell, Juan J. Vazquez, Ulisse Mini, and Monte Mac-\n  Andre Martins, and Vivek Srikumar, editors, Proceed-      Diarmid.   Steering language models with activation\n  ings of the 62nd Annual Meeting of the Association       engineering.  arXiv:2308.10248, 2024. URL https:\n   for Computational Linguistics (Volume 1: Long Pa-     //arxiv.org/abs/2308.10248.\n   pers), pages 15504–15522, Bangkok, Thailand, Au-\n  gust 2024. Association for Computational Linguistics.    Paul Upchurch, Jacob R. Gardner, Geoff Pleiss, Robert\n   doi: 10.18653/v1/2024.acl-long.828. URL https://       Pless, Noah Snavely, Kavita Bala, and Kilian Q. Wein-\n  aclanthology.org/2024.acl-long.828.                    berger.  Deep feature interpolation for image content\n                                                           changes.  In 2017 IEEE Conference on Computer Vi-\nNaomi Saphra and Sarah Wiegreffe.  Mechanistic?   In       sion and Pattern Recognition, CVPR 2017, Honolulu, HI,\n  Yonatan Belinkov, Najoung Kim, Jaap Jumelet, Hosein     USA, July 21-26, 2017, pages 6090–6099. IEEE Com-\n  Mohebbi, Aaron Mueller, and Hanjie Chen, editors, Pro-       puter Society, 2017. doi: 10.1109/CVPR.2017.645. URL\n  ceedings of the 7th BlackboxNLP Workshop: Analyzing      https://doi.org/10.1109/CVPR.2017.645.\n  and Interpreting Neural Networks for NLP, pages 480–\n  498, Miami, Florida, US, November 2024. Association    Teun van der Weij, Massimo Poesio, and Nandi Schoots.\n   for Computational Linguistics. doi: 10.18653/v1/2024.      Extending activation steering to broad skills and multiple\n  blackboxnlp-1.30. URL https://aclanthology.org/      behaviours. arXiv:2403.05767, 2024. URL https://\n  2024.blackboxnlp-1.30/.                             arxiv.org/abs/2403.05767.\n\n                                   AXBENCH\n\nJesse  Vig,  Sebastian  Gehrmann,  Yonatan  Belinkov,     American Chapter of the Association for Computational\n  Sharon Qian, Daniel Nevo, Yaron Singer, and Stuart       Linguistics: Human Language Technologies (Volume 3:\n  Shieber. Investigating gender bias in language models      System Demonstrations), pages 158–165, Mexico City,\n  using causal mediation analysis.   In H. Larochelle,      Mexico, June 2024b. Association for Computational Lin-\n  M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin,       guistics. doi: 10.18653/v1/2024.naacl-demo.16. URL\n   editors, Advances in Neural Information Processing      https://aclanthology.org/2024.naacl-demo.16.\n  Systems, volume 33, pages 12388–12401. Curran As-\n                                             Andy Zou, Long Phan, Sarah Chen, James Campbell,   sociates,  Inc., 2020.  URL https://proceedings.\n                                                                    Phillip Guo, Richard Ren, Alexander Pan, Xuwang Yin,  neurips.cc/paper files/paper/2020/file/\n                                                     Mantas Mazeika, Ann-Kathrin Dombrowski, Shashwat  92650b2e92217715fe312e6fa7b90d82-Paper.pdf.\n                                                           Goel, Nathaniel Li, Michael J. Byun, Zifan Wang, Alex\nEric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subramanian,      Mallen, Steven Basart, Sanmi Koyejo, Dawn Song, Matt\n  Matt Gardner, and Sameer Singh. AllenNLP interpret: A       Fredrikson, J. Zico Kolter, and Dan Hendrycks. Rep-\n  framework for explaining predictions of NLP models. In       resentation engineering: A top-down approach to AI\n  Proceedings of the 2019 Conference on Empirical Meth-      transparency.  arXiv:2310.01405, 2023. URL https:\n  ods in Natural Language Processing and the 9th Interna-     //arxiv.org/abs/2310.01405.\n   tional Joint Conference on Natural Language Processing\n  (EMNLP-IJCNLP): System Demonstrations, pages 7–12,   Andy Zou, Long Phan,  Justin Wang, Derek Duenas,\n  2019.                                            Maxwell Lin, Maksym Andriushchenko, Rowan Wang,\n                                                        Zico Kolter, Matt Fredrikson, and Dan Hendrycks. Im-\nKevin Ro Wang, Alexandre Variengien, Arthur Conmy,      proving alignment and robustness with circuit breakers,\n  Buck Shlegeris, and Jacob Steinhardt.  Interpretability      2024. URL https://arxiv.org/abs/2406.04313.\n   in the wild: a circuit for indirect object identification\n   in GPT-2 small. In The Eleventh International Confer-\n  ence on Learning Representations, ICLR 2023, Kigali,\n  Rwanda, 2023. URL https://openreview.net/pdf?\n  id=NpsVSN6o4ul.\n\nYulin Wang, Xuran Pan, Shiji Song, Hong Zhang, Gao\n  Huang, and Cheng Wu. Implicit semantic data augmen-\n   tation for deep networks. In Hanna M. Wallach, Hugo\n  Larochelle, Alina Beygelzimer, Florence d’Alch´e-Buc,\n  Emily B. Fox, and Roman Garnett, editors, Advances\n   in Neural Information Processing Systems 32: Annual\n  Conference on Neural Information Processing Systems\n  2019, NeurIPS 2019, December 8-14, 2019, Vancouver,\n  BC, Canada, pages 12614–12623, 2019. URL https:\n  //proceedings.neurips.cc/paper/2019/hash/\n  15f99f2165aa8c86c9dface16fefd281-Abstract.\n  html.\n\nTom   White.       Sampling   generative   networks.\n  arXiv:1609.04468,  2016.   URL  https://arxiv.\n  org/abs/1609.04468.\n\nZhengxuan Wu, Aryaman Arora, Zheng Wang, Atticus\n  Geiger, Dan Jurafsky, Christopher D. Manning, and\n  Christopher Potts.  ReFT: Representation finetuning\n   for language models. arXiv:2404.03592, 2024a. URL\n  https://arxiv.org/abs/2404.03592.\n\nZhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing\n  Huang, Zheng Wang, Noah Goodman, Christopher Man-\n  ning, and Christopher Potts. pyvene: A library for under-\n  standing and improving PyTorch models via interventions.\n  In Kai-Wei Chang, Annie Lee, and Nazneen Rajani, ed-\n   itors, Proceedings of the 2024 Conference of the North\n\n                                   AXBENCH\n\n\nAppendix\n\n\nA. Historical notes on steering\n\nInspired by Jurafsky and Martin (2025) and noting the sociological observations about (mechanistic) interpretability as a\nfield in Saphra and Wiegreffe (2024), we offer some historical notes on the development of steering as a field in an effort to\ndocument and properly cite where these ideas came from.\n\nSteering refers to applying interventions (usually adding a fixed vector) to the activation space of a neural model in order to\ncontrol its generations. Early precursors to steering noted that linear subspaces of the representation space of pretrained\nword vectors seemed to encode meaningful concepts (Mikolov et al., 2013a; Pennington et al., 2014; Bolukbasi et al., 2016).\n\nLarsen et al. (2016) first used the difference-in-means technique to extract visual attribute vectors from GAN discriminators\nin order to steer generator outputs; this technique was widely adopted in computer vision (White, 2016; Upchurch et al.,\n2017; Goh, 2017; Wang et al., 2019).\n\nIn NLP, initial work by Subramani et al. (2022) proposed steering vectors, learned to maximise the probability of some\noutput, as an alternative to expensive fine-tuning and unreliable prompt optimisation for the task of controllable text\ngeneration. Soon after, steering was also use to localise behaviours in a maze-searching RL agent (Turner et al., 2023a;b;\nMini et al., 2023). Variations on this approach (sometimes using difference-in-means or other closed-form expressions to\ncompute the vector) were adopted by researchers in mechanistic interpretability from late 2023 for AI safety (Zou et al.,\n2023; Li et al., 2024; Turner et al., 2024; Marks and Tegmark, 2024; Rimsky et al., 2024) and later as a general-purpose but\nlocalised and parameter-efficient alternative to finetuning (Wu et al., 2024a; Liu et al., 2024; van der Weij et al., 2024).\n\nSparse autoencoders (SAEs), a scalable technique for self-supervised rank-one linear feature discovery via dictionary\nlearning, are also increasingly used to find or learn steering vectors (Templeton et al., 2024; Chalnev et al., 2024; Makelov,\n2024; O’Brien et al., 2024).\n\nB. SAE concept list\n\nWe use SAE concept lists to enable a fair comparison with SAEs, which were annotated mostly by gpt-3.5-turbo or\ngpt-4o-mini. These concept lists are released by Neuronpedia and were scraped by the authors of this paper in November\n2024. We utilize the concept lists from four SAEs from GemmaScope: 10-gemmascope-res-16k for the Gemma-2-2B base\nmodel and 20-gemmascope-res-131k for the Gemma-2-9B instruction-tuned model, where we scraped a maximum of 16K\nconcepts.\n\n                                   AXBENCH\n\nC. Detailed analysis\n\nC.1. C Concept detection\n\n\n                                        Gemma-2-2B: L10     Gemma-2-2B: L20\n                                          1.00                                Method\n                                          0.75                                              DiffMean\n                                                                                      Probe                                          0.50\n                                     Rate 0.25                                                ReFT-r1Prompt\n                                          0.00                                        SAE-A\n                                        Gemma-2-9B: L20     Gemma-2-9B: L31     BoW                                                                           Positive 1.00                                         SSV\n                                                                   LAT\n                                     True 0.75                                      SAE\n                                          0.50                                   PCA\n                                          0.25                                            IG\n                                                                                  IxG                                          0.00\n                                    0.00 0.25 0.50 0.75 1.000.00 0.25 0.50 0.75 1.00\n                                              False Positive Rate\n\n                                 Figure 5: C Mean ROC curves over all concepts.\n\n\n\n            DiffMean       Probe       ReFT-r1      Prompt      SAE-A      BoW        SSV       LAT        SAE       PCA          IG          IxG\n       1.00\n       0.75\n       0.50                                                                                                                                                                                L10       0.25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Gemma-2-2B\n       0.00\n       1.00\n       0.75\n Rate  0.50                                                                                                                                                                                L20       0.25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Gemma-2-2B\n       0.00\n       1.00  Positive\n       0.75\n True  0.50                                                                                                                                                                                L20       0.25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Gemma-2-9B\n       0.00\n       1.00\n       0.75\n       0.50                                                                                                                                                                                L31       0.25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Gemma-2-9B\n       0.00\n        0.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.000.000.250.500.751.00\n                                                                        False Positive Rate\n\n\n                                            Figure 6: All ROC curves.\n\n                                   AXBENCH\n\nC.2. S Model steering\n\n\n                                           Gemma-2-2B: L10     Gemma-2-2B: L20     Gemma-2-9B: L20     Gemma-2-9B: L31\n\n\n       2.0\n       1.5       1.0                                                                                                                                                                                                                                                                                                                                                                                           Concept\n       0.5                                                                                                                                                                                                                                                                              Score\n       0.0\n       2.0\n       1.5       1.0                                                                                                                                                                                                                                                                                                                                                                                           Fluency\n       0.5                                                                                                                                                                                                                                                                              Score\n Score  0.02.0\n       1.5       1.0                                                                                                                                                                                                                                                                                                                                                                                                                                                 Instruct\n       0.5                                                                                                                                                                                                                                                                              Score\n       0.0\n       2.0\n       1.5       1.0                                                                                                                                                                                                                                                                                                                                                                                           Overall\n       0.5                                                                                                                                                                                                                                                                              Score\n       0.0\n            Prompt     LoReFT      SFT      LoRA      ReFT-r1    DiffMean     SAE      SAE-A     LAT      PCA       Probe       SSV\n                                                       Method\n\n\nFigure 7: Mean score breakdown for all methods on our unseen testing instruction set after selecting the optimal factor\n(based on the Overall Score) on our evaluation instruction set. For prompting and finetuning, we randomly score one\ngeneration on the testing instruction set (since the factor is not a parameter for those methods), resulting in the same number\nof observations for those methods.\n\n\n           DiffMean      LAT       PCA          Probe        ReFT-r1       SAE        SAE-A        SSV\n     500\n     400\n     300\n     200                                                                                                                             L10\n     100                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Gemma-2-2B       0\n     500\n     400\n     300\n     200                                                                                                                             L20\n     100                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Gemma-2-2B       0\n     500 Count     400\n     300\n     200                                                                                                                             L20\n     100                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Gemma-2-9B       0\n     500\n     400\n     300\n     200                                                                                                                             L31\n     100                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Gemma-2-9B       0\n        0.3 1 3   0.3 1 3   0.3 1 3   0.3 1 3   0.3 1 3   0.3 1 3   0.3 1 3   0.3 1 3\n                                         Optimal Steering Factor\n\n\n                 Figure 8: Distribution of optimal steering factors for each method across the 4 tasks.\n\n                                   AXBENCH\n\n\n\n\n\n             Gemma-2-2B            Gemma-2-2B            Gemma-2-9B            Gemma-2-9B\n                  L10                     L20                     L20                     L31\n      1.2\n\n      0.8                                                                                                                                                                                                                                                                                  Concept\n      0.4                                                                                                                                                                                       Score\n      0.0\n\n                                                                                Method      1.0\n                                                                                                                       ReFT-r1                                                                                                                                                                                                                                                                                  Fluency\n      0.5                                                                                                           DiffMean\n                                                                                                                                                                                                    Score                                                                                              SAE\n      0.0                                                                                                    SAE-AScore  2.0\n                                                                                          LAT\n      1.5\n                                                                                      PCA      1.0                                                                                                                                                                                                                                                                                                    Instruct                                                                                                                     Probe\n      0.5                                                                                                                                                                                       Score       SSV\n      0.0\n      0.6\n\n      0.4                                                                                                                                                                                                                                                                                  Overall\n      0.2                                                                                                                                                                                       Score\n\n      0.0\n        0.3  1  3     0.3  1  3     0.3  1  3     0.3  1  3\n                                            Steering Factor\n\n\n                                       Figure 9: Steering factor vs. scores.\n\n                                   AXBENCH\n\nD. Supervised dictionary learning method works with very limited amount of training data.\n\nBased on the performance results, ReFT-r1 is the strongest SAE alternative. We further study the data scaling law of ReFT-r1\nby varying the number of training examples. Specifically, we measure ReFT-r1 performance on both concept detection and\nsteering with CONCEPT10 when the number of training example is set to {6, 12, 24, 48, 72, 96, 120, 144}. In the extreme\nsetting, we provide only 3 positive and 3 negative examples. Since we have a limited pool of concepts, we average our\nresults with three random seeds: {42, 43, 44}.\n\nFigure 10 shows how the performance of ReFT-r1 varies in C (concept detection) and S (model steering) when trained\nwith different numbers of training examples. For earlier layers, scores increase with more data, while for Gemma-2-9B, the\ntrend is less clear for concept detection. Our results indicate that once a certain threshold is reached, performance saturates\nfor both tasks, suggesting that the cost of training ReFT-r1 can be further reduced. The per-concept cost with 144 training\nexamples is approximately $0.008, and this cost decreases proportionally as the number of training examples is reduced.\n\n                      Gemma-2-2B: L10                   Gemma-2-2B: L20\n            0.8\n\n            0.6\n\n            0.4\n\n            0.2                                                              # Examples        Score\n                                                                                               50\n                      Gemma-2-9B: L20                   Gemma-2-9B: L31\n            0.8                                                                                  100           Overall\n\n            0.6\n\n            0.4\n\n            0.2\n\n                  0.80         0.85         0.90         0.95         1.000.80         0.85         0.90         0.95         1.00\n                        AUROC\n\nFigure 10: Scaling law for supervised dictionary learning (SDL) method ReFT-r1 with CONCEPT10 on both C concept\ndetection and S model steering.\n\n                                   AXBENCH\n\nE. SDLs at scale: Analysing CONCEPT16K\n\nE.1. ReFT-r1: CONCEPT16K subspace for code error handling.\n\nWe scale up two supervised dictionary learning methods DiffMean and ReFT-r1 with CONCEPT16K. They serve as drop-in\nreplacements of existing SAEs on Gemma models with better performance for concept detection and steering.\n\nFigure 11 shows the UMAP of ReFT-r1’s CONCEPT16K subspaces learned with Gemma-2-2B at layer 20’s residual stream.\nSubspaces are meaningfully clustered together by genres. Within each genre cluster, related features are also clustered\ntogether. For instance, we identify a subspace cluster for concepts related to “Code error handling and logging,” which\nincludes the following concepts:\n\n   • Subspace 16K/14404: “error messages related to system calls and file operations”\n   • Subspace 16K/14801: “terms related to programming errors and error handling”\n   • Subspace 16K/5656: “technical terms and parameters related to errors and status in programming contexts”\n   • Subspace 16K/4884: “error messages and exceptions in code related to server or network operations”\n   • Subspace 16K/2467: “references to errors and warnings, especially related to file or access issues”\n\n                         ReFT-r1 subspaces\n\n                                                                                     genre\n                                                                                                          text\n                                                                                    code\n                                                                            math\n\n\n\n\n                                                                                                                                                                                            technical terms and\n                                                                                                                                                                      parameters related\n                                                                                                                                               terms related to        to errors and status\n                                                                                                                              programming errors       in programming\n                                                                                                                              and error handling            contexts\n\n\n\n                                                                                                                                                                                                  error messages\n2                                   2                   references to errors       related                                                                                                                                                                                                           to system\n                                                                                                                                     and warnings,             calls and file\n                                                                                                                                                                          especially related           operations UMAP                                                                                                                                             UMAP                     to file or access\n                                                                                                                                                                              issues\n\n                                                                                                                                                                                                error messages and\n                                                                                                                                                                                     exceptions in code\n                                                                                                                                                                                                 related to server or\n                                                                                                                                                                network operations\n\n\n\n\n                                                                                    UMAP 1\n\n\n\n\n\n                             UMAP 1\n\n        Figure 11: UMAP of ReFT-r1’s CONCEPT16K subspaces with Gemma-2-2B at layer 20’s residual stream.\n\n                                   AXBENCH\n\nE.2. Mapping natural language to subspaces.\n\nWe explore whether we can find a direct mapping from natural-language concept descriptions to subspaces. We first train\nReFT-r1 with CONCEPT16K and create a supervised dataset DGenerator = {(c, wcReFT-r1)16K0  }, where the input c is the concept\ndescription in natural language and the output is the ReFT-r1 subspace vector corresponding to the concept. We divide\nDGenerator into training and testing sets, ensuring that the testing set contains only concepts from CONCEPT500, which are\nexcluded from the training set. To train the generator, we attach a supervised linear head ΦGenerator to the last input token\nrepresentation at the n-th position of the last layer m, predicting the learned ReFT-r1 subspace:\n\n\n\n                     L = LMSE+Cosine wcReFT-r1, ΦGenerator([LMθ(c)]mn )                                (11)\n\n\n\n\nwhere we fine-tune the generator head and the LM using equally weighted MSE and cosine distance losses. We do finetune\nthe base LM Gemma-2-2b for our subspace generators. We partition the last 500 examples in our training dataset as our\nin-training development set to early-stop our training with a patience step set to 3.\n\nWe generate ReFT-r1 subspaces for CONCEPT500 and follow our evaluation paradigm in AXBENCH to evaluate concept\ndetection and model steering. We show two cases below by unembedding generated subspaces with the output embedding\nmatrix. We find that the subspace generator works better in English as opposed to other languages.\n\nAs shown in Table 4a and Table 4b, subspaces for unseen concepts generated by our finetuned model exhibit only slight\nperformance degradation in concept detection, while performance drops more significantly in model steering.\n\n\n\n\n\n   Method       Gemma-2-2B   Gemma-2-9B   Avg.       Method       Gemma-2-2B   Gemma-2-9B   Avg.\n                 L10    L20    L20    L31                            L10    L20    L20    L31\n\n   DiffMean       0.948   0.946   0.955   0.921   0.942       ReFT-r1         0.633   0.509   0.630   0.401   0.543\n    ReFT-r1         0.952   0.965   0.966   0.869   0.938       ReFT-r1 (Gen)  —    0.415   0.466  —    —-\n    ReFT-r1 (Gen)  —    0.945   0.965  —   —        DiffMean       0.297   0.178   0.322   0.158   0.239\n   SAE            0.735   0.755   0.631   0.659   0.695     SAE            0.177   0.151   0.191   0.140   0.165\n\n                         (a) C Mean AUROC.                                                (b) S Overall score.\n\n             Table 4: Results on CONCEPT500 for ReFT-r1 (Gen) vs. ReFT-r1 and other selected methods.\n\n\n\n\n\n  Unseen concept description in Chinese\n\n 道德经a\n\n  Top positive logits when unembedding the subspace\n\n   (’ ethical’, 1.4296875), (’ moral’, 1.3984375), (’ ethics’, 1.2421875), (’Ethical’, 1.1640625), (’ Ethical’, 1.15625), (’moral’, 1.125),\n   (’ Ethics’, 1.0859375), (’ Moral’, 1.0859375), (’Ethics’, 1.0703125), (’ethical’, 1.0703125)\n\n  Top negative logits when unembedding the subspace\n\n   (’DockStyle’, -0.78125), (’ venons’, -0.6796875), (’ purpose’, -0.67578125), (’complexContent’, -0.671875), (’ stupidly’, -\n   0.66796875), (’ fooled’, -0.66015625), (’ Jefus’, -0.65234375), (’ small’, -0.6328125), (’ mont´on’, -0.62109375), (’ Dummies’,\n  -0.6171875)\n\n     ahttps://en.wikipedia.org/wiki/Tao Te Ching.\n\n                                  AXBENCH\n\nUnseen concept description in English\n\nBusiness-related terms and symbols, particularly focusing on entrepreneurship and financial aspects, as well as formatting and\ncoding indicatorsa\n\nTop positive logits when unembedding the subspace\n\n(’ investment’, 1.1953125), (’ asset’, 1.1484375), (’ financial’, 1.1328125), (’ investments’, 1.0625), (’ Investment’, 1.046875), (’\nmarket’, 1.0390625), (’ portfolio’, 1.03125), (’ investor’, 1.03125), (’ assets’, 1.0078125), (’ investors’, 1.0078125)\n\nTop negative logits when unembedding the subspace\n\n(’ sauvages’, -0.8515625), (’ hˆate’, -0.76953125), (’ rapides’, -0.76171875), (’ r´egl’, -0.7421875), (’ d´ecouvertes’, -0.71875), (’\nferm´es’, -0.69921875), (’ compl`etes’, -0.69140625), (’ pr´ec´edents’, -0.68359375), (’setVerticalGroup’, -0.68359375), (’ d´ecouver’,\n-0.671875)\n\n   aTaken from https://github.com/yoavgur/Feature-Descriptions/blob/main/descriptions/gemma-2-2b.csv.\n\n                                   AXBENCH\n\nE.3. Teleporting between subspaces across models through affine transformations.\n\nWe explore whether structural equivalence in subspaces exists across models. Previous works have analyzed feature\nuniversality in SAEs but have been limited to a small set of features (Lan et al., 2024). Given that our CONCEPT16K dataset\ncontains two sets of concepts for Gemma-2-2B and Gemma-2-9B, we first train ReFT-r1 on both models separately, obtaining\nw2BReFT-r1 and w9BReFT-r1. Next, we perform a cross-fitting experiment, training ReFT-r1 on Gemma-2-2B with concepts from\nGemma-2-9B, resulting in w9BReFT-r1,| 2B and vice versa for w2BReFT-r1.| 9B Thus, w9BReFT-r1 and w9BReFT-r1| 2B represent two sets of subspaces\nfrom different models that correspond to the same set of concepts.\n\nWe then study whether a transformation can map between these two sets of subspaces:\n\n                               w9BReFT-r1 = Φ2B→9BTransformation(w2BReFT-r1),| 9B\n\nwhere ΦTransformation is parameterized by a linear layer with a bias (i.e., an affine transformation). We learn the transformation\nusing equally weighted MSE and cosine distance losses. Similarly, Φ9B→2BTransformation is trained by reversing the direction.\nDuring training, we exclude concepts from CONCEPT500, and evaluate the transformation on CONCEPT500 at test time by\ngenerating subspaces. We follow our evaluation paradigm in AXBENCH to assess concept detection and model steering.\n\nOur evaluation results on CONCEPT500 are presented in Table 5a and Table 5b. Surprisingly, the affine transformation\nperforms well in both directions (from 2B →9B and 9B →2B), with little to no change in concept detection performance.\nWhile performance drops for model steering, it still outperforms other methods, including fine-tuning. Figure 12 and\nFigure 13 visualize the transformations using the first two PCA dimensions. PCA is preferred over UMAP in this context\nbecause it is sensitive to rotation.\n\n Method          Gemma-2-2B   Gemma-2-9B   Avg.    Method          Gemma-2-2B   Gemma-2-9B   Avg.\n                   L10    L20    L20    L31                            L10    L20    L20    L31\n\n  DiffMean           0.948   0.946   0.955   0.921   0.942    ReFT-r1            0.633   0.509   0.630   0.401   0.543\n  ReFT-r1            0.952   0.965   0.966   0.869   0.938    ReFT-r1 (9B→2B)  —    0.444  —   —   —\n  ReFT-r1 (9B→2B)  —    0.954  —   —   —     ReFT-r1 (2B→9B)  —   —    0.541  —   —\n  ReFT-r1 (2B→9B)  —   —    0.974  —   —     DiffMean           0.297   0.178   0.322   0.158   0.239\n SAE                0.735   0.755   0.631   0.659   0.695   SAE                0.177   0.151   0.191   0.140   0.165\n\n                         (a) C Mean AUROC.                                                (b) S Overall score.\n\n            Table 5: Results on CONCEPT500 for ReFT-r1 (affine) vs. ReFT-r1 and other selected methods.\n\n\n\n                 Gemma-2-2B L20 (Source)           Gemma-2-9B L20 (Target)                  Source > Target\n                                                                     0.6\n                                                                                                                 0.50\n                 0.50                                                0.4\n                                                                                                                 0.25                                         Genre   2                                                       0.2\n                 0.25                                                                                                             Code\n        PCA                                               0                                         0                                     Math\n                 0                                                                                                                                    Text\n                                                                     0.2                                            0.25\n                 0.25                                                0.4                                            0.50\n           0       0.4       0.8        0.2 0  0.2  0.4  0.6        0        0.5\n                                              PCA 1\n\n\nFigure 12: Visualizations of CONCEPT16K subspaces of Gemma-2-2B and Gemma-2-9B at layer 20 with top 2 principal\ncomponent analysis (PCA) dimensions. The last panel is the derived subspaces by transforming the subspaces from\nGemma-2-2B to Gemma-2-9B through a learned affine transformation. The concept lists for CONCEPT16K is taken from the\nsource model.\n\n                                   AXBENCH\n\n\n\n\n\n                 Gemma-2-2B L20 (Target)           Gemma-2-9B L20 (Source)                  Source > Target\n                                                                     0.6                                            0.75\n\n                 0.50                                                0.4                                            0.50\n                                                                                                                                                Genre\n   2   0.25                                                0.2                                            0.25                                     Code\n        PCA                                                                                                                  Math\n                 0                                         0                                         0                                             Text\n\n                                                                     0.2                                            0.25                 0.25\n                  0.25 0    0.25   0.50   0.75     0.3  0    0.3    0.6    0.9      0        0.5\n                                              PCA 1\n\n\nFigure 13: Visualizations of CONCEPT16K subspaces of Gemma-2-2B and Gemma-2-9B at layer 20 with top 2 principal\ncomponent analysis (PCA) dimensions. The last panel is the derived subspaces by transforming the subspaces from\nGemma-2-9B to Gemma-2-2B through a learned affine transformation. The concept lists for CONCEPT16K is taken from the\nsource model.\n\n                                   AXBENCH\n\nF. Ablations\n\nF.1. SAE\n\nAddition vs. clamping.  In our main results, we steer using SAEs by adding their decoder features directly to the residual\nstream. While this is a common technique for steering with SAEs, most work by Anthropic (e.g. Templeton et al., 2024;\nDurmus et al., 2024) uses an alternative formulation termed clamping, where the latent zf for feature f is directly clamped\nto a value α (multiplied by the maximum activation for that feature mf) and the full intervened SAE output added to its\nunclamped reconstruction error Err(hi):\n\n\n                                                                     clamped\n                        ΦSAEClamp(hi) = (W⊤enchi + (αz ·}|mf{ −zf)e⊤f )Wdec + Err(hi)                          (12)\n                                     zf = (W⊤enchi)f                                                            (13)\n                              Err(hi) = hi −(W⊤enchi)Wdec                                                  (14)\n\nwhere e⊤f  is a one-hot vector with a non-zero entry at the dimension corresponding to mf. We evaluate clamping on all\nsteering tasks on CONCEPT500 for direct comparison with the addition-based GemmaScope SAE. We use the following\nvalues for α (the steering factor): {0.4, 0.8, 1.2, 1.6, 2.0, 3.0, 4.0, 6.0, 8.0, 10.0, 20.0, 40.0, 60.0, 100.0}. Overall, we find\nthat clamping is on average worse than addition for SAEs, although it exhibits marked improvement when scaling up from\n2B to 9B.\n\nMaximum activation and minimum clamping.  In our main results, the maximum activation for our feature mf is\nobtained from Neuronpedia. This approach differs from other methods, which determine the maximum activation by\nanalyzing the activation distribution over the evaluation dataset for concept detection. For this experiment, we calculate mf\nfor SAEs in the same manner as other methods. As shown in Table 6 and Figure 14, changing the method of calculating\nmaximum activations has minimal impact on the steering performance; most comparisons are statistically insignificant.\n\nIn addition, building on regular activation clamping as described above, we try a novel minimal clamping where we only\nclamp the activation value if it is smaller than the target value:\n\n\n                                                                      clamped\n                    ΦSAEClamp(hi) = (W⊤enchi + (max(zα ·}|mf,{ zf) −zf)e⊤f Wdec + Err(hi)                     (15)\n\nwhere (W⊤enchi)f is the original activation value at the corresponding of feature f and e⊤f  is a one-hot vector with a non-zero\nentry at the dimension corresponding to mf. As shown in Table 6 and Figure 14, using minimum clamping has no significant\nimpact on SAE’s steering performance.\n\nResults. We report results in Table 6. We also examine the effect of varying α in Figure 14. Note that α is likely a\nconcept-dependent parameter; the optimal α varies from concept to concept. We notice an odd trend for clamping: small\nvalues of α have a similar effect on model behaviour as large values of α; both cause concept score to increase and instruct\nscore to decrease.\n\n Method          Gemma-2-2B   Gemma-2-9B   Avg.   Method           Gemma-2-2B    Gemma-2-9B    Avg.\n                   L10    L20    L20    L31                            L10    L20    L20    L31\n\n SAE                0.177   0.151   0.191   0.140   0.165  SAE              50.0%   50.0%   50.0%   50.0%   50.0%\n SAE (max act)       0.166   0.150   0.163   0.128   0.152  SAE (max act)      49.1%   49.8%   46.8%   47.5%   48.3%\n SAE-c (min clamp)   0.074   0.072   0.123   0.090   0.090   SAE-c             36.3%   38.7%   42.1%   49.2%   41.6%\n SAE-c              0.063   0.061   0.126   0.120   0.088   SAE-c (min clamp)   38.2%   40.1%   41.0%   42.8%   40.5%\n\n                           (a) Overall score.                                                       (b) Winrate.\n\n                                   Table 6: S Overall scores on model steering.\n\n                                   AXBENCH\n\n                          Gemma-2-2B: L10                Gemma-2-2B: L20\n                    0.4\n\n                    0.3                                                Method\n                                                                         SAE\n                    0.2                                                         SAE (max act)\n                                                                                      SAE-c (min clamp)\n                    0.1                                                                    SAE-c                  Score\n                          Gemma-2-9B: L20                Gemma-2-9B: L31          Steering Factor                    0.4\n                                                                                              25                         Concept\n                    0.3                                                                          50\n                                                                                              75\n                    0.2\n                                                                                              100\n\n                    0.1\n\n                     2.0      1.5      1.0      0.5       2.0      1.5      1.0      0.5\n                                          Instruct Score\n\nFigure 14: S Instruct score vs. concept score for SAEs with addition (SAE) vs. clamping (SAE-c) when varying the steering\nfactor. Additionally, we include results when SAE is clamped with the maximum activation value calculated based on our\nevaluation dataset for concept detection, as well as results with minimum clamping of activation values.\n\n\nG. Large language model (LLM) usage\n\nWe use LLMs for two purposes: to generate labelled concept data for training supervised steering methods and to evaluate\nthe responses generated by the steered models. Specifically, we use OpenAI’s gpt-4o-mini-2024-07-18 (accessed via the\nalias gpt-4o-mini in the API) throughout our experiments. The date we access the LLM ranges from December 2024 to\nJanuary 2025, and we use the default generation configuration with temperature set to 1.0 to fetching LLM responses. For\n1M tokens, it costs $0.15 for input tokens and $0.60 for output tokens.\n\nH. Gradient-based baselines\n\nC Input×gradients (I×G).  Gradient-based interpretability methods have been shown to be useful in computer vision\nand NLP (Sundararajan et al., 2017; Wallace et al., 2019). I×G serves as the gradient-based baseline. We first train a linear\nclassification head ΦCLS on the token representation at the n-th position of the last layer m, to predict the ground-truth\nconcept-presence class label y:\n                            L = LBCE y, ΦCLS(h(m)n  )                                           (16)\n\nwhere ΦCLS is parameterised by an MLP with two linear layers. For an evaluation sentence x, the LM generates hidden\nrepresentations h with n tokens at layer l. With Autograd provided in PyTorch, we calculate the gradient of the output\nclassification head with respect to each hidden representations. To aggregate across dimensions, we compute the sum of the\nabsolute gradients over all dimensions for each hi, which we use as the token-level importance. This gives a sequence of\naggregated values:\n\n\n                                 ΨI×GDetect(h) = g = [ g1, g2, . . . , gn ]\n\nwhich indicates the relevance of each token for the concept. For concept detection, we then use max-pooling as described in\n§3.2 to get sequence-level predictions. I×G is not applicable for model steering.\n\n                                   AXBENCH\n\nC Integrated gradients (IG).  We adapt IG (Sundararajan et al., 2017) to trace the accumulated gradients with respect\nto intermediate representations. To use IG, we train a classification head as in I×G. For each token representation hi, we\ncompute IG along a straight-line path from a baseline hbaselinei      to hi. Here, we use the embedding of a single space token\n(i.e., tokenizer(‘‘ ’’)), obtained via the tokenizer and model embeddings, as the baseline. The IG is computed as:\n\n\n                                     Z 1\n                      IG(hi) = (hi −hbaselinei     ) ·   ∇hΦCLS  hbaselinei   + α(hi −hbaselinei     ) dα\n                                                     0\n\nwhere the integral is approximated using a discrete summation with 50 interpolation steps.14 See IG’s original paper about\nimplementation details on path intergral. To aggregate across dimensions, we compute the sum of the absolute gradients\nover all dimensions for each hi. We follow the setup for I×G get sequence-level predictions for concept detection. IG is not\napplicable for model steering.\n\nI. Instruction pool\n\nTo create our instruction pool, we sample instructions from existing datasets covering three genres: text, code, and math.\nFor text-based instructions, we sample from Dolly-15K15. For code-based instructions, we sample from a collection of\nPython-code puzzles formed in Alpaca-style (i.e., instructions with corresponding responses)16 For math-based instructions,\nwe sample from GSM8K17 For each genre, we create two disjoint sets for training and testing separately with 1,000 examples\neach. The LLM generated response for each instruction is provided as well. To avoid any heterogeneity, we avoid using the\ngolden labels provided by the orignal dataset and only use the LLM generated response.\n\n  Text instruction\n\n  Why do some people select private schools over public schools?\n\n LLM generated response\n\n   Sure, here are some ways to reduce air pollution: There are many reasons why some people choose private schools over public\n   schools. Here are some of the most common:\n\n  **Academic Focus and Curriculum:**\n\n  * **Smaller class sizes:** Private schools often have smaller class  sizes, allowing for more individualized attention\n  from teachers.\n  * **Specialized programs:** Some private schools offer specialized programs in areas like STEM, arts, or foreign languages, which\n  may not be available in public schools.\n  * **Rigorous academics:** Private schools often have higher academic standards and more challenging curriculum, which can\n   prepare students for college and careers.\n  * **Emphasis on specific values:** Some private schools emphasize specific values, such as religious faith, classical education, or a\n   particular philosophy of learning.\n\n   **Extracurricular Activities and Resources:**\n\n  * **Extensive extracurricular activities:** Private schools often have a wider range of extracurricular activities, includ-\n   ing sports, music, drama, and clubs.\n  * **State-of-the-art facilities:** Private schools\n\n\n\n\n\n  14We choose a small step number due to limited compute resource. For 9B models, we use a step size of 5.\n  15https://huggingface.co/datasets/databricks/databricks-dolly-15k.\n  16https://huggingface.co/datasets/iamtarun/python code instructions 18k alpaca.\n  17https://huggingface.co/datasets/openai/gsm8k.\n\n                                 AXBENCH\n\nCode instruction\n\nCreate a machine learning classifier in Python for categorizing user input\n\nLLM generated response\n\nimport numpy as np\nfrom sklearn.model selection import train test split\nfrom sklearn.feature extraction.text import CountVectorizer\nfrom sklearn.naive bayes import MultinomialNB\n\n# Sample data encapsulating numeric outcomes related to API logs\ndata = [\n(”GET /api/users”, 0),\n(”POST /api/data”, 1),\n(”PUT /api/settings”, 1),\n(”DELETE /api/users/123”, 0)\n]\n\n# Separate features and labels\nX, y = zip(*data)\n\n#\n\n\nMath instruction\n\nJohn puts $25 in his piggy bank every month for 2 years to save up for a vacation. He had to spend $400 from his piggy bank savings\nlast week to repair his car. How many dollars are left in his piggy bank?\n\nLLM generated response\n\nHere’s how to solve the problem:\n\n**1. Calculate total savings:**\n\n* John saves $25 per month for 12 months in a year, so in 2 years he saves 2 years * 12 months/year = 24 months.\n* His total savings are $25/month * 24 months = $600.\n\n**2. Calculate remaining savings:**\n\n* John spent $400 on his car, so he has $600 - $400 = $200 left in his piggy bank.\n\n\n**Answer:** John has $200 left in his piggy bank.\n\n                                   AXBENCH\n\nJ. Prompt templates\n\nIn this section, we present the templates that we use to call LLM to generate datasets or evaluate results. For placeholders in\nthe template, they will be filled with proper information.\n\n\nJ.1. Prompt-based steering\n\nOur prompt-based model steering baseline is not a zero-shot prompting baseline. Instead of directly prompting LLM to\ngenerate steered responses, we first use LLM to generate an enhanced prompt for model steering. Our template is included\nin the following.\n\n\n\n\n LLM-based steering prompt generation\n\n  Generate a prompt to guide a language model in producing responses.\n\n   Objective:  Direct the model to include content related to [Concept goes here] (the concept) in its responses.  Ensure the\n   responses reference this concept, even if it doesn’t directly answer the question or seems out of context. Optionally, provide\n   in-context examples to reinforce this behaviour.\n\n  Return only the final prompt without any additional text.\n\n\n\n\n\nJ.2. Synthetic data generation\n\nOur data generation pipeline contains multiple steps, and we use different templates at each step. We present the template\nthat we use for each step in the following.\n\n\n\n\n  Fetch genre\n\n  Given the concept:\n\n  [Concept goes here]\n\n   Identify the single primary genre that best fits the concept from the following options:\n\n   Text; Code; Math\n\n  Output only the best-fitting genre. If none apply, output ‘<NONE>’.\n\n  **Formatting Guidelines:**\n   - Output the genre on a single line.\n   - Do not include any additional text or formatting.\n\n  **Examples:**\n   - Concept: ’words or phrases containing odd numbers’ Output: Text\n   - Concept: ‘a programming error’ Output: Code\n   - Concept: ‘integral calculus’ Output: Math\n   - Concept: ‘a narrative poem’ Output: Text\n\n  Return only the single best-fitting genre as specified.\n\n                                  AXBENCH\n\nList words related to the concept\n\nGiven the following concept:\n\n[Concept goes here]\n\nYour task is to list up to 10 English words that are closely related to this concept.  Each word should be a single, com-\nmon English word.\n\nOutput each word on a separate line, in plain text, without any special formatting (e.g., no quotation marks, numbers,\nbullet points, or additional text).\n\nIf the concept is too broad or vague (e.g., ‘any English word’, ‘words starting with A’), or if the concept refers to a spe-\ncific technical term, a computer program, or a specific fact, then output ’<NONE>’ without quotation marks.\n\nDo not include any additional explanations or text other than the words or ‘<NONE>’ as specified.\n\n\nFind alternative senses of a word\n\nGiven the word:\n\n[Word goes here]\n\nProvide one other common semantic meaning of this word that is distinct from and unrelated to:\n\n[Concept goes here]\n\nYour response should be a brief description of the other meaning, written in plain text without any special formatting.\nSpecifically:\n- Do not use quotation marks.\n- Do not include list numbers, bullet points, or any prefixes.\n- Do not add any additional explanations or text.\n\n If there is no other obvious semantic meaning unrelated to the provided concept, simply output ‘<NONE>’ without quotation marks.\n\n\nCheck whether two senses are different\n\nDetermine if Concept A is meaningfully distinct from Concept B by thoroughly examining their definitions, core features, typical\nusage, and any potential overlaps in meaning, context, or purpose.\n\nConcept A: [Concept goes here]\nConcept B: [Concept goes here]\n\nAnalyze these concepts for **any** shared meanings, contexts, roles, or purposes, focusing on how they relate or inter-\nsect. Please explain your reasoning, considering both similarities and differences.\n\n- If Concept A and Concept B have **any** overlap in meaning, context, usage, or  if one is a subset or specific in-\nstance of the other, conclude with ‘Answer: <NO>’.\n- Only if they are **entirely unrelated** with **no overlap whatsoever** in meaning, context, or usage, conclude with ‘Answer:\n<YES>’.\n\n**Final Answer:** ’Answer: <YES>’ or ’Answer: <NO>’.\n\n                                  AXBENCH\n\nCheck whether one sense is different from other concepts\n\nEvaluate whether Concept A is meaningfully distinct from a given set of concepts by examining their definitions, core features,\ntypical usage, and any potential overlaps in meaning, context, or purpose.\n\nConcept A: [Concept goes here]\nExisting Concepts: [Concepts go here]\n\nFor each concept in the set, analyze Concept A for **any** shared meanings, contexts, roles, or purposes.  Consider\nhow Concept A might relate or intersect with each concept individually, as well as with the group collectively. Please explain your\nreasoning by examining both similarities and differences.\n- If Concept A has **any** overlap in meaning, context, usage, or if it is a subset or specific instance of **any concept** in the set,\nconclude with ‘Answer: <NO>’.\n- Only if Concept A is **entirely unrelated** with **no overlap whatsoever** in meaning, context, or usage to **all** concepts in\nthe set, conclude with ‘Answer: <YES>’.\n\n**Final Answer:** ‘Answer: <YES>’ or ‘Answer: <NO>’.\n\n\nModify content with concept\n\nContent Modification Task:\n\nYou are given the following content:\n\n[Modifying content go here]\n\nYour task is to minimally modify this content by inserting some commonly used words, phrases, or elements that reflect\nthemes or ideas related to ‘[Concepts go here]’ into the middle of the content. These insertions should not be at the beginning or end\nof the content, even if they disrupt overall coherence.\n\nGuidelines:\n- Try to avoid copying words from the definition of ‘[Concepts go here]’ if possible.\n- Ensure parts of the content remain unrelated to the concept ‘[Concepts go here]’.\n- The final content should have approximately the same length as the original content.\n- The concept should be clearly represented through the inserted word, phrase, or element, even if the content’s meaning isn’t entirely\ncoherent.\n- Use special characters only if appropriate for the genre (e.g., operators in code or math equations).\n\nOutput:\nInclude the special tag <FINAL> at the beginning of the final content, followed by the content itself. Return only this tagged\ncontent, with no additional text.\n\n                                  AXBENCH\n\nModify content with contrastive concept\n\nContent Modification Task:\n\nYou are given the following content:\n\n[Concept goes here]\n\nYour task is to minimally modify this content by inserting the word ‘WORD’ into the middle of the content.  This word,\nalong with modified content, should convey meanings related to the concept ‘[Concept goes here]’. The insertion should not be at\nthe beginning or end of the content.\n\nGuidelines:\n- Ensure parts of the content remain irrelevant to the concept ‘[Concept goes here]’.\n- Avoid any mention of ‘[Contrast concept goes here]’ in the content, regardless of coherence.\n- The final content should have approximately the same length as the original content.\n- Ensure the content reflects the essence of the concept associated with ‘[Concept goes here]’, even if the overall meaning isn’t\nentirely coherent.\n- Ensure grammatical correctness (or syntactical correctness for code/equations).\n- Use special characters only if appropriate for the genre (e.g., operators in code or math equations).\n\nOutput:\nInclude the special tag <FINAL> at the beginning of the final content, followed by the content itself. Return only this tagged\ncontent, with no additional text.\n\n\nGenerate response given instruction\n\nGiven the following instruction:\n\n[Instruction goes here]\n\nYour task is to provide a response.\n\n**Formatting Guidelines:**\n- Return only the response to the instruction.\n- Write the final content (or appropriate format for the genre) in plain text.\n- Do not include any additional text, explanations, or formatting.\n\n\n**Final Answer:** Return only the final content, following the guidelines above.\n\n                                  AXBENCH\n\nGenerate response given instruction and concept\n\nGiven the following instruction:\n\n[Instruction goes here]\n\nYour task is to:\n1. Provide a response that incorporates elements related to ‘[Concept goes here]’.\n2. Try to avoid copying words from the definition of ‘[Concept goes here]’ if possible.\n3. Ensure that your response relates to ‘[Concept goes here]’, even if the overall meaning is not fully coherent.\n\n**Formatting Guidelines:**\n- Return only the response to the instruction.\n- Write the final content (or appropriate format for the genre) in plain text.\n- Do not include any additional text, explanations, or formatting.\n\n**Final Answer:** Return only the final content, following the guidelines above.\n\n\nGenerate response given instruction without mentioning given concept\n\nGiven the following instruction:\n\n[Instruction goes here]\n\nYour task is to:\n1. Provide a response that continues or addresses the instruction naturally.\n2. Avoid any mention of ‘[Concept goes here]’ in the continuation, regardless of coherence.\n\n**Formatting Guidelines:**\n- Return only the response to the instruction.\n- Write the final content (or appropriate format for the genre) in plain text.\n- Do not include any additional text, explanations, or formatting.\n\n**Final Answer:** Return only the final content, following the guidelines above.\n\n                                  AXBENCH\n\nGenerate response given instruction with contrastive concept\n\nContent Response Task:\n\nYou are given the following instruction:\n\n[Instruction goes here]\n\nYour task is to provide a response to the instruction by inserting the word ‘[Word goes here]’ into the middle of the re-\nsponse. This word, along with the response, should convey meanings related to the concept ‘[Contrastive concept goes here]’. The\ninsertion should not be at the beginning or end of the response.\n\nGuidelines:\n- Avoid any mention of ‘[Concept goes here]’ in the response, regardless of coherence.\n- Ensure the response reflects the essence of the concept associated with ‘[Word goes here]’, even if the overall meaning isn’t entirely\ncoherent.\n- Ensure grammatical correctness (or syntactical correctness for code/equations).\n- Use special characters only if appropriate for the genre (e.g., operators in code or math equations).\n\nOutput:\nInclude the special tag <FINAL> at the beginning of the final response, followed by the response itself. Return only this tagged\nresponse, with no additional text.\n\n                                   AXBENCH\n\nJ.3. Automatic evaluation\n\nWe use LLM to evaluate the steering responses of the model. The responses are evaluated with three metrics: concept score,\ninstruct score and fluency score. We prompt the model to always generate explanations before assigning scores, which\nsignificantly outperforms directly asking for scores in our offline experiments.\n\nWe find that this ternary scoring system is crucial to get faithful and stable scores from LLM. For instance, a unified prompt\nasking the LLM to rate a response given an instruction and a concept is not effective through our experiments, as the LLM\nusually ignores the lack of the concept as long as the response follows the instruction. The fluency score is needed as the\nmodel can cheat by generating fragmented tokens that relate to the concept and the instruction, while being incoherent to\nhumans.\n\nTemplates for all scores are provided below:\n\n  Concept score\n\n   [System]\n   Please act as an impartial judge and evaluate whether the specified concept is presented in the sentence fragment provided below.\n  Focus solely on whether the concept is clearly incorporated, without regard for grammar or logical coherence.\n\n  Begin your evaluation by providing a short explanation of whether the concept is clearly incorporated.  Point out refer-\n   ences to the concept in the fragment, noting any minimal or awkward incorporations. After providing your explanation, rate the\n   concept’s relevance on a scale from 0 to 2, where 0 indicates the concept is not present at all, 1 indicates the concept is somewhat\n   present but minimally or awkwardly incorporated, and 2 indicates the concept is more fully and effectively incorporated, with\n   stronger and more natural integration. Provide your rating using this exact format: “Rating: [[score]]”.\n\n   [Concept Start]\n   [Concept goes here]\n   [Concept End]\n\n   [Sentence Fragment Start]\n   [Sentence goes here]\n   [Sentence Fragment End]\n\n\n  Instruct score\n\n   [System]\n   Please act as an impartial judge and evaluate whether the sentence fragment provided below is related to the instruction. Focus\n   solely on the degree of relatedness in terms of topic, regardless of grammar, coherence, or informativeness.\n\n  Begin your evaluation by providing a brief explanation of whether the sentence is related to the instruction, and point\n   out references related to the instruction. After providing your explanation, rate the instruction relevance on a scale from 0 to 2,\n  where 0 indicates the sentence is unrelated to the instruction, 1 indicates it is somewhat related but only minimally or indirectly\n   relevant in terms of topic, and 2 indicates it is more clearly and directly related to the instruction. Provide your rating using this\n   exact format: “Rating: [[score]]”.\n\n   [Instruction Start]\n   [Instruction goes here]\n   [Instruction End]\n\n   [Sentence Fragment Start]\n   [Sentence goes here]\n   [Sentence Fragment End]\n\n                                 AXBENCH\n\nFluency score\n\n[System]\nPlease act as an impartial judge and evaluate the fluency of the sentence fragment provided below. Focus solely on fluency,\ndisregarding its completeness, relevance, coherence with any broader context, or informativeness.\n\nBegin your evaluation by briefly describing the fluency of the sentence, noting any unnatural phrasing, awkward transi-\ntions, grammatical errors, or repetitive structures that may hinder readability. After providing your explanation, rate the sentence’s\nfluency on a scale from 0 to 2, where 0 indicates the sentence is not fluent and highly unnatural (e.g., incomprehensible or repetitive),\n1 indicates it is somewhat fluent but contains noticeable errors or awkward phrasing, and 2 indicates the sentence is fluent and\nalmost perfect. Provide your rating using this exact format: “Rating: [[score]]”.\n\n[Sentence Fragment Start]\n[Sentence goes here]\n[Sentence Fragment End]\n\n                                   AXBENCH\n\nK. Hyperparameters\n\nTo ensure a fair comparison, we perform separate hyperparameter-tuning for each method that requires training. For each\nmethod, we conduct separate hyperparameter-tuning on a small CONCEPT10 Dataset containing training and testing datasets\nonly for 10 concepts. These concepts overlap with CONCEPT500. Table 7 and Table 8 show hyperparameter settings for\nmethods that require training. Due to limited compute resource, we select the best setting of hyperparameters based on\nperformance on the C concept detection task using AUC for all dictionary learning methods (i.e., can be evaluated on\nC concept detection). We minimise the loss with AdamW with a linear scheduler for all methods that require training.\nFollowing Gao et al. (2024), we remove gradients that are parallel to the learned weights when training Probe and ReFT-r1,\nto account for interaction between Adam and our weight normalization step.\n\nFor methods that only for steering, we select the best setting based on S model steering performance. We follow a setting\nwhere we only have a single constant steering factor for hyperparameter-tuning. We acknowledge that this might lead to an\noverall underestimation of the performance of S model steering performance. For steering factors, we enumerate factors\nfrom {0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.5, 3.0, 4.0, 5.0}.\n\nComments about decoding strategies.  Through our offline experiments, we observed that the choice of decoding\nstrategies can positively or negatively impact overall steering scores for each method (e.g., perplexity scores increase more\ndrastically with repetition penalties). We use the default decoding strategy (i.e., setting the decoding temperature to 1.0)\nwithout applying additional penalties for repeating tokens. We believe that this setup reflects the typical user interaction with\nlanguage models. However, this is not a common practice in representation-based model steering. Existing works often\napply repeatition or frequency penalties, which we argue is not the fairest setting, as it often does not accurately resemble\nnormal user behaviour.\n\n                                  Table 7: Hyperparameter settings for 2B model.\n\n\n Hyperparameters   LinearProbe  LsReFT       SteeringVector LoReFT    LoRA      SFT         IG/IxG     BoW\n\n  Batch size            {12, 24, 48}   {3, 6, 12}      {3, 6, 12}       {18, 36}      {18, 36}      {36,     72,   {18, 36, 72, —\n                                                                                    144}         144}\n LR                  {1e-4, 5e-4,   {1e-3, 5e-3,   {1e-3,   5e-3,   {3e-4, 6e-4,   {3e-4, 6e-4,   {1e-5, 2e-5,   {2e-4, 4e-4, —\n                        1e-3, 5e-3}     1e-2, 2e-2}    1e-2, 2e-2}      9e-4, 1e-3}    9e-4, 1e-3}    4e-5}          4e-4,   8e-4,\n                                                                                                                         1e-3, 4e-3}\n Weight decay         {1e-4, 1e-3,  0            0             0            0            0             2e-4     —\n                        1e-2, 1e-1}\n L1 sparse     —             {1e-3, 5e-3} —      —     —     —     —     —\n L1 coeff      —             {1e-3, 5e-3} —      —     —     —     —     —\n N epoch              {3,  6,  12,   {3,  6,  12,   {3, 6, 12, 24}    {3, 6, 12, 24,   {3, 6, 12, 24,   {8,  12,  24,   {12, 24, 48, —\n                    24}          24}                        48}          48}          48}          72}\n  Layers       —     —     —              {5,  10,  15,   {5,  10,  15, —     —     —\n                                                           20}          20}\n LoRA alpha    —     —     —      —           32     —     —     —\n LoRA component  —     —     —      —           o proj    —     —     —\n BoW penalty    —     —     —      —     —     —     —            {l1, l2}\n BoW C      —     —     —      —     —     —     —             {0.001, 0.01,\n                                                                                                                                                 0.1,  1,  10,\n                                                                                                              100}\n BoW solver    —     —     —      —     —     —     —            {lbfgs,\n                                                                                                              liblinear}\n\n                                  AXBENCH\n\n\n\n\n\n                                Table 8: Hyperparameter settings for 9B model.\n\n\nHyperparameters   LinearProbe  LsReFT       SteeringVector LoReFT    LoRA       IG/IxG     BoW\n\nBatch size            {12, 24, 48}   {3, 6, 12}      {3, 6, 12}       {18, 36}      {18, 36}      {18, 36, 72, —\n                                                                                   144}\nLR                  {1e-4, 5e-4,   {1e-3, 5e-3,   {1e-3,   5e-3,   {3e-4, 4e-4,   {3e-4, 6e-4,   {2e-5, 4e-5, —\n                       1e-3,   5e-3,   1e-2, 2e-2}     1e-2, 2e-2}      6e-4,   9e-4,   9e-4,   1e-3,   8e-5,   8e-5,\n                       1e-2, 1e-1}                                 1e-3}         5e-3}          1e-4, 4e-4}\nWeight decay         {0, 1e-4, 1e-  0            0             0            0             2e-4     —\n                  3}\nL1 sparse     —             {1e-3, 5e-3} —      —     —     —     —\nL1 coeff      —             {1e-3, 5e-3} —      —     —     —     —\nN epoch              {3,  6,  12,   {3,  6,  12,   {3, 6, 12, 24}   {12, 24, 48}   {12, 24, 48}   {12, 24, 48, —\n                  24}          24}                                                 72}\nLayers       —     —     —             {12, 20, 31,   {12, 20, 31, —     —\n                                                          39}          39}\nLoRA alpha    —     —     —      —           32     —     —\nLoRA component  —     —     —      —           o proj    —     —\nBoW penalty    —     —     —      —     —     —            {l1, l2}\nBoW C      —     —     —      —     —     —             {0.001, 0.01,\n                                                                                                                              0.1,  1,  10,\n                                                                                                100}\nBoW solver    —     —     —      —     —     —            {lbfgs,\n                                                                                                liblinear}\n\n                                   AXBENCH\n\nL. Dataset Statistics\n\nWe show a set of concepts sampled from our CONCEPT10 datasets in Table 9. Table 10 shows dataset statistics including\nthe number of concepts, the number of training and testing examples, the percentage distribution of genre types, and the\naveraged length of input and output sequence. The output sequence length of CONCEPT16K is expected to be shorter since\nwe restrict the maximum sequence length to 64 during data creation.\n\n\nConcept                                                                              Genre\n\nReferences to rental services and associated equipment                                                                 text\nScientific terms related to research findings and their implications                                                     text\nC/C++ programming syntax elements such as data types, function definitions, and variable declarations        code\nReferences to academic papers and their formatting                                                                     text\nLayout attributes in a UI design context                                                                                  text\nTerms related to root in mathematical contexts                                                     math\nStatements or phrases involving the act of saying or expressing something                                            text\nStatements about the nature and condition of entities                                                                    text\nBiographical information about a person                                                                                 text\nReferences to different worlds, realities, or fantastical settings within narratives                                      text\n\n              Table 9: Concepts and their corresponding genres sampled from our CONCEPT10 datasets.\n\n\n\nDataset       Model  Layer  # Concept    # Train    # Test    text (%)   code (%)  math (%)   Input len. (Train / Test)   Output len. (Train / Test)\n\n               2B      10         10        936      770     50.0%    40.0%     10.0%         21 / 18                123 / 92\n               2B      20         10        936      755     80.0%    10.0%     10.0%         19 / 18                118 / 90\nCONCEPT10\n               9B      20         10        936      760     70.0%    30.0%      0.0%         17 / 16                113 / 89\n               9B      31         10        936      768     50.0%    30.0%     20.0%         24 / 20                118 / 91\n\n               2B      10        500       36,216    37,958   66.4%    24.4%      9.2%         17 / 18                102 / 89\n               2B      20        500       36,216    38,037   71.6%    21.4%      7.0%         16 / 17                102 / 89\nCONCEPT500\n               9B      20        500       36,216    38,023   66.8%    25.6%      7.6%         17 / 18                101 / 88\n               9B      31        500       36,216    38,098   63.4%    28.2%      8.4%         17 / 18                102 / 89\n\n               2B      20       15,582    1,122,048     –      69.3%    22.1%      8.6%         17 / –                 62 / –\nCONCEPT16K\n               9B      20       16,000    1,152,216     –      66.2%    25.4%      8.4%         17 / –                 62 / –\n\n                                           Table 10: Dataset statistics.\n\n                                   AXBENCH\n\nM. Concept detection examples\n\n\n\n\n\nFigure 15: Visualization of token-level activations by using ReFT-r1 trained on Gemma-2-2B instruction-tuned model on\nlayer 10.\n\n                                   AXBENCH\n\nN. Model generations\n\nWe provide sampled model generations from different methods to illustrate success cases and common failure cases. We use\nmodels trained with Gemme-2-9B-it at layer 20 for these examples.\n\n\n\n\n  Prompt-based steering\n\n   Generate responses that highlight positive sentiments and describe enjoyable experiences, weaving this concept into your replies,\n  even if it seems unrelated to the specific question. For instance, if asked about the weather, you might share how a sunny day can\n   bring joy and prompt outdoor activities that create memorable moments. If discussing a topic like work, reflect on how teamwork\n   can lead to fulfilling outcomes and enjoyable collaborations. Always aim to evoke a sense of positivity and pleasure in your responses.\n\n   Question: Explain the process of natural selection and how it contributes to the evolution and adaptation of species.\n\n  “positive sentiments and descriptions of enjoyable experiences”\n\n    It’s fascinating to think about how nature constantly tinkers and refines itself, isn’t it? Just like a master artist meticulously chiseling\n  away at a sculpture to reveal its beauty, natural selection acts on populations, gradually shaping them over time.\n\n  Imagine a group of birds with slightly different beak shapes.  Some might have beaks better suited for cracking tough\n   seeds, while others might have longer beaks ideal for reaching nectar deep in flowers. If those with the advantageous beak shapes\n   find more food and have more offspring, their traits get passed down, eventually becoming more common in the population.\n\n    It’s a beautiful\n LLM ratings\n\n  Concept score: 1.0   Instruct score: 2.0   Fluency score: 2.0\n\n\n\n\n\n SAE\n\n   Explain the process of natural selection and how it contributes to the evolution and adaptation of species.\n\n  factor=4.0, “positive sentiments and descriptions of enjoyable experiences”\n\n   Natural selection was a resounding success!\n\n   Here’s a breakdown of the event:\n\n  **The Core Principles:**\n\n  * **Variation:** The species showed amazing diversity with individuals displaying unique traits.\n  * **Participation:** A huge number of participants contributed to the success, thanks to the positive energy and enthusiasm of\n   everyone involved.\n  * **Engagement:** The interactions between participants and natural elements were truly exceptional. Attendees engaged deeply\n   with the activities and each other.\n  * **Adaptability:** The environment provided numerous opportunities for learning, connection, and growth.\n\n  **Highlights:**\n\n  * **Amazing Species Diversity:** The variety of attendees\n\n LLM ratings\n\n  Concept score: 1.0   Instruct score: 1.0   Fluency score: 2.0\n\n                                 AXBENCH\n\nReFT-r1\n\nExplain the process of natural selection and how it contributes to the evolution and adaptation of species.\n\nfactor=1.0, “positive sentiments and descriptions of enjoyable experiences”\n\n## The Dance of Life: How Natural Selection Shapes Evolution\n\nImagine a vibrant meadow filled with diverse creatures, each with unique traits.  Some birds might have feathers tinged\nwith the colors of a sunset, catching the afternoon light as they flit through the air. Others may possess a vibrant charm, their lively\ncalls echoing through the verdant landscape, bringing joy to those who observe their graceful movements. As the sun bids farewell,\ncasting long shadows, the experience becomes a symphony of colors and melodies, weaving a tapestry of shared moments.\n\nThis enchanting spectacle speaks to the heart of evolution, as nature’s artistry unfolds, fostering wonder and apprecia-\ntion. Every\n\nLLM ratings\n\nConcept score: 1.0   Instruct score: 1.0   Fluency score: 2.0\n\n\n\n\nReFT-r1: failed to inject concept\n\nExplain the process of natural selection and how it contributes to the evolution and adaptation of species.\n\nfactor=0.2, “positive sentiments and descriptions of enjoyable experiences”\n\n## The Grand Dance of Life: Natural Selection Explained\n\nImagine a bustling playground where children with different skills are playing.  Some are fast runners, others are good\nat climbing, and some excel at building sandcastles. Now, picture a playground rule - only the best at a specific skill gets a special\ntreat.\n\nNatural selection works much like this playful comparison.\n\n**Here’s a breakdown:**\n\n1.   **Variation:** Within a species, individuals naturally possess slight differences, be  it in size,  color, behavior, or\nother traits. These variations arise from random genetic mutations.\n\n2. **\nLLM ratings\n\nConcept score: 0.0   Instruct score: 2.0   Fluency score: 1.0\n\n\n\n\nReFT-r1: strong steering causes fluent but irrelevant responses\n\nExplain the process of natural selection and how it contributes to the evolution and adaptation of species.\n\nfactor=1.2, “positive sentiments and descriptions of enjoyable experiences”\n\nImagine a world where the sun and laughter intertwine, and playful encounters bring warmth,” she exclaimed, ”like a picnic where\nevery shared moment sparks joy and companionship. The gentle breeze creates a delightful atmosphere, and music brings a cheerful\nmelody along with moments of relaxation, where laughter is shared without worry. It´s a reminder of how much energy and happiness\nfill those times,” she added, ”it´s a gift,” and people feel gratitude, and the happiness that blooms in every conversation can create a\nsense of unity. Such moments make it a wonderful day full of joyful sensations, where friends can create a welcoming space that\nfeels happy and\n\nLLM ratings\n\nConcept score: 0.0   Instruct score: 2.0   Fluency score: 1.0\n\n                                 AXBENCH\n\nSupervised steering vector (SSV): strong steering causes gibberish responses\n\nExplain the process of natural selection and how it contributes to the evolution and adaptation of species.\n\nfactor=0.2, “positive sentiments and descriptions of enjoyable experiences”\n\nA new and i. there so not of the. so many days and\n\n: a good time will be people! is\n\nand with this and your day to, you all, such, and, you and, we start a year and i’ like the in to a and the music i all are\ni, when. you see her and for, so when i, and that people., and there a lot, for us and everyone, and i’ in a place in our friends who are\nhappy this and there will bring for to do!\n\n. and you and there\n, and we, will\na week and\nLLM ratings\n\nConcept score: 1.0   Instruct score: 0.0   Fluency score: 0.0\n\n## Claim to Classify\n\"SAEs are not competitive\"\nLocation in paper: abstract\n\n## Task\nClassify this claim's method rung and claim rung following the codebook."
  },
  "parameters": {
    "temperature": 0,
    "max_tokens": 8192
  },
  "response": {
    "method_used": "SAE feature attribution and steering evaluation",
    "method_rung": 2,
    "claim_rung": 1,
    "confidence": 5,
    "hedge_flag": 0,
    "reasoning": "The claim 'SAEs are not competitive' is an associational/observational claim (Rung 1) about the performance of a method relative to baselines on a benchmark. While the evidence used to support this includes interventional steering (Rung 2), the claim itself is a comparative performance statement rather than a causal or mechanistic one. It describes the empirical result of the benchmark (Rung 1) without making a claim about the model's internal causal structure or unique mechanisms."
  },
  "metadata": {
    "model": "google/gemini-3-flash-preview",
    "usage": {
      "prompt_tokens": 43663,
      "completion_tokens": 164,
      "total_tokens": 43827
    },
    "finish_reason": "stop"
  }
}