           Falsifying Sparse Autoencoder Reasoning Features in Language Models



                          George Ma 1 Zhongyuan Liang 1 2 Irene Y. Chen 1 2 Somayeh Sojoudi 1


                         Abstract                             capabilities are often enabled by chain-of-thought (CoT)
                                                               prompting and other inference-time strategies, which en-          We study how  reliably  sparse autoencoders
                                                                 courage LLMs to generate intermediate reasoning traces             (SAEs) support claims about reasoning-related
                                                                              prior to producing a final answer (Wei et al., 2022; Yao et al.,                 internal features in large language models. We
                                                                    2023). Motivated by these advances, a growing body of                     first give a stylized analysis showing that sparsity-
                                                          work has explored mechanistic interpretability approaches                regularized decoding can preferentially retain sta-
                                                                              to identify and interpret the internal representations underly-2026         ble low-dimensional correlates while suppressing                                                                      ing reasoning in LLMs (Chen et al., 2025; Li et al., 2025b).               high-dimensional within-behavior variation, mo-
                 tivating the possibility that contrastively selected     A prominent interpretability approach in this area is theFeb        “reasoning” features may concentrate on cue-like        use of sparse autoencoders (SAEs). SAEs learn sparse de-
                 structure when such cues are coupled with reason-        compositions that disentangle polysemantic neuron activa-8
               ing traces. Building on this perspective, we pro-          tions into more monosemantic and human-interpretable fea-
              pose a falsification-based evaluation framework          tures (Bricken et al., 2023; Templeton et al., 2024). When
                 that combines causal token injection with LLM-        studying reasoning with SAEs, many prior works rely on
              guided counterexample construction. Across 22         contrastive methods to identify reasoning features. In this
                configurations spanning multiple model families,        paradigm, SAE features are evaluated on contrastive datasets
                 layers, and reasoning datasets, we find that many         constructed from reasoning and non-reasoning text (e.g.,[cs.LG]
                 contrastively selected candidates are highly sensi-      CoT responses versus direct answers), and features exhibit-
                 tive to token-level interventions, with 45%–90%         ing large activation differences are interpreted as reasoning
                activating after injecting only a few associated          features that encode reasoning processes (Chen et al., 2025;
               tokens into non-reasoning text. For the remaining         Galichin et al., 2025; Venhoff et al., 2025; Li et al., 2025b).
               context-dependent candidates, LLM-guided falsi-
                                                                   Despite their widespread use, these contrastive activation-                 fication produces targeted non-reasoning inputs
                                                                based methods suffer from fundamental ambiguities. Be-                 that trigger activation and meaning-preserving
                                                                  cause CoT responses differ systematically from direct an-               paraphrases of top-activating reasoning traces that
                                                                 swers not only in their underlying reasoning processes but               suppress it. A small steering study yields minimal
                                                                         also in surface lexical usage and stylistic patterns, features              changes on the evaluated benchmarks. Overall,
                                                                  with large activation differences may reflect shallow lex-              our results suggest that, in the settings we study,
                                                                                 ical confounds, such as recurring discourse tokens (e.g.,                sparse decompositions can favor low-dimensional
                                                                       Wait, But, Let) rather than the model’s internal reasoning                correlates that co-occur with reasoning, under-
                                                                   computations. Therefore, activation differences alone are                scoring the need for falsification when attributing
                                                                               insufficient to determine whether an SAE feature capturesarXiv:2601.05679v6         high-level behaviors to individual SAE features.                                                                  genuine reasoning behavior.            Code is available at https://github.com/
           GeorgeMLP/reasoning-probing.             To address this ambiguity, we present a theoretical analysis
                                                               showing that sparsity in SAE decoding can induce an asym-
                                                               metry between low- and high-dimensional structure. In a
          1. Introduction                                            stylized setting where a high-level behavior admits many
                                                                     semantically equivalent realizations but co-occurs with a
         Recent advances in large language models (LLMs) have                                                                              stable low-dimensional lexical cue, sparse decoding can pre-
          demonstrated strong performance on tasks that require multi-                                                                      serve the cue coordinate while suppressing the remaining
           step reasoning (Huang et al., 2024; Ahn et al., 2024). These                                                                           distributed variation. Notably, we do not treat lexical pat-
                                                                              terns and reasoning as opposing: they are often coupled, and           1UC Berkeley 2UCSF. Correspondence  to:  George Ma
          <george ma@berkeley.edu>.                                      sparsity can cause SAE features to preferentially capture the
                                                                   low-dimensional part of that coupled signal.
            Preprint. February 10, 2026.

                                                         1

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models


             Contrastive Feature Selection                        Causal Token Injection
   Reasoning text (Chain-of-Thought)              SAE Feature Activations       Non-reasoning                 Non-reasoning input
                                                                                   input                        with injected tokens
     Let us reason step by step.
       First, we analyze the problem.                                                Plain sentence                       Let sentence
     Therefore, the answer is…                                                                              Wait sentence

   Non-reasoning text                                                              45–90% of features
                                          Language                                                      exhibit significant
     Paris is the capital of France.                                            Model                                                      activation increases
     This article describes a method.
                                                                                                                             Low feature                                   Low feature         High feature
                                                                                                                          Candidates                                             activation                                                     activation             activation
       Standard contrastive methods select features based on activation differences                      Lexical cues are sufficient to trigger most candidate features

            LLM-Guided Falsification                  Steering (Sanity Check)        Conclusion

                            LLM proposes hyp-
                                    otheses about what
                                       the feature detects
   Non-reasoning text                           Reasoning text
    with similar style                             with different style        Amplify
                                     Activation decoupled                                       feature                           Reasoning-
    Okay, the biggest                                              Let's assume x is a
                                   from reasoning                                                                                                     direction                           associated SAE    issue with this coffee                                                                       rational number. If that
                                       behavior
    machine is the noise…                                                                                 is true, it can be…                            Transformer                    features are often
          False positive:       0 genuine                False negative:                                   minimal or slightly       attributable to
            activates without       reasoning                       fails to activate                                degraded performance                                                                                                         linguistic
           reasoning          features found            on reasoning                Performance changes do not
          LLM generates feature semantics and falsifying counterexamples                        imply reasoning representation             correlates

Figure 1. Overview of our falsification-based evaluation framework for reasoning features. We begin with SAE features identified by
contrastive methods. We then test whether lexical cues are sufficient to induce activation via causal token injection. Remaining features
are subjected to LLM-guided adversarial counterexample generation, which decouples reasoning behavior from feature activation. Across
all configurations, this process fails to identify any feature that satisfies our criteria for genuine reasoning behavior.


Motivated by this mechanism, we introduce a falsification-    2. Related Work
based evaluation framework that probes whether con-
trastively selected “reasoning features” reflect cue-like struc-    2.1. Mechanistic Interpretability and SAEs
ture or remain robust under increasingly targeted tests. We    Mechanistic interpretability aims to reverse-engineer LLMs
start from contrastive candidates and perform causal token    by analyzing and decomposing their internal representations
injection by inserting a few feature-associated tokens into    (Sharkey et al., 2025).  Building on the linear represen-
non-reasoning text to test whether lexical cues alone are     tation hypothesis (Elhage et al., 2022; Park et al., 2024),
sufficient to elicit activation. We then apply LLM-guided   SAEs have emerged as a prominent tool for disentangling
falsification to construct counterexamples: non-reasoning    polysemantic neurons into more monosemantic, human-
false positives (FP) that instantiate hypothesized lexical,    interpretable features, by learning a sparse decomposition of
syntactic, or discourse patterns, and false negatives (FN)   model activations (Bricken et al., 2023; Cunningham et al.,
obtained by paraphrasing a feature’s top-activating reason-    2023; Templeton et al., 2024). Recent work has further ex-
ing traces to preserve meaning while suppressing activation.    plored a range of SAE variants and training strategies, lead-
We also include a small steering study as a supplementary    ing to improved feature quality and interpretability (Chanin
behavioral check. Figure 1 summarizes the pipeline.            et al., 2025; Leask et al., 2025; Li et al., 2025a). Empirical
                                                                 studies report that SAE features can align with semanticallyAcross 22 configurations, token injection shows that many
                                                          coherent content patterns, including programming-relatedcontrastive candidates are elicited by inserting only a few
                                                                      text (Bricken et al., 2023), arithmetic concepts (Engels et al.,associated tokens or short contexts into non-reasoning text.
                                                            2025), and safety-related content (O’Brien et al., 2025). De-For the remaining features, LLM-guided falsification reli-
                                                                    spite these findings, the interpretability of SAE features hasably constructs targeted FPs and meaning-preserving FNs
                                                               primarily been shown through easily identifiable textual pat-that separate activation from the presence of a reasoning
                                                                    terns, leaving open the question of whether these featurestrace in the input. Under our operational criteria, we do not
                                                            capture deeper, higher-level aspects of model behavior.observe features that robustly track reasoning across these
probes. Together, these results suggest sparse decomposi-
tions can favor low-dimensional correlates that co-occur     2.2. SAEs for Reasoning in LLMs
with reasoning, underscoring the need for falsification when                                                      Recent LLMs, such as OpenAI o1 (Jaech et al., 2024) and
attributing high-level behaviors to individual SAE features.                                                  DeepSeek-R1 (Guo et al., 2025), are trained to elicit multi-


                                                2

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

step reasoning, yielding substantial performance gains on    reconstruction error) by projecting onto this basis. This lets
complex tasks (Wang et al., 2023; Wei et al., 2022). Moti-    us attribute any loss of the high-dimensional component to
vated by these advances, several recent works apply SAEs    the sparsity objective rather than dictionary mismatch. Let
to identify internal features associated with reasoning pro- W := [v1, . . . , vk] ∈Rd×k and consider the ℓ1-regularizedcesses. One line of work applies contrastive activation-based    code
methods to identify features that exhibit large activation dif-
ferences or correlate with the presence of reasoning text.         z⋆(h) ∈arg minz∈Rk∥h −Wz∥2                                                                                                        2 + λ∥z∥1.    (2)Steering such features has been shown to increase reasoning
length and model confidence (Venhoff et al., 2025; Chen                                                The following theorem shows that, for fixed sparsity level
et al., 2025; Li et al., 2025b). Complementary approaches                                                          λ/b, the recovered energy from the high-dimensional com-
define sets of reasoning-related vocabularies and then iden-                                                       ponent bg is exponentially suppressed as the intrinsic di-
tify reasoning features either by selective activation on these
                                                     mension k −1 grows. In contrast, Appendix B.2 shows thattokens (Galichin et al., 2025) or by exhibiting strong posi-                                                              the v1 coordinate is comparatively easy to retain.
tive logit contributions to them (Fang et al., 2026). However,
existing approaches implicitly assume that features corre-   Theorem 3.1 (High-dimensional residual is suppressed by
lated with reasoning-style text reflect underlying reasoning    ℓ1 decoding). Fix integers k ≥2 and d ≥k. Let W =
processes. In practice, it remains unclear whether such cor-    [v1, . . . , vk] have orthonormal columns. Let h be generated
relations reflect the model’s internal reasoning computations    by (1), and z⋆(h) be any minimizer of (2). Define z⋆2:k :=
                                                                              λ√k−1
                                                                                                               2b    , we haveor instead arise from superficial token-level confounds.       (z⋆2, . . . , z⋆k) ∈Rk−1. Then with u :=


                                                                               23. Theory: Sparsity Biases SAEs Toward                                                            ≤b2Ψ(u),    Ψ(u) := 2ϕ(u)/u,                                         E ∥z⋆2:k∥2
  Low-Dimensional Correlates                                                     where ϕ is the standard normal density. In particular,
SAEs minimize reconstruction error under an explicit spar-
sity pressure, commonly implemented as an ℓ1 penalty on             Ψ(u) = p 2/π exp −u2/2 /u,
feature activations (Tibshirani, 1996; Olshausen & Field,
1997). In this section, we use a minimal model to motivate    so the expected recovered energy from the (k −1)-
why this objective can preferentially surface token-level    dimensional component decays exponentially in (k −1)λ2.
correlates of reasoning traces, even when the underlying
                                                Theorem 3.1 captures the core asymmetry underlying ourreasoning behavior is present and correlated with those cues.
                                                           empirical pipeline. When a high-level behavior co-occursThis motivates the falsification pipeline developed later.
                                                        with a stable cue, sparse decoding can explain a large por-
We model reasoning activations as having two parts that     tion of the contrastive signal using the low-dimensional
co-occur in typical CoT data. The first is a stable low-    coordinate alone, while distributing the remaining behavior-
dimensional cue that reliably appears in reasoning traces,    specific variation across many small coordinates that are
such as a recurring token like wait. The second is a high-    individually penalized. This provides a concrete mecha-
dimensional component that varies across semantically    nism by which contrastive feature detection can identify
equivalent realizations of a reasoning trace, capturing dif-    features that separate reasoning from non-reasoning, yet
ferences in phrasing, decomposition into steps, and local      still fail to isolate a single feature that tracks reasoning it-
                                                                            self. Unlike feature absorption (Chanin et al., 2025) (nested-rhetorical structure. Formally, let {v1, . . . , vk} ⊂Rd be an
orthonormal set and define a reasoning activation vector       feature competition), our analysis isolates a dimensionality
                                                                     effect: sparsity penalizes representing high-dimensional
     h := av1 + bg,  g ∈span{v2, . . . , vk}      (1)    within-behavior variability more than retaining a stable low-
                                            k−1   .    dimensional correlate, even under a perfect dictionary. Fullwhere a ≥0 and b > 0 are scalars and g ∼N 0, Ik−1We interpret v1 as a cue direction shared across many rea-    proofs and an analogous theorem for Top-K activations are
soning traces, while the remaining component is distributed    provided in Appendix B.
across the other k −1 directions. The Gaussian model for    Our model is intentionally simplified. It abstracts reasoningg serves as a tractable proxy for high-dimensional within-                                                            as high-dimensional variation within a subspace and ana-reasoning variability.                                                               lyzes an idealized sparse decoding objective rather than full
To isolate the effect of sparsity, we analyze the decoding   SAE training dynamics. The value of the theory is therefore
step induced by an ℓ1 objective. Concretely, we consider    motivational: it isolates a sparsity-driven failure mode that
the best-case setting where the decoder columns span the    makes token-level correlates attractive to SAEs when they
true reasoning subspace, so that without any sparsity pres-    co-occur with richer behavior, which is precisely what our
sure the least-squares code would recover h exactly (zero     falsification experiments are designed to test.

                                                3

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

4. Methodology                                              4.2. Identifying Candidate Reasoning Features

This section specifies (i) an operational definition of genuine    Following prior work (Venhoff et al., 2025; Chen et al.,
reasoning features in SAEs, (ii) a contrastive method for    2025; Li et al., 2025b), we start by identifying candidate fea-
identifying candidate reasoning features, and (iii) causal     tures that satisfy Reasoning specificity using contrastive
injection and LLM-based falsification experiments to distin-    activation-based methods applied to reasoning and non-
guish genuine reasoning features from superficial correlates.    reasoning text. We then consider a range of metrics to
                                                                   select top-ranked features as reasoning-related candidates.
4.1. Defining Reasoning Features in SAEs                 Let    and      denote corpora of reasoning and non-                                            DR    DNR
In this section, we define what we term a genuine reasoning    reasoning text, respectively. For each input sequence x, we
feature in SAEs. Such a feature should reflect underlying    aggregate each feature’s activation across token positions
reasoning processes, such as logical deduction or counter-   by taking the maximum: ai(x) = maxt fi(x, t), where
factual reasoning, rather than surface-level correlates of    fi(x, t) denotes the activation of feature i at token posi-
reasoning-style text. Crucially, it is defined at the level of     tion t for input x. We use a maximum aggregator to retain
semantic computation rather than lexical form.                the single most salient activation while reducing sensitivity
                                                                to sequence length and repeated occurrences of the same
Formally, let x         denote a residual stream activation                                                             cue. Applying this aggregation to all samples yields two               ∈Rdmodelat layer ℓof a transformer language model, and let f =                                                             empirical                                                                            activation                                                                                           distributions,                                                                                         j=1 and                                                                                                            k=1,                                                                                         {aNRi,k}nNR                                                                              {aRi,j}nRSAEenc(x)        be the output of an SAE encoder. We                                                           corresponding                                                                                  to reasoning                                                                             and non-reasoning                                                                                                            corpora.                                                                                                   Can-         ∈RdSAErefer to fi as feature i. We say that fi is a genuine reasoning                                                              didate reasoning features are those whose activation distri-
feature iff it satisfies all of the following criteria:                                                             butions differ substantially between these two sets.
Reasoning specificity.  The feature activates reliably on   Our primary metric for selecting candidate features is Co-
text that involves reasoning behavior, while exhibiting sub-    hen’s d, which measures the standardized mean difference
stantially lower activation on non-reasoning text.            between two distributions (Cohen, 2013). Specifically, for
                                                       each feature i, we compute
Non-spurious correlation.  The feature does not activate
                                                                                                             ¯aRi       ion non-reasoning text that merely contains phrases associ-                                                                                    di =   −¯aNR ,
ated with reasoning corpora, including discourse markers                                       spooled
such as “therefore” or “let us consider,” as well as other
                                                                                                                                         i )2+(nNR−1)(sNRi )2                                                                                                                                                                           , and ¯aRi andsurface-level lexical artifacts frequently found in CoT text.    where spooled = q (nR−1)(sRnR+nNR−2
                                                                    ¯aNRi  denote the sample means of      j=1 and      k=1,Semantic invariance.  The feature remains stable under                              {aRi,j}nR     {aNRi,k}nNR
                                                                 respectively, with sRi and sNRi  denoting the correspondingparaphrases and stylistic transformations that preserve the
                                                      sample standard deviations.underlying reasoning structure. That is, changing tone, vo-
cabulary, or presentation style without altering the logical    Cohen’s d provides a scale-invariant measure of effect size,
content should not substantially alter the feature’s activation.    reflecting the practical significance of activation differences.
                                        We rank all SAE features by di and select the top k features
This definition is intentionally strict:  it excludes features                                                             as candidate reasoning features, with k = 100 in all experi-
whose apparent “reasoning selectivity” is explained by shal-                                                           ments. In addition to Cohen’s d, we assess robustness using
low lexical or stylistic regularities, rather than by a stable                                                    two additional metrics: (i) ROC-AUC when using ai(x) as a
representation of the underlying reasoning process. This                                                             score to discriminate between reasoning and non-reasoning
distinction matters because SAE features can sharply sepa-                                                         samples; and (ii) activation frequency ratio on reasoning
rate reasoning from non-reasoning while encoding only a                                                    and non-reasoning samples. We observe consistent results
low-dimensional cue. For example, a feature that primarily                                                              across metrics, and provide detailed definitions and analyses
detects a token such as “wait” can score highly under con-                                                                 for these additional metrics in Appendix D.
trastive selection, and steering it can increase the model’s
tendency to emit that cue, potentially changing downstream                                                                    4.3. Causal Token Injection Framework
generation style without implying that the feature represents
reasoning computations such as reflection or backtracking.    In this section, we test whether the candidate features iden-
We therefore treat contrastive correlations as hypotheses     tified in Section 4.2 satisfy the Non-spurious correlation
and use causal and adversarial tests to evaluate whether     criterion through causal token injection experiments. Our
an interpretation survives meaning-preserving paraphrase     central hypothesis is straightforward: if a feature encodes
and cue-matched counterexamples; see Appendix A for a    genuine reasoning, then inserting a small number of its
detailed discussion.                                   most activating tokens into non-reasoning text should not

                                                4

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

substantially increase its activation.                              1. Token-driven: d ≥0.8 with p < 0.01, corresponding to                                                            a large effect.
For each candidate feature fi, we start by identifying the                                                                    2. Partially token-driven: 0.5   < 0.8 with p < 0.01,tokens and short token sequences that most strongly activate                 ≤d                                                            corresponding to a medium effect.it on the reasoning corpus.
                                                                    3. Weakly token-driven: 0.2 ≤d < 0.5 with p < 0.05,                                                            corresponding to a small effect.
Unigram ranking.  For each unique token t, we compute
                                                                    4. Context-dependent: d < 0.2 or p ≥0.05, indicating aits mean activation                                                                   negligible effect.
                   1
                        ¯fi,t =  X  fi(x, j),
                         |It| (x,j)∈It                               4.4. LLM-Guided Falsification
                                                 The token injection experiments described above eliminate
where It = {(x, j): tokenx,j = t} denotes the set of all    a large class of lexical and short-range contextual confounds.token positions at which token t occurs in the reasoning    Features classified as context dependent, however, are not
corpus. Tokens are then ranked by ¯fi,t in descending order.    well explained by token-level triggers alone and may instead
                                                       respond to higher-level semantic patterns that are difficult
Bigram and trigram ranking.  We extend the same pro-    to probe through token manipulations. We therefore ap-
cedure to contiguous bigrams and trigrams. We restrict    ply LLM-guided falsification to test whether these features
attention to bigrams that appear at least three times and tri-    satisfy the Semantic invariance criterion by constructing tar-
grams at least two times. Mean activations are computed    geted counterexamples that attempt to falsify proposed ex-
analogously and ranked within each n-gram category.          planations. These counterexamples include non-reasoning
                                                                    text designed to induce spurious activation, as well as para-
We then evaluate whether the lexical patterns identified                                                          phrases of previously activating reasoning text that fail to
above are sufficient to drive feature activation outside rea-                                                                            elicit activation. We detail this process next.
soning contexts. For each feature fi, we construct two sets
of samples: Baseline, consisting of non-reasoning inputs
                                                     Hypothesis generation.  The LLM is first provided with
drawn from DNR, and Injected, consisting of the same non-    three sources of information: the top-activating tokens iden-reasoning inputs with top-activating tokens inserted.
                                                                         tified in Section 4.3, a small set of reasoning samples that
                                                             strongly activate the feature, and token-level activation
Injection strategies.  To probe different forms of lexical                                                                traces within those samples. Using this information, the
sensitivity, we consider various injection strategies. First,                                   LLM proposes an explicit hypothesis describing what lin-
simple token injection inserts three top-ranked tokens ei-                                                                   guistic or structural pattern the feature may be detecting.
ther by prepending them to the text, uniformly interspersing
them throughout the text, or replacing randomly selected
                                                   Counterexample construction.  Given a proposed hypoth-words. Second, n-gram injection inserts either two top-
                                                                       esis, the LLM generates two complementary types of testranked bigrams or one top-ranked trigram at uniformly sam-
                                                               cases.  First, it produces non-reasoning text that instanti-pled positions within the text. Third, contextual injection
                                                                ates the hypothesized pattern, serving as candidate falseinserts tokens along with their frequent preceding context
                                                                positives (FP). Second, for false negatives (FN), it para-to preserve local co-occurrence structure.
                                                            phrases the feature’s top-activating reasoning samples while
                                                                  explicitly preserving their semantic content and reasoning
Feature Classification.  For each feature i, we quantify                                                                     intent, but altering surface form such as vocabulary, syn-
the activation shift induced by injection using Cohen’s d:                                                                    tax, or presentation style. Each candidate is evaluated by
                                                          running it through the target model and measuring the maxi-
                                     ¯ainjectedi             i                    dinjectedi   =          −¯abaseline ,           mum activation of the feature. A non-reasoning candidate
                                     spooled                                is considered a valid FP if its activation exceeds a threshold
                                                          τ                                                                                                             ),                                                                                while                                                                                      a                                                                                        paraphrased                                                                                                      reasoning                                                       maxj                                                                  ai(xRj                                  = 0.5 ×where ¯ainjectedi     and ¯abaselinei     denote the mean activations on                                                           candidate                                                                                        is                                                                      considered                                                                              a                                                                                          valid                                                           FN                                                                                                                                 if                                                                                                                               its activation                                                                                                     remains
injected and baseline samples, respectively, and spooled is    below 0.1τ, where the maximum is taken over the original
the pooled standard deviation.                                                            reasoning samples. The generation steps are repeated for up
We assess statistical significance using independent two-    to T = 10 iterations, with early termination if at least three
sample t-tests comparing injected and baseline activations.    valid FP and three valid FN are obtained.
Following standard conventions for effect size interpreta-
tion (Cohen, 2013), each feature is classified based on the    Final classification.  Given the constructed counterexam-
strongest effect observed across all injection strategies:         ples, the LLM produces a consolidated interpretation of

                                                5

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

the feature, including the linguistic or structural pattern it                   0.9                                 Analyzed layers        0.40
                                                                                                                                                                                                                                                                                                                                                                                                                                                      Entropy 0.35appears to detect and the conditions under which it acti-                   0.80.7
                                                                                                                                                                                                                    0.30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Concentration 0.6vates or fails to activate. A final classification is then made                                                                                                                                                             0.5                                                                                                                                                                    Normalizedusing all evidence accumulated during the procedure, in-                    Token                                                              0.25                                                                                                                                                                                                                    0.20
cluding the success or failure of generated counterexamples,                 Mean 0.4                                                                  Mean 0.15                                 Analyzed layers
activation measurements on those candidates, and consis-                     0           10   Layer 20           30                0           10   Layer 20           30
tency across iterations. To ensure reliability, we report all
LLM-generated interpretations and counterexamples for a    Figure 2. Token concentration ratio and normalized activation
                                                                  entropy for SAE features across all layers of Gemma-3-4B-Instructrepresentative experiment in Appendix G.
                                                         on the s1K dataset. Middle layers exhibit lower concentration and
                                                                  higher entropy, indicating reduced reliance on specific tokens.
4.5. Steering Experiments

As a supplementary analysis, we conduct steering experi-
ment to probe whether amplifying candidate features identi-   dominated by lexical processing, while late layers are in-
fied in Section 4.2 has a measurable effect on downstream    creasingly specialized toward output token prediction (Ma
reasoning task performance.                                      et al., 2025). To further support this choice, we analyze
                                            how concentrated SAE feature activations are on individ-
Feature Steering.  For a feature fi with decoder direction    ual tokens. Specifically, we compute a token concentration
Wdec,i ∈Rdmodel, we intervene onmaxthe residual stream at     ratio, defined as the fraction of a feature’s activation masslayer ℓaccording to x′ = x +                       γfi   Wdec,i, where γ ∈R     attributable to its 30 most activating tokens, and the normal-                       maxis the steering strength and fi     is the maximum activation    ized entropy of the activation distribution across tokens.
of fi on the reasoning corpus.                                                         Figure 2 shows diagnostics for Gemma-3-4B-Instruct on
                                                             the s1K dataset. Middle layers consistently exhibit lower
5. Experiments                                         concentration ratios and higher entropy than early or late
                                                                  layers. Similar trends are observed across models. If gen-
5.1. Experimental Setup                                                            uine reasoning exists at the level of individual features, these
We conduct experiments on six open-weight transformer    layers constitute the most plausible candidates.
language models. Our primary models are Gemma-3-12B-                                        We conduct all experiments on a single NVIDIA A100 GPU
Instruct and Gemma-3-4B-Instruct (Gemma Team et al.,                                                        with 80 GB VRAM. Feature detection and token injection
2025).  For both, we analyze a subset of middle-to-late                                                          experiments require around 1 hour per configuration, while
layers and use SAEs from the GemmaScope-2 release (Mc-                                                 LLM-guided falsification requires approximately 2 hours.
Dougall et al., 2025), each with 16,384 features trained
on residual stream activations.  We additionally study                                                                    5.2. Feature Detection Results
DeepSeek-R1-Distill-Llama-8B (Guo et al., 2025), analyz-
ing a representative middle layer using an SAE trained on   We apply the contrastive procedure described in Section 4.2
reasoning-oriented corpora, specifically LMSys-Chat-1M     to identify candidate reasoning features. For each configu-
(Zheng et al., 2024) and OpenThoughts-114k (Guha et al.,    ration, we rank SAE features by Cohen’s d and select the
2025), with 65,536 features (Galichin et al., 2025). Results    top 100 features. Results obtained using alternative metrics,
for Llama-3.1-8B (Grattafiori et al., 2024), Gemma-2-2B    including ROC-AUC and activation frequency ratios, are
and Gemma-2-9B (Gemma Team et al., 2024) are reported    reported in Appendix D and are qualitatively consistent.
in Appendix C.                                                         Table 1 reports the mean Cohen’s d of the top 100 features
For reasoning corpora, we use s1K-1.1, which consists of     for each configuration. Mean effect sizes range from 0.675
1,000 challenging mathematics problems with detailed CoT    to 1.043, corresponding to medium to large effects under
traces (Muennighoff et al., 2025), and the General Inquiry    standard conventions (Cohen, 2013). This indicates that
Thinking Chain-of-Thought dataset, which contains 6,000   SAE features can reliably distinguish between reasoning
question-answer pairs spanning diverse domains with ex-   and non-reasoning text at a statistical level.
plicit reasoning annotations (Wensey, 2025). As a non-                                                         Figure 3 shows the full distribution of Cohen’s d valuesreasoning corpus, we use an uncopyrighted subset of the                                                                for Gemma-3-12B-Instruct at layer 22 on the s1K dataset.Pile (Gao et al., 2020), a large-scale collection of general                                                The distribution exhibits a long tail, with a small subset ofweb text. From each corpus, we uniformly sample 1,000                                                                features achieving substantially larger effect sizes than thetexts and chunk inputs to 64 tokens.                                                                 majority. These top-ranked features form a clearly separated
We focus on middle-to-late layers, motivated by both prior    region in the right tail, motivating their selection for further
work and empirical analysis.  Early layers are typically     falsification analyses.

                                                6

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models




                                                                                                                                                                                                                                                                                                                     Weakly                                                                                                                                                                                                                                               TD    Table 1. Mean Cohen’s d values for the top 100 features.                           100                                                                                                                               Token-drivenPartially TD                                                                                                                                                                                                                                                                                                                                                              Context-dependent

 Model                  Layer   s1K   General Inquiry CoT                 (%)  80
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Features  60 Gemma-3-12B-Instruct     17    0.775         0.947                       of

                                                                                                                                                                                 40 Gemma-3-12B-Instruct     22    0.835         0.924                                                                                                                    Percentage Gemma-3-12B-Instruct     27    0.805         0.995
 Gemma-3-4B-Instruct      17    0.909         0.984                                       20



                                                                                                                                                                                                                                                           G3-12b Gemma-3-4B-Instruct      22    0.892         1.043                                        0            G3-12bL17s1K Gemma-3-4B-Instruct      27    0.888         1.010                                                                              GenInqL17        G3-12bL22s1K        G3-12bGenInqL22        G3-12bL27s1K        G3-12bGenInqL27        G3-4bL17s1K        GenInqG3-4bL17        G3-4bL22s1K        GenInqG3-4bL22        G3-4bL27s1K        GenInqG3-4bL27        DS-8bL19s1K        GenInqDS-8bL19
 DS-R1-Distill-Llama-8B    19    0.675         0.781                                                                 Figure 4. Distribution of token injection classifications across con-
                                                                          figurations. Each bar corresponds to a model-layer configuration,
                                                              with segments indicating the proportion of features classified as
          104                                                         Other features              token-driven (TD), partially TD, weakly TD, or context-dependent.
                                                               Top 100 features
                                                                       Threshold (d ≥0.3)          103
               Features                                                     Additional statistics are reported in Appendix E. Overall,
    of 102                                                       these results indicate that most candidate reasoning features
                                                              are driven by superficial lexical patterns. We therefore sub-           Number 101
                                                                      ject the remaining context-dependent features to the LLM-
                                                        guided falsification analysis described next.          100
                 −1           0            1            2            3
                                     Cohen’s d                              5.4. LLM-Guided Falsification Results

Figure 3. Distribution of Cohen’s d values across SAE features for   We apply the LLM-guided falsification procedure described
Gemma-3-12B-Instruct at layer 22.                                in Section 4.4 to features that remain context dependent
                                                                    after token injection. For configurations with more than
                                                  20 such features, we randomly sample 20 for analysis. All
5.3. Token Injection Results                                      falsification experiments are conducted using Gemini 3 Pro
                                                             as the LLM hypothesis generator and interpreter.We apply the token injection procedure described in Sec-
tion 4.3 to the top 100 candidate reasoning features per    Table 3 and 4 summarize the results for the s1K and General
configuration. For each feature, we test whether inserting    Inquiry CoT datasets, respectively. For each configuration,
its most activating tokens into non-reasoning text is suffi-   we report the number of analyzed features, the number
cient to elicit strong activation, and assign the feature to the     classified as genuine reasoning features, and the number
strongest classification observed across all injection strate-    classified as confounds with high confidence.
gies, following Section 4.3.                                                      Across all 248 context-dependent features analyzed, none
Table 2 summarizes the resulting classifications. Across all    are classified as genuine reasoning features. Each feature
models, layers, and datasets, the majority of features exhibit    admits systematic false positives and false negatives under
substantial activation increases under token injection alone,    the LLM-guided protocol, with most classified as confounds
indicating strong sensitivity to token-level patterns.           with high confidence due to repeated success in generating
                                                                   falsifying counterexamples. These outcomes are consistentAcross configurations, between 45% and 90% of features are                                                          with the interpretation that feature activations can be drivenclassified as token-driven, partially token-driven, or weakly                                                  by correlated linguistic or discourse patterns rather thantoken-driven, demonstrating statistically significant activa-                                                                  reliably tracking reasoning behavior.tion increases induced by token injection alone. Only a
minority of features remain context-dependent after injec-    Qualitative analysis reveals recurring categories of con-
tion. As reported in Appendix E.3, mean Cohen’s d values    founds. Many features respond to instructional or planning-
range from 0.521 to 1.471 across configurations, indicating    oriented discourse openers, such as “Let’s break down” or
that inserting a small number of tokens into non-reasoning   “I need to figure out”, while others are triggered by formal
text is sufficient to produce substantial activation changes.    academic framing common in explanatory writing, includ-
                                                            ing phrases like “We are given” or “The problem asks”. InFigure 4 visualizes these results across all configurations.                                                      each case, the feature activates on non-reasoning text thatThe overall pattern is consistent across models and lay-                                                     matches the pattern and fails to activate on reasoning texters. Gemma-3-12B-Instruct evaluated on the s1K dataset                                                                     that avoids it. All interpretations and counterexamples for aexhibits the largest fraction of context-dependent features                                                                representative experiment are reported in Appendix G.at 55%, while several Gemma configurations on the same
dataset exhibit fewer than 12%.                               Overall, even features that are not explained by simple to-

                                                7

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Table 2. Token injection classification results for the top 100 features per configuration. TD denotes token-driven, PTD partially
token-driven, WTD weakly token-driven, and CD context-dependent.

                                                   s1K                General Inquiry CoT
               Model                   Layer  TD  PTD  WTD  CD  TD  PTD  WTD  CD
                 Gemma-3-12B-Instruct     17    54    10     15    21   47    11     25    17
                 Gemma-3-12B-Instruct     22    23    6     16    55   33    8     15    44
                 Gemma-3-12B-Instruct     27    38    16     21    25   29    16     19    36
                 Gemma-3-4B-Instruct      17    58    13     19    10   46    15     18    21
                 Gemma-3-4B-Instruct      22    63    9     18    10   47    13     18    22
                 Gemma-3-4B-Instruct      27    66    9     14    11   39    15     18    28
                  DS-R1-Distill-Llama-8B    19    46    12     19    23   25    14     20    41


Table 3. LLM-guided falsification results for context-dependent    a reliable indicator of whether a feature encodes reason-
features on the s1K dataset.                                                                  ing. Prior work shows that simple lexical interventions can
 Model                  Layer   Analyzed  Genuine  High Conf.      substantially improve these benchmarks without engaging
                                                          reasoning mechanisms (Muennighoff et al., 2025). Con- Gemma-3-12B-Instruct     17       20        0         20
 Gemma-3-12B-Instruct     22       20        0         18          sistent with our broader results, steering yields minimal
 Gemma-3-12B-Instruct     27       20        0         20        changes or degradations in accuracy.
 Gemma-3-4B-Instruct      17       10        0         10
 Gemma-3-4B-Instruct      22       10        0         10
 Gemma-3-4B-Instruct      27       11        0         11        6. Summary
 DS-R1-Distill-Llama-8B    19       20        0         14
                                                            In this work, we study whether SAEs identify genuine rea-
Table 4. LLM-guided falsification results for context-dependent    soning features in LLMs. Motivated by a stylized analysis
features on the General Inquiry CoT dataset.                     suggesting that sparsity can favor stable low-dimensional
                                                                correlates over high-dimensional within-reasoning varia-
 Model                  Layer   Analyzed  Genuine  High Conf.
                                                                     tion, we develop a falsification-oriented evaluation frame-
 Gemma-3-12B-Instruct     17       17        0         17       work that combines causal token injection with LLM-guided Gemma-3-12B-Instruct     22       20        0         19
 Gemma-3-12B-Instruct     27       20        0         18        counterexample generation. Across 22 configurations, most
 Gemma-3-4B-Instruct      17       20        0         20         contrastively selected candidates are highly sensitive to in-
 Gemma-3-4B-Instruct      22       20        0         20         jecting only a few associated tokens, and the remaining
 Gemma-3-4B-Instruct      27       20        0         20
 DS-R1-Distill-Llama-8B    19       20        0         19         features admit targeted counterexamples that decouple ac-
                                                                  tivation from the presence of a reasoning trace. Overall,
                                                        our results suggest that contrastive correlations are not, by
ken injection can still admit targeted counterexamples under    themselves, sufficient evidence for monosemantic reasoning
falsification, suggesting that caution is warranted when at-    features, and that causal validation is important when at-
tributing such features to reasoning itself.                       tributing high-level behaviors to individual SAE directions.

5.5. Steering Results                                     7. Limitations
We report a small-scale steering experiment as a supple-   Our conclusions are scoped to the contrastive candidate
mentary analysis, following the setup in Section 4.5. We     features and experimental settings we study, and primarily
focus on Gemma-3-12B-Instruct at layer 22 and select the    address monosemantic interpretations of individual SAE fea-
top three features on the s1K dataset. For each feature fi,    tures selected by activation-based criteria. They do not rule
we apply steering to the residual stream with γ ∈{0, 2}.    out non-monosemantic features that mix cue-like patterns
Table 5 reports one-shot accuracy under these conditions.     with aspects of reasoning, nor the possibility that reasoning-
                                                               relevant information is distributed across many features or
Table 5. Steering results on Gemma-3-12B-Instruct at layer 22                                                           represented nonlinearly in ways that resist single-featureusing the top three features on the s1K dataset.
                                                                       attribution. Accordingly, we view our results as guidance on
  Feature  AIME Baseline  AIME Steered  GPQA Baseline  GPQA Steered     what current contrastive pipelines reliably establish, and we
  1053       26.7%         20.0%         37.9%         13.6%      recommend treating contrastive correlations as hypotheses
    0        26.7%         10.0%         37.9%         20.2%         that warrant causal and adversarial validation.   578       26.7%         26.7%         37.9%         33.3%

As discussed in Section 4.1, steering performance is not

                                                8

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Impact Statement                                    One-Dimensionally Linear. In Proceedings of the 13th
                                                                International Conference on Learning Representations,
This paper presents work whose goal is to advance the field                                                           2025.
of Machine Learning. There are many potential societal
consequences of our work, none which we feel must be    Fang, Y., Wang, W., Xue, M., Deng, B., Xu,  F., Liu,
specifically highlighted here.                                   D., and Feng, F.  Controllable LLM Reasoning via
                                                          Sparse Autoencoder-Based Steering.  arXiv preprint
                                                           arXiv:2601.03595, 2026.References
                                                           Ferrando, J., Obeso, O. B., Rajamanoharan, S., and Nanda,Ahn, J., Verma, R., Lou, R., Liu, D., Zhang, R., and Yin,
                                                     N. Do I Know This Entity? Knowledge Awareness and  W. Large Language Models for Mathematical Reason-
                                                              Hallucinations in Language Models. In Proceedings of   ing: Progresses and Challenges. In Proceedings of the
                                                                  the 13th International Conference on Learning Represen-  18th Conference of the European Chapter of the Associ-
                                                                       tations, 2025.  ation for Computational Linguistics: Student Research
  Workshop, pp. 225–237, 2024.                             Galichin, A., Dontsov, A., Druzhinina, P., Razzhigaev, A.,
                                                       Rogov, O. Y., Tutubalina, E., and Oseledets, I.  I Have
Bricken, T., Templeton, A., Batson, J., Chen, B., Jermyn,                                                        Covered All the Bases Here: Interpreting Reasoning Fea-
  A., Conerly, T., Turner, N. L., Anil, C., Denison, C.,                                                                     tures in Large Language Models via Sparse Autoencoders.
  Askell, A., Lasenby, R., Wu, Y., Kravec, S., Schiefer,                                                           arXiv preprint arXiv:2503.18878, 2025.
  N., Maxwell, T., Joseph, N., Tamkin, A., Nguyen, K.,
  McLean, B., Burke, J. E., Hume, T., Carter, S., Henighan,   Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T.,
   T., and Olah, C. Towards Monosemanticity: Decompos-       Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N.,
  ing Language Models With Dictionary Learning. Trans-       et al. The Pile: An 800GB Dataset of Diverse Text for
  former Circuits Thread, 2023.                           Language Modeling. arXiv preprint arXiv:2101.00027,
                                                           2020.
Chanin, D., Wilken-Smith, J., Dulka, T., Bhatnagar, H.,
                                        Gemma Team, Riviere, M., Pathak, S., Sessa, P. G., Hardin,  Golechha, S., and Bloom, J. I. A is for Absorption: Study-
                                                                  C., Bhupatiraju, S., Hussenot, L., Mesnard, T., Shahri-  ing Feature Splitting and Absorption in Sparse Autoen-
                                                                               ari, B., Ram´e, A., et al. Gemma 2: Improving Open   coders. In Proceedings of the 39th Annual Conference on
                                                    Language Models at a Practical Size.  arXiv preprint  Neural Information Processing Systems, 2025.
                                                           arXiv:2408.00118, 2024.
Chen, X., Plaat, A., and van Stein, N. How does Chain of
                                        Gemma Team, Kamath, A., Ferret, J., Pathak, S., Vieillard,  Thought Think? Mechanistic Interpretability of Chain-
                                                               N., Merhej, R., Perrin, S., Matejovicova, T., Ram´e, A.,  of-Thought Reasoning with Sparse Autoencoding. arXiv
                                                                         Rivi`ere, M., et al. Gemma 3 Technical Report. arXiv   preprint arXiv:2507.22928, 2025.
                                                                 preprint arXiv:2503.19786, 2025.
Cohen, J.  Statistical Power Analysis for the Behavioral                                                                   Grattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian,
  Sciences. Routledge, 2013.                                                               A., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A.,
                                                       Vaughan, A., et al. The Llama 3 Herd of Models. arXivCunningham, H., Ewart, A., Riggs, L., Huben, R., and
                                                                 preprint arXiv:2407.21783, 2024.  Sharkey, L.  Sparse Autoencoders Find Highly Inter-
   pretable Features in Language Models. arXiv preprint    Guha, E., Marten, R., Keh, S., Raoof, N., Smyrnis, G.,
  arXiv:2309.08600, 2023.                                   Bansal, H., Nezhurina, M., Mercat, J., Vu, T., Sprague,
                                                                      Z., et al. OpenThoughts: Data Recipes for Reasoning
Dong, F., Yan, Z., Ge, X., Xu, Z., Zhang, M., Chen, X.,                                                         Models. arXiv preprint arXiv:2506.04178, 2025.
  He, B., Xin, X., Chen, Z., and Zhou, Y.  Identifying
  and Transferring Reasoning-Critical Neurons: Improving    Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R.,
 LLM Inference Reliability via Activation Steering. arXiv      Zhu, Q., Ma, S., Wang, P., Bi, X., et al. DeepSeek-R1:
   preprint arXiv:2601.19847, 2026.                             Incentivizing Reasoning Capability in LLMs via Rein-
                                                         forcement Learning. arXiv preprint arXiv:2501.12948,
Elhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan,      2025.
   T., Kravec, S., Hatfield-Dodds, Z., Lasenby, R., Drain,
                                                     He, Z., Shu, W., Ge, X., Chen, L., Wang, J., Zhou, Y., Liu,   D., Chen, C., et al. Toy Models of Superposition. arXiv
                                                                               F., Guo, Q., Huang, X., Wu, Z., et al. Llama Scope:   preprint arXiv:2209.10652, 2022.
                                                                Extracting Millions of Features from Llama-3.1-8B with
Engels,  J., Michaud, E.  J., Liao,  I., Gurnee, W., and      Sparse Autoencoders. arXiv preprint arXiv:2410.20526,
  Tegmark, M. Not All Language Model Features Are      2024.

                                                9

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

He, Z., Zhao, H., Qiao, Y., Yang, F., Payani, A., Ma, J.,    McDougall, C., Conmy, A., Kram´ar, J., Lieberum, T., Raja-
  and Du, M. SAIF: A Sparse Autoencoder Framework      manoharan, S., and Nanda, N. Gemma Scope 2 - Techni-
   for Interpreting and Steering Instruction Following of       cal Paper. Google DeepMind Blog, 2025.
  Language Models.  arXiv preprint arXiv:2502.11356,
  2025.                                               Muennighoff, N., Yang, Z., Shi, W., Li, X. L., Fei-Fei,
                                                                      L., Hajishirzi, H., Zettlemoyer, L., Liang, P., Cand`es,
He, Z., Xiong, G., Liu, B., Sinha, S., and Zhang, A. Rea-       E., and Hashimoto, T. B. s1: Simple test-time scaling.
  soning Beyond Chain-of-Thought: A Latent Computa-      In Proceedings of the 2025 Conference on Empirical
   tional Mode in Large Language Models. arXiv preprint      Methods in Natural Language Processing, pp. 20286–
  arXiv:2601.08058, 2026.                                 20332, 2025.
Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian,                                                        O’Brien, K., Majercak, D., Fernandes, X., Edgar, R. G.,
  D., Wang, Y., Tang, R., and Chen, E. Understanding                                                               Bullwinkel, B., Chen, J., Nori, H., Carignan, D., Horvitz,
  the planning of LLM agents: A survey. arXiv preprint                                                                        E., and Poursabzi-Sangdeh, F. Steering Language Model
  arXiv:2402.02716, 2024.                                                             Refusal with Sparse Autoencoders. In ICML 2025 Work-
                                                       shop on Reliable and Responsible Foundation Models,Jaech, A., Kalai, A., Lerer, A., Richardson, A., El-Kishky,
                                                          2025.  A., Low, A., Helyar, A., Madry, A., Beutel, A., Car-
  ney, A., et al. OpenAI o1 System Card. arXiv preprint
                                                        Olshausen, B. A. and Field, D. J. Sparse Coding with an  arXiv:2412.16720, 2024.
                                                       Overcomplete Basis Set: A Strategy Employed by V1?
Leask, P., Bussmann, B., Pearce, M. T., Bloom, J. I., Tigges,      Vision research, 37(23):3311–3325, 1997.
   C., Al Moubayed, N., Sharkey, L., and Nanda, N. Sparse
                                                            Park, K., Choe, Y. J., and Veitch, V. The Linear Represen-  Autoencoders Do Not Find Canonical Units of Analysis.
                                                                     tation Hypothesis and the Geometry of Large Language  In Proceedings of the 13th International Conference on
                                                         Models. In Proceedings of the 41st International Confer-  Learning Representations, 2025.
                                                         ence on Machine Learning, 2024.
Li, C., Zhang, K., Xu, H., Shi, Y., Zhang, Z., Song, K.,
  and Ren, K. Interpreting and Controlling LLM Reason-    Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y.,
  ing through Integrated Policy Gradient. arXiv preprint       Dirani, J., Michael, J., and Bowman, S. R. GPQA: A
  arXiv:2602.02313, 2026.                                  Graduate-Level Google-Proof Q&A Benchmark. In Pro-
                                                           ceedings of the 1st Conference on Language Modeling,
Li, Y., Michaud, E. J., Baek, D. D., Engels, J., Sun, X., and                                                          2024.
  Tegmark, M. The Geometry of Concepts: Sparse Autoen-
  coder Feature Structure. Entropy, 27(4):344, 2025a.        Sharkey, L., Chughtai, B., Batson, J., Lindsey, J., Wu, J.,
                                                       Bushnaq, L., Goldowsky-Dill, N., Heimersheim, S., Or-
Li, Z., Wang, X., Yang, Y., Yao, Z., Xiong, H., and Du, M.                                                                      tega, A., Bloom, J., et al. Open Problems in Mechanistic
  Feature Extraction and Steering for Enhanced Chain-of-                                                                        Interpretability. arXiv preprint arXiv:2501.16496, 2025.
  Thought Reasoning in Language Models. arXiv preprint
  arXiv:2505.15634, 2025b.                                                         Templeton, A., Conerly, T., Marcus, J., Lindsey, J., Bricken,
                                                                              T., Chen, B., Pearce, A., Citro, C., Ameisen, E., Jones, A.,Lieberum, T., Rajamanoharan, S., Conmy, A., Smith, L.,
                                                     Cunningham, H., Turner, N. L., McDougall, C., MacDi-  Sonnerat, N., Varma, V., Kram´ar, J., Dragan, A., Shah,
                                                             armid, M., Tamkin, A., Durmus, E., Hume, T., Mosconi,   R., and Nanda, N. Gemma Scope: Open Sparse Au-
                                                                               F., Freeman, C. D., Sumers, T. R., Rees, E., Batson, J.,  toencoders Everywhere All At Once on Gemma 2. In
                                                           Jermyn, A., Carter, S., Olah, C., and Henighan, T. Scaling  Proceedings of the 7th BlackboxNLP Workshop: Ana-
                                                           Monosemanticity: Extracting Interpretable Features from  lyzing and Interpreting Neural Networks for NLP, pp.
                                                        Claude 3 Sonnet. Transformer Circuits Thread, 2024.  278–300, 2024.
Ma, G., Pfrommer, S., and Sojoudi, S. Revising and Fal-    Tibshirani, R. Regression Shrinkage and Selection via the
  sifying Sparse Autoencoder Feature Explanations.  In      Lasso. Journal of the Royal Statistical Society Series B:
  Proceedings of the 39th Annual Conference on Neural        Statistical Methodology, 58(1):267–288, 1996.
  Information Processing Systems, 2025.
                                                           Venhoff, C., Arcuschin, I., Torr, P., Conmy, A., and Nanda,
Mann, H. B. and Whitney, D. R. On a Test of Whether      N. Understanding Reasoning in Thinking Language Mod-
  one of Two Random Variables is Stochastically Larger       els via Steering Vectors.  In ICLR 2025 Workshop on
  than the Other. The Annals of Mathematical Statistics,      Reasoning and Planning for Large Language Models,
  pp. 50–60, 1947.                                         2025.

                                                10

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Wang, S., Asilis, J., Akg¨ul, ¨O. F., Bilgin, E. B., Liu, O.,
  Fu, D., and Neiswanger, W. Resa: Transparent Reason-
  ing Models via SAEs. arXiv preprint arXiv:2506.09967,
  2025.

Wang, X., Wei,  J., Schuurmans, D., Le, Q. V., Chi,
  E. H., Narang, S., Chowdhery, A., and Zhou, D. Self-
  Consistency Improves Chain of Thought Reasoning in
  Language Models. In Proceedings of the 11th Interna-
   tional Conference on Learning Representations, 2023.

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F.,
  Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-Thought
  Prompting Elicits Reasoning in Large Language Models.
  In Proceedings of the 36th Annual Conference on Neural
  Information Processing Systems, volume 35, pp. 24824–
  24837, 2022.

Wensey, M. R. General Inquiry Thinking Chain-of-Thought
  Dataset. HuggingFace Dataset, 2025.

Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao,
   Y., and Narasimhan, K. Tree of Thoughts: Deliberate
  Problem Solving with Large Language Models. In Pro-
  ceedings of the 37th Annual Conference on Neural Infor-
  mation Processing Systems, volume 36, pp. 11809–11822,
  2023.

Yeo, W. J., Prakash, N., Neo, C., Lee, R. K.-W., Cambria,
   E., and Satapathy, R.  Understanding Refusal in Lan-
  guage Models with Sparse Autoencoders. arXiv preprint
  arXiv:2505.23556, 2025.

Zhang, Y. and Math-AI Team. American Invitational Math-
  ematics Examination (AIME) 2024, 2024.

Zhang, Z., Zhang, S., Lambert, J., Zhou, W., Wang, Z.,
  Chen, M., Hard, A., Mathews, R., and Wang, L. Fantastic
  Reasoning Behaviors and Where to Find Them: Unsuper-
  vised Discovery of the Reasoning Process. arXiv preprint
  arXiv:2512.23988, 2025.

Zheng, L., Chiang, W.-L., Sheng, Y., Li, T., Zhuang, S., Wu,
   Z., Zhuang, Y., Li, Z., Lin, Z., Xing, E., et al. LMSYS-
  Chat-1M: A Large-Scale Real-World LLM Conversation
   Dataset. In Proceedings of the 12th International Confer-
  ence on Learning Representations, 2024.





                                                11

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models


Appendix

Table of Contents

    A On interpreting high-level behaviors with sparse autoencoders                                        13

    B  Theory: Sparsity suppresses high-dimensional within-reasoning variation                              15
         B.1  Setting and notation  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   15
         B.2  Main theorems .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   15
         B.3  Proofs   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   16

    C  Experiment results on additional models                                                          21
         C.1  Llama-3.1-8B   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   21
         C.2  Gemma-2-9B    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   21
         C.3  Gemma-2-2B    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   22

    D  Experiment results on alternative ranking metrics                                                  23
         D.1 ROC-AUC based selection    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   23
         D.2  Frequency ratio based selection   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   23
         D.3  Comparison across ranking metrics   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   24

    E  Additional experimental statistics                                                                25
         E.1  Token dependency statistics across configurations .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   25
         E.2  Injection strategy performance    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   25
         E.3  Average injection effect sizes across configurations  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   27
         E.4  Activation magnitude analysis  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   27
         E.5  LLM-guided falsification convergence    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   28
         E.6  Feature overlap across reasoning datasets  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   28

     F  Hyperparameter settings                                                                       30
          F.1   Feature detection    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30
          F.2  Token injection    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30
          F.3  LLM-guided falsification   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30
          F.4   Steering experiments    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   30
          F.5  Model and SAE configuration  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   31

    G LLM-guided feature interpretation results                                                         32

    H  Dataset details                                                                                46
         H.1  s1K-1.1    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   46
         H.2  General Inquiry Thinking Chain-of-Thought   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   46
         H.3  Pile Uncopyrighted    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   46

       I  Benchmark details                                                                             47
            I.1  AIME 2024   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   47
            I.2  GPQA Diamond  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   47

     J  Licenses and responsible use                                                                    48



                                                12

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

A. On interpreting high-level behaviors with sparse autoencoders

A growing body of work uses sparse autoencoders (SAEs) to study reasoning in large language models by identifying
features whose activations differ between reasoning and non-reasoning corpora and then interpreting these directions as
reasoning-related features (Galichin et al., 2025; Venhoff et al., 2025; Chen et al., 2025; Li et al., 2025b; Wang et al., 2025;
Fang et al., 2026; Zhang et al., 2025; Dong et al., 2026; He et al., 2026; Li et al., 2026). These results provide strong
evidence that SAEs surface directions that reliably separate reasoning-style text from other generations, and they have
enabled detailed case studies and interventions. Our results refine how to read such separations. In the main text, we present
a stylized theoretical analysis showing that sparsity regularization intrinsically favors stable low-dimensional correlates over
high-dimensional within-behavior variation, even when the dictionary contains the relevant directions. When a high-level
behavior is tightly coupled with a recurring cue, sparse coding can retain the cue cheaply while suppressing the remaining
distributed component. This mechanism motivates why contrastive separability can coexist with a lack of monosemantic
features that track the underlying reasoning process. Figure 5 illustrates the core intuition: an SAE feature that detects a cue
token can separate reasoning from non-reasoning and can be steered to increase the probability of emitting that cue, yet still
encode no semantic information about the reasoning itself. Consistent with this picture, our falsification experiments go
beyond distributional contrasts by combining causal token injection with LLM-guided counterexamples, constructing both
false positives that elicit activation in non-reasoning text via associated token-level patterns and false negatives obtained
by paraphrasing top-activating reasoning samples to preserve meaning while suppressing activation. Together, these tests
provide direct evidence that many contrastively selected features are better explained as linguistic correlates than as isolated
representations of reasoning computations. This perspective also aligns with observations from test-time scaling, where
substantial gains on reasoning benchmarks can arise from simple inference-time manipulations that change token usage and
generation length (Muennighoff et al., 2025).


        Token-level confounds can mimic 'reasoning features' in SAEs

    (a) Contrastive selection can pick token-cue features
                                                                                                                    SAE Toy SAE feature fi     Reasoning samples (contain cue token)
                                                                                             High activation when token = 'Wait'
           Wait, let's bound the error term. If x ≥ 0, then log(1+x) ≤ x, so the remainder is at most ε.
                                                                                                     Activation on example inputs

           Wait, we can do a case split. If n is even, the parity argument applies; otherwise we reduce
             to the even case.
                                                                                                                  Wait, …             This recipe …     Non-reasoning samples (no cue token)                                                                                                                                                                                                                                                                                                                                                                            Activation

                                                                                       Separates reasoning vs. non-reasoning,
           This recipe uses olive oil, garlic, and lemon. Roast the vegetables for 25 minutes.
                                                                                               yet encodes a low-dimensional lexical cue.

         The laptop arrived on time. The screen is bright and the battery lasts about nine hours.           A contrastive method can rank fi highly even if it
                                                                                                       does not represent reasoning computations.


    (b) Steering may change behavior without encoding reasoning
                                                                                      Observed output (example)
                  Steer the feature                      Effect on next-token probability           Before steering
                                                                              (illustrative)
                                                                         We compute the value directly. The answer is 42.
                   Amplify feature fi                                            0.25                   0.23                                                      After steering
      LLM       Add                       a                             small                                      positive     Updated
       internal                                                internal                    0.10             0.12  0.08                   Wait, I should double-check. If I substitute back,                    push                                  in                               the feature
                                                                               0.02                                             the result changes. The answer is 41.        state               direction             state
                             (strength γ)                                      wait therefore the       wait therefore the             Behavior change is driven by the base LLM's
                                                                     Before                After                              learned dynamics.
                  Goal: increase activation of fi                   Amplifying fi increases P(next token = 'wait')      The SAEnotfeaturethe underlyingmay only encodereasoningtheprocess.token cue 'wait',
     Key takeaway
                    Steering a cue feature can elicit more “reflective” outputs, but the feature may only capture a token-level cue such as
                        “wait.” This is useful for control, but insufficient for interpreting the underlying reasoning.

Figure 5. Illustration of cue-driven separability without semantic reasoning representation. Top: Reasoning traces often contain stable
cue tokens such as wait, while non-reasoning text does not. A contrastively selected SAE feature that activates on the cue can separate
reasoning from non-reasoning despite encoding only a low-dimensional lexical pattern. Bottom: Steering such a feature can increase the
probability that the LLM emits the cue token, which may correlate with more reflective or backtracking-like outputs. This behavioral
change reflects dynamics already present in the base LLM, and does not imply that the SAE feature represents the underlying reasoning
process.

                                                13

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Our framing is not that linguistic patterns and high-level behaviors are separate or opposing. Reasoning traces
inevitably involve language, and token-level structure can be a genuine part of how reasoning is expressed. The issue is
coupling. When a recurring cue is strongly correlated with a broader behavioral state, sparsity creates an asymmetry in
what is easiest to represent: low-dimensional correlates are retained by activating a small number of coordinates, while
high-dimensional variability across semantically equivalent realizations is penalized because it requires distributing mass
across many coordinates. This is conceptually different from feature absorption (Chanin et al., 2025). Feature absorption
studies how, under sparsity, a feature that is a subset of another can dominate because it achieves lower sparsity cost (for
example, a “short” feature outcompeting a broader “starts with s” feature). Our theoretical analysis instead highlights a
dimensionality effect: sparsity penalizes representing an isotropic or otherwise high-dimensional component more heavily
than a stable low-dimensional correlate, even when both are part of the same behavioral phenomenon and even under an
idealized dictionary.
Related concerns and opportunities appear in SAE analyses of other high-level behaviors such as refusal, hallucination,
and instruction following. For refusals, SAE features can predict and influence refusal behavior, while also correlating
with specific refusal phrases (Yeo et al., 2025). For hallucination and knowledge awareness, latent directions associated
with entity familiarity can causally affect whether a model abstains or hallucinates attributes (Ferrando et al., 2025).
For instruction-following settings, SAEs can be used to steer performance on structured tasks (He et al., 2025). These
works demonstrate the practical utility of SAE features as control levers and as diagnostic signals. Our results suggest
a complementary methodological caution: when an SAE feature correlates with a high-level behavior, that correlation
can arise because the feature captures a low-dimensional linguistic correlate of the behavior, rather than a monosemantic
representation of the underlying computation. This does not reduce the value of the features for intervention or analysis, but
it affects what kinds of semantic claims are warranted without falsification.
Our falsification results have important limitations. First, they primarily address monosemantic interpretations of individual
contrastive SAE features. They do not rule out the existence of non-monosemantic features that jointly respond to both a
token-level cue and aspects of reasoning behavior, nor do they exclude the possibility that reasoning-relevant information is
spread across many features in a way that resists single-feature attribution. Second, while our theoretical analysis explains
why sparse objectives can suppress high-dimensional within-reasoning variation, it is not a complete characterization of
SAE training dynamics or of how distributed computations manifest across layers and time steps. As a result, our evidence
should be read as guidance about what current contrastive pipelines reliably establish, not as a claim that SAEs cannot
represent any reasoning-relevant structure. In practice, we advocate treating contrastive correlations as hypotheses and
using causal and adversarial tests, including paraphrase-based falsification of top-activating samples, to assess whether an
interpretation is robust.
Overall, our findings suggest a constructive direction for the literature that interprets SAE features for high-level behaviors.
The goal is not to dismiss SAE-based interpretability, but to strengthen it. SAEs remain a powerful tool for surfacing
consistent internal directions and for enabling targeted interventions (Galichin et al., 2025; Venhoff et al., 2025; Chen et al.,
2025; Li et al., 2025b; Wang et al., 2025; Fang et al., 2026; Zhang et al., 2025; Dong et al., 2026; He et al., 2026; Li et al.,
2026; Yeo et al., 2025; Ferrando et al., 2025; He et al., 2025). Our contribution is to clarify a sparsity-driven failure mode
that is especially relevant when high-level behaviors co-occur with low-dimensional linguistic correlates, and to provide
falsification-oriented evaluations that can help practitioners distinguish robust behavioral representations from cue-like
correlates.





                                                14

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

B. Theory: Sparsity suppresses high-dimensional within-reasoning variation

B.1. Setting and notation
Fix integers k ≥2 and d ≥k. Let {v1, . . . , vk} ⊂Rd be an orthonormal set and define the dictionary matrix W :=
[v1, . . . , vk] ∈Rd×k so that W⊤W = Ik. We consider a stylized “reasoning subspace” in which reasoning-related
activations lie in span{v1, . . . , vk}, with v1 capturing a stable low-dimensional correlate and the remaining directionscapturing within-reasoning variability.
Let a ≥0 and b > 0 be scalars. We define a random activation vector
                                h := av1 + bg,                                                    (3)

where g ∈span{v2, . . . , vk} is distributed as
                                                   1
                                    g ∼N  0, k −1Ik−1                                                 (4)
in the coordinate system of the basis {v2, . . . , vk}. Explicitly, let ξ ∈Rk−1 have i.i.d. N(0, k−1)1   coordinates and set
g := Pki=2 ξi−1vi. Then h has coordinates
             W⊤h = x ∈Rk,    x1 = a,     xi = bξi−1 for i ∈{2, . . . , k}.                         (5)
In particular, for i ∈{2, . . . , k},                                                                        b2
                                         xi ∼N  0, σ2  ,    σ2 := k −1,
and the x2, . . . , xk are independent.
We analyze two activation rules used in sparse autoencoders.

(i) ℓ1-regularized decoding.  Given λ > 0, define the ℓ1-regularized code

                                                                      2 + λ∥z∥1.                                       (6)                                z⋆(h) ∈argz∈Rkmin ∥h −Wz∥2

(ii) Top-K decoding.  Given an integer K ∈{0, 1, . . . , k}, define the Top-K approximation by keeping the K largest-
magnitude coordinates of x = W⊤h and zeroing the rest. Formally, let SK(x) ⊆{1, . . . , k} be any size-K index set
achieving the K largest values of |xi|. Define z(K) ∈Rk by
                                         z(K)i   := xi · 1[i ∈SK(x)].                                              (7)
Then Wz(K) is the orthogonal projection of h onto the span of the selected basis directions.

B.2. Main theorems

We first record how the cue coordinate behaves under the same sparse decoding rules we analyze for the residual. This
makes the setting in Equations (3) and (4) easier to interpret: the cue component av1 is a single stable direction, while the
behavioral component bg is isotropic within a (k −1)-dimensional subspace. We then state and prove the ℓ1 suppressionresult used in the main text, followed by an analogous bound for Top-K.
Lemma B.1 (ℓ1 recovers the cue by soft-thresholding). Fix k ≥2 and let W ∈Rd×k have orthonormal columns with
W = [v1, . . . , vk]. Let h follow Equations (3) and (4) with parameters a ≥0 and b > 0, and let z⋆(h) be any minimizer ofEquation (6). Then
                                  z⋆1(h) = ST(a, λ/2) = max (a −λ/2, 0) .                                      (8)
In particular, if a ≥λ/2 then the cue reconstruction error along v1 equals (a −z⋆1(h))2 = (λ/2)2.
Lemma B.2 (Top-K selects the cue when it exceeds the residual order statistic). Fix k ≥2 and let W ∈Rd×k have
orthonormal columns with W = [v1, . . . , vk]. Let h follow Equations (3) and (4) with parameters a ≥0 and b > 0, and let

                                                15

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models



                                                                                                                        (1)                                                                                                                (k−1)z(K) be the Top-K code defined in Equation (7) with K ≥1. Let xi := ⟨vi, h⟩for i ≥2, and let X2                                                              ≥· · · ≥X2
denote the order statistics of {x22, . . . , x2k}. Then
                                                                         (K).                                        (9)                                    z(K)1  (h) = a  whenever  a2 ≥X2
Moreover, with σ2 := k−1,b2
                         P  z(K)1  (h) ̸= a ≤2(k −1) exp −a22σ2    .                                 (10)

Lemmas B.1 and B.2 formalize a basic asymmetry in our setting. The cue component is a single coordinate in the
orthonormal dictionary and is therefore inexpensive to represent: under ℓ1, it is recovered up to the usual soft-threshold
bias, and under Top-K, it is selected whenever its magnitude is not dominated by the K-th largest residual coordinate. In
contrast, the residual component is spread isotropically across k −1 coordinates. The theorems below quantify how sparsitysuppresses the recovered energy from this high-dimensional residual, even though the cue is still recovered.
Theorem B.3 (ℓ1 suppresses high-dimensional residual). Fix k ≥2 and let W have orthonormal columns. Let h followEquations (3) and (4) with parameters
                                                b2                               a ≥0 and b > 0, λand letλ√k−1z⋆(h) be any minimizer of Equation (6). Define
                                 k−1 and define u := 2σ =    2b    . Thenz⋆2:k := (z⋆2, . . . , z⋆k) ∈Rk−1. Let σ2 =
                                             2 = (k −1)E ST(X, λ/2)2 ≤b2Ψ(u),                     E ∥z⋆2:k∥2
where X ∼N(0, σ2), ST(x, t) := sign(x) max{|x| −t, 0}, and
                                                   2ϕ(u)
                                        Ψ(u) :=           .                                               (11)
                                             u
In particular,
                        r 2 1                         E                                    ∥z⋆2:k∥22 ≤b2  π u exp −u22     ,                                    (12)
which decays exponentially in (k −1)λ2/b2 for fixed λ/b.
Theorem B.4 (Top-K captures at most a K log k/k fraction of isotropic residual). Fix k ≥2 and let W ∈Rd×k have
orthonormal columns. Let h follow Equations (3) and (4) with parameters a ≥0 and b > 0, and let z(K) be the Top-Kcode defined in Equation (7). Define the residual energy captured outside the cue coordinate as

                                                                          2
                          RK :=   z(K)2    , . . . , z(K)k          .
                                                                          2

Let σ2 := k−1b2  and let X1, . . . , Xk−1 be i.i.d.      σ2). Then for any K       1, . . . , k                                   N(0,                ∈{0,       −1},
                              E[RK] ≤σ2K (2 log (2(k −1)) + 2) .                                    (13)
Equivalently,
                              E[RK]   K
                                                    (2 log (2(k    + 2) .                                   (14)                                          b2  ≤ k            −1))                             −1
Theorem B.4 implies that if K is held fixed while k grows, the expected recovered fraction from the isotropic residual
vanishes. More generally, the recovered fraction is at most on the order of K log k/k, so capturing a constant fraction of a
high-dimensional isotropic component requires K to scale nearly linearly in k up to logarithmic factors. This formalizes the
intuition that representing isotropic high-dimensional variation requires activating many coordinates, which sparse Top-K
codes cannot do when K ≪k.

B.3. Proofs
Proof of Lemma B.1.  Let x := W⊤h ∈Rk. Since W has orthonormal columns,
                                                                                    2
                                                                                                                           .                                                                                    2                         ∥h −Wz∥2                                                2 = ∥x −z∥2                                                             2 +   I −WW⊤ h

                                                16

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

The second term does not depend on z, so minimizing Equation (6) is equivalent to minimizing ∥x −z∥2                                                                                                           2 + λ∥z∥1 over
z ∈Rk. This objective is separable across coordinates. Because g ∈span{v2, . . . , vk}, we have x1 = ⟨v1, h⟩= a.Therefore z⋆1 is any minimizer of the scalar problem
                                     minz∈R(z −a)2 + λ|z|.
The unique minimizer is the soft-threshold operator z = ST(a, λ/2). Since a ≥0, this equals max(a −λ/2, 0), whichproves Equation (8). The stated cue reconstruction error follows immediately.

Proof of Lemma B.2.  Let x := W⊤h = (x1, . . . , xk). As in the proof of Theorem B.4, Top-K decoding in an
orthonormal basis selects a support of size at most K that maximizes Pi∈S x2i , and then sets z(K)i  = xi on that support. If
a2 = x21 is at least the K-th largest value among {x22, . . . , x2k}, then index 1 belongs to the set of K largest values among
                                                      1  = x1 = a, proving Equation (9). For the probability bound, the{x21, . . . , x2k}, and Top-K must select index 1. Thus z(K)
                1failure event {z(K)                     ̸= a} implies max2≤i≤k x2                                                                  i > a2, hence max2≤i≤k |xi| > a. By Equation (5), for i ≥2 the random
variables xi are i.i.d. N(0, σ2) with σ2 = b2/(k −1). A union bound and the Gaussian tail inequality yield
                                      k
          P  max   > a X P   > a) = (k      > a)          exp                ,                2≤i≤k |xi|    ≤       (|xi|        −1)P (|X|    ≤2(k −1)    −a22σ2
                                    i=2
which is Equation (10).

Proof of Theorem B.3.  We proceed in steps.

Step 1: reduce the optimization to coordinates.  Since W has orthonormal columns, for any z ∈Rk,
                                                                                             2 + C0,                                                                                2 = ∥x −z∥2                                                           2 + ∥h −WW⊤h∥2                                 2 = ∥W⊤h −W⊤Wz∥2               ∥h −Wz∥2
                                               2 does not depend on z. Therefore, minimizing Equation (6) is equivalent towhere x := W⊤h and C0 := ∥h −WW⊤h∥2
                                   min         2 +                                                  (15)                                         z∈Rk ∥x −z∥2   λ∥z∥1.

Step 2: separability and the soft-thresholding solution.  The objective in Equation (15) is separable across coordinates:

                                                         k
                                              2 + λ∥z∥1 = X  (xi −zi)2 + λ|zi|  .                         ∥x −z∥2
                                                       i=1
Thus a minimizer z⋆can be obtained by minimizing each coordinate independently:
                                        z⋆i ∈argz∈Rmin(xi −z)2 + λ|z|.
We claim that the unique minimizer is z⋆i = ST(xi, λ/2). To verify, fix x ∈R and consider f(z) := (x −z)2 + λ|z|.
If z > 0, then f(z) = (x −z)2 + λz and f ′(z) = 2(z −x) + λ. Setting f ′(z) = 0 yields z = x −λ/2. This solution liesin the region z > 0 iff x > λ/2.
If z < 0, then f(z) = (x −z)2 −λz and f ′(z) = 2(z −x) −λ. Setting f ′(z) = 0 yields z = x + λ/2. This solution lies
in the region z < 0 iff x < −λ/2.
If |x| ≤λ/2, then the stationary points above fall outside their regions. In this case, the minimizer occurs at the non-
differentiable point z = 0. To confirm, note that for z > 0 with |x| ≤λ/2,
                               f ′(z) = 2(z −x) + λ ≥2(0 −|x|) + λ ≥0,
so f is non-decreasing on (0, ∞) and minimized at z = 0. Similarly for z < 0,
                               f ′(z) = 2(z −x) −λ ≤2(0 + |x|) −λ ≤0,
so f is non-increasing on (−∞, 0) and minimized at z = 0. Therefore,
                      z⋆= ST(x, λ/2) = sign(x) max (|x| −λ/2, 0) .
Applying this to each coordinate yields z⋆i = ST(xi, λ/2).

                                                17

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Step 3: compute              b2   E[∥z⋆2:k∥22] in terms of a one-dimensional expectation.  By Equation (5), x2, . . . , xk are i.i.d. N(0, σ2)
with σ2 = k−1. By Step 2,
                                   z⋆i = ST(xi, λ/2)   for   i ∈{2, . . . , k}.
Thus
                                             k
                   E ∥z⋆2:k∥2                                          2 = X E (z⋆i )2 = (k −1)E ST(X, λ/2)2  ,                           (16)
                                            i=2
where X ∼N(0, σ2).
Step 4: compute E[ST(X, t)2] in closed form.  Let t > 0 and set u := t/σ. Write X = σZ with Z ∼N(0, 1). Then
             ST(X, t) = sign(Z)σ max (|Z| −u, 0) ,    ST(X, t)2 = σ2 (|Z| −u)2 1[|Z| > u].
By symmetry,
                                            Z ∞
                       E ST(X, t)2 = 2σ2                                                              (z −u)2ϕ(z) dz.                                  (17)                                                     u
Expand (z −u)2 = z2 −2uz + u2 and integrate term by term:
               Z ∞              Z ∞            Z ∞           Z ∞

                   u                        (z −u)2ϕ(z) dz =  u  z2ϕ(z) dz −2u  u  zϕ(z) dz + u2  u  ϕ(z) dz.                 (18)
We now evaluate each integral. First,
                                    Z ∞
                                              zϕ(z) dz = ϕ(u),                                            (19)
                                           u
since dz(−ϕ(z))d     = zϕ(z). Second,       ∞                                  Z
                                             ϕ(z) dz = 1 −Φ(u).                                          (20)                                          u
Third, using ϕ′(z) = −zϕ(z),
           Z ∞          Z ∞                       Z ∞
                 z2ϕ(z) dz =                                                        u +                                                                 ϕ(z) dz = uϕ(u) + 1 −Φ(u).           (21)              u                              u  z(−ϕ′(z)) dz = −[zϕ(z)]∞                                                             u
Substituting Equations (19) to (21) into Equation (18) gives
     Z ∞
           (z −u)2ϕ(z) dz = uϕ(u) + 1 −Φ(u) −2uϕ(u) + u2 1 −Φ(u) = (1 + u2) 1 −Φ(u) −uϕ(u).       u
Combining with Equation (17) yields
                    E ST(X, t)2 = 2σ2  (1 + u2)(1 −Φ(u)) −uϕ(u)  .                            (22)

Step 5: upper bound using Mill’s ratio and define Ψ.  We use the standard inequality for u > 0,
                                         1 −Φ(u) ≤ϕ(u)u   .                                              (23)
Substitute Equation (23) into Equation (22):

                                                           ϕ(u)                       ϕ(u)       E ST(X, t)2          (1 + u2)ϕ(u)      = 2σ2    + uϕ(u)      = 2σ2        .       (24)                 ≤2σ2         u  −uϕ(u)         u        −uϕ(u)        u
                         λ   λ√k−1
We now set t = λ/2, so u = 2σ =    2b    . Plugging Equation (24) into Equation (16) gives

                                                  ϕ(u)        ϕ(u)                   E                           ∥z⋆2:k∥22 ≤(k −1)  2σ2 u  = 2b2 u = b2Ψ(u),

                                             √1                                                              expwhere we define Ψ(u) := 2ϕ(u)u   as in Equation (11). Finally, since ϕ(u) =                                                                                        2    , we obtain Equation (12). This                                                                      2π                                                            −u2
concludes the proof.

                                                18

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Proof of Theorem B.4.  We prove Equation (13) by reducing Top-K decoding in an orthonormal basis to a bound on the
maximum of Gaussian coordinates and then integrating a tail inequality.

Step 1: Top-K decoding in an orthonormal basis.  Let x := W⊤h ∈Rk. Since W has orthonormal columns, for any
z ∈Rk,                                                       2                      2
                                                                                                                               .                                                               2                                                                                       2                       ∥h −Wz∥2                                             2 = W⊤h −z                                 +   I −WW⊤ h
The second term is independent of z, hence z(K) minimizes ∥x −z∥2                                                                         2 subject to ∥z∥0 ≤K. For any fixed support
                                                                                                                                             i/∈S x2i .S ⊆{1, . . . , k} with |S| ≤K, the minimizer is zi = xi for i ∈S and zi = 0 otherwise, with objective value P
Therefore, an optimal support maximizes Pi∈S x2i , so Top-K selects indices of the K largest values of x2i .

Step 2: reduction to residual coordinates and a monotone upper bound.  Let xi :=                                                                                                       b2⟨vi, h⟩so that x = (x1, . . . , xk).
By Equation (5), the residual coordinates (x2, . . . , xk) are i.i.d. N(0, σ2) with σ2 = k−1. Since RK keeps at most Kcoordinates from (x2, . . . , xk), it is upper bounded by the sum of the K largest squared residual coordinates:


                                    K
                              RK ≤ X X2(j),                                               (25)
                                                    j=1

where X2(1) ≥· · · ≥X2                      (k−1) are the order statistics of X21, . . . , X2k−1 for i.i.d. Xi ∼N(0, σ2).
Step 3: upper bound by K times the maximum.  Let

                     M :=  max X2i .
                                                1≤i≤k−1

Since X2(j) ≤M for all j, we have
                                K
              X X2(j) ≤KM.                                              (26)
                                             j=1
Combining Equations (25) and (26) and taking expectation yields
                                     E[RK] ≤KE[M].                                              (27)
Step 4: a tail bound for the maximum.  Let Y := max1≤i≤k−1 |Xi|, so M = Y 2. For any t ≥0, by a union bound andsymmetry,
                                       k−1
                      P (Y ≥t) ≤ X P (|Xi| ≥t) = (k −1)P (|X| ≥t) ,
                                            i=1
where X ∼N(0, σ2). Write X = σZ with Z ∼N(0, 1). Using P(|Z| ≥u) ≤2 exp −u2/2  for u ≥0, we obtain
                        P (|X| ≥t) = P (|Z| ≥t/σ) ≤2 exp −t22σ2    ,

and therefore
                           P (Y ≥t) ≤2(k −1) exp −t22σ2    .                                    (28)

Step 5: bounding E[M] by tail integration.  Since Y ≥0, the tail integral identity gives
                                   ∞                       ∞
                               Z                                                Z
                                               P Y                          E[Y 2] =                                                                         du.                                      ≥√u                               P Y 2 ≥u du =                                                                    0                                            0

Using Equation (28),
                                Z ∞
                            E[Y 2] ≤  0  min  1, 2(k −1) exp −u2σ2    du.

                                                19

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Let u0 := 2σ2 log (2(k −1)) so that 2(k −1) exp −u0/(2σ2) = 1. Splitting the integral at u0 yields
                               Z u0      Z ∞
                           E[Y 2] ≤  0  1 du +  u0 2(k −1) exp −u2σ2  du
                     = u0 + 4σ2(k −1) exp −u02σ2
                     = 2σ2 log (2(k −1)) + 2σ2.                                              (29)
Because M = Y 2, Equation (29) implies
                              E[M] ≤2σ2 log (2(k −1)) + 2σ2.                                      (30)

Step 6: conclude the bound on E[RK].  Substituting Equation (30) into Equation (27) gives
                  E[RK] ≤K 2σ2 log (2(k −1)) + 2σ2 = σ2K (2 log (2(k −1)) + 2) ,
which is Equation (13). Dividing by b2 = (k −1)σ2 yields Equation (14). This completes the proof.





                                                20

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

C. Experiment results on additional models

To assess the generality of our findings beyond the Gemma-3 family, we apply the same experimental protocol described in
Sections 4 and 5 to three additional models: Llama-3.1-8B (Grattafiori et al., 2024) and two models from the Gemma-2
family (Gemma-2-9B and Gemma-2-2B) (Gemma Team et al., 2024). These models span different architectural families
and scales, providing a comprehensive test of robustness across contemporary open-weight language models.

C.1. Llama-3.1-8B

We analyze Llama-3.1-8B, an 8B parameter model with 32 transformer layers from Meta AI. We focus on layer 16 (50%
depth), selected based on minimal token concentration following the same criterion used in Section 5.1. We use sparse
autoencoders from the Llama Scope release (He et al., 2024) with 32,768 features trained on residual stream activations.
Table 6 summarizes feature detection and token injection results for both reasoning datasets. As in the main experiments, we
identify the top 100 features by Cohen’s d and classify them using the token injection framework from Section 4.3.

Table 6. Feature detection and token injection results for Llama-3.1-8B. TD denotes token-driven, PTD partially token-driven, WTD
weakly token-driven, and CD context-dependent.

           Dataset            Mean d    TD     PTD    WTD    CD     Avg. Inject. d
         s1K                   0.851   37 (37%)  18 (18%)  28 (28%)  17 (17%)      0.909
           General Inquiry CoT    1.015   26 (26%)  17 (17%)  24 (24%)  33 (33%)      0.613

Llama-3.1-8B exhibits moderate token injection effects intermediate between Gemma-3 and Gemma-2 models. For s1K,
83% of features show some degree of token-driven behavior (combining all three categories), with an average injection
Cohen’s d of 0.909. For General Inquiry CoT, 67% show token-driven behavior with average d of 0.613. The higher
proportion of context-dependent features on General Inquiry CoT (33%) compared to s1K (17%) mirrors patterns observed
in other models, suggesting dataset-specific differences in feature activation patterns.
To investigate the context-dependent features, we apply the LLM-guided falsification protocol from Section 4.4 to a random
sample from each dataset (17 features from s1K, 20 from General Inquiry CoT). Across all 37 analyzed features, none
satisfy the criteria for genuine reasoning behavior. The LLM classifies all features as confounds, with high confidence for 30
of them (81%). The dominant confounds include conversational discourse markers, formal writing style, meta-cognitive
planning phrases, and technical vocabulary that appears in both reasoning and non-reasoning contexts.

C.2. Gemma-2-9B

We analyze Gemma-2-9B, a 9B parameter model with 42 transformer layers, focusing on a representative middle layer
selected based on minimal token concentration in a preliminary analysis, following the same criterion used in Section 5.1.
We use sparse autoencoders from the GemmaScope release (Lieberum et al., 2024) with 16,384 features trained on residual
stream activations.
Table 7 summarizes feature detection and token injection results for both reasoning datasets. As in the main experiments, we
identify the top 100 features by Cohen’s d and classify them using the token injection framework from Section 4.3.

Table 7. Feature detection and token injection results for Gemma-2-9B. TD denotes token-driven, PTD partially token-driven, WTD
weakly token-driven, and CD context-dependent.

             Dataset            Mean d   TD    PTD   WTD    CD     Avg. Inject. d
           s1K                   0.709   6 (8%)  7 (9%)  23 (29%)  42 (54%)      0.285
             General Inquiry CoT    0.764   6 (6%)  4 (4%)  33 (33%)  57 (57%)      0.294

Compared to Gemma-3 models, Gemma-2-9B exhibits a substantially larger fraction of context-dependent features and
markedly smaller injection effect sizes. Although statistically significant activation differences between reasoning and
non-reasoning text are still observed at the detection stage, the average Cohen’s d induced by token injection is below 0.3
for both datasets. This indicates weaker reliance on shallow token-level cues, but does not by itself imply the presence of
genuine reasoning features.

                                                21

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

To further investigate these context-dependent features, we apply the LLM-guided falsification protocol from Section 4.4 to
20 randomly sampled features per dataset. Across all 40 analyzed features, none satisfy the criteria for genuine reasoning
behavior. The LLM classifies all features as confounds, with high confidence for 34 of them. The dominant confounds
include formal academic writing style, meta-cognitive discourse markers, and technical vocabulary that appears in both
reasoning and non-reasoning contexts.

C.3. Gemma-2-2B

We next analyze Gemma-2-2B, a 2B parameter model with 26 layers, using the same methodology. We again select a middle
layer based on token concentration analysis and apply an SAE with 16,384 features.
Table 8 reports the corresponding feature detection and token injection results.

                             Table 8. Feature detection and token injection results for Gemma-2-2B.

            Dataset            Mean d   TD     PTD    WTD    CD     Avg. Inject. d
          s1K                   0.636   2 (2%)  18 (18%)  36 (36%)  44 (44%)      0.281
            General Inquiry CoT    0.602   1 (1%)   7 (7%)   35 (35%)  57 (57%)      0.207

Gemma-2-2B shows the weakest token injection effects among all models studied. Only a small fraction of features are
classified as strongly token-driven, while between 44% and 57% are context-dependent. Average injection effect sizes are
also the lowest observed. Despite this reduced token sensitivity, LLM-guided analysis of 40 context-dependent features
again identifies no genuine reasoning features. Thirty-six of these features are classified as confounds with high confidence.
The identified confounds include procedural discourse markers, formal sentence structure, and domain-specific vocabulary
patterns.





                                                22

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

D. Experiment results on alternative ranking metrics

In the main text, we use Cohen’s d as the primary criterion for ranking and selecting candidate reasoning features (Section 4.2).
To evaluate the robustness of our conclusions to this choice, we repeat the full experimental pipeline using two alternative
ranking metrics: ROC-AUC and frequency ratio. For every configuration, we rank all SAE features by the corresponding
metric and select the top 100 features that satisfy the following criteria: minimum Cohen’s d effect size d ≥0.3, Bonferroni-
corrected p-value ≤0.01 under the Mann-Whitney U test, and ROC-AUC ≥0.6 when using the feature activation as aunivariate classifier. All experiments in this section are conducted on Gemma-3-4B-Instruct at layer 22 using the s1K dataset,
with all other parameters held fixed, including datasets, sample sizes, statistical thresholds, token injection strategies, and
LLM-guided falsification.

D.1. ROC-AUC based selection

ROC-AUC measures a feature’s ability to discriminate between reasoning and non-reasoning samples across all possible
thresholds. For a feature i, it is defined as

                                                                 nR  nNR
                                                  1
                    AUCi = P aRi,j > aNRi,k =  X X 1 aRi,j > aNRi,k  .
                                            nRnNR j=1 k=1

This metric is distribution-free, invariant to monotonic transformations, and robust to class imbalance. We rank all SAE
features by ROC-AUC and select the top 100 features satisfying AUC ≥0.6, Bonferroni-corrected p ≤0.01, and Cohen’s
d ≥0.3.
Table 9 summarizes the resulting feature statistics and injection outcomes. Features selected by ROC-AUC exhibit token
injection behavior that closely mirrors the results obtained using Cohen’s d ranking. In particular, 95% of features fall
into one of the token-driven categories, while only a small fraction remain context-dependent. The mean Cohen’s d of the
selected features is comparable to that of the Cohen’s d ranked set, indicating strong agreement between the two metrics.

      Table 9. Results for the top 100 features ranked by ROC-AUC on Gemma-3-4B-Instruct at layer 22 using the s1K dataset.

                                     Metric                      Value
                             Mean Cohen’s d              0.830
                             Mean ROC-AUC             0.667
                                     Token-driven              59 (59%)
                                            Partially token-driven       18 (18%)
                                Weakly token-driven        18 (18%)
                                     Context-dependent          5 (5%)
                                       Features analyzed (LLM)       5
                                  Genuine reasoning features      0

All five context-dependent features identified under ROC-AUC ranking are classified as confounds by the LLM-guided
falsification procedure described in Section 4.4, with high confidence in each case.

D.2. Frequency ratio based selection

We next consider the frequency ratio metric, which measures how much more often a feature activates on reasoning samples
than on non-reasoning samples. For feature i, we define
                                                           freqRi + ϵ
                                         FreqRatioi =                 ,
                                                         freqNRi + ϵ
where freqRi and freqNRi  denote the proportion of samples whose maximum activation exceeds a fixed threshold, and ϵ = 0.01
is a smoothing constant. The activation threshold is set to max(0.5 · σbaseline, 0.01), following the same procedure used inthe auxiliary analyses described in Section 4.2.
Ranking features by frequency ratio and selecting the top 100 yields results that are nearly identical to those obtained with
ROC-AUC. As shown in Table 10, 96% of selected features exhibit statistically significant token-driven behavior, with

                                                23

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

only four features classified as context-dependent. These features also show comparable effect sizes and discriminative
performance.

    Table 10. Results for the top 100 features ranked by frequency ratio on Gemma-3-4B-Instruct at layer 22 using the s1K dataset.

                                     Metric                      Value
                             Mean Cohen’s d              0.830
                             Mean ROC-AUC             0.667
                                     Token-driven              65 (65%)
                                            Partially token-driven       14 (14%)
                                Weakly token-driven        17 (17%)
                                     Context-dependent          4 (4%)
                                       Features analyzed (LLM)       4
                                  Genuine reasoning features      0

LLM-guided analysis of all four context-dependent features again identifies no genuine reasoning features, with each
classified as a confound.

D.3. Comparison across ranking metrics

To quantify overlap between feature sets selected by different ranking metrics, we compute Jaccard similarities between
the top 100 features selected by Cohen’s d, ROC-AUC, and frequency ratio. Figure 6 shows that the overlap is substantial
across all pairs, indicating that the three metrics largely prioritize the same subset of features.


                                   1.0
                                                              Three-way overlap: 80 features
                                               0.82
                                   0.8                                                                       0.74                    0.75


                                   0.6                                                                                        Similarity

                                   0.4
                                                              Jaccard

                                   0.2


                                   0.0
                                               Cohen’s d                 Cohen’s d            AUC vs
                                                   vs AUC                    vs Freq                     Freq

Figure 6. Jaccard similarity between top-100 feature sets selected by different ranking metrics on Gemma-3-4B-Instruct at layer 22 using
the s1K dataset.

Taken together, these results demonstrate that our main conclusions do not depend on the specific choice of ranking metric.
Whether features are selected by Cohen’s d, ROC-AUC, or frequency ratio, the vast majority are explained by token-level or
short-range contextual confounds, and no genuine reasoning features are identified under any selection criterion.





                                                24

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

E. Additional experimental statistics

This section reports supplementary statistics from the main experiments that provide additional quantitative context for
interpreting the results presented in Section 5.

E.1. Token dependency statistics across configurations

Beyond the categorical classification induced by token injection, we analyze the degree to which feature activations are
concentrated on a small subset of tokens. For each feature, we compute a token concentration score defined as the fraction
of total activation mass attributable to the top 30 tokens ranked by mean activation. We additionally report normalized
activation entropy as a complementary measure of dispersion. High concentration and low entropy indicate strong reliance
on a limited set of lexical triggers.
Table 11 summarizes token dependency statistics for all main configurations. Across models, layers, and datasets, between
30% and 78% of features exhibit high token dependency, defined as concentration greater than 0.5. Notably, s1K con-
figurations generally show lower token concentration than General Inquiry CoT configurations for the same model and
layer. Gemma-3-4B-Instruct layer 17 on s1K shows the lowest token concentration (mean: 0.402, median: 0.265), while
Gemma-3-12B-Instruct layer 27 on General Inquiry CoT shows the highest (mean: 0.714, median: 0.735), suggesting both
architectural and dataset-specific influences on token dependency.


Table 11. Token concentration statistics for top-ranked features across all main configurations. High dependency denotes features with
concentration greater than 0.5.

                 Model                  Layer   Dataset   Mean  Median  High dep.
                  Gemma-3-12B-Instruct    17     s1K       0.529    0.478   41 (41%)
                  Gemma-3-12B-Instruct    17     Gen. Inq.   0.641    0.685   73 (73%)
                  Gemma-3-12B-Instruct    22     s1K       0.461    0.457   30 (30%)
                  Gemma-3-12B-Instruct    22     Gen. Inq.   0.622    0.681   73 (73%)
                  Gemma-3-12B-Instruct    27     s1K       0.521    0.480   41 (41%)
                  Gemma-3-12B-Instruct    27     Gen. Inq.   0.714    0.735   78 (78%)
                  Gemma-3-4B-Instruct     17     s1K       0.402    0.265   32 (32%)
                  Gemma-3-4B-Instruct     17     Gen. Inq.   0.639    0.699   63 (63%)
                  Gemma-3-4B-Instruct     22     s1K       0.539    0.449   47 (47%)
                  Gemma-3-4B-Instruct     22     Gen. Inq.   0.690    0.836   69 (69%)
                  Gemma-3-4B-Instruct     27     s1K       0.528    0.473   48 (48%)
                  Gemma-3-4B-Instruct     27     Gen. Inq.   0.674    0.760   71 (71%)
                   DS-R1-Distill-Llama-8B  19     s1K       0.569    0.528   52 (52%)
                   DS-R1-Distill-Llama-8B  19     Gen. Inq.   0.687    0.826   69 (69%)


For s1K configurations, median concentration values are often lower than means, indicating left-skewed distributions where
most features have moderate-to-low concentration with a minority showing very high concentration. Conversely, General
Inquiry CoT configurations show median values close to or higher than means, suggesting more uniform high concentration.
Figure 7 visualizes the distribution of token concentration across layers for representative models.

E.2. Injection strategy performance

We further analyze which injection strategies are most effective at eliciting feature activation.  For a representative
configuration, Gemma-3-12B-Instruct at layer 22 on s1K, we identify the injection strategy that yields the largest Cohen’s
d for each feature. The prepend strategy dominates, accounting for 69.7% of best-performing cases, followed by bigram
injection, replacement, and trigram injection. Context-preserving strategies collectively account for a small fraction of cases.
This distribution indicates that simple token presence is typically sufficient to drive feature activation, and that preserving
local co-occurrence or syntactic context does not substantially attenuate injection effects. Figure 8 compares Cohen’s d
distributions across strategies.

                                                25

                          Falsifying Sparse Autoencoder Reasoning Features in Language Models





                 1.0         High dependency threshold



                 0.8



                 0.6                                                 Concentration
                 0.4
                   Token

                 0.2



                 0.0

                              G3-12B          G3-12B          G3-12B          G3-4B           G3-4B           G3-4B
                               L17             L22             L27             L17             L22             L27

Figure 7. Token concentration distributions across layers for Gemma-3-12B-Instruct and Gemma-3-4B-Instruct on the s1K dataset.





               6
                                                                                                                                 Large effect
                                                                                                          Medium effect
               5                                                                                                          Small effect
                          Effect) 4


               3                                     (Injection
    d 2


               1                          Cohen’s

               0

                     Prepend        Intersperse      Bigram        Trigram      Bigram+Ctx    Trigram+Ctx
                                                     Injection Strategy

        Figure 8. Cohen’s d distributions across token injection strategies for Gemma-3-12B-Instruct at layer 22 on s1K.





                                              26

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

E.3. Average injection effect sizes across configurations

This section reports the magnitude of activation changes induced by token injection across all experimental configurations.
For each model, layer, and reasoning dataset, we compute the average Cohen’s d achieved by the best-performing injection
strategy for each of the 100 candidate features, as defined in Section 4.3. The reported values therefore summarize the
strength of the strongest token-level intervention per feature, averaged across features within each configuration.
Table 12 presents the resulting average effect sizes. Across all 14 configurations, the mean Cohen’s d ranges from 0.521
to 1.471, with an overall mean of 0.974 and median of 0.982. All configurations exceed d = 0.5, which corresponds to a
medium effect size under standard conventions (Cohen, 2013), and 6 of the 14 configurations exceed d = 1.0, indicating
very large effects.


Table 12. Average Cohen’s d for token injection across configurations. Values are computed by averaging, for each configuration, the best
injection effect size per feature across the top 100 candidate features.

                  Model                        Layer   s1K   General Inquiry CoT
                     Gemma-3-12B-Instruct           17    1.266         0.982
                     Gemma-3-12B-Instruct           22    0.539         0.660
                     Gemma-3-12B-Instruct           27    1.044         0.698
                     Gemma-3-4B-Instruct            17    1.404         1.078
                     Gemma-3-4B-Instruct            22    1.409         0.913
                     Gemma-3-4B-Instruct            27    1.471         0.756
                     DeepSeek-R1-Distill-Llama-8B    19    0.899         0.521


These effect sizes indicate that injecting a small number of feature-associated tokens into non-reasoning text is sufficient
to induce substantial activation shifts. In particular, injecting three tokens into 64-token sequences, which corresponds
to approximately 4.7% of the input tokens, produces activation increases that are comparable to or exceed conventional
medium and large effect size thresholds. The consistency of these effects across models, layers, and datasets provides strong
evidence that token-level patterns play a dominant role in driving the activation of features identified by contrastive methods.
We observe systematic variation across configurations. Gemma-3 models generally exhibit larger average injection effects
than DeepSeek-R1-Distill-Llama-8B. Gemma-3-4B-Instruct shows the highest injection effects (1.404–1.471 on s1K), while
Gemma-3-12B-Instruct layer 22 shows the lowest among Gemma-3 models (0.539–0.660). Nevertheless, even the smallest
observed average effect size represents a medium effect, underscoring that token injection reliably induces strong feature
activation across all tested conditions.

E.4. Activation magnitude analysis

To contextualize effect sizes, we analyze absolute activation magnitudes across conditions. For each feature, we compute
the mean activation across samples within each condition and then average these values across features.
Table 13 reports activation statistics for Gemma-3-12B-Instruct at layer 22 on s1K. Token injection increases mean activation
by a factor of approximately 1.32 relative to the non-reasoning baseline and reaches parity with activations observed on
genuine reasoning text. The overlap in upper-tail statistics further indicates that token injection is sufficient to reproduce the
activation regimes associated with reasoning inputs.


Table 13. Activation magnitude statistics for Gemma-3-12B-Instruct at layer 22 on s1K. Injected refers to the best-performing token
injection strategy per feature.

                         Condition             Mean     Std.    Median   90th pct.
                        Non-reasoning (baseline)   416.5   1102.8    26.2     1366.8
                        Non-reasoning (injected)   549.8   1123.1    68.5     1971.5
                        Reasoning text            558.3   1139.5    144.2    2010.3



                                                27

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

E.5. LLM-guided falsification convergence

We analyze the convergence behavior of the LLM-guided falsification protocol described in Section 4.4. Table 14 reports
the number of iterations required to reach the stopping criteria across all 153 context-dependent features from the main
experiments.

              Table 14. Iteration statistics for LLM-guided falsification across all analyzed context-dependent features.

                                       Statistic                         Value
                           Mean iterations to convergence        2.4
                              Median iterations to convergence      2.0
                                Converged in 1 iteration          47 (31%)
                                Converged in 2 iterations         68 (44%)
                                Converged in 3 or more iterations  38 (25%)
                               Reached max iterations (10)        3 (2%)

Most features converge rapidly, with 75% resolving within two iterations. Features requiring more iterations typically
involve overlapping stylistic or discourse-level patterns.


                        60                                                                                       Mean: 3.4
                                                                                              Median: 2
                        50

                        40                                                      Features
              of 30

                        20                                         Number

                        10

                         0
                                1     2     3     4     5     6     7     8     9    10
                                                 Iterations to Convergence

                       Figure 9. Distribution of iterations required for LLM-guided falsification to converge.


E.6. Feature overlap across reasoning datasets

Finally, we examine whether the same features are selected when ranking on different reasoning datasets. For each model
and layer, we compute the Jaccard similarity between the top 100 features identified using s1K and General Inquiry CoT.
Table 15 shows that overlap is generally low, with Jaccard similarities ranging from 0.058 to 0.190. Larger models exhibit
moderately higher overlap, while deeper layers tend to show reduced overlap. These results indicate that different reasoning
datasets activate largely distinct feature subsets.
Figure 10 provides a visual summary of feature overlap across datasets. LLM-guided analysis of shared context-dependent
features again identifies only confounds, including mathematical notation detectors, formal discourse markers, and meta-
cognitive phrases that appear across reasoning and non-reasoning text.





                                                28

                           Falsifying Sparse Autoencoder Reasoning Features in Language Models





                   Table 15. Overlap between top-ranked features selected using s1K and General Inquiry CoT.

                        Model                 Layer   Intersection   Jaccard
                          Gemma-3-12B-Instruct    17       27        0.156
                          Gemma-3-12B-Instruct    22       32        0.190
                          Gemma-3-12B-Instruct    27       12        0.064
                          Gemma-3-4B-Instruct     17       11        0.058
                          Gemma-3-4B-Instruct     22       16        0.087
                          Gemma-3-4B-Instruct     27       13        0.070





                                                                               1.0
                 s1K only
    175          Shared
                   Gen. Inq. only                                                   0.8
    150

    125Features                                                                           0.6of 100                                                                                                                                                                                                Similarity

     75                                                                                                                                                      Jaccard 0.4Number     50                                                                                                           0.19                                                                               0.2      0.16
     25                                                                                                             0.06       0.06       0.09       0.07
      0                                                                       0.0
          L17     L22     L27     L17     L22     L27                L17     L22     L27     L17     L22     L27
        G3-12B     G3-12B     G3-12B     G3-4B     G3-4B     G3-4B                  G3-12B     G3-12B     G3-12B     G3-4B     G3-4B     G3-4B

                   Figure 10. Feature overlap between s1K and General Inquiry CoT across models and layers.





                                               29

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

F. Hyperparameter settings

This section specifies all hyperparameters used throughout the experimental pipeline described in Sections 4 and 5. Unless
otherwise stated, these settings are shared across all models, layers, and datasets.

F.1. Feature detection

Candidate reasoning features were identified using 1,000 samples from each corpus, reasoning and non-reasoning, with each
sample truncated to a maximum of 64 tokens. Feature activations were aggregated using the maximum activation across
tokens. In the main experiments, features were ranked by Cohen’s d, while appendix experiments used alternative ranking
metrics as described in Appendix D.
We imposed three simultaneous selection thresholds: minimum Cohen’s d of 0.3, maximum Bonferroni-corrected p-value
of 0.01 using the Mann-Whitney U test (Mann & Whitney, 1947), and minimum ROC-AUC of 0.6. From the features
satisfying all criteria, we selected the top 100 ranked by the primary metric.
For token dependency analysis, we extracted the top 30 tokens per feature based on mean activation, requiring a minimum
of five occurrences. We additionally extracted the top 20 bigrams with at least three occurrences and the top 10 trigrams
with at least two occurrences. Activation collection used a batch size of 16 for all models.

F.2. Token injection

Token injection experiments were conducted on the top 100 features selected in the detection stage. For each feature, we
used 500 non-reasoning samples for the baseline condition and 500 non-reasoning samples for the injected condition, with
all samples chunked to 64 tokens. All processing used a batch size of 16.
We evaluated eight injection strategies: prepend, intersperse, replace, inject bigram, inject trigram,
bigram before, trigram, and comma list.  For simple token strategies, namely prepend, intersperse,
replace, and comma list, we injected three tokens selected from the top 10 tokens for the feature. For bigram-based
strategies, we injected two bigrams selected from the top 20 bigrams. For trigram-based strategies, we injected one trigram
selected from the top 10 trigrams.
Feature classification followed Cohen’s effect size conventions. Token-driven features required d ≥0.8 with p < 0.01.
Partially token-driven features required 0.5 ≤d < 0.8 with p < 0.01. Weakly token-driven features required 0.2 ≤d < 0.5
with p < 0.05. Features with d < 0.2 or p ≥0.05 were classified as context-dependent. For each feature, the injectionstrategy yielding the largest Cohen’s d was used for final classification.

F.3. LLM-guided falsification

For features classified as context-dependent in the injection stage, we randomly sampled up to 20 features per configuration
for LLM-guided falsification as described in Section 4.4. The protocol was run for a maximum of 10 iterations per feature,
with early stopping once three valid false positives and three valid false negatives were identified.
The activation threshold for validation was set to 0.5 times the maximum activation observed on reasoning samples for the
feature. A false positive was considered valid if its maximum activation exceeded this threshold, while a false negative was
considered valid if its maximum activation was below 0.1 times the threshold. In each iteration, the LLM generated five
candidate false positives and five candidate false negatives.
Temperature settings varied by phase. Hypothesis generation and final interpretation used temperature 0.3 to promote
consistency, while counterexample generation used temperature 0.8 to encourage diversity.

F.4. Steering experiments

Steering experiments were conducted exclusively on Gemma-3-12B-Instruct at layer 22, using the top three features ranked
by Cohen’s d on the s1K dataset. We evaluated two steering strengths, γ = 0.0 for the baseline condition and γ = 2.0 for
positive amplification. The steering intervention was scaled by the maximum feature activation observed in the reasoning
corpus.
Text generation used a maximum of 16,384 new tokens, sampling temperature 0.6, and nucleus sampling with top-p set


                                                30

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

to 0.95. All prompts followed the model’s chat template. Evaluation used one-shot chain-of-thought prompting. For
AIME 2024, performance was measured by exact numerical answer matching, while for GPQA Diamond, performance was
measured by multiple-choice accuracy.

F.5. Model and SAE configuration

All Gemma-3 models used the GemmaScope-2 sparse autoencoder release with 16,384 features per layer and small ℓ0
regularization. DeepSeek-R1-Distill-Llama-8B used an SAE with 65,536 features trained on reasoning-focused datasets.
All models were run in bfloat16 precision on a single NVIDIA A100 80GB GPU.
For additional models reported in Appendix C, we used analogous configurations. Llama-3.1-8B used SAEs from the Llama
Scope release with 32K features per layer. Gemma-2-9B and Gemma-2-2B both used SAEs with 16,384 features per layer
from the corresponding GemmaScope release. Experiments using alternative ranking metrics in Appendix D employed
identical model and SAE configurations, differing only in the feature ranking criterion.





                                                31

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

G. LLM-guided feature interpretation results

This section provides complete documentation of all LLM-generated feature interpretations, including high-activation
examples with token-level visualization, refined interpretations, and generated counterexamples, for one representative
configuration (Gemma-3-4B-Instruct, layer 22, General Inquiry CoT). For each feature, we show three high-activation
examples from the reasoning corpus with tokens colored by activation strength (darker blue indicates higher activation),
followed by the LLM’s interpretation and classification, and examples of false positives (non-reasoning text that activates
the feature) and false negatives (paraphrases of high-activating reasoning text that does not activate the feature).


Feature 163

High-Activation Examples:

Example 1: Then, I needed to describe how attention mechanisms address this by allowing the decoder to selectively
attend to different parts of the image during caption generation. Initially, I need to examine the steps involved in the
Example 2: AI excels at pattern recognition and data processing but struggles with common-sense reasoning and abstract
thinking. I realized this limitation would directly impact its ability to grasp the nuances of jokes.Next, I thought
Example 3: of these areas, I should provide a concise explanation of how NLP is used and its benefits. For example, for
chatbots, I can explain how NLP enables them to understand and respond to human language.
Interpretation: This feature detects a specific syntactic construction used to express procedural necessity and goal-oriented
sequencing, characterized by an initial infinitive of purpose (‘To [verb]...’) followed by sequence markers (‘first’, ‘then’) and
modals of obligation (‘must’, ‘need’, ‘should’). It does not distinguish between internal cognitive planning (reasoning) and
external physical instructions (navigation/policy), activating on both provided the grammatical structure is present.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To reach the ancient temple ruins, tourists first need to traverse the dense jungle path. Then, you will cross the river using
   the old bridge. To navigate the terrain safely, you must wear appropriate...
2. To cross the dangerous mountain pass safely, hikers first need to navigate the steep ridge clearly marked on the trail map.
   Then, you must traverse the glacier efficiently to avoid the risk of falling...
3. To enforce the privacy policy efficiently, the corporation first must identify the data sources clearly defined in the user
   agreement. The legal department should then review the consent forms thoroug...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Addressing improvements in image captioning via attention mechanisms starts by grasping the limits of older models
   lacking such features. Traditional systems compress images into fixed vectors, causin...
2. Initial thoughts focused on why AI finds humor difficult. Humor relies on complex human traits missing in current
   software. Thinking about key elements like surprise and context came before everything...
3. Grasping the request for practical Natural Language Processing examples is the starting point. Effective handling involves
   looking at NLP in business and daily tech. Analysis of application areas like...



Feature 13118

High-Activation Examples:

Example 1: effectively, I'll first identify the core challenges. These generally revolve around latency, throughput, data
freshness, resource management, and scalability/availability. Then, for each challenge, I'll outline
Example 2: multiplying 63 by 400, I can first multiply 63 by 4, and then multiply the result by 100. This strategy
simplifies the calculation because multiplying by

                                                32

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Example 3: PM). This involves finding the difference between the minutes and the hours. There are 30 minutes from 0:30
AM to 11:00 AM, and then
Interpretation: This feature detects procedural segmentation and distinctness, specifically triggering on vocabulary that
emphasizes handling components individually (e.g., “separately”, “individually”) within a step-by-step structure. It is not
specific to cognitive reasoning but rather identifies the linguistic pattern of breaking a task—whether mental or physical—into
discrete, sequential actions.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To pack the fragile china securely, I need to wrap the plates separately. First, I’ll cushion the cups individually with paper.
  The box itself is reinforced. The move entails a loading phase. Then, I’...
2. To style the hair perfectly, I need to curl the sections separately. First, I’ll spray the strands individually for hold. The
   heat itself is moderate. The look entails a setting phase. Then, I’ll brus...
3. To iron the dress shirts correctly, I need to press the collars separately. First, I’ll spray the cuffs individually with starch.
  The fabric itself is cotton. I must use a high heat setting for the be...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Real-time query systems face hurdles like latency or throughput so we should look at those core issues plus data freshness.
   Spotting these challenges helps us find targeted solutions for keeping syste...
2. Calculating the time from ten-thirty to noon means counting the minutes up to eleven plus the full hour that follows. This
   strategy gives us the total duration by combining the two parts.
3. Large number multiplication gets simpler with patterns like powers of ten. We can also use shortcuts for numbers like
   eleven or five to speed things up. These tricks make the calculation much faster.


Feature 1123

High-Activation Examples:

Example 1: First, I should consider the importance of consistency. A consistent UI helps users learn the system quickly
and reduces cognitive load. This leads me to the next point: clear feedback. Users need to know
Example 2: Initially, I need to examine the provided numbers. Jane has 7 stickers, and she gives 4 away. So, the operation
I need to perform is subtraction. That must mean I subtract
Example 3: answer this question effectively, I first needed to consider the current state of AI research and development. I
thought about the areas where I've been seeing the most buzz and advancements lately. I immediately thought
Interpretation: This feature detects a specific first-person syntactic template characterized by the dense usage of process-
oriented adverbs (specifically “effectively,” “comprehensively,” “thoroughly,” “accurately”) combined with sequence markers
(“first,” “next”) and the pronoun “I”. It activates on this lexical cluster regardless of whether the subject matter is cognitive
planning or physical action (e.g., cleaning a microphone or stocking a break room).
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To serve the colony effectively, I first comprehensively filtered the water supply. Next, I thoroughly inspected the storage
   tanks. I accurately measured the levels today. Therefore, I approach the ma...
2. To assist the developers effectively, I first comprehensively organized the server racks. Next, I thoroughly labeled the
   cables. I accurately connected the power supply. My approach indicates that the...
3. To support the developers effectively, I first comprehensively stocked the break room with fresh coffee beans. Next, I
   thoroughly organized the tangled power cables beneath the shared workstations. I ...

                                                33

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Solving the sticker problem requires basic arithmetic. Jane starts with 7 and gives away 4. Subtracting the given amount
   from the total yields the final count of stickers remaining.
2. Current trends in technology highlight Generative AI as a rapidly advancing field. Recent developments have seen
   models producing high-quality images and text, marking a significant shift in the capab...
3. Healthcare benefits significantly from machine learning integration. Key applications include improving diagnostics,
   tailoring medicine to individuals, and accelerating drug discovery. These technolog...


Feature 282

High-Activation Examples:

Example 1: I need to break down what factors might affect that performance. I can start with the most obvious one: the
data the model is trained on. If the data is flawed, the model will learn
Example 2: My approach begins with identifying these stages, which typically include idea generation, drafting, editing,
character development, and world-building (especially for genres like fantasy and science fiction). Initially, I need
Example 3: solving the numerical problem provided. Next, I need to address the specific problem: -8 +5 - (-3) -2. To
tackle this effectively, I will apply the rules
Interpretation: This feature detects the specific syntactic template of first-person procedural planning, characterized by the
combination of self-referential pronouns (“I”, “My”) with sequencing markers (“First”, “Then”) and strategic nouns/verbs
(“approach”, “need to”, “identify”). It functions as a style detector for the ‘Chain of Thought’ format rather than a semantic
detector of reasoning, as it activates on any content using this ‘First, I need to...’ structure (including simple descriptions)
but fails to detect identical reasoning processes when written in the passive voice or third person.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To describe this software feature, I need to clarify the structure. First, I need to define the user inputs. Then, I will provide
   an explanation of the background calculation. Next, I need to list the...
2. My approach to reviewing this novel involves a literary explanation. First, I need to identify the author’s objectives.
   Then, I must consider the narrative inputs and themes. Next, I will analyze the ...
3. To critique this novel effectively, I need to formulate a structured approach.  First, I need to consider the narrative
   explanation. Then, I must identify the thematic inputs provided by the author. Ne...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Defining ‘accuracy’ in the context of AI serves as the starting point. It essentially measures how well a model performs
   tasks like classification. Following the definition, an analysis of performance...
2. An analysis of the inquiry highlights the role of AI in creative writing. To provide a comprehensive answer, one must
   examine the various phases of the writing process. Identifying stages such as idea...
3. Answering the question comprehensively requires outlining key strategies for database optimization. Indexing is a critical
   tool for faster data retrieval. Describing the purpose of indexes and showing...


Feature 14872

High-Activation Examples:

Example 1: First, I should consider the division itself. 17 divided by 2 is 8.5. However, since I can't give half a candy, I
need to consider the whole

                                                34

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Example 2: last, I need to figure out how many times1 eraser can be taken out of the total of 4 erasers. This sounds like a
division problem. First, I needed to understand the
Example 3: friends. This is a division problem. I should divide the total number of bananas (4) by the number of friends
(2). So, I'll calculate 4 ÷ 2.
Interpretation: This feature detects the syntactic pattern of first-person procedural planning and self-narration, specifically
triggering on the combination of first-person pronouns (‘I’, ‘me’) with modals of necessity or intent (‘need’, ‘should’, ‘will’).
It identifies the linguistic style of an agent explicitly articulating their next steps, regardless of whether the content is abstract
mathematical reasoning or concrete physical instructions.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To assemble this bookshelf, I first need to determine which board is the bottom piece. I should look for the pre-drilled
   holes near the edge. I will align the side panel with the base. I need to figur...
2. First, I need to determine if the car tires are properly inflated. I should look for the recommended pressure on the door
    label. I need to figure out which tire looks low. I will simply attach the air...
3. First, I need to determine the correct time to set this alarm clock. I should check the time on my phone. I need to figure
   out which button changes the hour digit. I will simply hold down the ’set’ bu...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Analyzing the task involves splitting 17 candies between 2 kids without breaking any. The situation calls for integer
   division. 17 over 2 makes 8, leaving 1 behind. This calculation shows that 8 is th...
2. Review the provided data points. Mike holds 4 erasers total. Usage is 1 per day. Determining the duration involves
   dividing the total quantity by the daily consumption rate. The math is clear: 4 divid...
3. The problem asks for an equal share of bananas. With 4 bananas and 2 buddies, division is the necessary operation. Splits
   happen evenly here. Dividing 4 by 2 results in 2. Each friend receives exactly...


Feature 491

High-Activation Examples:

Example 1: the ethical concerns of AI, I need to consider the various aspects of AI development and deployment where
ethical issues can arise. First, I should consider the data used to train AI models. If the training
Example 2: , I need to consider various aspects of data handling and AI implementation. Initially, I need to examine the
stages where data privacy is most at risk, from data collection to model training and deployment. First
Example 3: problems. My approach begins with recognizing that multilingual support involves more than just translating
text. It encompasses a comprehensive adaptation of the software to different languages, cultures, and regional
requirements.Initially, I need
Interpretation: This feature detects the syntactic template and punctuation of explicit procedural planning preambles,
specifically the ‘To [goal], I need to [action]’ structure often found in Chain-of-Thought responses. It tracks the structural
markers (periods, commas, ‘First’, ‘effectively’) of this specific self-reflective planning style, activating equally strongly on
complex topics and trivial/synthetic examples provided they utilize this specific rhetorical template.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To address the topic of invisible ink effectively, I need to consider the transparency of the liquid. First, I need to recall the
   secret message. My approach begins with analyzing the blank paper comp...
2. To address the topic of arranging the bookshelf effectively, I need to consider the visual appeal of the covers. First, I
   should outline a color-coding system. My approach begins with sorting the book...

                                                35

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

3. To answer the question of how to brew tea comprehensively, I need to consider the water temperature. First, I need to
   identify the type of tea leaves. My approach begins with boiling the water to the ...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Mere translation fails to achieve true multilingual support; the software’s core architecture needs modification. The code
    itself must change to accommodate the structural differences between language...
2. Ethical risks in AI development are most prominent in the data collection phase, where biases in training sets can be
   learned and amplified by the system if not carefully managed.
3. Surrounding information allows AI systems to interpret user intent correctly by providing the necessary background for
   ambiguous queries.


Feature 4510

High-Activation Examples:

Example 1: for implicit constraints and requirements. The mention of “limited resources and time” suggests that I need to
focus on efficiency and cost-effectiveness. This eliminates approaches that are resource-intensive upfront, such as
Example 2: easier to track. Next, I need to consider other methods people use, like aligning numbers by place value and
adding column by column, carrying over when necessary. I should also think about ways to simplify
Example 3: resulting in P = 2 * length + 2 * width, which can also be written as P = 2 * (length + width).Next, I needed to
address the units of
Interpretation: This feature detects the infinitive marker “to” specifically when used in syntactic structures indicating purpose
(e.g., “To [verb]...”) or necessity (e.g., “need to...”). It is a grammatical feature that identifies goal-oriented procedural
language, activating on step-by-step plans regardless of whether the content is complex reasoning, a recipe, or a simple
narrative action.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To bake the perfect chocolate cake, I need to preheat the oven to 350 degrees. First, I need to sift the dry ingredients into
   a large bowl. To ensure the batter is smooth, I need to beat the eggs one ...
2. First, I need to hide before the guards come back. To stay alive, I need to reach the ventilation shaft in the ceiling. I need
   to move quietly. To open the grate, I need to use the small knife in my p...
3. To assemble this bookshelf, I need to identify the screws listed in the manual. First, I need to lay out all the wooden
   panels on the floor. To connect the sides, I need to use the allen wrench provid...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Understanding the central question regarding knowledge base expansion under tight resources is vital. Prioritizing
   strategies that maximize impact while minimizing effort is key. Initially, examining ...
2. Answering effectively requires considering various approaches for adding large sums. Breaking figures into hundreds,
    tens, and ones seems optimal, facilitating tracking and mirroring standard learning...
3. Calculating a rectangle’s perimeter starts by recalling the definition: total distance around a shape. Adding lengths of all
   four sides achieves this. Logic dictates summing two lengths and two widths...


Feature 3810

High-Activation Examples:

                                                36

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Example 1: the positive direction. I also need to provide a clear algebraic representation of this principle, such as`a - (-b)
= a + b`, and then give concrete examples to demonstrate the rule
Example 2: ?” and “What are the different types of AI?” Next, I should think about the practical applications and real-
world impacts of AI, which prompts questions like “What are the current applications of AI
Example 3: , I need to understand the question which is asking for practical examples of Natural Language Processing
(NLP). To tackle this effectively, I should consider various aspects of NLP usage in both everyday technology and
business.
Interpretation: This feature detects a specific lexical and syntactic template used for procedural planning, characterized by
the pattern ‘First, I need to [verb]’ or ‘To tackle this... effectively’. It responds strictly to the combination of first-person
modal necessity (‘I need to’) followed by analytical verbs (‘identify’, ‘define’, ‘outline’), regardless of whether the subject
matter is cognitive reasoning, sports strategy, or creative writing.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To tackle this dream effectively, I need to identify the shifting shadows. First, I should define the nature of the fog
   surrounding me. I need to outline the path through the void and establish a conn...
2. To tackle this awkward dinner effectively, I need to identify a safe topic of conversation. First, I should define the mood
   of the room to avoid tension. I need to outline my anecdotes and establish a...
3. To tackle this sculpture effectively, I need to identify the natural grain of the wood. First, I should define the posture of
   the central figure. I need to outline the rough cuts and establish the cor...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. The assignment is to demonstrate how to subtract negative integers. Step one is grasping the essence of subtraction and
  how it ties to addition. Subtraction acts like adding the inverse, so removing a...
2. The query seeks real-world samples of Natural Language Processing. A solid response involves exploring NLP’s role in
   daily tech and business. I will start by breaking down the specific areas using thi...
3. First, we have to retrieve the main formula for a rectangle’s area. The total space is the product of length and width. So,
   the rule is ‘area = length * width’. To add depth, I should also talk about ...


Feature 1148

High-Activation Examples:

Example 1: an AI model better, I need to break down the training process into key components. First, I need to consider
the data itself – its quality, preparation, and how it's fed into the
Example 2: multilingual software application support, I first need to break down the overall problem into smaller sub-
problems. My approach begins with recognizing that multilingual support involves more than just translating text. It
encompasses a comprehensive adaptation
Example 3: To tackle this effectively, I should break down the answer into two main parts: the considerations and the
types of services. For the considerations, I need to think about what someone would look for when
Interpretation: This feature detects a specific lexical cluster of formal vocabulary related to structural decomposition,
organization, and thoroughness (e.g., “break down,” “categorize,” “thoroughly,” “structured”). It activates on the presence of
these specific terms whether they are used in a meta-cognitive planning context or in static descriptions of systems, manuals,
and software updates. It fails to detect the semantic concept of problem decomposition when expressed in simpler or more
casual language.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

                                                37

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

1. Version 2.0 has been implemented to thoroughly address user feedback. We have categorized the settings menu to break
  down complex options into distinct panels. This update introduces a structured work...
2. The corporate safety manual is structured to thoroughly address workplace hazards. It categorizes the potential risks to
   break down the emergency protocols into distinct action plans, focusing on empl...
3. The corporate audit framework is employed to thoroughly address the question of financial transparency and compliance.
    It carefully categorizes the transaction logs to break down the complex revenue s...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Regarding the question on supporting software in multiple languages, I will split the big task into smaller bits. It starts
   with realizing that this involves more than just translating words. It requi...
2. Regarding the question on supporting software in multiple languages, I will split the big task into smaller bits. It starts
   with realizing that this is more than just translating text. It involves ful...
3. The user asks how to apply AI to personal tasks with few resources. Because that subject is huge, I will select particular
   spots where it works. I’ll start with writing and art tools.


Feature 6048

High-Activation Examples:

Example 1: question comprehensively, I need to outline several key strategies for optimizing database query performance.
First, I should consider indexing. Indexes are crucial for speeding up data retrieval, so I need to explain their purpose,
Example 2: question effectively, I need to explain what estimation is in the context of addition and then describe some
common strategies used for estimation. First, I need to define estimation as a method for approximating numbers to
simplify
Example 3: question effectively, I need to explain how subtraction can be understood in terms of adding negative
numbers. First, I need to define the concept of an additive inverse (or negative) of a number. This
Interpretation: This feature specifically detects the first-person pronoun “I” when used in the context of meta-cognitive
planning, self-narration, or outlining a response strategy (e.g., “I need to”, “I should”). It is strictly tied to the first-person
perspective and the syntactic structure of an agent explicitly stating their intentions, rather than the semantic content of
reasoning itself.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To answer this question about the course structure, I need to outline the core topics effectively. First, I should consider
   the introductory module. I need to identify the required textbooks and expla...
2. To answer this question about the perfect sourdough, I need to identify the core biological processes of fermentation.
    First, I should consider the activity of the wild yeast. I need to explain how te...
3. To answer this question effectively, I need to outline the core principles of interior design for small spaces. First, I should
   consider the layout and flow of the room. I need to identify how lightin...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. To provide a comprehensive answer regarding database query performance, an outline of key strategies is essential.
   Indexing functions as a primary consideration. Because indexes speed up data retrieva...
2. Tackling this inquiry effectively involves defining estimation within the context of addition, followed by a description of
  common strategies. The definition should characterize estimation as a method...
3. Understanding subtraction through the lens of adding negative numbers requires a clear explanation. A crucial initial step
   involves defining the additive inverse. This foundation establishes that subt...

                                                38

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Feature 791

High-Activation Examples:

Example 1: First, I should consider the data itself. If AI systems are dealing with sensitive data, robust security measures
must be in place, like encryption and anonymization. I need to highlight the risk
Example 2: additional marbles she finds, which is2. To determine the total number of marbles Olivia has, I must combine
these two quantities. This means I should add the number of initial marbles to the number
Example 3: To find the total number of seashells, I should add these two quantities together. So, I need to calculate 5 + 2.
Performing the addition, 5 + 2 equals 7
Interpretation: This feature detects the specific syntactic sequence of a comma following an introductory transition (like
“First” or “To answer...”) immediately preceding the phrase “I need to” or “I must.” It identifies a specific structural template
often used in Chain-of-Thought prompting but activates on this syntax regardless of whether the semantic content is logical,
nonsense, or creative.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To answer this question comprehensively, I need to consider the existential dread of a melted snowman. First, I need to
    identify where the carrot nose went, as this is the most pressing mystery of the...
2. First, I need to identify the melody within the noise. To compose this symphony, I need to consider the rhythm of the city
    streets and how the traffic sounds blend into a chaotic harmony.
3. To answer this question comprehensively, I first need to consider the possibility that we are all just butterflies dreaming. I
   should identify the color of my wings and determine if I can fly towards ...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Determining the suitability of AI for sensitive tasks requires analyzing the specific aspects that define sensitivity. Usually
    this implies handling regulated or confidential data. Consequently the re...
2. The calculation starts with the 7 marbles Olivia owns originally. Next comes accounting for the 2 additional marbles she
   discovered later. Finding the total demands combining these two separate quanti...
3. Recalling the standard formula for a rectangle’s area is the prerequisite step. Multiplying length by width yields the area.
   The core concept is ‘area = length * width’. Making the answer complete als...



Feature 444

High-Activation Examples:

Example 1: to break down the process into manageable steps: converting to improper fractions, finding a common
denominator, subtracting the fractions, converting back to a mixed number, and then addressing the borrowing scenario.
First,
Example 2: perform the calculation carefully. My approach begins with setting up the subtraction: 100 - 27 — Initially, I
need to examine the ones column. I can
Example 3: down the answer into key strategies. Let me start by analyzing what makes a conversation seamless and
engaging. This leads me to consider defining clear goals, mapping user journeys, and structuring the flow hierarchically.
Interpretation: This feature functions as a semantic detector for specific abstract, categorical, or procedural nouns (e.g.,
“process,” “problem,” “sentence,” “recipe,” “topic”) that label systems, tasks, or structural elements. While these words
frequently appear during planning (hence the initial hypothesis), the feature activates reliably on these tokens in non-
reasoning contexts such as technical manuals, formal narratives, and descriptive writing, indicating it is tied to the vocabulary
rather than the cognitive process.

                                                39

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. The editor circled the **sentence** in red. She noted that the **structure** was awkward and the **topic** was unclear.
  The entire **paragraph** lacked coherence. She recommended rewriting the **text*...
2. The manual outlines the installation **process**. It describes the **functionality** of each **element**. The **system**
   handles the data **retrieval** automatically. Users can configure the **setting...
3. The moderator posed the **question** to the panel. The **topic** of discussion was renewable energy. The expert
   provided a detailed **answer**. She analyzed the **issue** from a scientific **perspecti...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. I need to determine what makes a bot chat effective. I’ll look at clarity and engagement. I’ll discuss the requirements,
   starting with creating a smooth exchange for the user.
2. I have to subtract 27 from 100. Because of the zeros, I need to borrow. I will place 100 on top of 27. The ones place is
   zero, so I must borrow from the neighboring columns before subtracting.
3.  I have to take 27 away from 100. Because of the zeros, I need to borrow. I will place 100 on top of 27. The ones place is
   zero, so I must borrow from the left.


Feature 34

High-Activation Examples:

Example 1: Expressions (CTEs) often helps. Using `EXPLAIN` to analyze the execution plan is crucial because it shows
how the database intends to run the query and highlights inefficiencies like full table scans. Rew
Example 2: list.sort()` modifies the list in-place. Then, I must explain the crucial role of the `key` parameter, which
allows specifying a function to extract the sorting key from each object.
Example 3: that could be the information surrounding a user's query. Initially, I need to examine what kinds of
information might constitute context for an AI. I must then connect this to how the AI processes this
Interpretation: This feature detects determiners (primarily “the”, “its”, “their”) when they appear within specific procedural
or instructional sentence templates, typically characterized by introductory markers like “First,” “To,” or “//” followed by
intent phrases like “I need to identify” or “address the.” It identifies the syntactic structure of outlining a primary step or
definition, regardless of whether the content is cognitive reasoning, code documentation, or physical description.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1.  // First, to initialize the module, identify the core dependency. // The entire script relies on this file. // To handle the input,
   the function parses the string. // The core logic is defined in the ...
2. First, I need to identify the bird on the branch. To see the colors, I use my binoculars. The entire flock takes flight. I need
   to capture the image. To focus the lens, I turn the dial. The core marki...
3.  // First, to execute the script, identify the core function. // The entire process runs in the background. // To handle the
   output, the system writes to the log. // Its configuration is loaded from th...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Start by grasping what constitutes complex database queries. Typically, such requests involve multiple tables, intricate
    filtering, plus massive datasets. Handling these efficiently demands attention ...
2. Addressing how one sorts lists of Python objects using attributes requires providing a full guide on various techniques.
    First, introducing `sorted()` functions and `list.sort()` methods is best, noti...

                                                40

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

3. Answering how context affects AI outputs requires considering what ‘context’ means for AI and usage patterns. My
   approach starts by thinking about general definitions of context—circumstances forming ...


Feature 13167

High-Activation Examples:

Example 1: , I need to identify the core capabilities of AI. These generally include machine learning, natural language
processing, computer vision, robotics, and expert systems. I need to define each of these capabilities clearly,
Example 2: , I need to determine the core issue the question is addressing, which is how to improve the precision of
search queries. To tackle this effectively, I need to break down the concept of search query precision
Example 3: , I need to consider the core aspects of LLMs and their functionalities to identify potential limitations. To
tackle this effectively, I'll start by thinking about what LLMs are good at, which is
Interpretation: This feature functions as a precise n-gram detector for the sequence “First, I need to”, specifically activating
on the token “I” within this structure. It captures the syntactic initiation of a first-person sequential action or plan, but it is
agnostic to the semantic content, activating equally on abstract cognitive planning and mundane physical chores.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. First, I need to remove the core of the apple. It is hard and inedible, so I use a small paring knife to carefully cut it out.
  Once that is done, I can slice the rest of the fruit into even rings for ...
2. First, I need to identify my suitcase on the crowded luggage carousel. There are so many black bags that look exactly
    alike, circling around and around. I squint my eyes under the fluorescent lights, ...
3. First, I need to catch my breath. I ran all the way from the subway station to the office building because I overslept and
  was running late. My heart is pounding in my chest, and I have to lean agains...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. To initiate the process, one must outline the fundamental functions of artificial intelligence. These elements typically
   comprise machine learning, natural language processing, and robotics. Defining ...
2. The starting point is determining the main issue: improving search query precision. To handle this, breaking down the
   concept of accuracy is required, along with finding methods that influence it. The...
3. Let us begin by evaluating the primary aspects of Large Language Models to find their constraints. An effective analysis
    starts by looking at their strengths, which are mainly text processing based on...


Feature 928

High-Activation Examples:

Example 1: should prioritize strategies that maximize impact while minimizing time and effort.Initially, I should
examine the question for implicit constraints and requirements. The mention of “limited resources and time” suggests
that I need to
Example 2: tackle this effectively, I should use an example to illustrate this principle. Initially, I need to examine a simple
arithmetic expression that involves subtracting a negative number. Let's choose `5 - (-3
Example 3: to identify that the core problem is the unlike denominators. To tackle this, I need to explain the concept of a
common denominator, specifically the least common multiple (LCM). I should illustrate how to find
Interpretation: This feature detects specific syntactic constructions related to first-person agency, intent, and necessity,
characterized by the combination of first-person pronouns (‘I’, ‘me’, ‘we’) with modals (‘should’, ‘can’, ‘will’) and infinitives
(‘to’). It is not a reasoning detector; rather, it identifies the grammatical structure of a speaker stating what they are doing,

                                                41

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

need to do, or will do, regardless of whether the context is solving a complex logic puzzle, making casual social plans, or
describing physical actions.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1.  I’ll come over to your place directly after work. You simply need to let me know the time. I can bring the drinks, and I
   should probably pick up ice too. This allows me to help out. We typically eat l...
2. To open the box, I need to pull the tab. This allows me to lift the lid. You can see the contents inside. I should handle it
    carefully. I’ll place it on the table directly. I’ve checked the seal. It s...
3. I should have told you sooner. It leads me to feel guilty. I’ll make it up to you, I promise. You can trust me on that. I
   simply forgot the date. I’ve been so busy lately. I need to apologize properly...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Understanding the core question regarding knowledge base growth under tight resources is key. This requires prioritizing
   high-impact strategies with minimal time or effort. Checking for implicit const...
2. Answering this requires explaining subtraction of negative numbers and the link with addition. Defining the core principle
   comes first: subtracting a negative equals adding a positive. Using an exampl...
3. Adding fractions with different denominators demands outlining the process. Identifying the unlike denominators is the
   main issue. Explaining the common denominator concept, specifically the least com...



Feature 934

High-Activation Examples:

Example 1: for me is to recall the multiplication table. I remember that 7 times 8 is a standard multiplication fact. If I
didn't remember it directly, I could break it down. For example
Example 2: So, (2/5) *150 gives me the number of apples sold.After calculating the apples sold, I need to subtract that
number from the original150
Example 3: ` by itself on one side of the equation. To do this, I need to undo the addition of 5. The opposite operation is
subtraction, so I should subtract 5 from *both*
Interpretation: This feature detects procedural discourse markers and sequential transitions used to organize step-by-step
processes. It activates strongly on temporal connectors (e.g., “Then”, “Next”, “Initially”, “So”) and syntactic structures
that introduce a sequence of actions (e.g., “To [action], I first...”), appearing in both logical reasoning chains and mundane
physical instructions (like painting or cleaning). It tracks the linguistic structure of a sequence rather than the semantic
content of reasoning.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. To paint the room effectively, I first needed to prime the walls. Initially, the color looked too dark. Then, it dried to a
    lighter shade. Next, I applied the second coat. So, the finish was smooth. I...
2. To clean the garage effectively, I first needed to move the boxes. Initially, the dust made me sneeze. Then, I swept the
    floor. Next, I organized the tools. So, the space became usable again. Now, the...
3. To assemble the table effectively, I first needed to sort the screws. Initially, the parts looked similar. Then, I read the
   diagram. Next, I tightened the bolts. This led to a sturdy frame. So, the ta...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

                                                42

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

1. Multiplication is essentially repeated addition. Seven times eight translates to adding the number seven eight separate
   times. Memorizing the multiplication table offers a faster route. 7 multiplied b...
2. Figuring out the remaining apples involves calculating the sold amount. The market sales accounted for two-fifths of the
  150 total apples. Multiplying 150 by 0.4 results in 60 apples sold. Deducting t...
3. Isolating `x` in the equation `3x + 5 = 14` is the primary objective. The addition of 5 necessitates subtraction as the
   inverse operation. Removing 5 from both sides preserves equality and simplifies ...



Feature 4010

High-Activation Examples:

Example 1: , I need to consider the number of marbles Olivia initially possesses, which is 7. Then, I need to account for
the additional marbles she finds, which is2. To determine the total
Example 2: , I need to identify the core mathematical operation required to solve the problem. The question asks how
many cookies each friend receives when 9 cookies are shared among 3 friends. This indicates a division problem
Example 3: , I need to figure out the total number of stamps Lily started with, which is 6. Then, I need to subtract the
number of stamps she lost, which is 1. So,
Interpretation: This feature functions as a precise n-gram or phrase detector for the sequence “First, I need to”, specifically
activating on the pronoun “I” within this rigid structure. It is semantically blind, activating with identical strength (∼677) onboth complex cognitive planning and mundane physical descriptions (e.g., wiping tables), provided the specific introductory
phrase is used.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. First, I need to unlock the front door. The key is right here in my pocket. I truly struggle with this old lock sometimes.
  We are finally home after a long trip. I just want to get inside and sit down...
2. First, I need to wipe the table. It is covered in crumbs from dinner. I sure hope we have enough paper towels left. I truly
   dislike a messy kitchen. We just finished eating. I need to clean this up qu...
3. First, I need to put on my heavy coat. It is freezing outside today. I truly hate the winter cold. I just want to stay warm
   while we walk. We are going to the shops down the street. I need to find my ...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Start by noting the 7 marbles Olivia has originally. Add the 2 extra marbles she found to that amount for the total. The
  sum of 7 and 2 is 9. This means she has 9 marbles in total.
2. To calculate the share for each friend divide the 9 cookies by 3 people. This division problem of 9 over 3 results in 3.
   Each friend receives 3 cookies.
3. Lily established a collection of 6 stamps initially. She lost 1 stamp so subtraction is the right step. Calculating 6 minus 1
   leaves 5. The final number of stamps is 5.



Feature 1430

High-Activation Examples:

Example 1: dive into the technical details. So I should provide options for both online courses and books. For online
courses, I should consider platforms like Coursera, edX, fast.ai, and Udacity
Example 2: subtract 5 from *both* sides of the equation. This maintains the balance of the equation. When I subtract 5
from both sides, I get `3x + 5 - 5

                                                43

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

Example 3: extraction, and content recommendation. For each of these areas, I should provide a concise explanation of
how NLP is used and its benefits. For example, for chatbots, I can explain how NLP enables them
Interpretation: This feature detects a specific cluster of technical, geometric, and categorical vocabulary (e.g., “cube”,
“rectangle”, “category”, “samples”) alongside adverbs of precision (e.g., “accurately”, “effectively”, “thoroughly”). While
these words frequently appear during the decomposition phase of formal problem-solving, the feature is lexical rather than
functional, activating equally strongly on static descriptions of physical objects, data layouts, or artwork that utilize this
specific vocabulary.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. The sculpture consists of a large **cube** resting on a wide **rectangle**. To view the **samples** **accurately**,
   observers should stand to the **left**. This angle reveals the **biased** perspectiv...
2. The textbook page illustrates the concept of numbers by showing a grid of **integers** and **fractions** inside a yellow
   **rectangle**. The accompanying text answers the student’s **question** **compr...
3. The laboratory rack holds the test **samples** sorted by **category**. To record the **data** **accurately**, the
   technician scans the barcode on the **left**. The protocol manual outlines the storage...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. We need a dozen even wedges from one pie. The simplest path is splitting the circle in half, then into quarters. One cut
   makes two bits, and a cross cut yields four.
2. The request seeks practical uses for language processing tech. A good response covers its role in both daily gadgets and
   corporate tools. We can begin by spotting main fields like automated chat agent...
3. The core task is adding speech control to a Python app. The work divides into steps: grabbing audio, changing sound to
    text, parsing commands, running actions, and signaling the person that it is fini...


Feature 1171

High-Activation Examples:

Example 1: a number line. First, I need to consider what subtraction means visually on a number line — it means moving
to the left. The first number in the subtraction problem is where I should start on the
Example 2: 2, dividing by 2 and then dividing by 2 again will give the same result as dividing by 4. For example, if I want
to divide 20 by 4, I
Example 3: missing addend. First, I need to identify the basic components of an addition equation: the addends and the
sum is the total you get when you add the addends together.
Interpretation: This feature detects a specific lexical cluster involving modals of necessity, ability, and intent (e.g.,
“need”, “can”, “wants”) combined with conditional or resultative connectors (e.g., “if”, “gives”, “until”, “where”). Rather
than detecting the semantic process of reasoning, it identifies sentences that describe requirements and their subsequent
outcomes or conditions, which appears frequently in ‘step-by-step’ planning but equally in recipes, sports commentary, and
troubleshooting guides.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. This is a classic recipe where patience gives the best flavor. The dough needs to rest in a warm bowl until it doubles in
    size. If you can wait, the high heat gives it a perfect golden crust. The bake...
2. Here is the answer to the connection issue everyone is asking about. The system wants to update automatically. If you
   can click the prompt, it gives you immediate access. We need to address the server...

                                                44

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

3. He wants the victory more than anything. If he gives his best effort on the field, he can succeed. The fans are asking for a
    final goal. He needs to run hard until the whistle blows. This match gives ...

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. Division works by subtracting the divisor repeatedly. Remove the specific amount from the starting total over and over.
   The cycle ends at zero. Counting the removals reveals the final answer.
2. Like terms are defined by sharing the same variable and power. In the expression 3x + 4y - 2x + 5y, certain elements
    align. Note that 3x and -2x both use x to the first power. Thus, they belong togeth...
3. Division functions fundamentally as repeated subtraction. One subtracts the divisor from the main number repeatedly.
   The process concludes once the value hits zero. The total count of these subtractio...


Feature 14138

High-Activation Examples:

Example 1: natural language. First, I need to think about the initial stage, which is obtaining the text data itself. So, the
first step would naturally be **Text Acquisition**. After acquiring the raw text,
Example 2: he's sharing them with3 siblings. It's crucial to understand that Alex is sharing with *his* siblings, and not
including himself in the distribution. To figure out how many toys
Example 3: define “borrowing” in the context of subtraction, highlighting that it's more accurately described as
regrouping. My approach begins with identifying the core issue – when a digit in the subtrahend
Interpretation: This feature detects a specific lexical cluster of words commonly found in educational word problems,
technical descriptions, and illustrative examples.  It activates on a fixed set of nouns (e.g., “birds”, “eggs”, “interface”,
“tax”, “students”) and verbs (e.g., “sharing”, “handle”, “indicates”, “constitutes”) regardless of the surrounding context.
While these words frequently appear in the setup phase of reasoning tasks (e.g., a math problem about sharing), the feature
responds to the vocabulary itself rather than the syntactic structure or reasoning process.
Classification: Confound (Confidence: HIGH)
False Positives (Non-reasoning content that strongly activates the feature):

1. The main ingredient in the recipe is organic **eggs**. **She** is **sharing** the chocolate **cakes** **with** the
   family. The process involves **handling** the batter carefully. The taste **is** **tr...
2. The garden is full of wild **birds** and **flies**. The stone path is described **as** **geometric**. The broken shell
   **indicates** the presence of **eggs**. The environment **constitutes** a safe ha...
3. The new computer features a **robust** **interface**. The software is **optimizing** the processing speed. The guide
    is **about** how to **handle** errors. The screen **indicates** the system status.

False Negatives (Semantic paraphrases of high-activation samples that fail to activate):

1. To solve this efficiently, I must review the standard NLP workflow. My process starts by gathering raw data. We label
    this step Text Acquisition. Once I have the material, I usually find it disorganiz...
2.  I need to extract the key figures from the problem statement. Alex possesses 9 toys. He allocates these items to 3 siblings.
  We must note that Alex gives them away rather than keeping any. To find the...
3. To solve this, I will review the standard NLP sequence. Collecting data happens first. We label this phase Text Acquisition.
  Raw inputs often contain noise and need cleaning.





                                                45

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

H. Dataset details

This section provides detailed descriptions of the datasets used to construct reasoning and non-reasoning corpora in our
experiments (Section 5). We use two reasoning datasets with explicit chain-of-thought traces and one general-text dataset as
a non-reasoning baseline.

H.1. s1K-1.1

The s1K-1.1 dataset is a curated collection of 1,000 challenging mathematics problems, derived from the original s1K dataset
introduced by Muennighoff et al. (2025). The questions span a range of mathematical domains, including algebra, geometry,
number theory, and combinatorics, and are designed to require multi-step reasoning. In contrast to the original s1K dataset,
which contains reasoning traces generated by Gemini Thinking, s1K-1.1 augments the same set of 1,000 questions with
additional chain-of-thought traces generated by DeepSeek-R1, resulting in a mixture of Gemini- and DeepSeek-generated
solutions. We use both types of traces in our experiments.
Each example consists of a problem statement and an associated reasoning trace that decomposes the solution into explicit
intermediate steps. The traces are written in natural language and include algebraic manipulations, case analyses, and
explanatory commentary. We treat the reasoning trace as the reasoning text and exclude the final answer when constructing
inputs for feature analysis, in order to focus on intermediate reasoning behavior rather than answer tokens. For all
experiments, inputs are truncated to a maximum of 64 tokens.

H.2. General Inquiry Thinking Chain-of-Thought

To evaluate reasoning features beyond mathematics, we use the General Inquiry Thinking Chain-of-Thought dataset (Wensey,
2025). This dataset contains approximately 6,000 question-answer pairs with explicit chain-of-thought annotations. Unlike
mathematics-focused datasets, General Inquiry spans a broad range of domains, including scientific reasoning, logical
puzzles, everyday decision making, and philosophical or conceptual questions.
Each example includes a user question and a step-by-step reasoning trace that justifies the final answer. The diversity of
topics and styles reduces the risk that results are driven by domain-specific vocabulary or formatting conventions. As with
s1K-1.1, we use only the chain-of-thought portion of each example and truncate inputs to 64 tokens. For each experimental
configuration, we randomly sample 1,000 examples from the dataset to form the reasoning corpus.

H.3. Pile Uncopyrighted

As a source of non-reasoning text, we use the uncopyrighted subset of the Pile (Gao et al., 2020). The Pile is a large-scale
English text corpus constructed from 22 heterogeneous sources, including academic writing, books, reference material, and
web text. The uncopyrighted version removes all copyrighted components to support responsible use.
We randomly sample 1,000 text passages from this corpus and truncate each passage to 64 tokens. These samples are
treated as non-reasoning text and are used as the baseline distribution in contrastive feature detection (Section 4.2) and token
injection experiments (Section 4.3). While some passages may contain implicit reasoning, the dataset does not include
explicit chain-of-thought traces or structured problem-solving discourse, making it a suitable non-reasoning comparison
corpus.





                                                46

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

I. Benchmark details

This section describes the external benchmarks used to evaluate the behavioral effects of feature steering (Section 5.5).
These benchmarks are used only as supplementary evaluations and do not form the basis of our primary conclusions.

I.1. AIME 2024

We evaluate mathematical reasoning performance using problems from the American Invitational Mathematics Examination
(AIME) 2024 (Zhang & Math-AI Team, 2024). AIME is a well-established mathematics competition at the advanced high
school level, consisting of problems that require multi-step symbolic reasoning and careful algebraic manipulation. The
2024 edition includes 30 problems drawn from the AIME I and AIME II contests.
Each problem has a single integer answer, and detailed official solutions are available. In our experiments, we use the
problem statements as prompts and evaluate model outputs based on exact match with the ground-truth numerical answers.
We use one-shot chain-of-thought prompting and allow long generation lengths to avoid truncating reasoning traces.

I.2. GPQA Diamond

We also evaluate scientific reasoning using the Diamond split of the Graduate-Level Google-Proof Question Answering
benchmark (GPQA) (Rein et al., 2024). GPQA is a multiple-choice question answering dataset constructed by domain
experts in biology, physics, and chemistry. The questions are intentionally designed to be difficult for both non-experts and
state-of-the-art language models, even with access to external resources.
The Diamond split consists of the most challenging subset of questions and is commonly used as a stress test for advanced
reasoning capabilities. Expert annotators achieve substantially higher accuracy within their own domains than non-expert
validators, highlighting the depth of domain knowledge required. Due to the sensitivity of the dataset and the risk of leakage,
we do not reproduce or paraphrase individual questions in this paper.
In our steering experiments, we evaluate accuracy on the multiple-choice answers using one-shot chain-of-thought prompting.
As with AIME 2024, these results are reported as supplementary evidence and are interpreted cautiously, since performance
changes alone do not imply that a steered feature encodes a genuine reasoning mechanism.





                                                47

                            Falsifying Sparse Autoencoder Reasoning Features in Language Models

J. Licenses and responsible use

We carefully adhere to the licenses and usage terms of all datasets, models, and benchmarks used in this study. For
non-reasoning text, we use the uncopyrighted subset of the Pile dataset. The s1K-1.1 dataset and the General Inquiry
Thinking Chain-of-Thought dataset are released under the MIT license.
We evaluate open-weight language models released under permissive or research-friendly terms. The Gemma 2 and Gemma
3 models are used in accordance with the Gemma Terms of Use. The Llama 3.1 models are used under the Llama 3.1
Community License Agreement. The DeepSeek distilled models are released under the MIT license. Sparse autoencoders
from the Gemma Scope and Gemma Scope 2 releases are licensed under the Creative Commons Attribution 4.0 License,
and the Llama Scope release is licensed under the Apache License 2.0.
For evaluation benchmarks, AIME 2024 is used under the Apache License 2.0, and GPQA is released under the Creative
Commons Attribution 4.0 License.
Figure 1 incorporates icons created by karyative and Bartama Graphic from the Noun Project, licensed under the Creative
Commons Attribution 3.0 License (CC BY 3.0). The icons have been resized and stylistically adapted for consistency with
the figure design. Use of these icons complies with the license requirements, including attribution to the original creators
and indication of modifications.
All experiments are conducted for research purposes only. We do not release any new model weights or datasets, and we do
not modify or redistribute licensed resources beyond what is permitted by their respective terms. We encourage future work
building on this study to similarly respect licensing constraints and responsible research practices.





                                                48